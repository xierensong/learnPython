diff --git hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
index 759822a..3ea8b9e 100644
--- hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
+++ hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
@@ -185,6 +185,7 @@ public class HBaseAdmin implements Admin {
    *
    * @param c Configuration object. Copied internally.
    */
+  @Deprecated
   public HBaseAdmin(Configuration c)
   throws MasterNotRunningException, ZooKeeperConnectionException, IOException {
     // Will not leak connections, as the new implementation of the constructor
diff --git hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java
index 9ae00f9..cd8a541 100644
--- hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java
+++ hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java
@@ -25,7 +25,7 @@ import java.util.List;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.ClusterManager.ServiceType;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HConnection;
 import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
@@ -45,7 +45,7 @@ import com.google.common.collect.Sets;
 @InterfaceAudience.Private
 public class DistributedHBaseCluster extends HBaseCluster {
 
-  private HBaseAdmin admin;
+  private Admin admin;
 
   private ClusterManager clusterManager;
 
@@ -53,7 +53,7 @@ public class DistributedHBaseCluster extends HBaseCluster {
       throws IOException {
     super(conf);
     this.clusterManager = clusterManager;
-    this.admin = new HBaseAdmin(conf);
+    this.admin = HConnectionManager.createConnection(conf).getAdmin();
     this.initialClusterStatus = getClusterStatus();
   }
 
@@ -374,7 +374,7 @@ public class DistributedHBaseCluster extends HBaseCluster {
     } catch (IOException ioe) {
       LOG.warn("While closing the old connection", ioe);
     }
-    this.admin = new HBaseAdmin(conf);
+    this.admin = HConnectionManager.createConnection(conf).getAdmin();
     LOG.info("Added new HBaseAdmin");
     return true;
   }
diff --git hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/AddColumnAction.java hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/AddColumnAction.java
index 24c0dcb..5f65b75 100644
--- hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/AddColumnAction.java
+++ hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/AddColumnAction.java
@@ -23,7 +23,6 @@ import java.io.IOException;
 import org.apache.commons.lang.RandomStringUtils;
 import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HTableDescriptor;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.util.Bytes;
 
 /**
diff --git hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/ChangeBloomFilterAction.java hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/ChangeBloomFilterAction.java
index 3479f46..9eef3a9 100644
--- hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/ChangeBloomFilterAction.java
+++ hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/actions/ChangeBloomFilterAction.java
@@ -23,7 +23,6 @@ import java.util.Random;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
 import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HTableDescriptor;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.regionserver.BloomType;
 import org.apache.hadoop.hbase.util.Bytes;
 
diff --git hbase-it/src/test/java/org/apache/hadoop/hbase/mttr/IntegrationTestMTTR.java hbase-it/src/test/java/org/apache/hadoop/hbase/mttr/IntegrationTestMTTR.java
index 7a6b85b..c048888 100644
--- hbase-it/src/test/java/org/apache/hadoop/hbase/mttr/IntegrationTestMTTR.java
+++ hbase-it/src/test/java/org/apache/hadoop/hbase/mttr/IntegrationTestMTTR.java
@@ -48,7 +48,9 @@ import org.apache.hadoop.hbase.chaos.actions.MoveRegionsOfTableAction;
 import org.apache.hadoop.hbase.chaos.actions.RestartActiveMasterAction;
 import org.apache.hadoop.hbase.chaos.actions.RestartRsHoldingMetaAction;
 import org.apache.hadoop.hbase.chaos.actions.RestartRsHoldingTableAction;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -528,9 +530,9 @@ public class IntegrationTestMTTR {
 
     @Override
     protected boolean doAction() throws Exception {
-      HBaseAdmin admin = null;
+      Admin admin = null;
       try {
-        admin = new HBaseAdmin(util.getConfiguration());
+        admin = HConnectionManager.createConnection(util.getConfiguration()).getAdmin();
         ClusterStatus status = admin.getClusterStatus();
         return status != null;
       } finally {
diff --git hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestBigLinkedList.java hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestBigLinkedList.java
index 6244071..eabca07 100644
--- hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestBigLinkedList.java
+++ hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestBigLinkedList.java
@@ -48,8 +48,8 @@ import org.apache.hadoop.hbase.IntegrationTestBase;
 import org.apache.hadoop.hbase.IntegrationTestingUtility;
 import org.apache.hadoop.hbase.IntegrationTests;
 import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.client.HConnection;
 import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
@@ -440,7 +440,7 @@ public class IntegrationTestBigLinkedList extends IntegrationTestBase {
     }
 
     protected void createSchema() throws IOException {
-      HBaseAdmin admin = new HBaseAdmin(getConf());
+      Admin admin = HConnectionManager.createConnection(getConf()).getAdmin();
       TableName tableName = getTableName(getConf());
       if (!admin.tableExists(tableName)) {
         HTableDescriptor htd = new HTableDescriptor(getTableName(getConf()));
diff --git hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestLoadAndVerify.java hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestLoadAndVerify.java
index 0bc5e5c..548a9f6 100644
--- hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestLoadAndVerify.java
+++ hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestLoadAndVerify.java
@@ -42,7 +42,9 @@ import org.apache.hadoop.hbase.IntegrationTestBase;
 import org.apache.hadoop.hbase.IntegrationTestingUtility;
 import org.apache.hadoop.hbase.IntegrationTests;
 import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -445,7 +447,7 @@ public void cleanUpCluster() throws Exception {
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(table));
     htd.addFamily(new HColumnDescriptor(TEST_FAMILY));
 
-    HBaseAdmin admin = new HBaseAdmin(getConf());
+    Admin admin = HConnectionManager.createConnection(getConf()).getAdmin();
     if (doLoad) {
       admin.createTable(htd, Bytes.toBytes(0L), Bytes.toBytes(-1L), numPresplits);
       doLoad(getConf(), htd);
diff --git hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestWithCellVisibilityLoadAndVerify.java hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestWithCellVisibilityLoadAndVerify.java
index 52ca4c2..6532add 100644
--- hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestWithCellVisibilityLoadAndVerify.java
+++ hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestWithCellVisibilityLoadAndVerify.java
@@ -34,7 +34,9 @@ import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.IntegrationTestingUtility;
 import org.apache.hadoop.hbase.IntegrationTests;
 import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
 import org.apache.hadoop.hbase.client.Scan;
@@ -351,7 +353,7 @@ public class IntegrationTestWithCellVisibilityLoadAndVerify extends IntegrationT
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(table));
     htd.addFamily(new HColumnDescriptor(TEST_FAMILY));
 
-    HBaseAdmin admin = new HBaseAdmin(getConf());
+    Admin admin = HConnectionManager.createConnection(getConf()).getAdmin();
     try {
       admin.createTable(htd, Bytes.toBytes(0L), Bytes.toBytes(-1L), numPresplits);
     } finally {
diff --git hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/master/MasterStatusTmpl.jamon hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/master/MasterStatusTmpl.jamon
index 73e9fab..c7c0e60 100644
--- hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/master/MasterStatusTmpl.jamon
+++ hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/master/MasterStatusTmpl.jamon
@@ -18,7 +18,7 @@ limitations under the License.
 </%doc>
 <%args>
 HMaster master;
-HBaseAdmin admin;
+Admin admin;
 Map<String, Integer> frags = null;
 ServerName metaLocation = null;
 List<ServerName> servers = null;
@@ -42,7 +42,7 @@ org.apache.hadoop.hbase.HConstants;
 org.apache.hadoop.hbase.NamespaceDescriptor;
 org.apache.hadoop.hbase.ServerLoad;
 org.apache.hadoop.hbase.ServerName;
-org.apache.hadoop.hbase.client.HBaseAdmin;
+org.apache.hadoop.hbase.client.Admin;
 org.apache.hadoop.hbase.client.HConnectionManager;
 org.apache.hadoop.hbase.HTableDescriptor;
 org.apache.hadoop.hbase.HBaseConfiguration;
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/LocalHBaseCluster.java hbase-server/src/main/java/org/apache/hadoop/hbase/LocalHBaseCluster.java
index 8550367..bc81f59 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/LocalHBaseCluster.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/LocalHBaseCluster.java
@@ -29,12 +29,12 @@ import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
 import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.consensus.ConsensusProvider;
 import org.apache.hadoop.hbase.consensus.ConsensusProviderFactory;
 import org.apache.hadoop.hbase.regionserver.HRegionServer;
 import org.apache.hadoop.hbase.security.User;
-import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.JVMClusterUtil.RegionServerThread;
 import org.apache.hadoop.hbase.util.Threads;
 
@@ -455,7 +455,7 @@ public class LocalHBaseCluster {
     Configuration conf = HBaseConfiguration.create();
     LocalHBaseCluster cluster = new LocalHBaseCluster(conf);
     cluster.startup();
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
     HTableDescriptor htd =
       new HTableDescriptor(TableName.valueOf(cluster.getClass().getName()));
     admin.createTable(htd);
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/Import.java hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/Import.java
index 29760af..e25a07e 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/Import.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/Import.java
@@ -40,9 +40,10 @@ import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.KeyValueUtil;
 import org.apache.hadoop.hbase.ZooKeeperConnectionException;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Durability;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Mutation;
 import org.apache.hadoop.hbase.client.Put;
@@ -466,13 +467,13 @@ public class Import {
   public static void flushRegionsIfNecessary(Configuration conf) throws IOException,
       InterruptedException {
     String tableName = conf.get(TABLE_NAME);
-    HBaseAdmin hAdmin = null;
+    Admin hAdmin = null;
     String durability = conf.get(WAL_DURABILITY);
     // Need to flush if the data is written to hbase and skip wal is enabled.
     if (conf.get(BULK_OUTPUT_CONF_KEY) == null && durability != null
         && Durability.SKIP_WAL.name().equalsIgnoreCase(durability)) {
       try {
-        hAdmin = new HBaseAdmin(conf);
+        hAdmin = HConnectionManager.createConnection(conf).getAdmin();
         hAdmin.flush(tableName);
       } finally {
         if (hAdmin != null) {
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java
index e4887fe..c372736 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java
@@ -37,7 +37,8 @@ import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
@@ -393,7 +394,7 @@ public class ImportTsv extends Configured implements Tool {
   public static Job createSubmittableJob(Configuration conf, String[] args)
       throws IOException, ClassNotFoundException {
 
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
 
     // Support non-XML supported characters
     // by re-encoding the passed separator as a Base64 string.
@@ -420,7 +421,7 @@ public class ImportTsv extends Configured implements Tool {
     String hfileOutPath = conf.get(BULK_OUTPUT_CONF_KEY);
     String columns[] = conf.getStrings(COLUMNS_CONF_KEY);
     if (hfileOutPath != null) {
-      if (!admin.tableExists(tableName)) {
+      if (!admin.tableExists(TableName.valueOf(tableName))) {
         LOG.warn(format("Table '%s' does not exist.", tableName));
         // TODO: this is backwards. Instead of depending on the existence of a table,
         // create a sane splits file for HFileOutputFormat based on data sampling.
@@ -459,7 +460,7 @@ public class ImportTsv extends Configured implements Tool {
     return job;
   }
 
-  private static void createTable(HBaseAdmin admin, String tableName, String[] columns)
+  private static void createTable(Admin admin, String tableName, String[] columns)
       throws IOException {
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(tableName));
     Set<String> cfSet = new HashSet<String>();
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java
index aabac3f..be3df79 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java
@@ -62,8 +62,9 @@ import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.KeyValueUtil;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.TableNotFoundException;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HConnection;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.RegionServerCallable;
 import org.apache.hadoop.hbase.client.RpcRetryingCallerFactory;
@@ -104,7 +105,7 @@ import com.google.common.util.concurrent.ThreadFactoryBuilder;
 public class LoadIncrementalHFiles extends Configured implements Tool {
   private static final Log LOG = LogFactory.getLog(LoadIncrementalHFiles.class);
   static final AtomicLong regionCount = new AtomicLong(0);
-  private HBaseAdmin hbAdmin;
+  private Admin hbAdmin;
 
   public static final String NAME = "completebulkload";
   public static final String MAX_FILES_PER_REGION_PER_FAMILY
@@ -127,7 +128,7 @@ public class LoadIncrementalHFiles extends Configured implements Tool {
     setConf(HBaseConfiguration.create(getConf()));
     // disable blockcache for tool invocation, see HBASE-10500
     getConf().setFloat(HConstants.HFILE_BLOCK_CACHE_SIZE_KEY, 0);
-    this.hbAdmin = new HBaseAdmin(conf);
+    this.hbAdmin = HConnectionManager.createConnection(conf).getAdmin();
     this.userProvider = UserProvider.instantiate(conf);
     this.fsDelegationToken = new FsDelegationToken(userProvider, "renewer");
     assignSeqIds = conf.getBoolean(ASSIGN_SEQ_IDS, true);
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMasterCommandLine.java hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMasterCommandLine.java
index 587459c..f869abf 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMasterCommandLine.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMasterCommandLine.java
@@ -35,7 +35,8 @@ import org.apache.hadoop.hbase.ZNodeClearer;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.LocalHBaseCluster;
 import org.apache.hadoop.hbase.ZooKeeperConnectionException;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.consensus.ConsensusProvider;
 import org.apache.hadoop.hbase.regionserver.HRegionServer;
 import org.apache.hadoop.hbase.util.JVMClusterUtil;
@@ -204,12 +205,12 @@ public class HMasterCommandLine extends ServerCommandLine {
   }
 
   private int stopMaster() {
-    HBaseAdmin adm = null;
+    Admin adm = null;
     try {
       Configuration conf = getConf();
       // Don't try more than once
       conf.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 1);
-      adm = new HBaseAdmin(getConf());
+      adm = HConnectionManager.createConnection(getConf()).getAdmin();
     } catch (MasterNotRunningException e) {
       LOG.error("Master not running");
       return 1;
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterStatusServlet.java hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterStatusServlet.java
index 7a27489..892fc89 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterStatusServlet.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterStatusServlet.java
@@ -32,7 +32,8 @@ import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.ServerName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.tmpl.master.MasterStatusTmpl;
 import org.apache.hadoop.hbase.util.FSUtils;
 
@@ -55,7 +56,7 @@ public class MasterStatusServlet extends HttpServlet {
     response.setContentType("text/html");
 
     Configuration conf = master.getConfiguration();
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
 
     Map<String, Integer> frags = getFragmentationInfo(master, conf);
     ServerName metaLocation = null;
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java
index 848ce7a..790daca 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java
@@ -48,8 +48,9 @@ import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.catalog.CatalogTracker;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HConnection;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper;
 import org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan;
 import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
@@ -92,7 +93,7 @@ public class RegionPlacementMaintainer {
   private Configuration conf;
   private final boolean enforceLocality;
   private final boolean enforceMinAssignmentMove;
-  private HBaseAdmin admin;
+  private Admin admin;
   private RackManager rackManager;
   private Set<TableName> targetTableSet;
 
@@ -127,9 +128,9 @@ public class RegionPlacementMaintainer {
    * @return the cached HBaseAdmin
    * @throws IOException
    */
-  private HBaseAdmin getHBaseAdmin() throws IOException {
+  private synchronized Admin getAdmin() throws IOException {
     if (this.admin == null) {
-      this.admin = new HBaseAdmin(this.conf);
+      this.admin = HConnectionManager.createConnection(this.conf).getAdmin();
     }
     return this.admin;
   }
@@ -209,7 +210,7 @@ public class RegionPlacementMaintainer {
 
       // Get the all the region servers
       List<ServerName> servers = new ArrayList<ServerName>();
-      servers.addAll(getHBaseAdmin().getClusterStatus().getServers());
+      servers.addAll(getAdmin().getClusterStatus().getServers());
       
       LOG.info("Start to generate assignment plan for " + numRegions +
           " regions from table " + tableName + " with " +
@@ -659,7 +660,7 @@ public class RegionPlacementMaintainer {
     // Get the region to region server map
     Map<ServerName, List<HRegionInfo>> currentAssignment =
       this.getRegionAssignmentSnapshot().getRegionServerToRegionMap();
-    HConnection connection = this.getHBaseAdmin().getConnection();
+    HConnection connection = this.getAdmin().getConnection();
 
     // track of the failed and succeeded updates
     int succeededNum = 0;
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/rest/RESTServlet.java hbase-server/src/main/java/org/apache/hadoop/hbase/rest/RESTServlet.java
index c265e40..5a801c6 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/rest/RESTServlet.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/rest/RESTServlet.java
@@ -27,7 +27,7 @@ import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.Chore;
 import org.apache.hadoop.hbase.Stoppable;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HConnection;
 import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTableInterface;
@@ -76,7 +76,7 @@ public class RESTServlet implements Constants {
     final HConnection connection;
     final String userName;
 
-    volatile HBaseAdmin admin;
+    volatile Admin admin;
     private long lastAccessTime;
     private boolean closed;
 
@@ -192,13 +192,13 @@ public class RESTServlet implements Constants {
    * Caller doesn't close the admin afterwards.
    * We need to manage it and close it properly.
    */
-  HBaseAdmin getAdmin() throws IOException {
+  Admin getAdmin() throws IOException {
     ConnectionInfo connInfo = getCurrentConnection();
     if (connInfo.admin == null) {
       Lock lock = locker.acquireLock(effectiveUser.get().getUserName());
       try {
         if (connInfo.admin == null) {
-          connInfo.admin = new HBaseAdmin(connInfo.connection);
+          connInfo.admin = connInfo.connection.getAdmin();
         }
       } finally {
         lock.unlock();
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java hbase-server/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java
index ae03651..e538fd7 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java
@@ -43,7 +43,7 @@ import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.TableExistsException;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.TableNotFoundException;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HTableInterface;
 import org.apache.hadoop.hbase.rest.model.ColumnSchemaModel;
 import org.apache.hadoop.hbase.rest.model.TableSchemaModel;
@@ -102,15 +102,15 @@ public class SchemaResource extends ResourceBase {
     } 
   }
 
-  private Response replace(final byte[] name, final TableSchemaModel model,
-      final UriInfo uriInfo, final HBaseAdmin admin) {
+  private Response replace(TableName name, final TableSchemaModel model,
+      final UriInfo uriInfo, final Admin admin) {
     if (servlet.isReadOnly()) {
       return Response.status(Response.Status.FORBIDDEN)
         .type(MIMETYPE_TEXT).entity("Forbidden" + CRLF)
         .build();
     }
     try {
-      HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(name));
+      HTableDescriptor htd = new HTableDescriptor(name);
       for (Map.Entry<QName,Object> e: model.getAny().entrySet()) {
         htd.setValue(e.getKey().getLocalPart(), e.getValue().toString());
       }
@@ -142,8 +142,8 @@ public class SchemaResource extends ResourceBase {
     }
   }
 
-  private Response update(final byte[] name, final TableSchemaModel model,
-      final UriInfo uriInfo, final HBaseAdmin admin) {
+  private Response update(TableName name, final TableSchemaModel model,
+      final UriInfo uriInfo, final Admin admin) {
     if (servlet.isReadOnly()) {
       return Response.status(Response.Status.FORBIDDEN)
         .type(MIMETYPE_TEXT).entity("Forbidden" + CRLF)
@@ -169,7 +169,7 @@ public class SchemaResource extends ResourceBase {
           .type(MIMETYPE_TEXT).entity("Unavailable" + CRLF)
           .build();
       } finally {
-        admin.enableTable(tableResource.getName());
+        admin.enableTable(TableName.valueOf(tableResource.getName()));
       }
       servlet.getMetrics().incrementSucessfulPutRequests(1);
       return Response.ok().build();
@@ -182,8 +182,8 @@ public class SchemaResource extends ResourceBase {
   private Response update(final TableSchemaModel model, final boolean replace,
       final UriInfo uriInfo) {
     try {
-      byte[] name = Bytes.toBytes(tableResource.getName());
-      HBaseAdmin admin = servlet.getAdmin();
+      TableName name = TableName.valueOf(tableResource.getName());
+      Admin admin = servlet.getAdmin();
       if (replace || !admin.tableExists(name)) {
         return replace(name, model, uriInfo, admin);
       } else {
@@ -230,10 +230,10 @@ public class SchemaResource extends ResourceBase {
           .entity("Forbidden" + CRLF).build();
     }
     try {
-      HBaseAdmin admin = servlet.getAdmin();
+      Admin admin = servlet.getAdmin();
       boolean success = false;
       for (int i = 0; i < 10; i++) try {
-        admin.disableTable(tableResource.getName());
+        admin.disableTable(TableName.valueOf(tableResource.getName()));
         success = true;
         break;
       } catch (IOException e) {
@@ -241,7 +241,7 @@ public class SchemaResource extends ResourceBase {
       if (!success) {
         throw new IOException("could not disable table");
       }
-      admin.deleteTable(tableResource.getName());
+      admin.deleteTable(TableName.valueOf(tableResource.getName()));
       servlet.getMetrics().incrementSucessfulDeleteRequests(1);
       return Response.ok().build();
     } catch (Exception e) {
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java hbase-server/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java
index 963e900..65879c6 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java
@@ -35,6 +35,7 @@ import org.apache.commons.lang.StringUtils;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
+import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.client.HTableInterface;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.filter.Filter;
@@ -44,7 +45,7 @@ import org.apache.hadoop.hbase.util.Bytes;
 @InterfaceAudience.Private
 public class TableResource extends ResourceBase {
 
-  String table;
+  TableName table;
   private static final Log LOG = LogFactory.getLog(TableResource.class);
 
   /**
@@ -54,12 +55,12 @@ public class TableResource extends ResourceBase {
    */
   public TableResource(String table) throws IOException {
     super();
-    this.table = table;
+    this.table = TableName.valueOf(table);
   }
 
   /** @return the table name */
   String getName() {
-    return table;
+    return table.getNameAsString();
   }
 
   /**
@@ -141,7 +142,7 @@ public class TableResource extends ResourceBase {
           + " End Row => " + endRow + " Columns => " + column + " Start Time => " + startTime
           + " End Time => " + endTime + " Cache Blocks => " + cacheBlocks + " Max Versions => "
           + maxVersions + " Batch Size => " + batchSize);
-      HTableInterface hTable = RESTServlet.getInstance().getTable(this.table);
+      HTableInterface hTable = RESTServlet.getInstance().getTable(this.table.getNameAsString());
       Scan tableScan = new Scan();
       tableScan.setBatch(batchSize);
       tableScan.setMaxVersions(maxVersions);
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java
index 2667eaa..1d16996 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java
@@ -43,8 +43,9 @@ import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.TableNotEnabledException;
 import org.apache.hadoop.hbase.TableNotFoundException;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.ResultScanner;
 import org.apache.hadoop.hbase.client.Scan;
@@ -325,7 +326,7 @@ public final class Canary implements Tool {
   public static abstract class Monitor implements Runnable {
 
     protected Configuration config;
-    protected HBaseAdmin admin;
+    protected Admin admin;
     protected String[] targets;
     protected boolean useRegExp;
     protected boolean initialized = false;
@@ -358,7 +359,7 @@ public final class Canary implements Tool {
     protected boolean initAdmin() {
       if (null == this.admin) {
         try {
-          this.admin = new HBaseAdmin(config);
+          this.admin = HConnectionManager.createConnection(config).getAdmin();
         } catch (Exception e) {
           LOG.error("Initial HBaseAdmin failed...", e);
           this.errorCode = INIT_ERROR_EXIT_CODE;
@@ -387,7 +388,7 @@ public final class Canary implements Tool {
             String[] tables = generateMonitorTables(this.targets);
             this.initialized = true;
             for (String table : tables) {
-              Canary.sniff(admin, sink, table);
+              Canary.sniff(admin, sink, TableName.valueOf(table));
             }
           } else {
             sniff();
@@ -453,18 +454,18 @@ public final class Canary implements Tool {
    * Canary entry point for specified table.
    * @throws Exception
    */
-  public static void sniff(final HBaseAdmin admin, TableName tableName) throws Exception {
-    sniff(admin, new StdOutSink(), tableName.getNameAsString());
+  public static void sniff(final Admin admin, TableName tableName) throws Exception {
+    sniff(admin, new StdOutSink(), tableName);
   }
 
   /**
    * Canary entry point for specified table.
    * @throws Exception
    */
-  private static void sniff(final HBaseAdmin admin, final Sink sink, String tableName)
+  private static void sniff(final Admin admin, final Sink sink, TableName tableName)
       throws Exception {
     if (admin.isTableAvailable(tableName)) {
-      sniff(admin, sink, admin.getTableDescriptor(tableName.getBytes()));
+      sniff(admin, sink, admin.getTableDescriptor(tableName));
     } else {
       LOG.warn(String.format("Table %s is not available", tableName));
     }
@@ -473,7 +474,7 @@ public final class Canary implements Tool {
   /*
    * Loops over regions that owns this table, and output some information abouts the state.
    */
-  private static void sniff(final HBaseAdmin admin, final Sink sink, HTableDescriptor tableDesc)
+  private static void sniff(final Admin admin, final Sink sink, HTableDescriptor tableDesc)
       throws Exception {
     HTable table = null;
 
@@ -484,7 +485,7 @@ public final class Canary implements Tool {
     }
 
     try {
-      for (HRegionInfo region : admin.getTableRegions(tableDesc.getName())) {
+      for (HRegionInfo region : admin.getTableRegions(tableDesc.getTableName())) {
         try {
           sniffRegion(admin, sink, region, table);
         } catch (Exception e) {
@@ -502,7 +503,7 @@ public final class Canary implements Tool {
    * failure.
    */
   private static void sniffRegion(
-      final HBaseAdmin admin,
+      final Admin admin,
       final Sink sink,
       HRegionInfo region,
       HTable table) throws Exception {
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java
index 1fcbc5c..5d15486 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java
@@ -72,9 +72,9 @@ import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.ZooKeeperConnectionException;
 import org.apache.hadoop.hbase.catalog.MetaEditor;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.client.HConnectable;
 import org.apache.hadoop.hbase.client.HConnection;
 import org.apache.hadoop.hbase.client.HConnectionManager;
@@ -182,7 +182,7 @@ public class HBaseFsck extends Configured {
   private static final Log LOG = LogFactory.getLog(HBaseFsck.class.getName());
   private ClusterStatus status;
   private HConnection connection;
-  private HBaseAdmin admin;
+  private Admin admin;
   private HTable meta;
   // threads to do ||izable tasks: retrieve data from regionservers, handle overlapping regions
   protected ExecutorService executor;
@@ -303,7 +303,7 @@ public class HBaseFsck extends Configured {
    */
   public void connect() throws IOException {
     connection = HConnectionManager.createConnection(getConf());
-    admin = new HBaseAdmin(connection);
+    admin = connection.getAdmin();
     meta = new HTable(TableName.META_TABLE_NAME, connection);
     status = admin.getClusterStatus();
   }
@@ -2722,10 +2722,10 @@ public class HBaseFsck extends Configured {
 
   HTableDescriptor[] getHTableDescriptors(List<TableName> tableNames) {
     HTableDescriptor[] htd = new HTableDescriptor[0];
-    HBaseAdmin admin = null;
+    Admin admin = null;
     try {
       LOG.info("getHTableDescriptors == tableNames => " + tableNames);
-      admin = new HBaseAdmin(getConf());
+      admin = HConnectionManager.createConnection(getConf()).getAdmin();
       htd = admin.getTableDescriptorsByTableName(tableNames);
     } catch (IOException e) {
       LOG.debug("Exception getting table descriptors", e);
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsckRepair.java hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsckRepair.java
index d985299..0945681 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsckRepair.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsckRepair.java
@@ -33,7 +33,7 @@ import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.ZooKeeperConnectionException;
 import org.apache.hadoop.hbase.catalog.MetaEditor;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HConnection;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.master.RegionState;
@@ -59,7 +59,7 @@ public class HBaseFsckRepair {
    * @param region Region to undeploy
    * @param servers list of Servers to undeploy from
    */
-  public static void fixMultiAssignment(HBaseAdmin admin, HRegionInfo region,
+  public static void fixMultiAssignment(Admin admin, HRegionInfo region,
       List<ServerName> servers)
   throws IOException, KeeperException, InterruptedException {
     HRegionInfo actualRegion = new HRegionInfo(region);
@@ -85,7 +85,7 @@ public class HBaseFsckRepair {
    * @throws IOException
    * @throws KeeperException
    */
-  public static void fixUnassigned(HBaseAdmin admin, HRegionInfo region)
+  public static void fixUnassigned(Admin admin, HRegionInfo region)
       throws IOException, KeeperException {
     HRegionInfo actualRegion = new HRegionInfo(region);
 
@@ -105,7 +105,7 @@ public class HBaseFsckRepair {
    * side-effect of requiring a HRegionInfo that considers regionId (timestamp)
    * in comparators that is addressed by HBASE-5563.
    */
-  private static void forceOfflineInZK(HBaseAdmin admin, final HRegionInfo region)
+  private static void forceOfflineInZK(Admin admin, final HRegionInfo region)
   throws ZooKeeperConnectionException, KeeperException, IOException {
     admin.assign(region.getRegionName());
   }
@@ -113,7 +113,7 @@ public class HBaseFsckRepair {
   /*
    * Should we check all assignments or just not in RIT?
    */
-  public static void waitUntilAssigned(HBaseAdmin admin,
+  public static void waitUntilAssigned(Admin admin,
       HRegionInfo region) throws IOException, InterruptedException {
     long timeout = admin.getConfiguration().getLong("hbase.hbck.assign.timeout", 120000);
     long expiration = timeout + System.currentTimeMillis();
@@ -143,7 +143,7 @@ public class HBaseFsckRepair {
    * Contacts a region server and waits up to hbase.hbck.close.timeout ms
    * (default 120s) to close the region.  This bypasses the active hmaster.
    */
-  public static void closeRegionSilentlyAndWait(HBaseAdmin admin,
+  public static void closeRegionSilentlyAndWait(Admin admin,
       ServerName server, HRegionInfo region) throws IOException, InterruptedException {
     HConnection connection = admin.getConnection();
     AdminService.BlockingInterface rs = connection.getAdmin(server);
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/util/HMerge.java hbase-server/src/main/java/org/apache/hadoop/hbase/util/HMerge.java
index 80bf475..2066969 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/util/HMerge.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/util/HMerge.java
@@ -37,8 +37,8 @@ import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.RemoteExceptionHandler;
 import org.apache.hadoop.hbase.TableNotDisabledException;
 import org.apache.hadoop.hbase.catalog.MetaEditor;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.client.HConnectable;
 import org.apache.hadoop.hbase.client.HConnection;
 import org.apache.hadoop.hbase.client.HConnectionManager;
@@ -124,7 +124,7 @@ class HMerge {
         throw new IllegalStateException(
             "HBase instance must be running to merge a normal table");
       }
-      HBaseAdmin admin = new HBaseAdmin(conf);
+      Admin admin = HConnectionManager.createConnection(conf).getAdmin();
       try {
         if (!admin.isTableDisabled(tableName)) {
           throw new TableNotDisabledException(tableName);
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSizeCalculator.java hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSizeCalculator.java
index fa5500b..22bf3ff 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSizeCalculator.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSizeCalculator.java
@@ -27,7 +27,8 @@ import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.RegionLoad;
 import org.apache.hadoop.hbase.ServerLoad;
 import org.apache.hadoop.hbase.ServerName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 
 import java.io.IOException;
@@ -61,11 +62,11 @@ public class RegionSizeCalculator {
    * Computes size of each region for table and given column families.
    * */
   public RegionSizeCalculator(HTable table) throws IOException {
-    this(table, new HBaseAdmin(table.getConfiguration()));
+    this(table, HConnectionManager.createConnection(table.getConfiguration()).getAdmin());
   }
 
   /** ctor for unit testing */
-  RegionSizeCalculator (HTable table, HBaseAdmin admin) throws IOException {
+  RegionSizeCalculator (HTable table, Admin admin) throws IOException {
 
     try {
       if (!enabled(table.getConfiguration())) {
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java
index 7ed1530..a4bb86f 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java
@@ -53,7 +53,8 @@ import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.catalog.MetaReader;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.NoServerForRegionException;
 import org.apache.hadoop.hbase.regionserver.HRegionFileSystem;
@@ -378,8 +379,8 @@ public class RegionSplitter {
     for (String cf : columnFamilies) {
       desc.addFamily(new HColumnDescriptor(Bytes.toBytes(cf)));
     }
-    HBaseAdmin admin = new HBaseAdmin(conf);
-    Preconditions.checkArgument(!admin.tableExists(tableName),
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
+    Preconditions.checkArgument(!admin.tableExists(TableName.valueOf(tableName)),
         "Table already exists: " + tableName);
     admin.createTable(desc, splitAlgo.split(splitCount));
     admin.close();
@@ -528,7 +529,7 @@ public class RegionSplitter {
           // we have a good region, time to split!
           byte[] split = dr.getSecond();
           LOG.debug("Splitting at " + splitAlgo.rowToStr(split));
-          HBaseAdmin admin = new HBaseAdmin(table.getConfiguration());
+          Admin admin = HConnectionManager.createConnection(table.getConfiguration()).getAdmin();
           admin.split(table.getTableName(), split);
 
           LinkedList<Pair<byte[], byte[]>> finished = Lists.newLinkedList();
diff --git hbase-server/src/main/resources/hbase-webapps/master/snapshot.jsp hbase-server/src/main/resources/hbase-webapps/master/snapshot.jsp
index be9c750..e7096c1 100644
--- hbase-server/src/main/resources/hbase-webapps/master/snapshot.jsp
+++ hbase-server/src/main/resources/hbase-webapps/master/snapshot.jsp
@@ -20,7 +20,7 @@
 <%@ page contentType="text/html;charset=UTF-8"
   import="java.util.Date"
   import="org.apache.hadoop.conf.Configuration"
-  import="org.apache.hadoop.hbase.client.HBaseAdmin"
+  import="org.apache.hadoop.hbase.client.Admin"
   import="org.apache.hadoop.hbase.client.HConnectionManager"
   import="org.apache.hadoop.hbase.master.HMaster"
   import="org.apache.hadoop.hbase.snapshot.SnapshotInfo"
@@ -31,7 +31,7 @@
 <%
   HMaster master = (HMaster)getServletContext().getAttribute(HMaster.MASTER);
   Configuration conf = master.getConfiguration();
-  HBaseAdmin hbadmin = new HBaseAdmin(conf);
+  Admin hbadmin = HConnectionManager.createConnection(conf).getAdmin();
   boolean readOnly = conf.getBoolean("hbase.master.ui.readonly", false);
   String snapshotName = request.getParameter("name");
   SnapshotDescription snapshot = null;
@@ -117,7 +117,7 @@
     %> Restore Snapshot request accepted. <%
   } else if (action.equals("clone")) {
     if (cloneName != null && cloneName.length() > 0) {
-      hbadmin.cloneSnapshot(snapshotName, cloneName);
+      hbadmin.cloneSnapshot(snapshotName, TableName.valueOf(cloneName));
       %> Clone from Snapshot request accepted. <%
     } else {
       %> Clone from Snapshot request failed, No table name specified. <%
diff --git hbase-server/src/main/resources/hbase-webapps/master/table.jsp hbase-server/src/main/resources/hbase-webapps/master/table.jsp
index 8df53cb..8a61408 100644
--- hbase-server/src/main/resources/hbase-webapps/master/table.jsp
+++ hbase-server/src/main/resources/hbase-webapps/master/table.jsp
@@ -23,7 +23,7 @@
   import="java.util.Map"
   import="org.apache.hadoop.conf.Configuration"
   import="org.apache.hadoop.hbase.client.HTable"
-  import="org.apache.hadoop.hbase.client.HBaseAdmin"
+  import="org.apache.hadoop.hbase.client.Admin"
   import="org.apache.hadoop.hbase.client.HConnectionManager"
   import="org.apache.hadoop.hbase.HRegionInfo"
   import="org.apache.hadoop.hbase.ServerName"
@@ -39,7 +39,7 @@
 <%
   HMaster master = (HMaster)getServletContext().getAttribute(HMaster.MASTER);
   Configuration conf = master.getConfiguration();
-  HBaseAdmin hbadmin = new HBaseAdmin(conf);
+  Admin hbadmin = HConnectionManager.createConnection(conf).getAdmin();
   String fqtn = request.getParameter("name");
   HTable table = new HTable(conf, fqtn);
   String tableHeader = "<h2>Table Regions</h2><table class=\"table table-striped\"><tr><th>Name</th><th>Region Server</th><th>Start Key</th><th>End Key</th><th>Requests</th></tr>";
@@ -219,7 +219,7 @@
   </tr>
   <tr>
       <td>Enabled</td>
-      <td><%= hbadmin.isTableEnabled(table.getTableName()) %></td>
+      <td><%= hbadmin.isTableEnabled(table.getName()) %></td>
       <td>Is the table enabled</td>
   </tr>
   <tr>
diff --git hbase-server/src/main/resources/hbase-webapps/master/tablesDetailed.jsp hbase-server/src/main/resources/hbase-webapps/master/tablesDetailed.jsp
index e586322..abb68f8 100644
--- hbase-server/src/main/resources/hbase-webapps/master/tablesDetailed.jsp
+++ hbase-server/src/main/resources/hbase-webapps/master/tablesDetailed.jsp
@@ -21,9 +21,10 @@
   import="static org.apache.commons.lang.StringEscapeUtils.escapeXml"
   import="org.apache.hadoop.conf.Configuration"
   import="org.apache.hadoop.hbase.master.HMaster"
-  import="org.apache.hadoop.hbase.client.HBaseAdmin"
+  import="org.apache.hadoop.hbase.client.Admin"
   import="org.apache.hadoop.hbase.HTableDescriptor"
   import="org.apache.hadoop.hbase.HBaseConfiguration" %>
+<%@ page import="org.apache.hadoop.hbase.client.HConnectionManager" %>
 <%
   HMaster master = (HMaster)getServletContext().getAttribute(HMaster.MASTER);
   Configuration conf = master.getConfiguration();
@@ -81,7 +82,7 @@
         </div>
     </div>
 
-<% HTableDescriptor[] tables = new HBaseAdmin(conf).listTables();
+<% HTableDescriptor[] tables = HConnectionManager.createConnection(conf).listTables();
    if(tables != null && tables.length > 0) { %>
 <table class="table table-striped">
 <tr>
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
index 12c86bf..23850ab 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
@@ -55,11 +55,13 @@ import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.Waiter.Predicate;
 import org.apache.hadoop.hbase.catalog.MetaEditor;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Durability;
 import org.apache.hadoop.hbase.client.Get;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.client.HConnection;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -2601,10 +2603,10 @@ public class HBaseTestingUtility extends HBaseCommonTestingUtility {
     waitTableAvailable(getHBaseAdmin(), table, timeoutMillis);
   }
 
-  public void waitTableAvailable(HBaseAdmin admin, byte[] table, long timeoutMillis)
-  throws InterruptedException, IOException {
+  public void waitTableAvailable(Admin admin, byte[] table, long timeoutMillis)
+      throws InterruptedException, IOException {
     long startWait = System.currentTimeMillis();
-    while (!admin.isTableAvailable(table)) {
+    while (!admin.isTableAvailable(TableName.valueOf(table))) {
       assertTrue("Timed out waiting for table to become available " +
         Bytes.toStringBinary(table),
         System.currentTimeMillis() - startWait < timeoutMillis);
@@ -2626,7 +2628,7 @@ public class HBaseTestingUtility extends HBaseCommonTestingUtility {
     waitTableEnabled(getHBaseAdmin(), table, 30000);
   }
 
-  public void waitTableEnabled(HBaseAdmin admin, byte[] table)
+  public void waitTableEnabled(Admin admin, byte[] table)
       throws InterruptedException, IOException {
     waitTableEnabled(admin, table, 30000);
   }
@@ -2645,12 +2647,12 @@ public class HBaseTestingUtility extends HBaseCommonTestingUtility {
     waitTableEnabled(getHBaseAdmin(), table, timeoutMillis);
   }
 
-  public void waitTableEnabled(HBaseAdmin admin, byte[] table, long timeoutMillis)
+  public void waitTableEnabled(Admin admin, byte[] table, long timeoutMillis)
   throws InterruptedException, IOException {
     long startWait = System.currentTimeMillis();
     waitTableAvailable(admin, table, timeoutMillis);
     long remainder = System.currentTimeMillis() - startWait;
-    while (!admin.isTableEnabled(table)) {
+    while (!admin.isTableEnabled(TableName.valueOf(table))) {
       assertTrue("Timed out waiting for table to become available and enabled " +
          Bytes.toStringBinary(table),
          System.currentTimeMillis() - remainder < timeoutMillis);
@@ -3186,7 +3188,7 @@ public class HBaseTestingUtility extends HBaseCommonTestingUtility {
     }
 
     int totalNumberOfRegions = 0;
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
     try {
       // create a table a pre-splits regions.
       // The number of splits is set as:
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java
index f8cf627..22e5d53 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/PerformanceEvaluation.java
@@ -45,6 +45,7 @@ import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.conf.Configured;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Durability;
 import org.apache.hadoop.hbase.client.Get;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
@@ -255,7 +256,7 @@ public class PerformanceEvaluation extends Configured implements Tool {
    * @return True if we created the table.
    * @throws IOException
    */
-  private static boolean checkTable(HBaseAdmin admin, TestOptions opts) throws IOException {
+  private static boolean checkTable(Admin admin, TestOptions opts) throws IOException {
     HTableDescriptor tableDescriptor = getTableDescriptor(opts);
     if (opts.presplitRegions > 0) {
       // presplit requested
@@ -1065,9 +1066,9 @@ public class PerformanceEvaluation extends Configured implements Tool {
 
   private void runTest(final Class<? extends Test> cmd, TestOptions opts) throws IOException,
       InterruptedException, ClassNotFoundException {
-    HBaseAdmin admin = null;
+    Admin admin = null;
     try {
-      admin = new HBaseAdmin(getConf());
+      admin = HConnectionManager.createConnection(getConf()).getAdmin();
       checkTable(admin, opts);
     } finally {
       if (admin != null) admin.close();
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java hbase-server/src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java
index d73dd38..b381d32 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java
@@ -28,8 +28,9 @@ import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.MultithreadedTestUtil.RepeatingTestThread;
 import org.apache.hadoop.hbase.MultithreadedTestUtil.TestContext;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -271,7 +272,7 @@ public class TestAcidGuarantees implements Tool {
     }
     // Add a flusher
     ctx.addThread(new RepeatingTestThread(ctx) {
-      HBaseAdmin admin = new HBaseAdmin(util.getConfiguration());
+      Admin admin = HConnectionManager.createConnection(util.getConfiguration()).getAdmin();
       public void doAnAction() throws Exception {
         try {
           admin.flush(TABLE_NAME);
@@ -356,7 +357,7 @@ public class TestAcidGuarantees implements Tool {
 
   ////////////////////////////////////////////////////////////////////////////
   // Tool interface
-  ////////////////////////////////////////////////////////////////////////////
+  ////////////////////////////////////////////////////////////////////cd////////
   @Override
   public Configuration getConf() {
     return conf;
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java
index 6e74214..66ff937 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java
@@ -31,7 +31,8 @@ import org.apache.commons.logging.impl.Log4JLogger;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy;
 import org.apache.hadoop.hbase.regionserver.HRegion;
@@ -235,10 +236,10 @@ public class TestIOFencing {
     LOG.info("Starting mini cluster");
     TEST_UTIL.startMiniCluster(1);
     CompactionBlockerRegion compactingRegion = null;
-    HBaseAdmin admin = null;
+    Admin admin = null;
     try {
       LOG.info("Creating admin");
-      admin = new HBaseAdmin(c);
+      admin = HConnectionManager.createConnection(c).getAdmin();
       LOG.info("Creating table");
       TEST_UTIL.createTable(TABLE_NAME, FAMILY);
       HTable table = new HTable(c, TABLE_NAME);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/TestMultiVersions.java hbase-server/src/test/java/org/apache/hadoop/hbase/TestMultiVersions.java
index 5f45be3..89b38a0 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/TestMultiVersions.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/TestMultiVersions.java
@@ -33,8 +33,9 @@ import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.HBaseTestCase.FlushCache;
 import org.apache.hadoop.hbase.HBaseTestCase.HTableIncommon;
 import org.apache.hadoop.hbase.HBaseTestCase.Incommon;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -56,7 +57,7 @@ import org.junit.experimental.categories.Category;
 public class TestMultiVersions {
   private static final Log LOG = LogFactory.getLog(TestMultiVersions.class);
   private static final HBaseTestingUtility UTIL = new HBaseTestingUtility();
-  private HBaseAdmin admin;
+  private Admin admin;
   
   private static final int NUM_SLAVES = 3;
 
@@ -73,7 +74,7 @@ public class TestMultiVersions {
   @Before
   public void before()
   throws MasterNotRunningException, ZooKeeperConnectionException, IOException {
-    this.admin = new HBaseAdmin(UTIL.getConfiguration());
+    this.admin = HConnectionManager.createConnection(UTIL.getConfiguration()).getAdmin();
   }
 
   @After
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/TestRegionRebalancing.java hbase-server/src/test/java/org/apache/hadoop/hbase/TestRegionRebalancing.java
index 0b0e290..1020fb5 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/TestRegionRebalancing.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/TestRegionRebalancing.java
@@ -31,7 +31,8 @@ import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hbase.catalog.CatalogTracker;
 import org.apache.hadoop.hbase.catalog.MetaReader;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.regionserver.HRegionServer;
@@ -94,7 +95,7 @@ public class TestRegionRebalancing {
   @Test (timeout=300000)
   public void testRebalanceOnRegionServerNumberChange()
   throws IOException, InterruptedException {
-    HBaseAdmin admin = new HBaseAdmin(UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(UTIL.getConfiguration()).getAdmin();
     admin.createTable(this.desc, Arrays.copyOfRange(HBaseTestingUtility.KEYS,
         1, HBaseTestingUtility.KEYS.length));
     this.table = new HTable(UTIL.getConfiguration(), this.desc.getTableName());
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java
index e65430b..73e91c3 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java
@@ -34,8 +34,8 @@ import java.util.Map;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.client.HConnection;
 import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
@@ -250,7 +250,7 @@ public class TestZooKeeper {
     HColumnDescriptor family = new HColumnDescriptor("fam");
     desc.addFamily(family);
     LOG.info("Creating table " + tableName);
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     try {
       admin.createTable(desc);
     } finally {
@@ -491,7 +491,7 @@ public class TestZooKeeper {
     ZooKeeperWatcher zkw = m.getZooKeeper();
     int expectedNumOfListeners = zkw.getNumberOfListeners();
     // now the cluster is up. So assign some regions.
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     try {
       byte[][] SPLIT_KEYS = new byte[][] { Bytes.toBytes("a"), Bytes.toBytes("b"),
         Bytes.toBytes("c"), Bytes.toBytes("d"), Bytes.toBytes("e"), Bytes.toBytes("f"),
@@ -530,7 +530,7 @@ public class TestZooKeeper {
     cluster.startRegionServer();
     HMaster m = cluster.getMaster();
     // now the cluster is up. So assign some regions.
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     HTable table = null;
     try {
       byte[][] SPLIT_KEYS = new byte[][] { Bytes.toBytes("1"), Bytes.toBytes("2"),
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAdmin.java hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAdmin.java
index 82c2123..0985f01 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAdmin.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAdmin.java
@@ -87,7 +87,7 @@ import com.google.protobuf.ServiceException;
 public class TestAdmin {
   final Log LOG = LogFactory.getLog(getClass());
   private final static HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
-  private HBaseAdmin admin;
+  private Admin admin;
 
   @BeforeClass
   public static void setUpBeforeClass() throws Exception {
@@ -145,11 +145,12 @@ public class TestAdmin {
   @Test (timeout=300000)
   public void testDeleteEditUnknownColumnFamilyAndOrTable() throws IOException {
     // Test we get exception if we try to
-    final String nonexistent = "nonexistent";
+    final byte[] nonexistent = Bytes.toBytes("nonexistent");
+    final TableName nonexistentTableName = TableName.valueOf(nonexistent);
     HColumnDescriptor nonexistentHcd = new HColumnDescriptor(nonexistent);
     Exception exception = null;
     try {
-      this.admin.addColumn(nonexistent, nonexistentHcd);
+      this.admin.addColumn(nonexistentTableName, nonexistentHcd);
     } catch (IOException e) {
       exception = e;
     }
@@ -157,7 +158,7 @@ public class TestAdmin {
 
     exception = null;
     try {
-      this.admin.deleteTable(nonexistent);
+      this.admin.deleteTable(nonexistentTableName);
     } catch (IOException e) {
       exception = e;
     }
@@ -165,7 +166,7 @@ public class TestAdmin {
 
     exception = null;
     try {
-      this.admin.deleteColumn(nonexistent, nonexistent);
+      this.admin.deleteColumn(nonexistentTableName, nonexistent);
     } catch (IOException e) {
       exception = e;
     }
@@ -173,7 +174,7 @@ public class TestAdmin {
 
     exception = null;
     try {
-      this.admin.disableTable(nonexistent);
+      this.admin.disableTable(nonexistentTableName);
     } catch (IOException e) {
       exception = e;
     }
@@ -181,7 +182,7 @@ public class TestAdmin {
 
     exception = null;
     try {
-      this.admin.enableTable(nonexistent);
+      this.admin.enableTable(nonexistentTableName);
     } catch (IOException e) {
       exception = e;
     }
@@ -189,7 +190,7 @@ public class TestAdmin {
 
     exception = null;
     try {
-      this.admin.modifyColumn(nonexistent, nonexistentHcd);
+      this.admin.modifyColumn(nonexistentTableName, nonexistentHcd);
     } catch (IOException e) {
       exception = e;
     }
@@ -231,8 +232,8 @@ public class TestAdmin {
       assertTrue("found=" + exception.getClass().getName(),
           exception instanceof InvalidFamilyOperationException);
     } finally {
-      this.admin.disableTable(tableName);
-      this.admin.deleteTable(tableName);
+      this.admin.disableTable(nonexistentTableName);
+      this.admin.deleteTable(nonexistentTableName);
     }
   }
 
@@ -241,7 +242,7 @@ public class TestAdmin {
     final byte [] row = Bytes.toBytes("row");
     final byte [] qualifier = Bytes.toBytes("qualifier");
     final byte [] value = Bytes.toBytes("value");
-    final byte [] table = Bytes.toBytes("testDisableAndEnableTable");
+    final TableName table = TableName.valueOf("testDisableAndEnableTable");
     HTable ht = TEST_UTIL.createTable(table, HConstants.CATALOG_FAMILY);
     Put put = new Put(row);
     put.add(HConstants.CATALOG_FAMILY, qualifier, value);
@@ -468,7 +469,7 @@ public class TestAdmin {
   @Test (timeout=300000)
   public void testShouldFailOnlineSchemaUpdateIfOnlineSchemaIsNotEnabled()
       throws Exception {
-    final byte[] tableName = Bytes.toBytes("changeTableSchemaOnlineFailure");
+    final TableName tableName = TableName.valueOf("changeTableSchemaOnlineFailure");
     TEST_UTIL.getMiniHBaseCluster().getMaster().getConfiguration().setBoolean(
         "hbase.online.schema.update.enable", false);
     HTableDescriptor[] tables = admin.listTables();
@@ -609,7 +610,11 @@ public class TestAdmin {
   @Test (timeout=300000)
   public void testCreateTableWithRegions() throws IOException, InterruptedException {
 
-    byte[] tableName = Bytes.toBytes("testCreateTableWithRegions");
+    final String tableNamePrefix = "testCreateTableWithRegions";
+    final TableName tableName1 = TableName.valueOf(tableNamePrefix + "_1");
+    final TableName tableName2 = TableName.valueOf(tableNamePrefix + "_2");
+    final TableName tableName3 = TableName.valueOf(tableNamePrefix + "_3");
+    final TableName tableName4 = TableName.valueOf(tableNamePrefix + "_4");
 
     byte [][] splitKeys = {
         new byte [] { 1, 1, 1 },
@@ -624,14 +629,14 @@ public class TestAdmin {
     };
     int expectedRegions = splitKeys.length + 1;
 
-    HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(tableName));
+    HTableDescriptor desc = new HTableDescriptor(tableName1);
     desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));
     admin.createTable(desc, splitKeys);
 
-    boolean tableAvailable = admin.isTableAvailable(Bytes.toString(tableName), splitKeys);
+    boolean tableAvailable = admin.isTableAvailable(tableName1, splitKeys);
     assertTrue("Table should be created with splitKyes + 1 rows in META", tableAvailable);
 
-    HTable ht = new HTable(TEST_UTIL.getConfiguration(), tableName);
+    HTable ht = new HTable(TEST_UTIL.getConfiguration(), tableName1);
     Map<HRegionInfo, ServerName> regions = ht.getRegionLocations();
     assertEquals("Tried to create " + expectedRegions + " regions " +
         "but only found " + regions.size(),
@@ -684,14 +689,12 @@ public class TestAdmin {
 
     expectedRegions = 10;
 
-    byte [] TABLE_2 = Bytes.add(tableName, Bytes.toBytes("_2"));
-
-    desc = new HTableDescriptor(TableName.valueOf(TABLE_2));
+    desc = new HTableDescriptor(tableName2);
     desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));
-    admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     admin.createTable(desc, startKey, endKey, expectedRegions);
 
-    HTable ht2 = new HTable(TEST_UTIL.getConfiguration(), TABLE_2);
+    HTable ht2 = new HTable(TEST_UTIL.getConfiguration(), tableName2);
     regions = ht2.getRegionLocations();
     assertEquals("Tried to create " + expectedRegions + " regions " +
         "but only found " + regions.size(),
@@ -740,15 +743,13 @@ public class TestAdmin {
 
     expectedRegions = 5;
 
-    byte [] TABLE_3 = Bytes.add(tableName, Bytes.toBytes("_3"));
-
-    desc = new HTableDescriptor(TableName.valueOf(TABLE_3));
+    desc = new HTableDescriptor(tableName3);
     desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));
-    admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     admin.createTable(desc, startKey, endKey, expectedRegions);
 
 
-    HTable ht3 = new HTable(TEST_UTIL.getConfiguration(), TABLE_3);
+    HTable ht3 = new HTable(TEST_UTIL.getConfiguration(), tableName3);
     regions = ht3.getRegionLocations();
     assertEquals("Tried to create " + expectedRegions + " regions " +
         "but only found " + regions.size(),
@@ -767,10 +768,9 @@ public class TestAdmin {
         new byte [] { 2, 2, 2 }
     };
 
-    byte [] TABLE_4 = Bytes.add(tableName, Bytes.toBytes("_4"));
-    desc = new HTableDescriptor(TableName.valueOf(TABLE_4));
+    desc = new HTableDescriptor(tableName4);
     desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));
-    HBaseAdmin ladmin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin ladmin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     try {
       ladmin.createTable(desc, splitKeys);
       assertTrue("Should not be able to create this table because of " +
@@ -783,8 +783,8 @@ public class TestAdmin {
 
   @Test (timeout=300000)
   public void testTableAvailableWithRandomSplitKeys() throws Exception {
-    byte[] tableName = Bytes.toBytes("testTableAvailableWithRandomSplitKeys");
-    HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(tableName));
+    TableName tableName = TableName.valueOf("testTableAvailableWithRandomSplitKeys");
+    HTableDescriptor desc = new HTableDescriptor(tableName);
     desc.addFamily(new HColumnDescriptor("col"));
     byte[][] splitKeys = new byte[1][];
     splitKeys = new byte [][] {
@@ -792,7 +792,7 @@ public class TestAdmin {
         new byte [] { 2, 2, 2 }
     };
     admin.createTable(desc);
-    boolean tableAvailable = admin.isTableAvailable(Bytes.toString(tableName), splitKeys);
+    boolean tableAvailable = admin.isTableAvailable(tableName, splitKeys);
     assertFalse("Table should be created with 1 row in META", tableAvailable);
   }
 
@@ -829,12 +829,12 @@ public class TestAdmin {
 
   @Test (timeout=120000)
   public void testTableExist() throws IOException {
-    final byte [] table = Bytes.toBytes("testTableExist");
+    final TableName tableName = TableName.valueOf("testTableExist");
     boolean exist;
-    exist = this.admin.tableExists(table);
+    exist = this.admin.tableExists(tableName);
     assertEquals(false, exist);
-    TEST_UTIL.createTable(table, HConstants.CATALOG_FAMILY);
-    exist = this.admin.tableExists(table);
+    TEST_UTIL.createTable(tableName, HConstants.CATALOG_FAMILY);
+    exist = this.admin.tableExists(tableName);
     assertEquals(true, exist);
   }
 
@@ -862,13 +862,13 @@ public class TestAdmin {
    */
   @Test (timeout=300000)
   public void testEnableTableRetainAssignment() throws IOException {
-    byte[] tableName = Bytes.toBytes("testEnableTableAssignment");
+    final TableName tableName = TableName.valueOf("testEnableTableAssignment");
     byte[][] splitKeys = { new byte[] { 1, 1, 1 }, new byte[] { 2, 2, 2 },
         new byte[] { 3, 3, 3 }, new byte[] { 4, 4, 4 }, new byte[] { 5, 5, 5 },
         new byte[] { 6, 6, 6 }, new byte[] { 7, 7, 7 }, new byte[] { 8, 8, 8 },
         new byte[] { 9, 9, 9 } };
     int expectedRegions = splitKeys.length + 1;
-    HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(tableName));
+    HTableDescriptor desc = new HTableDescriptor(tableName);
     desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));
     admin.createTable(desc, splitKeys);
     HTable ht = new HTable(TEST_UTIL.getConfiguration(), tableName);
@@ -1122,7 +1122,7 @@ public class TestAdmin {
     Thread [] threads = new Thread [count];
     final AtomicInteger successes = new AtomicInteger(0);
     final AtomicInteger failures = new AtomicInteger(0);
-    final HBaseAdmin localAdmin = this.admin;
+    final Admin localAdmin = this.admin;
     for (int i = 0; i < count; i++) {
       threads[i] = new Thread(Integer.toString(i)) {
         @Override
@@ -1191,7 +1191,7 @@ public class TestAdmin {
       // Use 80 bit numbers to make sure we aren't limited
       byte [] startKey = { 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 };
       byte [] endKey =   { 9, 9, 9, 9, 9, 9, 9, 9, 9, 9 };
-      HBaseAdmin hbaseadmin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+      Admin hbaseadmin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
       HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(name));
       htd.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));
       hbaseadmin.createTable(htd, startKey, endKey, expectedRegions);
@@ -1264,8 +1264,7 @@ public class TestAdmin {
    */
   @Test (expected=TableNotEnabledException.class, timeout=300000)
   public void testTableNotEnabledExceptionWithATable() throws IOException {
-    final byte [] name = Bytes.toBytes(
-      "testTableNotEnabledExceptionWithATable");
+    final TableName name = TableName.valueOf("testTableNotEnabledExceptionWithATable");
     TEST_UTIL.createTable(name, HConstants.CATALOG_FAMILY).close();
     this.admin.disableTable(name);
     this.admin.disableTable(name);
@@ -1277,11 +1276,10 @@ public class TestAdmin {
    */
   @Test (expected=TableNotDisabledException.class, timeout=300000)
   public void testTableNotDisabledExceptionWithATable() throws IOException {
-    final byte [] name = Bytes.toBytes(
-      "testTableNotDisabledExceptionWithATable");
-    HTable t = TEST_UTIL.createTable(name, HConstants.CATALOG_FAMILY);
+    final TableName tableName = TableName.valueOf("testTableNotDisabledExceptionWithATable");
+    HTable t = TEST_UTIL.createTable(tableName, HConstants.CATALOG_FAMILY);
     try {
-    this.admin.enableTable(name);
+    this.admin.enableTable(tableName);
     }finally {
        t.close();
     }
@@ -1462,12 +1460,12 @@ public class TestAdmin {
         onlineRegions.contains(info));
   }
 
-  private HBaseAdmin createTable(byte[] TABLENAME) throws IOException {
+  private Admin createTable(TableName tableName) throws IOException {
 
     Configuration config = TEST_UTIL.getConfiguration();
-    HBaseAdmin admin = new HBaseAdmin(config);
+    Admin admin = HConnectionManager.createConnection(config).getAdmin();
 
-    HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(TABLENAME));
+    HTableDescriptor htd = new HTableDescriptor(tableName);
     HColumnDescriptor hcd = new HColumnDescriptor("value");
 
     htd.addFamily(hcd);
@@ -1494,7 +1492,7 @@ public class TestAdmin {
   @Test (timeout=300000)
   public void testGetTableRegions() throws IOException {
 
-    byte[] tableName = Bytes.toBytes("testGetTableRegions");
+    final TableName tableName = TableName.valueOf("testGetTableRegions");
 
     int expectedRegions = 10;
 
@@ -1503,7 +1501,7 @@ public class TestAdmin {
     byte [] endKey =   { 9, 9, 9, 9, 9, 9, 9, 9, 9, 9 };
 
 
-    HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(tableName));
+    HTableDescriptor desc = new HTableDescriptor(tableName);
     desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));
     admin.createTable(desc, startKey, endKey, expectedRegions);
 
@@ -1544,10 +1542,10 @@ public class TestAdmin {
 
   @Test (timeout=300000)
   public void testMoveToPreviouslyAssignedRS() throws IOException, InterruptedException {
-    byte[] tableName = Bytes.toBytes("testMoveToPreviouslyAssignedRS");
+    TableName tableName = TableName.valueOf("testMoveToPreviouslyAssignedRS");
     MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
     HMaster master = cluster.getMaster();
-    HBaseAdmin localAdmin = createTable(tableName);
+    Admin localAdmin = createTable(tableName);
     List<HRegionInfo> tableRegions = localAdmin.getTableRegions(tableName);
     HRegionInfo hri = tableRegions.get(0);
     AssignmentManager am = master.getAssignmentManager();
@@ -1699,13 +1697,13 @@ public class TestAdmin {
   @Test (timeout=300000)
   public void testIsEnabledOrDisabledOnUnknownTable() throws Exception {
     try {
-      admin.isTableEnabled(Bytes.toBytes("unkownTable"));
+      admin.isTableEnabled(TableName.valueOf("unknownTable"));
       fail("Test should fail if isTableEnabled called on unknown table.");
     } catch (IOException e) {
     }
 
     try {
-      admin.isTableDisabled(Bytes.toBytes("unkownTable"));
+      admin.isTableDisabled(TableName.valueOf("unknownTable"));
       fail("Test should fail if isTableDisabled called on unknown table.");
     } catch (IOException e) {
     }
@@ -1724,9 +1722,11 @@ public class TestAdmin {
       HRegionLocation regionLocation = t.getRegionLocation("mmm");
       HRegionInfo region = regionLocation.getRegionInfo();
       byte[] regionName = region.getRegionName();
-      Pair<HRegionInfo, ServerName> pair = admin.getRegion(regionName, ct);
+      // TODO - replace hbadmin with this.admin
+      HBaseAdmin hbadmin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+      Pair<HRegionInfo, ServerName> pair = hbadmin.getRegion(regionName, ct);
       assertTrue(Bytes.equals(regionName, pair.getFirst().getRegionName()));
-      pair = admin.getRegion(region.getEncodedNameAsBytes(), ct);
+      pair = hbadmin.getRegion(region.getEncodedNameAsBytes(), ct);
       assertTrue(Bytes.equals(regionName, pair.getFirst().getRegionName()));
     } finally {
       ct.stop();
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientTimeouts.java hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientTimeouts.java
index 1d6ef77..fca8295 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientTimeouts.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientTimeouts.java
@@ -87,9 +87,9 @@ public class TestClientTimeouts {
         // Ensure the HBaseAdmin uses a new connection by changing Configuration.
         Configuration conf = HBaseConfiguration.create(TEST_UTIL.getConfiguration());
         conf.set(HConstants.HBASE_CLIENT_INSTANCE_ID, String.valueOf(-1));
-        HBaseAdmin admin = null;
+        Admin admin = null;
         try {
-          admin = new HBaseAdmin(conf);
+          admin = HConnectionManager.createConnection(conf).getAdmin();
           HConnection connection = admin.getConnection();
           assertFalse(connection == lastConnection);
           lastConnection = connection;
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
index ae25047..bf701ba 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
@@ -637,7 +637,7 @@ public class TestFromClientSide {
   private Map<HRegionInfo, ServerName> splitTable(final HTable t)
   throws IOException, InterruptedException {
     // Split this table in two.
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     admin.split(t.getTableName());
     admin.close();
     Map<HRegionInfo, ServerName> regions = waitOnSplit(t);
@@ -1708,7 +1708,7 @@ public class TestFromClientSide {
 
   @Test
   public void testDeleteFamilyVersion() throws Exception {
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     byte [] TABLE = Bytes.toBytes("testDeleteFamilyVersion");
 
     byte [][] QUALIFIERS = makeNAscii(QUALIFIER, 1);
@@ -1753,7 +1753,7 @@ public class TestFromClientSide {
     byte [][] VALUES = makeN(VALUE, 5);
     long [] ts = {1000, 2000, 3000, 4000, 5000};
 
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     HTable ht = TEST_UTIL.createTable(TABLE, FAMILY, 5);
     Put put = null;
     Result result = null;
@@ -3594,7 +3594,7 @@ public class TestFromClientSide {
     String tableName = "testUpdatesWithMajorCompaction";
     byte [] TABLE = Bytes.toBytes(tableName);
     HTable hTable = TEST_UTIL.createTable(TABLE, FAMILY, 10);
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
 
     // Write a column with values at timestamp 1, 2 and 3
     byte[] row = Bytes.toBytes("row2");
@@ -3656,7 +3656,7 @@ public class TestFromClientSide {
     String tableName = "testMajorCompactionBetweenTwoUpdates";
     byte [] TABLE = Bytes.toBytes(tableName);
     HTable hTable = TEST_UTIL.createTable(TABLE, FAMILY, 10);
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
 
     // Write a column with values at timestamp 1, 2 and 3
     byte[] row = Bytes.toBytes("row3");
@@ -4065,7 +4065,7 @@ public class TestFromClientSide {
     for (int i = 0; i < tables.length; i++) {
       TEST_UTIL.createTable(tables[i], FAMILY);
     }
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     HTableDescriptor[] ts = admin.listTables();
     HashSet<HTableDescriptor> result = new HashSet<HTableDescriptor>(ts.length);
     for (int i = 0; i < ts.length; i++) {
@@ -4092,7 +4092,7 @@ public class TestFromClientSide {
    * @return the created HTable object
    * @throws IOException
    */
-  HTable createUnmangedHConnectionHTable(final byte [] tableName) throws IOException {
+  HTable createUnmangedHConnectionHTable(TableName tableName) throws IOException {
     TEST_UTIL.createTable(tableName, HConstants.CATALOG_FAMILY);
     HConnection conn = HConnectionManager.createConnection(TEST_UTIL.getConfiguration());
     return (HTable)conn.getTable(tableName);
@@ -4106,9 +4106,9 @@ public class TestFromClientSide {
    */
   @Test
   public void testUnmanagedHConnection() throws IOException {
-    final byte[] tableName = Bytes.toBytes("testUnmanagedHConnection");
+    final TableName tableName = TableName.valueOf("testUnmanagedHConnection");
     HTable t = createUnmangedHConnectionHTable(tableName);
-    HBaseAdmin ha = new HBaseAdmin(t.getConnection());
+    Admin ha = t.getConnection().getAdmin();
     assertTrue(ha.tableExists(tableName));
     assertTrue(t.get(new Get(ROW)).isEmpty());
   }
@@ -4121,10 +4121,10 @@ public class TestFromClientSide {
    */
   @Test
   public void testUnmanagedHConnectionReconnect() throws Exception {
-    final byte[] tableName = Bytes.toBytes("testUnmanagedHConnectionReconnect");
+    final TableName tableName = TableName.valueOf("testUnmanagedHConnectionReconnect");
     HTable t = createUnmangedHConnectionHTable(tableName);
     HConnection conn = t.getConnection();
-    HBaseAdmin ha = new HBaseAdmin(conn);
+    Admin ha = conn.getAdmin();
     assertTrue(ha.tableExists(tableName));
     assertTrue(t.get(new Get(ROW)).isEmpty());
 
@@ -4139,14 +4139,14 @@ public class TestFromClientSide {
 
     // test that the same unmanaged connection works with a new
     // HBaseAdmin and can connect to the new master;
-    HBaseAdmin newAdmin = new HBaseAdmin(conn);
+    Admin newAdmin = conn.getAdmin();
     assertTrue(newAdmin.tableExists(tableName));
     assertTrue(newAdmin.getClusterStatus().getServersSize() == SLAVES + 1);
   }
 
   @Test
   public void testMiscHTableStuff() throws IOException {
-    final byte[] tableAname = Bytes.toBytes("testMiscHTableStuffA");
+    final TableName tableAname = TableName.valueOf("testMiscHTableStuffA");
     final byte[] tableBname = Bytes.toBytes("testMiscHTableStuffB");
     final byte[] attrName = Bytes.toBytes("TESTATTR");
     final byte[] attrValue = Bytes.toBytes("somevalue");
@@ -4189,7 +4189,7 @@ public class TestFromClientSide {
     // to be reloaded.
 
     // Test user metadata
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     // make a modifiable descriptor
     HTableDescriptor desc = new HTableDescriptor(a.getTableDescriptor());
     // offline the table
@@ -4206,8 +4206,7 @@ public class TestFromClientSide {
 
     // Test that attribute changes were applied
     desc = a.getTableDescriptor();
-    assertTrue("wrong table descriptor returned",
-      Bytes.compareTo(desc.getTableName().getName(), tableAname) == 0);
+    assertEquals("wrong table descriptor returned", desc.getTableName(), tableAname);
     // check HTD attribute
     value = desc.getValue(attrName);
     assertFalse("missing HTD attribute value", value == null);
@@ -5172,7 +5171,7 @@ public class TestFromClientSide {
     byte [] family1 = Bytes.toBytes("f1");
     byte [] family2 = Bytes.toBytes("f2");
     HTable table = TEST_UTIL.createTable(TABLE, new byte[][] {family1, family2}, 10);
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     Map <HRegionInfo, ServerName> regionsMap = table.getRegionLocations();
     assertEquals(1, regionsMap.size());
     HRegionInfo regionInfo = regionsMap.keySet().iterator().next();
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java
index e19f44c..a026467 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java
@@ -109,7 +109,7 @@ public class TestFromClientSide3 {
     table.put(put);
   }
 
-  private void performMultiplePutAndFlush(HBaseAdmin admin, HTable table,
+  private void performMultiplePutAndFlush(Admin admin, HTable table,
       byte[] row, byte[] family, int nFlushes, int nPuts) throws Exception {
 
     // connection needed for poll-wait
@@ -153,7 +153,7 @@ public class TestFromClientSide3 {
     TableName TABLE =
         TableName.valueOf(tableName);
     HTable hTable = TEST_UTIL.createTable(TABLE, FAMILY, 10);
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     HConnection connection = HConnectionManager.getConnection(TEST_UTIL
         .getConfiguration());
 
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHBaseAdminNoCluster.java hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHBaseAdminNoCluster.java
index ea92bd5..69d9675 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHBaseAdminNoCluster.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHBaseAdminNoCluster.java
@@ -71,7 +71,7 @@ public class TestHBaseAdminNoCluster {
         thenThrow(new ServiceException("Test fail").initCause(new PleaseHoldException("test")));
     Mockito.when(connection.getKeepAliveMasterService()).thenReturn(masterAdmin);
     // Mock up our admin Interfaces
-    HBaseAdmin admin = new HBaseAdmin(configuration);
+    Admin admin = HConnectionManager.createConnection(configuration).getAdmin();
     try {
       HTableDescriptor htd =
           new HTableDescriptor(TableName.valueOf("testMasterMonitorCollableRetries"));
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java
index 322ebaa..0c12ae1 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java
@@ -252,11 +252,12 @@ public class TestHTablePool {
 		public void testCloseTablePool() throws IOException {
 			HTablePool pool = new HTablePool(TEST_UTIL.getConfiguration(), 4,
 					getPoolType());
-			HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+			Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
+      TableName tableName = TableName.valueOf(TABLENAME);
 
-			if (admin.tableExists(TABLENAME)) {
-				admin.disableTable(TABLENAME);
-				admin.deleteTable(TABLENAME);
+			if (admin.tableExists(tableName)) {
+				admin.disableTable(tableName);
+				admin.deleteTable(tableName);
 			}
 
 			HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(TABLENAME));
@@ -328,11 +329,12 @@ public class TestHTablePool {
 		public void testCloseTablePool() throws IOException {
 			HTablePool pool = new HTablePool(TEST_UTIL.getConfiguration(), 4,
 					getPoolType());
-			HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+			Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
 
-			if (admin.tableExists(TABLENAME)) {
-				admin.disableTable(TABLENAME);
-				admin.deleteTable(TABLENAME);
+      TableName tableName = TableName.valueOf(TABLENAME);
+			if (admin.tableExists(tableName)) {
+				admin.disableTable(tableName);
+				admin.deleteTable(tableName);
 			}
 
 			HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(TABLENAME));
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBatchCoprocessorEndpoint.java hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBatchCoprocessorEndpoint.java
index be5f79d..549953f 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBatchCoprocessorEndpoint.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBatchCoprocessorEndpoint.java
@@ -35,7 +35,8 @@ import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.MediumTests;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.coprocessor.Batch;
@@ -84,7 +85,7 @@ public class TestBatchCoprocessorEndpoint {
     conf.setStrings(CoprocessorHost.MASTER_COPROCESSOR_CONF_KEY,
         ProtobufCoprocessorService.class.getName());
     util.startMiniCluster(2);
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
     HTableDescriptor desc = new HTableDescriptor(TEST_TABLE);
     desc.addFamily(new HColumnDescriptor(TEST_FAMILY));
     admin.createTable(desc, new byte[][]{ROWS[rowSeperator1], ROWS[rowSeperator2]});
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java
index 3cc73c1..f454c6f 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java
@@ -42,7 +42,9 @@ import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.MediumTests;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.coprocessor.Batch;
@@ -91,7 +93,7 @@ public class TestCoprocessorEndpoint {
     conf.setStrings(CoprocessorHost.MASTER_COPROCESSOR_CONF_KEY,
         ProtobufCoprocessorService.class.getName());
     util.startMiniCluster(2);
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
     HTableDescriptor desc = new HTableDescriptor(TEST_TABLE);
     desc.addFamily(new HColumnDescriptor(TEST_FAMILY));
     admin.createTable(desc, new byte[][]{ROWS[rowSeperator1], ROWS[rowSeperator2]});
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerObserver.java hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerObserver.java
index ada3e6f..83bf7e6 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerObserver.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerObserver.java
@@ -36,7 +36,8 @@ import org.apache.hadoop.hbase.MediumTests;
 import org.apache.hadoop.hbase.MiniHBaseCluster;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.catalog.MetaEditor;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.Mutation;
 import org.apache.hadoop.hbase.regionserver.HRegion;
 import org.apache.hadoop.hbase.regionserver.HRegionServer;
@@ -74,7 +75,7 @@ public class TestRegionServerObserver {
     // Start the cluster
     HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility(conf);
     TEST_UTIL.startMiniCluster(NUM_MASTERS, NUM_RS);
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
     try {
       MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
       HRegionServer regionServer = cluster.getRegionServer(0);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWithScanLimits.java hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWithScanLimits.java
index a35d5c5..687562c 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWithScanLimits.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWithScanLimits.java
@@ -42,7 +42,8 @@ import org.apache.hadoop.hbase.MasterNotRunningException;
 import org.apache.hadoop.hbase.MediumTests;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.ZooKeeperConnectionException;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -68,8 +69,8 @@ public class TestFilterWithScanLimits {
 
   private static final HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
   private static Configuration conf = null;
-  private static HBaseAdmin admin = null;
-  private static byte[] name = Bytes.toBytes("test");
+  private static Admin admin = null;
+  private static TableName name = TableName.valueOf("test");
 
   @Test
   public void testScanWithLimit() {
@@ -139,7 +140,7 @@ public class TestFilterWithScanLimits {
     assertNotNull("HBaseAdmin is not initialized successfully.", admin);
     if (admin != null) {
 
-      HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(name));
+      HTableDescriptor desc = new HTableDescriptor(name);
       HColumnDescriptor coldef = new HColumnDescriptor(Bytes.toBytes("f1"));
       desc.addFamily(coldef);
 
@@ -168,7 +169,7 @@ public class TestFilterWithScanLimits {
     TestFilterWithScanLimits.conf = HBaseConfiguration.create(conf);
     TestFilterWithScanLimits.conf.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 1);
     try {
-      admin = new HBaseAdmin(conf);
+      admin = HConnectionManager.createConnection(conf).getAdmin();
     } catch (MasterNotRunningException e) {
       assertNull("Master is not running", e);
     } catch (ZooKeeperConnectionException e) {
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWrapper.java hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWrapper.java
index 9587aa3..527d1f9 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWrapper.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWrapper.java
@@ -37,7 +37,8 @@ import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.MasterNotRunningException;
 import org.apache.hadoop.hbase.ZooKeeperConnectionException;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -63,8 +64,8 @@ public class TestFilterWrapper {
 
   private static final HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
   private static Configuration conf = null;
-  private static HBaseAdmin admin = null;
-  private static byte[] name = Bytes.toBytes("test");
+  private static Admin admin = null;
+  private static TableName name = TableName.valueOf("test");
 
   @Test
   public void testFilterWrapper() {
@@ -143,7 +144,7 @@ public class TestFilterWrapper {
     assertNotNull("HBaseAdmin is not initialized successfully.", admin);
     if (admin != null) {
 
-      HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(name));
+      HTableDescriptor desc = new HTableDescriptor(name);
       HColumnDescriptor coldef = new HColumnDescriptor(Bytes.toBytes("f1"));
       desc.addFamily(coldef);
 
@@ -172,7 +173,7 @@ public class TestFilterWrapper {
     TestFilterWrapper.conf = HBaseConfiguration.create(conf);
     TestFilterWrapper.conf.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 1);
     try {
-      admin = new HBaseAdmin(conf);
+      admin = HConnectionManager.createConnection(conf).getAdmin();
     } catch (MasterNotRunningException e) {
       assertNull("Master is not running", e);
     } catch (ZooKeeperConnectionException e) {
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestChangingEncoding.java hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestChangingEncoding.java
index 0ceb953..f77b51b 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestChangingEncoding.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestChangingEncoding.java
@@ -36,9 +36,10 @@ import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Durability;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -70,10 +71,10 @@ public class TestChangingEncoding {
 
   private static final int TIMEOUT_MS = 600000;
 
-  private HBaseAdmin admin;
+  private Admin admin;
   private HColumnDescriptor hcd;
 
-  private String tableName;
+  private TableName tableName;
   private static final List<DataBlockEncoding> ENCODINGS_TO_ITERATE =
       createEncodingsToIterate();
 
@@ -88,8 +89,8 @@ public class TestChangingEncoding {
   private int numBatchesWritten;
 
   private void prepareTest(String testId) throws IOException {
-    tableName = "test_table_" + testId;
-    HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(tableName));
+    tableName = TableName.valueOf("test_table_" + testId);
+    HTableDescriptor htd = new HTableDescriptor(tableName);
     hcd = new HColumnDescriptor(CF);
     htd.addFamily(hcd);
     admin.createTable(htd);
@@ -113,7 +114,7 @@ public class TestChangingEncoding {
 
   @Before
   public void setUp() throws Exception {
-    admin = new HBaseAdmin(conf);
+    admin = HConnectionManager.createConnection(conf).getAdmin();
   }
 
   @After
@@ -134,7 +135,7 @@ public class TestChangingEncoding {
         + "_col" + j);
   }
 
-  static void writeTestDataBatch(Configuration conf, String tableName,
+  static void writeTestDataBatch(Configuration conf, TableName tableName,
       int batchId) throws Exception {
     LOG.debug("Writing test data batch " + batchId);
     HTable table = new HTable(conf, tableName);
@@ -152,7 +153,7 @@ public class TestChangingEncoding {
     table.close();
   }
 
-  static void verifyTestDataBatch(Configuration conf, String tableName,
+  static void verifyTestDataBatch(Configuration conf, TableName tableName,
       int batchId) throws Exception {
     LOG.debug("Verifying test data batch " + batchId);
     HTable table = new HTable(conf, tableName);
@@ -226,7 +227,7 @@ public class TestChangingEncoding {
   private void compactAndWait() throws IOException, InterruptedException {
     LOG.debug("Compacting table " + tableName);
     HRegionServer rs = TEST_UTIL.getMiniHBaseCluster().getRegionServer(0);
-    admin.majorCompact(tableName);
+    admin.majorCompact(tableName.getName());
 
     // Waiting for the compaction to start, at least .5s.
     final long maxWaitime = System.currentTimeMillis() + 500;
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestLoadAndSwitchEncodeOnDisk.java hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestLoadAndSwitchEncodeOnDisk.java
index 0ebef3b..7df0c21 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestLoadAndSwitchEncodeOnDisk.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestLoadAndSwitchEncodeOnDisk.java
@@ -26,7 +26,8 @@ import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.MediumTests;
 import org.apache.hadoop.hbase.ServerName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Result;
 import org.apache.hadoop.hbase.client.ResultScanner;
@@ -67,7 +68,7 @@ public class TestLoadAndSwitchEncodeOnDisk extends
 
   @Test(timeout=TIMEOUT_MS)
   public void loadTest() throws Exception {
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
 
     compression = Compression.Algorithm.GZ; // used for table setup
     super.loadTest();
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java
index d13aa1b..afcc65c 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java
@@ -55,7 +55,8 @@ import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.PerformanceEvaluation;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -367,11 +368,11 @@ public class TestHFileOutputFormat  {
     util = new HBaseTestingUtility();
     Configuration conf = util.getConfiguration();
     byte[][] startKeys = generateRandomStartKeys(5);
-    HBaseAdmin admin = null;
+    Admin admin = null;
     try {
       util.startMiniCluster();
       Path testDir = util.getDataTestDirOnTestFS("testLocalMRIncrementalLoad");
-      admin = new HBaseAdmin(conf);
+      admin = HConnectionManager.createConnection(conf).getAdmin();
       HTable table = util.createTable(TABLE_NAME, FAMILIES);
       assertEquals("Should start with empty table",
           0, util.countRows(table));
@@ -401,7 +402,7 @@ public class TestHFileOutputFormat  {
       // handle the split case
       if (shouldChangeRegions) {
         LOG.info("Changing regions in table");
-        admin.disableTable(table.getTableName());
+        admin.disableTable(table.getName());
         while(util.getMiniHBaseCluster().getMaster().getAssignmentManager().
             getRegionStates().isRegionsInTransition()) {
           Threads.sleep(200);
@@ -410,9 +411,9 @@ public class TestHFileOutputFormat  {
         byte[][] newStartKeys = generateRandomStartKeys(15);
         util.createMultiRegions(
             util.getConfiguration(), table, FAMILIES[0], newStartKeys);
-        admin.enableTable(table.getTableName());
+        admin.enableTable(table.getName());
         while (table.getRegionLocations().size() != 15 ||
-            !admin.isTableAvailable(table.getTableName())) {
+            !admin.isTableAvailable(table.getName())) {
           Thread.sleep(200);
           LOG.info("Waiting for new region assignment to happen");
         }
@@ -890,7 +891,7 @@ public class TestHFileOutputFormat  {
     try {
       util.startMiniCluster();
       final FileSystem fs = util.getDFSCluster().getFileSystem();
-      HBaseAdmin admin = new HBaseAdmin(conf);
+      Admin admin = HConnectionManager.createConnection(conf).getAdmin();
       HTable table = util.createTable(TABLE_NAME, FAMILIES);
       assertEquals("Should start with empty table", 0, util.countRows(table));
 
@@ -958,7 +959,7 @@ public class TestHFileOutputFormat  {
       util.startMiniCluster();
       Path testDir = util.getDataTestDirOnTestFS("testExcludeMinorCompaction");
       final FileSystem fs = util.getDFSCluster().getFileSystem();
-      HBaseAdmin admin = new HBaseAdmin(conf);
+      Admin admin = HConnectionManager.createConnection(conf).getAdmin();
       HTable table = util.createTable(TABLE_NAME, FAMILIES);
       assertEquals("Should start with empty table", 0, util.countRows(table));
 
@@ -1045,9 +1046,9 @@ public class TestHFileOutputFormat  {
     Configuration conf = HBaseConfiguration.create();
     util = new HBaseTestingUtility(conf);
     if ("newtable".equals(args[0])) {
-      byte[] tname = args[1].getBytes();
+      TableName tname = TableName.valueOf(args[1]);
       HTable table = util.createTable(tname, FAMILIES);
-      HBaseAdmin admin = new HBaseAdmin(conf);
+      Admin admin = HConnectionManager.createConnection(conf).getAdmin();
       admin.disableTable(tname);
       byte[][] startKeys = generateRandomStartKeys(5);
       util.createMultiRegions(conf, table, FAMILIES[0], startKeys);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java
index 372db66..a3e8458 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java
@@ -53,7 +53,8 @@ import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.PerformanceEvaluation;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -366,11 +367,11 @@ public class TestHFileOutputFormat2  {
     util = new HBaseTestingUtility();
     Configuration conf = util.getConfiguration();
     byte[][] startKeys = generateRandomStartKeys(5);
-    HBaseAdmin admin = null;
+    Admin admin = null;
     try {
       util.startMiniCluster();
       Path testDir = util.getDataTestDirOnTestFS("testLocalMRIncrementalLoad");
-      admin = new HBaseAdmin(conf);
+      admin = HConnectionManager.createConnection(conf).getAdmin();
       HTable table = util.createTable(TABLE_NAME, FAMILIES);
       assertEquals("Should start with empty table",
           0, util.countRows(table));
@@ -400,7 +401,7 @@ public class TestHFileOutputFormat2  {
       // handle the split case
       if (shouldChangeRegions) {
         LOG.info("Changing regions in table");
-        admin.disableTable(table.getTableName());
+        admin.disableTable(table.getName());
         while(util.getMiniHBaseCluster().getMaster().getAssignmentManager().
             getRegionStates().isRegionsInTransition()) {
           Threads.sleep(200);
@@ -409,9 +410,9 @@ public class TestHFileOutputFormat2  {
         byte[][] newStartKeys = generateRandomStartKeys(15);
         util.createMultiRegions(
             util.getConfiguration(), table, FAMILIES[0], newStartKeys);
-        admin.enableTable(table.getTableName());
+        admin.enableTable(table.getName());
         while (table.getRegionLocations().size() != 15 ||
-            !admin.isTableAvailable(table.getTableName())) {
+            !admin.isTableAvailable(table.getName())) {
           Thread.sleep(200);
           LOG.info("Waiting for new region assignment to happen");
         }
@@ -890,7 +891,7 @@ public class TestHFileOutputFormat2  {
     try {
       util.startMiniCluster();
       final FileSystem fs = util.getDFSCluster().getFileSystem();
-      HBaseAdmin admin = new HBaseAdmin(conf);
+      Admin admin = HConnectionManager.createConnection(conf).getAdmin();
       HTable table = util.createTable(TABLE_NAME, FAMILIES);
       assertEquals("Should start with empty table", 0, util.countRows(table));
 
@@ -958,7 +959,7 @@ public class TestHFileOutputFormat2  {
       util.startMiniCluster();
       Path testDir = util.getDataTestDirOnTestFS("testExcludeMinorCompaction");
       final FileSystem fs = util.getDFSCluster().getFileSystem();
-      HBaseAdmin admin = new HBaseAdmin(conf);
+      Admin admin = HConnectionManager.createConnection(conf).getAdmin();
       HTable table = util.createTable(TABLE_NAME, FAMILIES);
       assertEquals("Should start with empty table", 0, util.countRows(table));
 
@@ -1045,9 +1046,9 @@ public class TestHFileOutputFormat2  {
     Configuration conf = HBaseConfiguration.create();
     util = new HBaseTestingUtility(conf);
     if ("newtable".equals(args[0])) {
-      byte[] tname = args[1].getBytes();
+      TableName tname = TableName.valueOf(args[1]);
       HTable table = util.createTable(tname, FAMILIES);
-      HBaseAdmin admin = new HBaseAdmin(conf);
+      Admin admin = HConnectionManager.createConnection(conf).getAdmin();
       admin.disableTable(tname);
       byte[][] startKeys = generateRandomStartKeys(5);
       util.createMultiRegions(conf, table, FAMILIES[0], startKeys);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java
index 3ae585b..6583f8e 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java
@@ -39,7 +39,6 @@ import org.apache.hadoop.hbase.HBaseTestingUtility;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.client.Durability;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -96,7 +95,6 @@ public class TestImportTSVWithOperationAttributes implements Configurable {
     conf.set("hbase.coprocessor.master.classes", OperationAttributesTestController.class.getName());
     conf.set("hbase.coprocessor.region.classes", OperationAttributesTestController.class.getName());
     util.startMiniCluster();
-    HBaseAdmin admin = new HBaseAdmin(util.getConfiguration());
     util.startMiniMapReduceCluster();
   }
 
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java
index 62005b8..c976500 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java
@@ -42,7 +42,8 @@ import org.apache.hadoop.hbase.CellUtil;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.LargeTests;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Result;
 import org.apache.hadoop.hbase.client.ResultScanner;
@@ -116,7 +117,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
     // Wait for the labels table to become available
     util.waitTableEnabled(VisibilityConstants.LABELS_TABLE_NAME.getName(), 50000);
     createLabels();
-    HBaseAdmin admin = new HBaseAdmin(util.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(util.getConfiguration()).getAdmin();
     util.startMiniMapReduceCluster();
   }
 
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java
index 860fcda..7f368e9 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java
@@ -35,7 +35,8 @@ import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.io.compress.Compression;
 import org.apache.hadoop.hbase.io.compress.Compression.Algorithm;
@@ -195,7 +196,7 @@ public class TestLoadIncrementalHFiles {
 
     final byte[] TABLE = Bytes.toBytes("mytable_"+testName);
 
-    HBaseAdmin admin = new HBaseAdmin(util.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(util.getConfiguration()).getAdmin();
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(TABLE));
     // set real family name to upper case in purpose to simulate the case that
     // family name in HFiles is invalid
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTimeRangeMapRed.java hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTimeRangeMapRed.java
index a5c0b92..10bbcc9 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTimeRangeMapRed.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTimeRangeMapRed.java
@@ -32,7 +32,8 @@ import org.apache.hadoop.conf.Configurable;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileUtil;
 import org.apache.hadoop.hbase.*;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -57,7 +58,7 @@ public class TestTimeRangeMapRed {
   private final static Log log = LogFactory.getLog(TestTimeRangeMapRed.class);
   private static final HBaseTestingUtility UTIL =
     new HBaseTestingUtility();
-  private HBaseAdmin admin;
+  private Admin admin;
 
   private static final byte [] KEY = Bytes.toBytes("row1");
   private static final NavigableMap<Long, Boolean> TIMESTAMP =
@@ -90,7 +91,7 @@ public class TestTimeRangeMapRed {
 
   @Before
   public void before() throws Exception {
-    this.admin = new HBaseAdmin(UTIL.getConfiguration());
+    this.admin = HConnectionManager.createConnection(UTIL.getConfiguration()).getAdmin();
   }
 
   @After
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterRestartAfterDisablingTable.java hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterRestartAfterDisablingTable.java
index c7ddddb..87daa6b 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterRestartAfterDisablingTable.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterRestartAfterDisablingTable.java
@@ -32,7 +32,8 @@ import org.apache.hadoop.hbase.HBaseTestingUtility;
 import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.MiniHBaseCluster;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.JVMClusterUtil.MasterThread;
@@ -66,7 +67,7 @@ public class TestMasterRestartAfterDisablingTable {
     HMaster master = cluster.getMaster();
 
     // Create a table with regions
-    byte[] table = Bytes.toBytes("tableRestart");
+    TableName table = TableName.valueOf("tableRestart");
     byte[] family = Bytes.toBytes("family");
     log("Creating table with " + NUM_REGIONS_TO_CREATE + " regions");
     HTable ht = TEST_UTIL.createTable(table, family);
@@ -100,7 +101,7 @@ public class TestMasterRestartAfterDisablingTable {
             TableName.valueOf("tableRestart")));
     log("Enabling table\n");
     // Need a new Admin, the previous one is on the old master
-    HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
     admin.enableTable(table);
     admin.close();
     log("Waiting for no more RIT\n");
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement.java hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement.java
index 5c797b2..e04ea8d 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement.java
@@ -50,7 +50,8 @@ import org.apache.hadoop.hbase.MiniHBaseCluster;
 import org.apache.hadoop.hbase.NamespaceDescriptor;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.MetaScanner;
 import org.apache.hadoop.hbase.client.MetaScanner.MetaScannerVisitor;
@@ -76,7 +77,7 @@ public class TestRegionPlacement {
   final static Log LOG = LogFactory.getLog(TestRegionPlacement.class);
   private final static HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
   private final static int SLAVES = 10;
-  private static HBaseAdmin admin;
+  private static Admin admin;
   private static RegionPlacementMaintainer rp;
   private static Position[] positions = Position.values();
   private int lastRegionOnPrimaryRSCount = 0;
@@ -95,7 +96,7 @@ public class TestRegionPlacement {
         FavoredNodeLoadBalancer.class, LoadBalancer.class);
     conf.setBoolean("hbase.tests.use.shortcircuit.reads", false);
     TEST_UTIL.startMiniCluster(SLAVES);
-    admin = new HBaseAdmin(conf);
+    admin = HConnectionManager.createConnection(conf).getAdmin();
     rp = new RegionPlacementMaintainer(conf);
   }
 
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionState.java hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionState.java
index 807751a..a99b801 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionState.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionState.java
@@ -31,7 +31,9 @@ import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
 import org.apache.hadoop.hbase.LargeTests;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState;
@@ -88,6 +90,7 @@ public class TestCompactionState {
     HTable ht = null;
     try {
       ht = TEST_UTIL.createTable(table, family);
+      // TODO - replace this with Admin
       HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
       try {
         admin.compact(table, fakecf);
@@ -137,7 +140,7 @@ public class TestCompactionState {
       int countBefore = countStoreFilesInFamilies(regions, families);
       int countBeforeSingleFamily = countStoreFilesInFamily(regions, family);
       assertTrue(countBefore > 0); // there should be some data files
-      HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+      Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
       if (expectedState == CompactionState.MINOR) {
         if (singleFamily) {
           admin.compact(table.getName(), family);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java
index 9c9ec70..2a5c910 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestFSErrorsExposed.java
@@ -44,7 +44,8 @@ import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.MediumTests;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.fs.HFileSystem;
 import org.apache.hadoop.hbase.io.hfile.CacheConfig;
@@ -188,7 +189,7 @@ public class TestFSErrorsExposed {
       byte[] tableName = Bytes.toBytes("table");
       byte[] fam = Bytes.toBytes("fam");
 
-      HBaseAdmin admin = new HBaseAdmin(util.getConfiguration());
+      Admin admin = HConnectionManager.createConnection(util.getConfiguration()).getAdmin();
       HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(tableName));
       desc.addFamily(new HColumnDescriptor(fam)
           .setMaxVersions(1)
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransactionOnCluster.java hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransactionOnCluster.java
index 4cf622d..b7dfc63 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransactionOnCluster.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransactionOnCluster.java
@@ -57,8 +57,9 @@ import org.apache.hadoop.hbase.Waiter;
 import org.apache.hadoop.hbase.ZooKeeperConnectionException;
 import org.apache.hadoop.hbase.catalog.MetaEditor;
 import org.apache.hadoop.hbase.catalog.MetaReader;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Mutation;
 import org.apache.hadoop.hbase.client.Put;
@@ -110,7 +111,7 @@ import com.google.protobuf.ServiceException;
 public class TestSplitTransactionOnCluster {
   private static final Log LOG =
     LogFactory.getLog(TestSplitTransactionOnCluster.class);
-  private HBaseAdmin admin = null;
+  private Admin admin = null;
   private MiniHBaseCluster cluster = null;
   private static final int NB_SERVERS = 3;
   private static CountDownLatch latch = new CountDownLatch(1);
@@ -132,7 +133,7 @@ public class TestSplitTransactionOnCluster {
 
   @Before public void setup() throws IOException {
     TESTING_UTIL.ensureSomeNonStoppedRegionServersAvailable(NB_SERVERS);
-    this.admin = new HBaseAdmin(TESTING_UTIL.getConfiguration());
+    this.admin = HConnectionManager.createConnection(TESTING_UTIL.getConfiguration()).getAdmin();
     this.cluster = TESTING_UTIL.getMiniHBaseCluster();
   }
 
@@ -302,7 +303,7 @@ public class TestSplitTransactionOnCluster {
   public void testSplitFailedCompactionAndSplit() throws Exception {
     final byte[] tableName = Bytes.toBytes("testSplitFailedCompactionAndSplit");
     Configuration conf = TESTING_UTIL.getConfiguration();
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
     // Create table then get the single region for our new table.
     HTableDescriptor htd = new HTableDescriptor(tableName);
     byte[] cf = Bytes.toBytes("cf");
@@ -714,7 +715,7 @@ public class TestSplitTransactionOnCluster {
       // abort and wait for new master.
       MockMasterWithoutCatalogJanitor master = abortAndWaitForMaster();
 
-      this.admin = new HBaseAdmin(TESTING_UTIL.getConfiguration());
+      this.admin = HConnectionManager.createConnection(TESTING_UTIL.getConfiguration()).getAdmin();
 
       // Update the region to be offline and split, so that HRegionInfo#equals
       // returns true in checking rebuilt region states map.
@@ -803,7 +804,7 @@ public class TestSplitTransactionOnCluster {
 
       MockMasterWithoutCatalogJanitor master = abortAndWaitForMaster();
 
-      this.admin = new HBaseAdmin(TESTING_UTIL.getConfiguration());
+      this.admin = HConnectionManager.createConnection(TESTING_UTIL.getConfiguration()).getAdmin();
 
       // Update the region to be offline and split, so that HRegionInfo#equals
       // returns true in checking rebuilt region states map.
@@ -883,7 +884,7 @@ public class TestSplitTransactionOnCluster {
     }
   }
 
-  private void insertData(final byte[] tableName, HBaseAdmin admin, HTable t) throws IOException,
+  private void insertData(final byte[] tableName, Admin admin, HTable t) throws IOException,
       InterruptedException {
     Put p = new Put(Bytes.toBytes("row1"));
     p.add(Bytes.toBytes("cf"), Bytes.toBytes("q1"), Bytes.toBytes("1"));
@@ -1188,8 +1189,7 @@ public class TestSplitTransactionOnCluster {
    * @throws org.apache.hadoop.hbase.ZooKeeperConnectionException
    * @throws InterruptedException
    */
-  private int ensureTableRegionNotOnSameServerAsMeta(final HBaseAdmin admin,
-      final HRegionInfo hri)
+  private int ensureTableRegionNotOnSameServerAsMeta(final Admin admin, final HRegionInfo hri)
   throws HBaseIOException, MasterNotRunningException,
   ZooKeeperConnectionException, InterruptedException {
     // Now make sure that the table region is not on same server as that hosting
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestMasterReplication.java hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestMasterReplication.java
index 72a1513..0f14a98 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestMasterReplication.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestMasterReplication.java
@@ -37,10 +37,11 @@ import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Durability;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -285,9 +286,9 @@ public class TestMasterReplication {
   private void createTableOnClusters(HTableDescriptor table) throws Exception {
     int numClusters = configurations.length;
     for (int i = 0; i < numClusters; i++) {
-      HBaseAdmin hbaseAdmin = null;
+      Admin hbaseAdmin = null;
       try {
-        hbaseAdmin = new HBaseAdmin(configurations[i]);
+        hbaseAdmin = HConnectionManager.createConnection(configurations[i]).getAdmin();
         hbaseAdmin.createTable(table);
       } finally {
         close(hbaseAdmin);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestMultiSlaveReplication.java hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestMultiSlaveReplication.java
index f3daa97..ace286a 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestMultiSlaveReplication.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestMultiSlaveReplication.java
@@ -31,7 +31,7 @@ import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.*;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -121,9 +121,9 @@ public class TestMultiSlaveReplication {
     utility3.startMiniCluster();
     ReplicationAdmin admin1 = new ReplicationAdmin(conf1);
 
-    new HBaseAdmin(conf1).createTable(table);
-    new HBaseAdmin(conf2).createTable(table);
-    new HBaseAdmin(conf3).createTable(table);
+    HConnectionManager.createConnection(conf1).getAdmin().createTable(table);
+    HConnectionManager.createConnection(conf2).getAdmin().createTable(table);
+    HConnectionManager.createConnection(conf3).getAdmin().createTable(table);
     HTable htable1 = new HTable(conf1, tableName);
     htable1.setWriteBufferSize(1024);
     HTable htable2 = new HTable(conf2, tableName);
@@ -142,7 +142,8 @@ public class TestMultiSlaveReplication {
     putAndWait(row2, famName, htable1, htable2);
 
     // now roll the region server's logs
-    new HBaseAdmin(conf1).rollHLogWriter(master.getRegionServer(0).getServerName().toString());
+    HConnectionManager.createConnection(conf1).getAdmin().rollHLogWriter(master.getRegionServer(0)
+        .getServerName().toString());
     // after the log was rolled put a new row
     putAndWait(row3, famName, htable1, htable2);
 
@@ -165,7 +166,7 @@ public class TestMultiSlaveReplication {
     p.add(famName, row, row);
     htable1.put(p);
     // now roll the logs again
-    new HBaseAdmin(conf1).rollHLogWriter(master.getRegionServer(0)
+    HConnectionManager.createConnection(conf1).getAdmin().rollHLogWriter(master.getRegionServer(0)
         .getServerName().toString());
 
     // cleanup "row2", also conveniently use this to wait replication
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestPerTableCFReplication.java hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestPerTableCFReplication.java
index ee102fc..b0c5bd0 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestPerTableCFReplication.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestPerTableCFReplication.java
@@ -33,9 +33,10 @@ import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.*;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -260,15 +261,18 @@ public class TestPerTableCFReplication {
     LOG.info("testPerTableCFReplication");
     ReplicationAdmin admin1 = new ReplicationAdmin(conf1);
 
-    new HBaseAdmin(conf1).createTable(tabA);
-    new HBaseAdmin(conf1).createTable(tabB);
-    new HBaseAdmin(conf1).createTable(tabC);
-    new HBaseAdmin(conf2).createTable(tabA);
-    new HBaseAdmin(conf2).createTable(tabB);
-    new HBaseAdmin(conf2).createTable(tabC);
-    new HBaseAdmin(conf3).createTable(tabA);
-    new HBaseAdmin(conf3).createTable(tabB);
-    new HBaseAdmin(conf3).createTable(tabC);
+    Admin hbadmin1 = HConnectionManager.createConnection(conf1).getAdmin();
+    Admin hbadmin2 = HConnectionManager.createConnection(conf2).getAdmin();
+    Admin hbadmin3 = HConnectionManager.createConnection(conf3).getAdmin();
+    hbadmin1.createTable(tabA);
+    hbadmin1.createTable(tabB);
+    hbadmin1.createTable(tabC);
+    hbadmin2.createTable(tabA);
+    hbadmin2.createTable(tabB);
+    hbadmin2.createTable(tabC);
+    hbadmin3.createTable(tabA);
+    hbadmin3.createTable(tabB);
+    hbadmin3.createTable(tabC);
 
     HTable htab1A = new HTable(conf1, tabAName);
     HTable htab2A = new HTable(conf2, tabAName);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationBase.java hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationBase.java
index 080d858..a7375c1 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationBase.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationBase.java
@@ -28,7 +28,8 @@ import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.replication.ReplicationAdmin;
 import org.apache.hadoop.hbase.replication.regionserver.ReplicationSource;
@@ -134,8 +135,8 @@ public class TestReplicationBase {
     table.addFamily(fam);
     fam = new HColumnDescriptor(noRepfamName);
     table.addFamily(fam);
-    HBaseAdmin admin1 = new HBaseAdmin(conf1);
-    HBaseAdmin admin2 = new HBaseAdmin(conf2);
+    Admin admin1 = HConnectionManager.createConnection(conf1).getAdmin();
+    Admin admin2 = HConnectionManager.createConnection(conf2).getAdmin();
     admin1.createTable(table, HBaseTestingUtility.KEYS_FOR_HBA_CREATE_TABLE);
     admin2.createTable(table, HBaseTestingUtility.KEYS_FOR_HBA_CREATE_TABLE);
     htable1 = new HTable(conf1, tableName);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
index 5c0f710..92ffa4c 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
@@ -35,9 +35,10 @@ import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -510,7 +511,7 @@ public class TestReplicationSmallTests extends TestReplicationBase {
     final String colFam = "cf1";
     final int numOfTables = 3;
 
-    HBaseAdmin hadmin = new HBaseAdmin(conf1);
+    Admin hadmin = HConnectionManager.createConnection(conf1).getAdmin();
 
     // Create Tables
     for (int i = 0; i < numOfTables; i++) {
@@ -541,7 +542,7 @@ public class TestReplicationSmallTests extends TestReplicationBase {
 
     // drop tables
     for (int i = 0; i < numOfTables; i++) {
-      String ht = tName + i;
+      TableName ht = TableName.valueOf(tName + i);
       hadmin.disableTable(ht);
       hadmin.deleteTable(ht);
     }
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSyncUpTool.java hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSyncUpTool.java
index e8620d4..323847e 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSyncUpTool.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSyncUpTool.java
@@ -25,8 +25,9 @@ import java.util.List;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hbase.*;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.replication.ReplicationAdmin;
@@ -175,12 +176,12 @@ public class TestReplicationSyncUpTool extends TestReplicationBase {
     ReplicationAdmin admin1 = new ReplicationAdmin(conf1);
     ReplicationAdmin admin2 = new ReplicationAdmin(conf2);
 
-    HBaseAdmin ha = new HBaseAdmin(conf1);
+    Admin ha = HConnectionManager.createConnection(conf1).getAdmin();
     ha.createTable(t1_syncupSource);
     ha.createTable(t2_syncupSource);
     ha.close();
 
-    ha = new HBaseAdmin(conf2);
+    ha = HConnectionManager.createConnection(conf2).getAdmin();
     ha.createTable(t1_syncupTarget);
     ha.createTable(t2_syncupTarget);
     ha.close();
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationWithTags.java hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationWithTags.java
index 491a9db..4e1f93b 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationWithTags.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationWithTags.java
@@ -39,9 +39,10 @@ import org.apache.hadoop.hbase.KeyValueUtil;
 import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.Tag;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Durability;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Result;
@@ -134,9 +135,9 @@ public class TestReplicationWithTags {
     fam.setMaxVersions(3);
     fam.setScope(HConstants.REPLICATION_SCOPE_GLOBAL);
     table.addFamily(fam);
-    HBaseAdmin admin = null;
+    Admin admin = null;
     try {
-      admin = new HBaseAdmin(conf1);
+      admin = HConnectionManager.createConnection(conf1).getAdmin();
       admin.createTable(table, HBaseTestingUtility.KEYS_FOR_HBA_CREATE_TABLE);
     } finally {
       if (admin != null) {
@@ -144,7 +145,7 @@ public class TestReplicationWithTags {
       }
     }
     try {
-      admin = new HBaseAdmin(conf2);
+      admin = HConnectionManager.createConnection(conf2).getAdmin();
       admin.createTable(table, HBaseTestingUtility.KEYS_FOR_HBA_CREATE_TABLE);
     } finally {
       if(admin != null){
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java
index 03142c5..28e00b9 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java
@@ -48,10 +48,12 @@ import org.apache.hadoop.hbase.MiniHBaseCluster;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.TableNotFoundException;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Append;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Get;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Increment;
 import org.apache.hadoop.hbase.client.Put;
@@ -890,7 +892,7 @@ public class TestAccessController extends SecureTestUtil {
 
       HTable table = new HTable(conf, tableName);
       try {
-        HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+        Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
         TEST_UTIL.waitTableEnabled(admin, tableName.getName());
         LoadIncrementalHFiles loader = new LoadIncrementalHFiles(conf);
         loader.doBulkLoad(loadPath, table);
@@ -1934,7 +1936,7 @@ public class TestAccessController extends SecureTestUtil {
     AccessTestAction listTablesAction = new AccessTestAction() {
       @Override
       public Object run() throws Exception {
-        HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+        Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
         try {
           admin.listTables();
         } finally {
@@ -1947,7 +1949,7 @@ public class TestAccessController extends SecureTestUtil {
     AccessTestAction getTableDescAction = new AccessTestAction() {
       @Override
       public Object run() throws Exception {
-        HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+        Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
         try {
           admin.getTableDescriptor(TEST_TABLE.getTableName());
         } finally {
@@ -1976,7 +1978,7 @@ public class TestAccessController extends SecureTestUtil {
     AccessTestAction deleteTableAction = new AccessTestAction() {
       @Override
       public Object run() throws Exception {
-        HBaseAdmin admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+        Admin admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
         try {
           admin.disableTable(TEST_TABLE.getTableName());
           admin.deleteTable(TEST_TABLE.getTableName());
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/util/LoadTestTool.java hbase-server/src/test/java/org/apache/hadoop/hbase/util/LoadTestTool.java
index d0357fa..bcb7cb0 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/util/LoadTestTool.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/util/LoadTestTool.java
@@ -38,7 +38,8 @@ import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.PerformanceEvaluation;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.io.compress.Compression;
 import org.apache.hadoop.hbase.io.crypto.Cipher;
 import org.apache.hadoop.hbase.io.crypto.Encryption;
@@ -213,7 +214,7 @@ public class LoadTestTool extends AbstractHBaseTool {
    */
   protected void applyColumnFamilyOptions(TableName tableName,
       byte[][] columnFamilies) throws IOException {
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
     HTableDescriptor tableDesc = admin.getTableDescriptor(tableName);
     LOG.info("Disabling table " + tableName);
     admin.disableTable(tableName);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHBaseFsck.java hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHBaseFsck.java
index 134a953..f32c7c0 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHBaseFsck.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestHBaseFsck.java
@@ -62,6 +62,7 @@ import org.apache.hadoop.hbase.MiniHBaseCluster;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.catalog.MetaEditor;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Durability;
 import org.apache.hadoop.hbase.client.Get;
@@ -215,9 +216,9 @@ public class TestHBaseFsck {
   @Test(timeout=180000)
   public void testFixAssignmentsWhenMETAinTransition() throws Exception {
     MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
-    HBaseAdmin admin = null;
+    Admin admin = null;
     try {
-      admin = new HBaseAdmin(TEST_UTIL.getConfiguration());
+      admin = HConnectionManager.createConnection(TEST_UTIL.getConfiguration()).getAdmin();
       admin.closeRegion(cluster.getServerHoldingMeta(),
           HRegionInfo.FIRST_META_REGIONINFO);
     } finally {
@@ -261,7 +262,7 @@ public class TestHBaseFsck {
    * This method is used to undeploy a region -- close it and attempt to
    * remove its state from the Master.
    */
-  private void undeployRegion(HBaseAdmin admin, ServerName sn,
+  private void undeployRegion(Admin admin, ServerName sn,
       HRegionInfo hri) throws IOException, InterruptedException {
     try {
       HBaseFsckRepair.closeRegionSilentlyAndWait(admin, sn, hri);
@@ -310,7 +311,7 @@ public class TestHBaseFsck {
 
         if (unassign) {
           LOG.info("Undeploying region " + hri + " from server " + hsa);
-          undeployRegion(new HBaseAdmin(conf), hsa, hri);
+          undeployRegion(HConnectionManager.createConnection(conf).getAdmin(), hsa, hri);
         }
 
         if (regionInfoOnly) {
@@ -394,7 +395,7 @@ public class TestHBaseFsck {
    * @throws IOException
    */
   void deleteTable(TableName tablename) throws IOException {
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
     admin.getConnection().clearRegionCache();
     if (admin.isTableEnabled(tablename)) {
       admin.disableTableAsync(tablename);
@@ -2163,14 +2164,14 @@ public class TestHBaseFsck {
 
   private void deleteMetaRegion(Configuration conf, boolean unassign, boolean hdfs,
       boolean regionInfoOnly) throws IOException, InterruptedException {
-    HConnection connection = HConnectionManager.getConnection(conf);
+    HConnection connection = HConnectionManager.createConnection(conf);
     HRegionLocation metaLocation = connection.locateRegion(TableName.META_TABLE_NAME,
         HConstants.EMPTY_START_ROW);
     ServerName hsa = metaLocation.getServerName();
     HRegionInfo hri = metaLocation.getRegionInfo();
     if (unassign) {
       LOG.info("Undeploying meta region " + hri + " from server " + hsa);
-      undeployRegion(new HBaseAdmin(conf), hsa, hri);
+      undeployRegion(HConnectionManager.createConnection(conf).getAdmin(), hsa, hri);
     }
 
     if (regionInfoOnly) {
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java
index c2e7ef1..eafa8f3 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMergeTable.java
@@ -31,7 +31,8 @@ import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.*;
 import org.apache.hadoop.hbase.catalog.CatalogTracker;
 import org.apache.hadoop.hbase.catalog.MetaReader;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Durability;
 import org.apache.hadoop.hbase.regionserver.HRegion;
@@ -117,7 +118,7 @@ public class TestMergeTable {
         MetaReader.getTableRegions(ct, desc.getTableName());
       LOG.info("originalTableRegions size=" + originalTableRegions.size() +
         "; " + originalTableRegions);
-      HBaseAdmin admin = new HBaseAdmin(c);
+      Admin admin = HConnectionManager.createConnection(c).getAdmin();
       admin.disableTable(desc.getTableName());
       HMerge.merge(c, FileSystem.get(c), desc.getTableName());
       List<HRegionInfo> postMergeTableRegions =
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMiniClusterLoadSequential.java hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMiniClusterLoadSequential.java
index 80948c7..b77e3fc 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMiniClusterLoadSequential.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestMiniClusterLoadSequential.java
@@ -33,7 +33,8 @@ import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.TableNotFoundException;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.io.compress.Compression;
 import org.apache.hadoop.hbase.io.encoding.DataBlockEncoding;
 import org.apache.hadoop.hbase.util.test.LoadTestDataGenerator;
@@ -150,7 +151,7 @@ public class TestMiniClusterLoadSequential {
     LOG.info("Starting load test: dataBlockEncoding=" + dataBlockEncoding +
         ", isMultiPut=" + isMultiPut);
     numKeys = numKeys();
-    HBaseAdmin admin = new HBaseAdmin(conf);
+    Admin admin = HConnectionManager.createConnection(conf).getAdmin();
     while (admin.getClusterStatus().getServers().size() < NUM_RS) {
       LOG.info("Sleeping until " + NUM_RS + " RSs are online");
       Threads.sleepWithoutInterrupt(1000);
@@ -172,7 +173,7 @@ public class TestMiniClusterLoadSequential {
     return 1000;
   }
 
-  protected HColumnDescriptor getColumnDesc(HBaseAdmin admin)
+  protected HColumnDescriptor getColumnDesc(Admin admin)
       throws TableNotFoundException, IOException {
     return admin.getTableDescriptor(TABLE).getFamily(CF);
   }
diff --git hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java
index 67a9b3c..08efaba 100644
--- hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java
+++ hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java
@@ -54,10 +54,11 @@ import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.TableNotFoundException;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Durability;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Increment;
 import org.apache.hadoop.hbase.client.OperationWithAttributes;
@@ -411,7 +412,7 @@ public class ThriftServerRunner implements Runnable {
    */
   public static class HBaseHandler implements Hbase.Iface {
     protected Configuration conf;
-    protected volatile HBaseAdmin admin = null;
+    protected volatile Admin admin = null;
     protected final Log LOG = LogFactory.getLog(this.getClass().getName());
 
     // nextScannerId and scannerMap are used to manage scanner state
@@ -521,11 +522,11 @@ public class ThriftServerRunner implements Runnable {
     /**
      * Obtain HBaseAdmin. Creates the instance if it is not already created.
      */
-    private HBaseAdmin getHBaseAdmin() throws IOException {
+    private synchronized Admin getHBaseAdmin() throws IOException {
       if (admin == null) {
         synchronized (this) {
           if (admin == null) {
-            admin = new HBaseAdmin(conf);
+            admin = HConnectionManager.createConnection(conf).getAdmin();
           }
         }
       }
@@ -535,7 +536,7 @@ public class ThriftServerRunner implements Runnable {
     @Override
     public void enableTable(ByteBuffer tableName) throws IOError {
       try{
-        getHBaseAdmin().enableTable(getBytes(tableName));
+        getHBaseAdmin().enableTable(TableName.valueOf(getBytes(tableName)));
       } catch (IOException e) {
         LOG.warn(e.getMessage(), e);
         throw new IOError(e.getMessage());
@@ -545,7 +546,7 @@ public class ThriftServerRunner implements Runnable {
     @Override
     public void disableTable(ByteBuffer tableName) throws IOError{
       try{
-        getHBaseAdmin().disableTable(getBytes(tableName));
+        getHBaseAdmin().disableTable(TableName.valueOf(getBytes(tableName)));
       } catch (IOException e) {
         LOG.warn(e.getMessage(), e);
         throw new IOError(e.getMessage());
@@ -955,12 +956,12 @@ public class ThriftServerRunner implements Runnable {
     public void createTable(ByteBuffer in_tableName,
         List<ColumnDescriptor> columnFamilies) throws IOError,
         IllegalArgument, AlreadyExists {
-      byte [] tableName = getBytes(in_tableName);
+      TableName tableName = TableName.valueOf(getBytes(in_tableName));
       try {
         if (getHBaseAdmin().tableExists(tableName)) {
           throw new AlreadyExists("table name already in use");
         }
-        HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(tableName));
+        HTableDescriptor desc = new HTableDescriptor(tableName);
         for (ColumnDescriptor col : columnFamilies) {
           HColumnDescriptor colDesc = ThriftUtilities.colDescFromThrift(col);
           desc.addFamily(colDesc);
@@ -977,9 +978,9 @@ public class ThriftServerRunner implements Runnable {
 
     @Override
     public void deleteTable(ByteBuffer in_tableName) throws IOError {
-      byte [] tableName = getBytes(in_tableName);
+      TableName tableName = TableName.valueOf(getBytes(in_tableName));
       if (LOG.isDebugEnabled()) {
-        LOG.debug("deleteTable: table=" + Bytes.toString(tableName));
+        LOG.debug("deleteTable: table=" + tableName.getNameAsString());
       }
       try {
         if (!getHBaseAdmin().tableExists(tableName)) {
diff --git hbase-thrift/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandler.java hbase-thrift/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandler.java
index dbafb20..3f8fa8e 100644
--- hbase-thrift/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandler.java
+++ hbase-thrift/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandler.java
@@ -27,8 +27,9 @@ import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.MediumTests;
 import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Get;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.client.Increment;
@@ -131,7 +132,7 @@ public class TestThriftHBaseServiceHandler {
   @BeforeClass
   public static void beforeClass() throws Exception {
     UTIL.startMiniCluster();
-    HBaseAdmin admin = new HBaseAdmin(UTIL.getConfiguration());
+    Admin admin = HConnectionManager.createConnection(UTIL.getConfiguration()).getAdmin();
     HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableAname));
     for (HColumnDescriptor family : families) {
       tableDescriptor.addFamily(family);
diff --git hbase-thrift/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandlerWithLabels.java hbase-thrift/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandlerWithLabels.java
index 4bc633d..986b082 100644
--- hbase-thrift/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandlerWithLabels.java
+++ hbase-thrift/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandlerWithLabels.java
@@ -39,7 +39,8 @@ import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.MediumTests;
 import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos.VisibilityLabelsResponse;
 import org.apache.hadoop.hbase.security.User;
 import org.apache.hadoop.hbase.security.visibility.ScanLabelGenerator;
@@ -135,7 +136,7 @@ public static void beforeClass() throws Exception {
   // Wait for the labels table to become available
   UTIL.waitTableEnabled(VisibilityConstants.LABELS_TABLE_NAME.getName(), 50000);
   createLabels();
-  HBaseAdmin admin = new HBaseAdmin(UTIL.getConfiguration());
+  Admin admin = HConnectionManager.createConnection(UTIL.getConfiguration()).getAdmin();
   HTableDescriptor tableDescriptor = new HTableDescriptor(
       TableName.valueOf(tableAname));
   for (HColumnDescriptor family : families) {
