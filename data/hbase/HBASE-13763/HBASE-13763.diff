diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
index 3c0383f..1e50525 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
@@ -1461,7 +1461,7 @@ boolean isProcedureFinished(String signature, String instance, Map<String, Strin
    * @throws IOException
    * @throws InterruptedException
    */
-  void compactMob(final TableName tableName) throws IOException,
+  void compactMobs(final TableName tableName) throws IOException,
     InterruptedException;
 
   /**
@@ -1482,7 +1482,7 @@ void compactMob(final TableName tableName, final byte[] columnFamily) throws IOE
    * @throws IOException
    * @throws InterruptedException
    */
-  void majorCompactMob(final TableName tableName) throws IOException,
+  void majorCompactMobs(final TableName tableName) throws IOException,
     InterruptedException;
 
   /**
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
index caa12d2..4461e5c 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
@@ -4052,7 +4052,7 @@ public void compactMob(final TableName tableName, final byte[] columnFamily)
    * {@inheritDoc}
    */
   @Override
-  public void compactMob(final TableName tableName) throws IOException, InterruptedException {
+  public void compactMobs(final TableName tableName) throws IOException, InterruptedException {
     checkTableNameNotNull(tableName);
     compactMob(tableName, null, false);
   }
@@ -4073,7 +4073,7 @@ public void majorCompactMob(final TableName tableName, final byte[] columnFamily
    * {@inheritDoc}
    */
   @Override
-  public void majorCompactMob(final TableName tableName) throws IOException, InterruptedException {
+  public void majorCompactMobs(final TableName tableName) throws IOException, InterruptedException {
     checkTableNameNotNull(tableName);
     compactMob(tableName, null, true);
   }
diff --git a/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapper.java b/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapper.java
index b609b4a..90d400a 100644
--- a/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapper.java
+++ b/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapper.java
@@ -258,22 +258,22 @@
   long getMajorCompactedCellsSize();
 
   /**
-   * Gets the number of cells move to mob during compaction.
+   * Gets the number of cells moved to mob during compaction.
    */
   long getMobCompactedIntoMobCellsCount();
 
   /**
-   * Gets the number of cells move from mob during compaction.
+   * Gets the number of cells moved from mob during compaction.
    */
   long getMobCompactedFromMobCellsCount();
 
   /**
-   * Gets the total amount of cells move to mob during compaction, in bytes.
+   * Gets the total amount of cells moved to mob during compaction, in bytes.
    */
   long getMobCompactedIntoMobCellsSize();
 
   /**
-   * Gets the total amount of cells move from mob during compaction, in bytes.
+   * Gets the total amount of cells moved from mob during compaction, in bytes.
    */
   long getMobCompactedFromMobCellsSize();
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java
index a950dce..d070539 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java
@@ -184,7 +184,9 @@ public Path getArchivePath() {
   /**
    * @return the path of the mob hfiles.
    */
-  public Path getMobPath() { return this.mobPath; }
+  public Path getMobPath() {
+    return this.mobPath;
+  }
 
     /**
    * @param path Path to check.
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ExpiredMobFileCleanerChore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ExpiredMobFileCleanerChore.java
index 7b06462..7ca3362 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ExpiredMobFileCleanerChore.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ExpiredMobFileCleanerChore.java
@@ -92,7 +92,7 @@ protected void chore() {
                   lock.release();
                 } catch (IOException e) {
                   LOG.error(
-                    "Fail to release the write lock for the table " + htd.getNameAsString(), e);
+                    "Fail to release the read lock for the table " + htd.getNameAsString(), e);
                 }
               }
             }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
index b3fc2a1..f03a5ae 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
@@ -110,7 +110,6 @@
 import org.apache.hadoop.hbase.procedure.flush.MasterFlushTableProcedureManager;
 import org.apache.hadoop.hbase.procedure2.ProcedureExecutor;
 import org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore;
-import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionServerInfo;
 import org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.SplitLogTask.RecoveryMode;
@@ -281,7 +280,7 @@ public void run() {
   private HFileCleaner hfileCleaner;
   private ExpiredMobFileCleanerChore expiredMobFileCleanerChore;
   private MobFileCompactionChore mobFileCompactChore;
-  MasterMobFileCompactionThread mobFileCompactThread;
+  private MasterMobFileCompactionThread mobFileCompactThread;
   // used to synchronize the mobFileCompactionStates
   private final IdLock mobFileCompactionLock = new IdLock();
   // save the information of mob file compactions in tables.
@@ -2497,6 +2496,18 @@ public void reportMobFileCompactionEnd(TableName tableName) throws IOException {
   }
 
   /**
+   * Requests mob file compaction.
+   * @param tableName The table the compact.
+   * @param compactedColumns The compacted columns.
+   * @param isForceAllFiles Whether add all mob files into the compaction.
+   */
+  public void requestMobFileCompaction(TableName tableName,
+    List<HColumnDescriptor> compactedColumns, boolean isForceAllFiles) throws IOException {
+    mobFileCompactThread.requestMobFileCompaction(conf, fs, tableName, compactedColumns,
+      tableLockManager, isForceAllFiles);
+  }
+
+  /**
    * Queries the state of the {@link LoadBalancerTracker}. If the balancer is not initialized,
    * false is returned.
    *
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java
index 4b8d6b8..ac15eaf 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java
@@ -1437,8 +1437,8 @@ private CompactRegionResponse compactMob(final CompactRegionRequest request,
       for (HColumnDescriptor hcd : hcds) {
         if (Bytes.equals(family, hcd.getName())) {
           if (!hcd.isMobEnabled()) {
-            LOG.error("Column family " + hcd.getName() + " is not a mob column family");
-            throw new DoNotRetryIOException("Column family " + hcd.getName()
+            LOG.error("Column family " + hcd.getNameAsString() + " is not a mob column family");
+            throw new DoNotRetryIOException("Column family " + hcd.getNameAsString()
                     + " is not a mob column family");
           }
           compactedColumns.add(hcd);
@@ -1464,9 +1464,7 @@ private CompactRegionResponse compactMob(final CompactRegionRequest request,
       LOG.trace("User-triggered mob file compaction requested for table: "
               + tableName.getNameAsString() + " for column family: " + familyLogMsg);
     }
-    master.mobFileCompactThread.requestMobFileCompaction(master.getConfiguration(),
-            master.getFileSystem(), tableName, compactedColumns,
-            master.getTableLockManager(), isForceAllFiles);
+    master.requestMobFileCompaction(tableName, compactedColumns, isForceAllFiles);
     return CompactRegionResponse.newBuilder().build();
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DeleteTableHandler.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DeleteTableHandler.java
index cbff5dd..6069eba 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DeleteTableHandler.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/DeleteTableHandler.java
@@ -47,6 +47,7 @@
 import org.apache.hadoop.hbase.mob.MobUtils;
 import org.apache.hadoop.hbase.master.RegionStates;
 import org.apache.hadoop.hbase.regionserver.HRegion;
+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
 import org.apache.hadoop.hbase.util.FSUtils;
 
 @InterfaceAudience.Private
@@ -73,8 +74,8 @@ protected void waitRegionInTransition(final List<HRegionInfo> regions)
     long waitTime = server.getConfiguration().
       getLong("hbase.master.wait.on.region", 5 * 60 * 1000);
     for (HRegionInfo region : regions) {
-      long done = System.currentTimeMillis() + waitTime;
-      while (System.currentTimeMillis() < done) {
+      long done = EnvironmentEdgeManager.currentTime() + waitTime;
+      while (EnvironmentEdgeManager.currentTime() < done) {
         if (states.isRegionInState(region, State.FAILED_OPEN)) {
           am.regionOffline(region);
         }
@@ -192,14 +193,7 @@ protected void removeTableData(final List<HRegionInfo> regions)
       }
 
       // Archive the mob data if there is a mob-enabled column
-      HColumnDescriptor[] hcds = hTableDescriptor.getColumnFamilies();
-      boolean hasMob = false;
-      for (HColumnDescriptor hcd : hcds) {
-        if (hcd.isMobEnabled()) {
-          hasMob = true;
-          break;
-        }
-      }
+      boolean hasMob = MobUtils.hasMobColumns(hTableDescriptor);
       Path mobTableDir = null;
       if (hasMob) {
         // Archive mob data
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/DeleteTableProcedure.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/DeleteTableProcedure.java
index dfc5762..0e561d7 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/DeleteTableProcedure.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/DeleteTableProcedure.java
@@ -344,14 +344,7 @@ protected static void deleteFromFs(final MasterProcedureEnv env,
 
     // Archive the mob data if there is a mob-enabled column
     HTableDescriptor htd = env.getMasterServices().getTableDescriptors().get(tableName);
-    HColumnDescriptor[] hcds = htd.getColumnFamilies();
-    boolean hasMob = false;
-    for (HColumnDescriptor hcd : hcds) {
-      if (hcd.isMobEnabled()) {
-        hasMob = true;
-        break;
-      }
-    }
+    boolean hasMob = MobUtils.hasMobColumns(htd);
     Path mobTableDir = null;
     if (hasMob) {
       // Archive mob data
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobCompactor.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobCompactor.java
index d54dca4..83eef78 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobCompactor.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobCompactor.java
@@ -83,6 +83,8 @@ protected InternalScanner createScanner(Store store, List<StoreFileScanner> scan
     Scan scan = new Scan();
     scan.setMaxVersions(store.getFamily().getMaxVersions());
     if (scanType == ScanType.COMPACT_DROP_DELETES) {
+      // In major compaction, we need to write the delete markers to del files, so we have to
+      // retain the them in scanning.
       scanType = ScanType.COMPACT_RETAIN_DELETES;
       return new MobCompactionStoreScanner(store, store.getScanInfo(), scan, scanners,
           scanType, smallestReadPoint, earliestPutTs, true);
@@ -133,6 +135,7 @@ protected InternalScanner createScanner(Store store, List<StoreFileScanner> scan
    * @param writer Where to write to.
    * @param smallestReadPoint Smallest read point.
    * @param cleanSeqId When true, remove seqId(used to be mvcc) value which is <= smallestReadPoint
+   * @param throughputController The compaction throughput controller.
    * @param major Is a major compaction.
    * @return Whether compaction ended; false if it was interrupted for any reason.
    */
@@ -180,8 +183,6 @@ protected boolean performCompaction(FileDetails fd, InternalScanner scanner, Cel
           store.getFamily().getCompression(), store.getRegionInfo().getStartKey());
       ScannerContext scannerContext =
               ScannerContext.newBuilder().setBatchLimit(compactionKVMax).build();
-
-
       do {
         hasMore = compactionScanner.next(cells, scannerContext);
         // output to writer:
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobStoreFlusher.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobStoreFlusher.java
index 608f4e2..45373c3 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobStoreFlusher.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobStoreFlusher.java
@@ -121,7 +121,7 @@ public DefaultMobStoreFlusher(Configuration conf, Store store) throws IOExceptio
     } finally {
       scanner.close();
     }
-    LOG.info("Flushed, sequenceid=" + cacheFlushId + ", memsize="
+    LOG.info("Mob store is flushed, sequenceid=" + cacheFlushId + ", memsize="
         + StringUtils.TraditionalBinaryPrefix.long2String(snapshot.getSize(), "", 1) +
         ", hasBloomFilter=" + writer.hasGeneralBloom() +
         ", into tmp file " + writer.getPath());
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileCache.java
index 7d8c9a5..bc973f1 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileCache.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileCache.java
@@ -249,7 +249,7 @@ public void closeFile(MobFile file) {
 
   public void shutdown() {
     this.scheduleThreadPool.shutdown();
-    for (int i = 0; i < 10; i++) {
+    for (int i = 0; i < 100; i++) {
       if (!this.scheduleThreadPool.isShutdown()) {
         try {
           Thread.sleep(10);
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileName.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileName.java
index 937e965..796fe4d 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileName.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileName.java
@@ -26,9 +26,9 @@
  * It consists of a md5 of a start key, a date and an uuid.
  * It looks like md5(start) + date + uuid.
  * <ol>
- * <li>0-31 characters: md5 hex string of a start key. Since the length of the start key is not
+ * <li>characters 0-31: md5 hex string of a start key. Since the length of the start key is not
  * fixed, have to use the md5 instead which has a fix length.</li>
- * <li>32-39 characters: a string of a date with format yyyymmdd. The date is the latest timestamp
+ * <li>characters 32-39: a string of a date with format yyyymmdd. The date is the latest timestamp
  * of cells in this file</li>
  * <li>the remaining characters: the uuid.</li>
  * </ol>
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
index 527aef2..6a45950 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
@@ -48,6 +48,7 @@
 import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.Tag;
@@ -555,7 +556,7 @@ public static KeyValue createMobRefKeyValue(Cell cell, byte[] fileName, Tag tabl
   }
 
   /**
-   * Creates a writer for the del file in temp directory.
+   * Creates a writer for the mob file in temp directory.
    * @param conf The current configuration.
    * @param fs The current file system.
    * @param family The descriptor of the current column family.
@@ -837,4 +838,19 @@ public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
     }
     return cryptoContext;
   }
+
+  /**
+   * Checks whether this table has mob-enabled columns.
+   * @param htd The current table descriptor.
+   * @return Whether this table has mob-enabled columns.
+   */
+  public static boolean hasMobColumns(HTableDescriptor htd) {
+    HColumnDescriptor[] hcds = htd.getColumnFamilies();
+    for (HColumnDescriptor hcd : hcds) {
+      if (hcd.isMobEnabled()) {
+        return true;
+      }
+    }
+    return false;
+  }
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactionRequest.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactionRequest.java
index d2ac1db..be62f37 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactionRequest.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactionRequest.java
@@ -91,7 +91,7 @@ public void addFile(FileStatus file) {
   /**
    * The partition id that consists of start key and date of the mob file name.
    */
-  protected static class CompactionPartitionId {
+  public static class CompactionPartitionId {
 
     private String startKey;
     private String date;
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java
index b3c7d83..504f378 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java
@@ -203,11 +203,11 @@ protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates
     // archive the del files if all the mob files are selected.
     if (request.type == CompactionType.ALL_FILES && !newDelPaths.isEmpty()) {
       LOG.info("After a mob file compaction with all files selected, archiving the del files "
-        + newDelFiles);
+        + newDelPaths);
       try {
         MobUtils.removeMobFiles(conf, fs, tableName, mobTableDir, column.getName(), newDelFiles);
       } catch (IOException e) {
-        LOG.error("Failed to archive the del files " + newDelFiles, e);
+        LOG.error("Failed to archive the del files " + newDelPaths, e);
       }
     }
     return paths;
@@ -245,18 +245,20 @@ protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates
       }
       // compact the partitions in parallel.
       boolean hasFailure = false;
+      List<CompactionPartitionId> failedPartitions = new ArrayList<CompactionPartitionId>();
       for (Entry<CompactionPartitionId, Future<List<Path>>> result : results.entrySet()) {
         try {
           paths.addAll(result.getValue().get());
         } catch (Exception e) {
           // just log the error
           LOG.error("Failed to compact the partition " + result.getKey(), e);
+          failedPartitions.add(result.getKey());
           hasFailure = true;
         }
       }
       if (hasFailure) {
         // if any partition fails in the compaction, directly throw an exception.
-        throw new IOException("Failed to compact the partitions");
+        throw new IOException("Failed to compact the partitions " + failedPartitions);
       }
     } finally {
       try {
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/MemStoreWrapper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/MemStoreWrapper.java
index 458e187..c2b05ea 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/MemStoreWrapper.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/MemStoreWrapper.java
@@ -39,8 +39,8 @@
 import org.apache.hadoop.hbase.io.hfile.CacheConfig;
 import org.apache.hadoop.hbase.mob.MobConstants;
 import org.apache.hadoop.hbase.mob.MobUtils;
+import org.apache.hadoop.hbase.mob.filecompactions.PartitionedMobFileCompactionRequest;
 import org.apache.hadoop.hbase.mob.mapreduce.SweepJob.SweepCounter;
-import org.apache.hadoop.hbase.mob.mapreduce.SweepReducer.SweepPartitionId;
 import org.apache.hadoop.hbase.regionserver.KeyValueScanner;
 import org.apache.hadoop.hbase.regionserver.MemStore;
 import org.apache.hadoop.hbase.regionserver.MemStoreSnapshot;
@@ -68,7 +68,7 @@
 
   private MemStore memstore;
   private long flushSize;
-  private SweepPartitionId partitionId;
+  private PartitionedMobFileCompactionRequest.CompactionPartitionId partitionId;
   private Context context;
   private Configuration conf;
   private BufferedMutator table;
@@ -78,8 +78,8 @@
   private CacheConfig cacheConfig;
   private Encryption.Context cryptoContext = Encryption.Context.NONE;
 
-  public MemStoreWrapper(Context context, FileSystem fs, BufferedMutator table, HColumnDescriptor hcd,
-      MemStore memstore, CacheConfig cacheConfig) throws IOException {
+  public MemStoreWrapper(Context context, FileSystem fs, BufferedMutator table,
+    HColumnDescriptor hcd, MemStore memstore, CacheConfig cacheConfig) throws IOException {
     this.memstore = memstore;
     this.context = context;
     this.fs = fs;
@@ -93,7 +93,8 @@ public MemStoreWrapper(Context context, FileSystem fs, BufferedMutator table, HC
     cryptoContext = MobUtils.createEncryptionContext(conf, hcd);
   }
 
-  public void setPartitionId(SweepPartitionId partitionId) {
+  public void setPartitionId(PartitionedMobFileCompactionRequest.CompactionPartitionId
+    partitionId) {
     this.partitionId = partitionId;
   }
 
@@ -155,16 +156,19 @@ private void internalFlushCache(final MemStoreSnapshot snapshot)
     scanner = snapshot.getScanner();
     scanner.seek(KeyValueUtil.createFirstOnRow(HConstants.EMPTY_START_ROW));
     cell = null;
-    Tag tableNameTag = new Tag(TagType.MOB_TABLE_NAME_TAG_TYPE, Bytes.toBytes(this.table.getName().toString()));
+    Tag tableNameTag = new Tag(TagType.MOB_TABLE_NAME_TAG_TYPE, Bytes.toBytes(this.table.getName()
+      .toString()));
+    long updatedCount = 0;
     while (null != (cell = scanner.next())) {
       KeyValue reference = MobUtils.createMobRefKeyValue(cell, referenceValue, tableNameTag);
       Put put =
           new Put(reference.getRowArray(), reference.getRowOffset(), reference.getRowLength());
       put.add(reference);
       table.mutate(put);
-      context.getCounter(SweepCounter.RECORDS_UPDATED).increment(1);
+      updatedCount++;
     }
     table.flush();
+    context.getCounter(SweepCounter.RECORDS_UPDATED).increment(updatedCount);
     scanner.close();
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/SweepJob.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/SweepJob.java
index 6e4ea98..f137f5e 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/SweepJob.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/SweepJob.java
@@ -85,12 +85,12 @@
   private final FileSystem fs;
   private final Configuration conf;
   private static final Log LOG = LogFactory.getLog(SweepJob.class);
-  static final String SWEEP_JOB_ID = "mob.sweep.job.id";
-  static final String SWEEP_JOB_SERVERNAME = "mob.sweep.job.servername";
-  static final String SWEEP_JOB_TABLE_NODE = "mob.sweep.job.table.node";
-  static final String WORKING_DIR_KEY = "mob.sweep.job.dir";
-  static final String WORKING_ALLNAMES_FILE_KEY = "mob.sweep.job.all.file";
-  static final String WORKING_VISITED_DIR_KEY = "mob.sweep.job.visited.dir";
+  static final String SWEEP_JOB_ID = "hbase.mob.sweep.job.id";
+  static final String SWEEP_JOB_SERVERNAME = "hbase.mob.sweep.job.servername";
+  static final String SWEEP_JOB_TABLE_NODE = "hbase.mob.sweep.job.table.node";
+  static final String WORKING_DIR_KEY = "hbase.mob.sweep.job.dir";
+  static final String WORKING_ALLNAMES_FILE_KEY = "hbase.mob.sweep.job.all.file";
+  static final String WORKING_VISITED_DIR_KEY = "hbase.mob.sweep.job.visited.dir";
   static final String WORKING_ALLNAMES_DIR = "all";
   static final String WORKING_VISITED_DIR = "visited";
   public static final String WORKING_FILES_DIR_KEY = "mob.sweep.job.files.dir";
@@ -480,10 +480,12 @@ public String getValue() {
 
     @Override
     public int compareTo(IndexedResult o) {
-      if (this.value == null) {
+      if (this.value == null && o.getValue() == null) {
         return 0;
       } else if (o.value == null) {
         return 1;
+      } else if (this.value == null) {
+        return -1;
       } else {
         return this.value.compareTo(o.value);
       }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/SweepReducer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/SweepReducer.java
index 787b242..cedb77c 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/SweepReducer.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/SweepReducer.java
@@ -51,6 +51,7 @@
 import org.apache.hadoop.hbase.mob.MobFile;
 import org.apache.hadoop.hbase.mob.MobFileName;
 import org.apache.hadoop.hbase.mob.MobUtils;
+import org.apache.hadoop.hbase.mob.filecompactions.PartitionedMobFileCompactionRequest;
 import org.apache.hadoop.hbase.mob.mapreduce.SweepJob.DummyMobAbortable;
 import org.apache.hadoop.hbase.mob.mapreduce.SweepJob.SweepCounter;
 import org.apache.hadoop.hbase.regionserver.BloomType;
@@ -138,7 +139,9 @@ protected void setup(Context context) throws IOException, InterruptedException {
     mobTableDir = FSUtils.getTableDir(MobUtils.getMobHome(conf), tn);
   }
 
-  private SweepPartition createPartition(SweepPartitionId id, Context context) throws IOException {
+  private SweepPartition createPartition(
+    PartitionedMobFileCompactionRequest.CompactionPartitionId id, Context context)
+    throws IOException {
     return new SweepPartition(id, context);
   }
 
@@ -161,13 +164,13 @@ public void run(Context context) throws IOException, InterruptedException {
       fout = fs.create(nameFilePath, true);
       writer = SequenceFile.createWriter(context.getConfiguration(), fout, String.class,
           String.class, CompressionType.NONE, null);
-      SweepPartitionId id;
+      PartitionedMobFileCompactionRequest.CompactionPartitionId id;
       SweepPartition partition = null;
       // the mob files which have the same start key and date are in the same partition.
       while (context.nextKey()) {
         Text key = context.getCurrentKey();
         String keyString = key.toString();
-        id = SweepPartitionId.create(keyString);
+        id = createPartitionId(keyString);
         if (null == partition || !id.equals(partition.getId())) {
           // It's the first mob file in the current partition.
           if (null != partition) {
@@ -215,21 +218,22 @@ public void run(Context context) throws IOException, InterruptedException {
    */
   public class SweepPartition {
 
-    private final SweepPartitionId id;
+    private final PartitionedMobFileCompactionRequest.CompactionPartitionId id;
     private final Context context;
     private boolean memstoreUpdated = false;
     private boolean mergeSmall = false;
     private final Map<String, MobFileStatus> fileStatusMap = new HashMap<String, MobFileStatus>();
     private final List<Path> toBeDeleted = new ArrayList<Path>();
 
-    public SweepPartition(SweepPartitionId id, Context context) throws IOException {
+    public SweepPartition(PartitionedMobFileCompactionRequest.CompactionPartitionId id,
+      Context context) throws IOException {
       this.id = id;
       this.context = context;
       memstore.setPartitionId(id);
       init();
     }
 
-    public SweepPartitionId getId() {
+    public PartitionedMobFileCompactionRequest.CompactionPartitionId getId() {
       return this.id;
     }
 
@@ -390,58 +394,15 @@ public boolean accept(Path path) {
   }
 
   /**
-   * The sweep partition id.
-   * It consists of the start key and date.
-   * The start key is a hex string of the checksum of a region start key.
-   * The date is the latest timestamp of cells in a mob file.
+   * Creates the partition id.
+   * @param fileNameAsString The current file name, in string.
+   * @return The partition id.
    */
-  public static class SweepPartitionId {
-    private String date;
-    private String startKey;
-
-    public SweepPartitionId(MobFileName fileName) {
-      this.date = fileName.getDate();
-      this.startKey = fileName.getStartKey();
-    }
-
-    public SweepPartitionId(String date, String startKey) {
-      this.date = date;
-      this.startKey = startKey;
-    }
-
-    public static SweepPartitionId create(String key) {
-      return new SweepPartitionId(MobFileName.create(key));
-    }
-
-    @Override
-    public boolean equals(Object anObject) {
-      if (this == anObject) {
-        return true;
-      }
-      if (anObject instanceof SweepPartitionId) {
-        SweepPartitionId another = (SweepPartitionId) anObject;
-        if (this.date.equals(another.getDate()) && this.startKey.equals(another.getStartKey())) {
-          return true;
-        }
-      }
-      return false;
-    }
-
-    public String getDate() {
-      return this.date;
-    }
-
-    public String getStartKey() {
-      return this.startKey;
-    }
-
-    public void setDate(String date) {
-      this.date = date;
-    }
-
-    public void setStartKey(String startKey) {
-      this.startKey = startKey;
-    }
+  private PartitionedMobFileCompactionRequest.CompactionPartitionId createPartitionId(
+    String fileNameAsString) {
+    MobFileName fileName = MobFileName.create(fileNameAsString);
+    return new PartitionedMobFileCompactionRequest.CompactionPartitionId(fileName.getStartKey(),
+      fileName.getDate());
   }
 
   /**
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/Sweeper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/Sweeper.java
index 9342a31..c21fa40 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/Sweeper.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/mapreduce/Sweeper.java
@@ -28,6 +28,7 @@
 import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.classification.InterfaceStability;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.util.Tool;
@@ -43,6 +44,7 @@
  * same column family are mutually exclusive too.
  */
 @InterfaceAudience.Public
+@InterfaceStability.Stable
 public class Sweeper extends Configured implements Tool {
 
   /**
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedMobStoreScanner.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedMobStoreScanner.java
index d1cca98..aa36e3e 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedMobStoreScanner.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ReversedMobStoreScanner.java
@@ -49,7 +49,7 @@
   }
 
   /**
-   * Firstly reads the cells from the HBase. If the cell are a reference cell (which has the
+   * Firstly reads the cells from the HBase. If the cell is a reference cell (which has the
    * reference tag), the scanner need seek this cell from the mob file, and use the cell found
    * from the mob file as the result.
    */
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java
index 8f94795..619a134 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java
@@ -58,7 +58,7 @@
     Pattern.compile("^(" + HFILE_NAME_REGEX + ")");
 
   /**
-   * A non-capture group, for hfiles, so that this can be embedded.
+   * A non-capture group, for del files, so that this can be embedded.
    * A del file has (_del) as suffix.
    */
   public static final String DELFILE_NAME_REGEX = "[0-9a-f]+(?:_del)";
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java
index 175e8d8..e7c4dac 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java
@@ -159,12 +159,12 @@ public void addMobRegion(HRegionInfo regionInfo, HColumnDescriptor[] hcds) throw
     RegionVisitor visitor = createRegionVisitor(desc);
 
     // 1. dump region meta info into the snapshot directory
-    LOG.debug("Storing '" + regionInfo + "' region-info for snapshot.");
+    LOG.debug("Storing mob region '" + regionInfo + "' region-info for snapshot.");
     Object regionData = visitor.regionOpen(regionInfo);
     monitor.rethrowException();
 
     // 2. iterate through all the stores in the region
-    LOG.debug("Creating references for hfiles");
+    LOG.debug("Creating references for mob files");
 
     Path mobRegionPath = MobUtils.getMobRegionPath(conf, regionInfo.getTable());
     for (HColumnDescriptor hcd : hcds) {
@@ -188,7 +188,7 @@ public void addMobRegion(HRegionInfo regionInfo, HColumnDescriptor[] hcds) throw
         storeFiles.add(new StoreFileInfo(conf, fs, stat));
       }
       if (LOG.isDebugEnabled()) {
-        LOG.debug("Adding snapshot references for " + storeFiles + " hfiles");
+        LOG.debug("Adding snapshot references for " + storeFiles + " mob files");
       }
 
       // 2.2. iterate through all the mob files and create "references".
@@ -198,7 +198,7 @@ public void addMobRegion(HRegionInfo regionInfo, HColumnDescriptor[] hcds) throw
 
         // create "reference" to this store file.
         if (LOG.isDebugEnabled()) {
-          LOG.debug("Adding reference for file (" + (i + 1) + "/" + sz + "): "
+          LOG.debug("Adding reference for mob file (" + (i + 1) + "/" + sz + "): "
             + storeFile.getPath());
         }
         visitor.storeFile(regionData, familyData, storeFile);
