diff --git a/security/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java b/security/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java
index b82ad5d..ddc3dc2 100644
--- a/security/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java
+++ b/security/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java
@@ -377,7 +377,7 @@ public class AccessController extends BaseRegionObserver
    * @throws IOException if obtaining the current user fails
    * @throws AccessDeniedException if user has no authorization
    */
-  private void requirePermission(byte[] tableName, byte[] family, byte[] qualifier,
+  public void requirePermission(byte[] tableName, byte[] family, byte[] qualifier,
       Action... permissions) throws IOException {
     User user = getActiveUser();
     AuthResult result = null;
diff --git a/security/src/main/java/org/apache/hadoop/hbase/security/access/SecureGroupAdminEndpoint.java b/security/src/main/java/org/apache/hadoop/hbase/security/access/SecureGroupAdminEndpoint.java
new file mode 100644
index 0000000..215311e
--- /dev/null
+++ b/security/src/main/java/org/apache/hadoop/hbase/security/access/SecureGroupAdminEndpoint.java
@@ -0,0 +1,62 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.security.access;
+
+import org.apache.hadoop.hbase.CoprocessorEnvironment;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment;
+import org.apache.hadoop.hbase.group.GroupAdminEndpoint;
+import org.apache.hadoop.hbase.group.GroupAdminProtocol;
+
+import java.io.IOException;
+import java.util.Set;
+
+public class SecureGroupAdminEndpoint extends GroupAdminEndpoint implements GroupAdminProtocol {
+  private MasterCoprocessorEnvironment menv;
+
+  @Override
+  public void start(CoprocessorEnvironment env) {
+    super.start(env);
+    menv = (MasterCoprocessorEnvironment)env;
+  }
+
+  @Override
+  public void moveServers(Set<String> hostPorts, String dstGroup) throws IOException {
+    getAccessController().requirePermission(HConstants.ROOT_TABLE_NAME, null, null, Permission.Action.ADMIN);
+    super.moveServers(hostPorts, dstGroup);
+  }
+
+  @Override
+  public void removeGroup(String groupName) throws IOException {
+    getAccessController().requirePermission(HConstants.ROOT_TABLE_NAME, null, null, Permission.Action.ADMIN);
+    super.removeGroup(groupName);
+  }
+
+  @Override
+  public void addGroup(String groupName) throws IOException {
+    getAccessController().requirePermission(HConstants.ROOT_TABLE_NAME, null, null, Permission.Action.ADMIN);
+    super.addGroup(groupName);
+  }
+
+  private AccessController getAccessController() {
+    return (AccessController)menv.getMasterServices()
+        .getCoprocessorHost().findCoprocessor(AccessController.class.getName());
+  }
+}
diff --git a/security/src/test/java/org/apache/hadoop/hbase/security/access/TestSecureGroupAdminEndpoint.java b/security/src/test/java/org/apache/hadoop/hbase/security/access/TestSecureGroupAdminEndpoint.java
new file mode 100644
index 0000000..ac9f000
--- /dev/null
+++ b/security/src/test/java/org/apache/hadoop/hbase/security/access/TestSecureGroupAdminEndpoint.java
@@ -0,0 +1,237 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.security.access;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.Coprocessor;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.LargeTests;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException;
+import org.apache.hadoop.hbase.group.GroupAdmin;
+import org.apache.hadoop.hbase.group.GroupBasedLoadBalancer;
+import org.apache.hadoop.hbase.master.MasterCoprocessorHost;
+import org.apache.hadoop.hbase.security.AccessDeniedException;
+import org.apache.hadoop.hbase.security.User;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+
+import java.io.IOException;
+import java.security.PrivilegedExceptionAction;
+import java.util.Set;
+import java.util.TreeSet;
+import java.util.concurrent.atomic.AtomicLong;
+
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
+/**
+ * Performs authorization checks for common operations, according to different
+ * levels of authorized users.
+ */
+@Category(LargeTests.class)
+@SuppressWarnings("rawtypes")
+public class TestSecureGroupAdminEndpoint {
+  private static HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
+  private static Configuration conf;
+
+  // user with all permissions
+  private static User SUPERUSER;
+  // user granted with all global permission
+  private static User USER_ADMIN;
+  // user with rw permissions
+  private static User USER_RW;
+  // user with read-only permissions
+  private static User USER_RO;
+  // user is table owner. will have all permissions on table
+  private static User USER_OWNER;
+  // user with create table permissions alone
+  private static User USER_CREATE;
+  // user with no permissions
+  private static User USER_NONE;
+
+  private static AccessController ACCESS_CONTROLLER;
+  private static SecureGroupAdminEndpoint GROUP_ENDPOINT;
+
+  @BeforeClass
+  public static void setupBeforeClass() throws Exception {
+    // setup configuration
+    conf = TEST_UTIL.getConfiguration();
+    SecureTestUtil.enableSecurity(conf);
+		TEST_UTIL.getConfiguration().set(
+				HConstants.HBASE_MASTER_LOADBALANCER_CLASS,
+				GroupBasedLoadBalancer.class.getName());
+    conf.set("hbase.coprocessor.master.classes",
+        conf.get("hbase.coprocessor.master.classes")+","+SecureGroupAdminEndpoint.class.getName());
+
+    TEST_UTIL.startMiniCluster(1,2);
+    MasterCoprocessorHost cpHost = TEST_UTIL.getMiniHBaseCluster().getMaster().getCoprocessorHost();
+    cpHost.load(AccessController.class, Coprocessor.PRIORITY_HIGHEST, conf);
+    ACCESS_CONTROLLER = (AccessController) cpHost.findCoprocessor(AccessController.class.getName());
+    GROUP_ENDPOINT = (SecureGroupAdminEndpoint)
+        TEST_UTIL.getMiniHBaseCluster().getMaster()
+           .getCoprocessorHost().findCoprocessor(SecureGroupAdminEndpoint.class.getName());
+    // Wait for the ACL table to become available
+    TEST_UTIL.waitTableAvailable(AccessControlLists.ACL_TABLE_NAME, 5000);
+
+
+
+    // create a set of test users
+    SUPERUSER = User.createUserForTesting(conf, "admin", new String[] { "supergroup" });
+    USER_ADMIN = User.createUserForTesting(conf, "admin2", new String[0]);
+    USER_NONE = User.createUserForTesting(conf, "nouser", new String[0]);
+
+    // initialize access control
+    HTable meta = new HTable(conf, AccessControlLists.ACL_TABLE_NAME);
+    AccessControllerProtocol protocol =
+        meta.coprocessorProxy(AccessControllerProtocol.class, HConstants.EMPTY_START_ROW);
+
+    protocol.grant(new UserPermission(Bytes.toBytes(USER_ADMIN.getShortName()),
+        Permission.Action.ADMIN, Permission.Action.CREATE, Permission.Action.READ,
+        Permission.Action.WRITE));
+  }
+
+  @AfterClass
+  public static void tearDownAfterClass() throws Exception {
+    TEST_UTIL.shutdownMiniCluster();
+  }
+
+  public void verifyAllowed(User user, PrivilegedExceptionAction... actions) throws Exception {
+    for (PrivilegedExceptionAction action : actions) {
+      try {
+        user.runAs(action);
+      } catch (AccessDeniedException ade) {
+        fail("Expected action to pass for user '" + user.getShortName() + "' but was denied");
+      }
+    }
+  }
+
+  public void verifyAllowed(PrivilegedExceptionAction action, User... users) throws Exception {
+    for (User user : users) {
+      verifyAllowed(user, action);
+    }
+  }
+
+  public void verifyDenied(User user, PrivilegedExceptionAction... actions) throws Exception {
+    for (PrivilegedExceptionAction action : actions) {
+      try {
+        user.runAs(action);
+        fail("Expected AccessDeniedException for user '" + user.getShortName() + "'");
+      } catch (RetriesExhaustedWithDetailsException e) {
+        // in case of batch operations, and put, the client assembles a
+        // RetriesExhaustedWithDetailsException instead of throwing an
+        // AccessDeniedException
+        boolean isAccessDeniedException = false;
+        for (Throwable ex : e.getCauses()) {
+          if (ex instanceof AccessDeniedException) {
+            isAccessDeniedException = true;
+            break;
+          }
+        }
+        if (!isAccessDeniedException) {
+          fail("Not receiving AccessDeniedException for user '" + user.getShortName() + "'");
+        }
+      } catch (AccessDeniedException ade) {
+        // expected result
+      }
+    }
+  }
+
+  public void verifyDenied(PrivilegedExceptionAction action, User... users) throws Exception {
+    for (User user : users) {
+      verifyDenied(user, action);
+    }
+  }
+
+  @Test
+  public void testGetAddRemove() throws Exception {
+    final AtomicLong counter = new AtomicLong(0);
+
+    PrivilegedExceptionAction getGroup = new PrivilegedExceptionAction() {
+      public Object run() throws Exception {
+        GROUP_ENDPOINT.getGroupInfo("default");
+        return null;
+      }
+    };
+    verifyAllowed(getGroup, SUPERUSER, USER_ADMIN, USER_NONE);
+
+    PrivilegedExceptionAction addGroup = new PrivilegedExceptionAction() {
+      public Object run() throws Exception {
+        GROUP_ENDPOINT.addGroup("testGetAddRemove"+counter.incrementAndGet());
+        return null;
+      }
+    };
+    verifyDenied(addGroup, USER_NONE);
+    verifyAllowed(addGroup, SUPERUSER, USER_ADMIN);
+
+    PrivilegedExceptionAction removeGroup = new PrivilegedExceptionAction() {
+      public Object run() throws Exception {
+        GROUP_ENDPOINT.removeGroup("testGetAddRemove"+counter.getAndDecrement());
+        return null;
+      }
+    };
+    verifyAllowed(removeGroup, SUPERUSER, USER_ADMIN);
+    verifyDenied(removeGroup, USER_NONE);
+  }
+
+  @Test
+  public void testMoveServer() throws Exception {
+    final AtomicLong counter = new AtomicLong(0);
+    Set<String> servers = new TreeSet<String>();
+    for(int i=1;i<=100;i++) {
+      GROUP_ENDPOINT.addGroup("testMoveServer_"+i);
+    }
+
+    PrivilegedExceptionAction action = new PrivilegedExceptionAction() {
+      public Object run() throws Exception {
+        String hostPort;
+        Set<String> set = new TreeSet<String>();
+        hostPort = TEST_UTIL.getMiniHBaseCluster().getRegionServer(1).getServerName().getHostAndPort();
+        set.add(hostPort);
+        GROUP_ENDPOINT.moveServers(set, "testMoveServer_" + counter.incrementAndGet());
+        waitForTransitions(GROUP_ENDPOINT);
+        return null;
+      }
+    };
+    verifyAllowed(action, SUPERUSER, USER_ADMIN);
+    verifyDenied(action, USER_NONE);
+  }
+
+  @Test
+  public void testListGroups() throws Exception {
+    PrivilegedExceptionAction action = new PrivilegedExceptionAction() {
+      public Object run() throws Exception {
+        GROUP_ENDPOINT.listGroups();
+        return null;
+      }
+    };
+    verifyAllowed(action, SUPERUSER, USER_ADMIN,USER_NONE);
+  }
+
+  private static void waitForTransitions(GroupAdmin gAdmin) throws IOException, InterruptedException {
+    while(gAdmin.listServersInTransition().size()>0) {
+      Thread.sleep(1000);
+    }
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/HConstants.java b/src/main/java/org/apache/hadoop/hbase/HConstants.java
index ba657e0..b016603 100644
--- a/src/main/java/org/apache/hadoop/hbase/HConstants.java
+++ b/src/main/java/org/apache/hadoop/hbase/HConstants.java
@@ -407,6 +407,7 @@ public final class HConstants {
   public static final String NAME = "NAME";
   public static final String VERSIONS = "VERSIONS";
   public static final String IN_MEMORY = "IN_MEMORY";
+  public static final String CONFIG = "CONFIG";
 
   /**
    * This is a retry backoff multiplier table similar to the BSD TCP syn
diff --git a/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
index ba3be8e..5ccbba1 100644
--- a/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
+++ b/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
@@ -89,7 +89,7 @@ public class HBaseAdmin implements Abortable, Closeable {
   // want to wait a long time.
   private final int retryLongerMultiplier;
   private boolean aborted;
-  
+
   /**
    * Constructor
    *
@@ -191,7 +191,7 @@ public class HBaseAdmin implements Abortable, Closeable {
     this.aborted = true;
     throw new RuntimeException(why, e);
   }
-  
+
   @Override
   public boolean isAborted(){
     return this.aborted;
@@ -598,7 +598,7 @@ public class HBaseAdmin implements Abortable, Closeable {
         // continue
       }
     }
-    
+
     if (tableExists) {
       throw new IOException("Retries exhausted, it took too long to wait"+
         " for the table " + Bytes.toString(tableName) + " to be deleted.");
@@ -1116,7 +1116,7 @@ public class HBaseAdmin implements Abortable, Closeable {
    * servername is provided then based on the online regions in the specified
    * regionserver the specified region will be closed. The master will not be
    * informed of the close. Note that the regionname is the encoded regionname.
-   * 
+   *
    * @param encodedRegionName
    *          The encoded region name; i.e. the hash that makes up the region
    *          name suffix: e.g. if regionname is
@@ -1747,7 +1747,7 @@ public class HBaseAdmin implements Abortable, Closeable {
    * @param tableName the name of the table
    * @return Ordered list of {@link HRegionInfo}.
    * @throws IOException
-   */  
+   */
   public List<HRegionInfo> getTableRegions(final byte[] tableName)
   throws IOException {
     CatalogTracker ct = getCatalogTracker();
@@ -1759,7 +1759,7 @@ public class HBaseAdmin implements Abortable, Closeable {
     }
     return Regions;
   }
-  
+
   public void close() throws IOException {
     if (this.connection != null) {
       this.connection.close();
@@ -1779,14 +1779,14 @@ public class HBaseAdmin implements Abortable, Closeable {
 
   /**
    * Roll the log writer. That is, start writing log messages to a new file.
-   * 
+   *
    * @param serverName
    *          The servername of the regionserver. A server name is made of host,
    *          port and startcode. This is mandatory. Here is an example:
    *          <code> host187.example.com,60020,1289493121758</code>
    * @return If lots of logs, flush the returned regions so next time through
    * we can clean logs. Returns null if nothing to flush.  Names are actual
-   * region names as returned by {@link HRegionInfo#getEncodedName()}  
+   * region names as returned by {@link HRegionInfo#getEncodedName()}
    * @throws IOException if a remote or network exception occurs
    * @throws FailedLogCloseException
    */
diff --git a/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java b/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java
index 012dc0c..1c5736f 100644
--- a/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java
+++ b/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java
@@ -269,7 +269,7 @@ public class ExecutorService {
     }
     return ret;
   }
-  
+
   /**
    * Executor instance.
    */
diff --git a/src/main/java/org/apache/hadoop/hbase/group/GroupAdmin.java b/src/main/java/org/apache/hadoop/hbase/group/GroupAdmin.java
new file mode 100644
index 0000000..aaa6f95
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/group/GroupAdmin.java
@@ -0,0 +1,115 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.group;
+
+import org.apache.hadoop.hbase.HRegionInfo;
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+public interface GroupAdmin {
+  /**
+   * Get online regions of a region server group.
+   *
+   * @param groupName the name of the group
+   * @return list of online regions this group contains
+   */
+  List<HRegionInfo> listOnlineRegionsOfGroup(String groupName) throws IOException;
+
+  /**
+   * Get member tables of a group.
+   *
+   * @param groupName the name of the group
+   * @return list of table names
+   */
+  Collection<String> listTablesOfGroup(String groupName) throws IOException;
+
+  /**
+   * Gets the group information.
+   *
+   * @param groupName the group name
+   * @return An instance of GroupInfo
+   */
+  GroupInfo getGroupInfo(String groupName) throws IOException;
+
+  /**
+   * Gets the group info of table.
+   *
+   * @param tableName the table name
+   * @return An instance of GroupInfo.
+   */
+  GroupInfo getGroupInfoOfTable(String tableName) throws IOException;
+
+  /**
+   * Move a set of serves to another group
+   *
+   * @param server the server
+   * @param targetGroup the target group
+   * @throws IOException Signals that an I/O exception has occurred.
+   */
+  void moveServers(Set<String> server, String targetGroup) throws IOException;
+
+  /**
+   * Move tables to a new group
+   * @param tables list of tables to move
+   * @param targetGroup target group
+   * @throws IOException
+   */
+  void moveTables(Set<String> tables, String targetGroup) throws IOException;
+
+  /**
+   * Add a new group
+   * @param name name of the group
+   * @throws IOException
+   */
+  void addGroup(String name) throws IOException;
+
+  /**
+   * Remove a new group
+   * @param name name of the group
+   * @throws IOException
+   */
+  void removeGroup(String name) throws IOException;
+
+  /**
+   * Gets the existing groups.
+   *
+   * @return Collection of GroupInfo.
+   */
+  List<GroupInfo> listGroups() throws IOException;
+
+  /**
+   * Retrieve the GroupInfo a server is affiliated to
+   * @param hostPort
+   * @return
+   * @throws IOException
+   */
+  GroupInfo getGroupOfServer(String hostPort) throws IOException;
+
+  /**
+   * List servers that are currently being moved to a new group
+   * @return
+   * @throws IOException
+   */
+  Map<String, String> listServersInTransition() throws IOException;
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/group/GroupAdminClient.java b/src/main/java/org/apache/hadoop/hbase/group/GroupAdminClient.java
new file mode 100644
index 0000000..ead322b
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/group/GroupAdminClient.java
@@ -0,0 +1,126 @@
+/**
+ * Copyright The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.group;
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.DoNotRetryIOException;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.MasterNotRunningException;
+import org.apache.hadoop.hbase.ZooKeeperConnectionException;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+
+/**
+ * This class is responsible for managing region server group information.
+ */
+public class GroupAdminClient implements GroupAdmin {
+  private GroupAdmin proxy;
+	private static final Log LOG = LogFactory.getLog(GroupAdminClient.class);
+  private int operationTimeout;
+
+  public GroupAdminClient(Configuration conf) throws ZooKeeperConnectionException, MasterNotRunningException {
+    proxy = new HBaseAdmin(conf).coprocessorProxy(GroupAdminProtocol.class);
+    operationTimeout = conf.getInt(HConstants.HBASE_CLIENT_OPERATION_TIMEOUT,
+            HConstants.DEFAULT_HBASE_CLIENT_OPERATION_TIMEOUT);
+  }
+
+  @Override
+  public List<HRegionInfo> listOnlineRegionsOfGroup(String groupName) throws IOException {
+    return proxy.listOnlineRegionsOfGroup(groupName);
+  }
+
+  @Override
+  public Collection<String> listTablesOfGroup(String groupName) throws IOException {
+    return proxy.listTablesOfGroup(groupName);
+  }
+
+  @Override
+  public GroupInfo getGroupInfo(String groupName) throws IOException {
+    return proxy.getGroupInfo(groupName);
+  }
+
+  @Override
+  public GroupInfo getGroupInfoOfTable(String tableName) throws IOException {
+    return proxy.getGroupInfoOfTable(tableName);
+  }
+
+  @Override
+  public void moveServers(Set<String> servers, String targetGroup) throws IOException {
+    proxy.moveServers(servers, targetGroup);
+    waitForTransitions(servers);
+  }
+
+  @Override
+  public void moveTables(Set<String> tables, String targetGroup) throws IOException {
+    proxy.moveTables(tables, targetGroup);
+  }
+
+  @Override
+  public void addGroup(String groupName) throws IOException {
+    proxy.addGroup(groupName);
+  }
+
+  @Override
+  public void removeGroup(String name) throws IOException {
+    proxy.removeGroup(name);
+  }
+
+  @Override
+  public List<GroupInfo> listGroups() throws IOException {
+    return proxy.listGroups();
+  }
+
+  @Override
+  public GroupInfo getGroupOfServer(String hostPort) throws IOException {
+    return proxy.getGroupOfServer(hostPort);
+  }
+
+  @Override
+  public Map<String, String> listServersInTransition() throws IOException {
+    return proxy.listServersInTransition();
+  }
+
+  private void waitForTransitions(Set<String> servers) throws IOException {
+    long endTime = System.currentTimeMillis()+operationTimeout;
+    boolean found;
+    do {
+      found = false;
+      for(String server: proxy.listServersInTransition().keySet()) {
+        found = found || servers.contains(server);
+      }
+      try {
+        Thread.sleep(1000);
+      } catch (InterruptedException e) {
+        LOG.debug("Sleep interrupted", e);
+      }
+    } while(found && System.currentTimeMillis() <= endTime);
+    if (found) {
+      throw new DoNotRetryIOException("Operation timed out.");
+    }
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/group/GroupAdminEndpoint.java b/src/main/java/org/apache/hadoop/hbase/group/GroupAdminEndpoint.java
new file mode 100644
index 0000000..60cb4e2
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/group/GroupAdminEndpoint.java
@@ -0,0 +1,210 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.group;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.CoprocessorEnvironment;
+import org.apache.hadoop.hbase.DoNotRetryIOException;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.coprocessor.BaseEndpointCoprocessor;
+import org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment;
+import org.apache.hadoop.hbase.master.MasterServices;
+import org.apache.hadoop.hbase.util.Bytes;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.LinkedBlockingDeque;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+
+/**
+ * Service to support Region Server Grouping (HBase-6721)
+ * This should be installed as a Master CoprocessorEndpoint
+ */
+public class GroupAdminEndpoint extends BaseEndpointCoprocessor
+    implements GroupAdminProtocol {
+	private static final Log LOG = LogFactory.getLog(GroupAdminEndpoint.class);
+
+  private final long threadKeepAliveTimeInMillis = 1000;
+  private int threadMax = 1;
+  private BlockingQueue<Runnable> threadQ;
+  private MasterCoprocessorEnvironment menv;
+  private MasterServices master;
+  private ExecutorService executorService;
+  //List of servers that are being moved from one group to another
+  //Key=host:port,Value=targetGroup
+  private ConcurrentMap<String,String> serversInTransition =
+      new ConcurrentHashMap<String,String>();
+
+  @Override
+  public void start(CoprocessorEnvironment env) {
+    menv = (MasterCoprocessorEnvironment)env;
+    master = menv.getMasterServices();
+    threadQ = new LinkedBlockingDeque<Runnable>();
+    threadMax = menv.getConfiguration().getInt("hbase.group.executor.threads", 1);
+    executorService = new ThreadPoolExecutor(threadMax, threadMax,
+        threadKeepAliveTimeInMillis, TimeUnit.MILLISECONDS, threadQ);
+  }
+
+  @Override
+  public void stop(CoprocessorEnvironment env) {
+    executorService.shutdown();
+  }
+
+  @Override
+  public List<HRegionInfo> listOnlineRegionsOfGroup(String groupName) throws IOException {
+		if (groupName == null) {
+      throw new NullPointerException("groupName can't be null");
+    }
+
+		List<HRegionInfo> regions = new ArrayList<HRegionInfo>();
+    GroupInfo groupInfo = getGroupInfoManager().getGroup(groupName);
+    if (groupInfo == null) {
+			return null;
+		} else {
+			Set<String> servers = groupInfo.getServers();
+      Map<String,List<HRegionInfo>> assignments = getOnlineRegions();
+      for(ServerName serverName: master.getServerManager().getOnlineServersList()) {
+        String hostPort = serverName.getHostAndPort();
+        if (servers.contains(hostPort) && assignments.containsKey(hostPort)) {
+          regions.addAll(assignments.get(hostPort));
+        }
+			}
+		}
+		return regions;
+	}
+
+  @Override
+  public Collection<String> listTablesOfGroup(String groupName) throws IOException {
+    return getGroupInfoManager().getGroup(groupName).getTables();
+	}
+
+
+  @Override
+  public GroupInfo getGroupInfo(String groupName) throws IOException {
+			return getGroupInfoManager().getGroup(groupName);
+	}
+
+
+  @Override
+  public GroupInfo getGroupInfoOfTable(String tableName) throws IOException {
+    return getGroupInfoManager().getGroup(getGroupInfoManager().getGroupOfTable(tableName));
+	}
+
+  @Override
+  public void moveServers(Set<String> servers, String targetGroup)
+			throws IOException {
+		if (servers == null) {
+			throw new IOException(
+					"The list of servers cannot be null.");
+		}
+    if (StringUtils.isEmpty(targetGroup)) {
+			throw new IOException(
+					"The target group cannot be null.");
+    }
+
+    GroupMoveServerWorker.MoveServerPlan plan =
+        new GroupMoveServerWorker.MoveServerPlan(servers, targetGroup);
+    GroupMoveServerWorker worker = null;
+    try {
+      worker = new GroupMoveServerWorker(master, serversInTransition, getGroupInfoManager(), plan);
+      executorService.submit(worker);
+      LOG.info("GroupMoveServerHanndlerSubmitted: "+plan.getTargetGroup());
+    } catch(Exception e) {
+      LOG.error("Failed to submit GroupMoveServerWorker", e);
+      if (worker != null) {
+        worker.complete();
+      }
+      throw new DoNotRetryIOException("Failed to submit GroupMoveServerWorker",e);
+    }
+	}
+
+  @Override
+  public void moveTables(Set<String> tables, String targetGroup) throws IOException {
+    getGroupInfoManager().moveTables(tables, targetGroup);
+    for(String table: tables) {
+      master.getAssignmentManager().unassign(
+          master.getAssignmentManager().getRegionsOfTable(Bytes.toBytes(table)));
+    }
+  }
+
+  @Override
+  public void addGroup(String name) throws IOException {
+    getGroupInfoManager().addGroup(new GroupInfo(name));
+  }
+
+  @Override
+  public void removeGroup(String name) throws IOException {
+    GroupInfoManager manager = getGroupInfoManager();
+    synchronized (manager) {
+      if (listTablesOfGroup(name).size() > 0) {
+        throw new DoNotRetryIOException("Group "+name+" must have no associated tables.");
+      }
+      manager.removeGroup(name);
+    }
+
+  }
+
+  @Override
+  public List<GroupInfo> listGroups() throws IOException {
+    return getGroupInfoManager().listGroups();
+  }
+
+  @Override
+  public GroupInfo getGroupOfServer(String hostPort) throws IOException {
+    return getGroupInfoManager().getGroupOfServer(hostPort);
+  }
+
+  @Override
+  public Map<String, String> listServersInTransition() throws IOException {
+    return Collections.unmodifiableMap(serversInTransition);
+  }
+
+  private GroupInfoManager getGroupInfoManager() throws IOException {
+    return ((GroupBasedLoadBalancer)menv.getMasterServices().getLoadBalancer()).getGroupInfoManager();
+  }
+
+  private Map<String,List<HRegionInfo>> getOnlineRegions() throws IOException {
+    Map<String,List<HRegionInfo>> result = new HashMap<String, List<HRegionInfo>>();
+    for(Map.Entry<ServerName, java.util.List<HRegionInfo>> el:
+        master.getAssignmentManager().getAssignments().entrySet()) {
+      if (!result.containsKey(el.getKey().getHostAndPort())) {
+        result.put(el.getKey().getHostAndPort(),new LinkedList<HRegionInfo>());
+      }
+      result.get(el.getKey().getHostAndPort()).addAll(el.getValue());
+    }
+    return result;
+  }
+
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/group/GroupAdminProtocol.java b/src/main/java/org/apache/hadoop/hbase/group/GroupAdminProtocol.java
new file mode 100644
index 0000000..075509d
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/group/GroupAdminProtocol.java
@@ -0,0 +1,25 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.group;
+
+import org.apache.hadoop.hbase.ipc.CoprocessorProtocol;
+
+public interface GroupAdminProtocol extends GroupAdmin, CoprocessorProtocol {
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/group/GroupBasedLoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/group/GroupBasedLoadBalancer.java
new file mode 100644
index 0000000..592dd02
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/group/GroupBasedLoadBalancer.java
@@ -0,0 +1,412 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.group;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.TreeMap;
+
+import com.google.common.collect.LinkedListMultimap;
+import com.google.common.collect.ListMultimap;
+import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.classification.InterfaceAudience;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.ClusterStatus;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.ServerName;
+
+import com.google.common.collect.ArrayListMultimap;
+import org.apache.hadoop.hbase.master.DefaultLoadBalancer;
+import org.apache.hadoop.hbase.master.LoadBalancer;
+import org.apache.hadoop.hbase.master.MasterServices;
+import org.apache.hadoop.hbase.master.RegionPlan;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.util.ReflectionUtils;
+
+/**
+ * GroupBasedLoadBalancer, used when Region Server Grouping is configured (HBase-6721)
+ * It does region balance based on a table's group membership.
+ *
+ * Most assignment methods contain two exclusive code paths: Online - when the group
+ * table is online and Offline - when it is unavailable.
+ *
+ * During Offline assignments are done randomly irrespective of group memebership.
+ * Though only the catalog tables and the group talbes are given non-empty/null assignments.
+ *
+ */
+public class GroupBasedLoadBalancer implements LoadBalancer {
+  /** Config for pluggable load balancers */
+  public static final String HBASE_GROUP_LOADBALANCER_CLASS = "hbase.group.grouploadbalancer.class";
+
+  private static final Log LOG = LogFactory.getLog(GroupBasedLoadBalancer.class);
+  private static final ServerName BOGUS_SERVER_NAME = ServerName.parseServerName("127.0.0.1:1");
+
+  public static final Set<String> SPECIAL_TABLES = new HashSet<String>();
+  static {
+    SPECIAL_TABLES.add(Bytes.toString(HConstants.ROOT_TABLE_NAME));
+    SPECIAL_TABLES.add(Bytes.toString(HConstants.META_TABLE_NAME));
+    SPECIAL_TABLES.add(GroupInfoManager.GROUP_TABLE_NAME);
+  }
+
+  private Configuration config;
+  private ClusterStatus clusterStatus;
+  private MasterServices masterServices;
+  private GroupInfoManager groupManager;
+  private LoadBalancer internalBalancer;
+
+  //used during reflection by LoadBalancerFactory
+  @InterfaceAudience.Private
+  public GroupBasedLoadBalancer() {
+  }
+
+  //This constructor should only be used for unit testing
+  @InterfaceAudience.Private
+  public GroupBasedLoadBalancer(GroupInfoManager groupManager) {
+    this.groupManager = groupManager;
+  }
+
+  @Override
+  public Configuration getConf() {
+    return config;
+  }
+
+  @Override
+  public void setConf(Configuration conf) {
+    this.config = conf;
+  }
+
+  @Override
+  public void setClusterStatus(ClusterStatus st) {
+    this.clusterStatus = st;
+  }
+
+  @Override
+  public void setMasterServices(MasterServices masterServices) {
+    this.masterServices = masterServices;
+  }
+
+  @Override
+  public List<RegionPlan> balanceCluster(Map<ServerName, List<HRegionInfo>> clusterState) {
+
+    if (!isOnline()) {
+      throw new IllegalStateException(GroupInfoManager.GROUP_TABLE_NAME+
+          " is not online, unable to perform balance");
+    }
+
+    Map<ServerName,List<HRegionInfo>> correctedState = correctAssignments(clusterState);
+    List<RegionPlan> regionPlans = new ArrayList<RegionPlan>();
+    try {
+      for (GroupInfo info : groupManager.listGroups()) {
+        Map<ServerName, List<HRegionInfo>> groupClusterState = new HashMap<ServerName, List<HRegionInfo>>();
+        for (String sName : info.getServers()) {
+          ServerName actual = ServerName.findServerWithSameHostnamePort(
+              clusterState.keySet(), ServerName.parseServerName(sName));
+          if (actual != null) {
+            groupClusterState.put(actual, correctedState.get(actual));
+          }
+        }
+        List<RegionPlan> groupPlans = this.internalBalancer
+            .balanceCluster(groupClusterState);
+        if (groupPlans != null) {
+          regionPlans.addAll(groupPlans);
+        }
+      }
+    } catch (IOException exp) {
+      LOG.warn("Exception while balancing cluster.", exp);
+    }
+    return regionPlans;
+  }
+
+  @Override
+  public Map<ServerName, List<HRegionInfo>> roundRobinAssignment(
+      List<HRegionInfo> regions, List<ServerName> servers) {
+    Map<ServerName, List<HRegionInfo>> assignments = Maps.newHashMap();
+    try {
+      ListMultimap<String,HRegionInfo> regionMap = LinkedListMultimap.create();
+      ListMultimap<String,ServerName> serverMap = LinkedListMultimap.create();
+      generateGroupMaps(regions, servers, regionMap, serverMap);
+      for(String groupKey : regionMap.keySet()) {
+        if (regionMap.get(groupKey).size() > 0) {
+          assignments.putAll(
+              this.internalBalancer.roundRobinAssignment(
+                  regionMap.get(groupKey),
+                  serverMap.get(groupKey)));
+        }
+      }
+    } catch (IOException e) {
+      LOG.error("Failed to access group store", e);
+    }
+    return assignments;
+  }
+
+  @Override
+  public Map<ServerName, List<HRegionInfo>> retainAssignment(
+      Map<HRegionInfo, ServerName> regions, List<ServerName> servers) {
+    if (!isOnline()) {
+      //We will just keep assignments even if they are incorrect.
+      //Chances are most will be assigned correctly.
+      //Then we just use balance to correct the misplaced few.
+      //we need to correct catalog and group table assignment anyway.
+      return internalBalancer.retainAssignment(regions, servers);
+    }
+    return onlineRetainAssignment(regions, servers);
+  }
+
+  public Map<ServerName, List<HRegionInfo>> onlineRetainAssignment(
+      Map<HRegionInfo, ServerName> regions, List<ServerName> servers) {
+    try {
+      Map<ServerName, List<HRegionInfo>> assignments = new TreeMap<ServerName, List<HRegionInfo>>();
+      ListMultimap<String, HRegionInfo> groupToRegion = ArrayListMultimap.create();
+      List<HRegionInfo> misplacedRegions = getMisplacedRegions(regions);
+      for (HRegionInfo region : regions.keySet()) {
+        if (!misplacedRegions.contains(region)) {
+          String groupName = groupManager.getGroupOfTable(region.getTableNameAsString());
+          groupToRegion.put(groupName, region);
+        }
+      }
+      // Now the "groupToRegion" map has only the regions which have correct
+      // assignments.
+      for (String key : groupToRegion.keys()) {
+        Map<HRegionInfo, ServerName> currentAssignmentMap = new TreeMap<HRegionInfo, ServerName>();
+        List<HRegionInfo> regionList = groupToRegion.get(key);
+        GroupInfo info = groupManager.getGroup(key);
+        List<ServerName> candidateList = filterOfflineServers(info, servers);
+        for (HRegionInfo region : regionList) {
+          currentAssignmentMap.put(region, regions.get(region));
+        }
+        assignments.putAll(this.internalBalancer.retainAssignment(
+            currentAssignmentMap, candidateList));
+      }
+
+      for (HRegionInfo region : misplacedRegions) {
+        String groupName = groupManager.getGroupOfTable(
+            region.getTableNameAsString());
+        GroupInfo info = groupManager.getGroup(groupName);
+        List<ServerName> candidateList = filterOfflineServers(info, servers);
+        ServerName server = this.internalBalancer.randomAssignment(region,
+            candidateList);
+        if (assignments.containsKey(server) == false) {
+          assignments.put(server, new ArrayList<HRegionInfo>());
+        }
+        assignments.get(server).add(region);
+      }
+      return assignments;
+    } catch (IOException e) {
+      LOG.error("Failed to access group store", e);
+      throw new IllegalStateException("Failed to access group store", e);
+    }
+  }
+
+  @Override
+  public Map<HRegionInfo, ServerName> immediateAssignment(
+      List<HRegionInfo> regions, List<ServerName> servers) {
+    Map<HRegionInfo,ServerName> assignments = Maps.newHashMap();
+    try {
+      ListMultimap<String,HRegionInfo> regionMap = LinkedListMultimap.create();
+      ListMultimap<String,ServerName> serverMap = LinkedListMultimap.create();
+      generateGroupMaps(regions, servers, regionMap, serverMap);
+      for(String groupKey : regionMap.keySet()) {
+        if (regionMap.get(groupKey).size() > 0) {
+          assignments.putAll(
+              this.internalBalancer.immediateAssignment(
+                  regionMap.get(groupKey),
+                  serverMap.get(groupKey)));
+        }
+      }
+    } catch (IOException e) {
+      LOG.error("Failed to access group store", e);
+    }
+    return assignments;
+  }
+
+  @Override
+  public ServerName randomAssignment(HRegionInfo region,
+      List<ServerName> servers) {
+    try {
+      ListMultimap<String,HRegionInfo> regionMap = LinkedListMultimap.create();
+      ListMultimap<String,ServerName> serverMap = LinkedListMultimap.create();
+      generateGroupMaps(Lists.newArrayList(region), servers, regionMap, serverMap);
+      List<ServerName> filteredServers = serverMap.get(regionMap.keySet().iterator().next());
+      return this.internalBalancer.randomAssignment(region, filteredServers);
+    } catch (IOException e) {
+      LOG.error("Failed to access group store", e);
+    }
+    return null;
+  }
+
+  private void generateGroupMaps(
+    List<HRegionInfo> regions,
+    List<ServerName> servers,
+    ListMultimap<String, HRegionInfo> regionMap,
+    ListMultimap<String, ServerName> serverMap) throws IOException {
+    if (isOnline()) {
+      for (HRegionInfo region : regions) {
+        String groupName = groupManager.getGroupOfTable(region.getTableNameAsString());
+        regionMap.put(groupName, region);
+      }
+      for (String groupKey : regionMap.keys()) {
+        GroupInfo info = groupManager.getGroup(groupKey);
+        serverMap.putAll(groupKey, filterOfflineServers(info, servers));
+      }
+    } else {
+      String nullGroup = "_null";
+      //populate serverMap
+      for(GroupInfo groupInfo: groupManager.listGroups()) {
+        serverMap.putAll(groupInfo.getName(), filterOfflineServers(groupInfo, servers));
+      }
+      //Add bogus server
+      serverMap.put(nullGroup, BOGUS_SERVER_NAME);
+      //group regions
+      for (HRegionInfo region : regions) {
+        //Even though some of the non-special tables may be part of the cached groups.
+        //We don't assign them here.
+        if(SPECIAL_TABLES.contains(region.getTableNameAsString())) {
+          regionMap.put(groupManager.getGroupOfTable(region.getTableNameAsString()),region);
+        } else {
+          regionMap.put(nullGroup,region);
+        }
+      }
+    }
+  }
+
+  private List<ServerName> filterOfflineServers(GroupInfo groupInfo,
+                                                List<ServerName> onlineServers) {
+    if (groupInfo != null) {
+      return filterServers(groupInfo.getServers(), onlineServers);
+    } else {
+      LOG.debug("Group Information found to be null. Some regions might be unassigned.");
+      return Collections.EMPTY_LIST;
+    }
+  }
+
+  /**
+   * Filter servers based on the online servers.
+   *
+   * @param servers
+   *          the servers
+   * @param onlineServers
+   *          List of servers which are online.
+   * @return the list
+   */
+  private List<ServerName> filterServers(Collection<String> servers,
+      Collection<ServerName> onlineServers) {
+    ArrayList<ServerName> finalList = new ArrayList<ServerName>();
+    for (String server : servers) {
+      ServerName actual = ServerName.findServerWithSameHostnamePort(
+          onlineServers, ServerName.parseServerName(server));
+      if (actual != null) {
+        finalList.add(actual);
+      }
+    }
+    return finalList;
+  }
+
+  private ListMultimap<String, HRegionInfo> groupRegions(
+      List<HRegionInfo> regionList) throws IOException {
+    ListMultimap<String, HRegionInfo> regionGroup = ArrayListMultimap
+        .create();
+    for (HRegionInfo region : regionList) {
+      String groupName = groupManager.getGroupOfTable(region.getTableNameAsString());
+      regionGroup.put(groupName, region);
+    }
+    return regionGroup;
+  }
+
+  private List<HRegionInfo> getMisplacedRegions(
+      Map<HRegionInfo, ServerName> regions) throws IOException {
+    List<HRegionInfo> misplacedRegions = new ArrayList<HRegionInfo>();
+    for (HRegionInfo region : regions.keySet()) {
+      ServerName assignedServer = regions.get(region);
+      GroupInfo info = groupManager.getGroup(groupManager.getGroupOfTable(region.getTableNameAsString()));
+      if ((info == null)|| (!info.containsServer(assignedServer.getHostAndPort()))) {
+        misplacedRegions.add(region);
+      }
+    }
+    return misplacedRegions;
+  }
+
+  private Map<ServerName, List<HRegionInfo>> correctAssignments(
+       Map<ServerName, List<HRegionInfo>> existingAssignments){
+    Map<ServerName, List<HRegionInfo>> correctAssignments = new TreeMap<ServerName, List<HRegionInfo>>();
+    List<HRegionInfo> misplacedRegions = new LinkedList<HRegionInfo>();
+    for (ServerName sName : existingAssignments.keySet()) {
+      correctAssignments.put(sName, new LinkedList<HRegionInfo>());
+      List<HRegionInfo> regions = existingAssignments.get(sName);
+      for (HRegionInfo region : regions) {
+        GroupInfo info = null;
+        try {
+          info = groupManager.getGroup(groupManager.getGroupOfTable(region.getTableNameAsString()));
+        }catch(IOException exp){
+          LOG.debug("Group information null for region of table " + region.getTableNameAsString(),
+              exp);
+        }
+        if ((info == null) || (!info.containsServer(sName.getHostAndPort()))) {
+          // Misplaced region.
+          misplacedRegions.add(region);
+        } else {
+          correctAssignments.get(sName).add(region);
+        }
+      }
+    }
+
+    //unassign misplaced regions, so that they are assigned to correct groups.
+    this.masterServices.getAssignmentManager().unassign(misplacedRegions);
+    return correctAssignments;
+  }
+
+  @Override
+  public void configure() throws IOException {
+    // Create the balancer
+    Class<? extends LoadBalancer> balancerKlass = config.getClass(
+        HBASE_GROUP_LOADBALANCER_CLASS,
+        DefaultLoadBalancer.class, LoadBalancer.class);
+    internalBalancer = ReflectionUtils.newInstance(balancerKlass, config);
+    internalBalancer.setClusterStatus(clusterStatus);
+    internalBalancer.setMasterServices(masterServices);
+    internalBalancer.setConf(config);
+    internalBalancer.configure();
+    //this will only happen if the unit tests constructor is used
+    if (groupManager == null) {
+      groupManager = new GroupInfoManagerImpl(masterServices);
+    }
+  }
+
+  public boolean isOnline() {
+    return groupManager != null && groupManager.isOnline();
+  }
+
+  @InterfaceAudience.Private
+  public GroupInfoManager getGroupInfoManager() throws IOException {
+    return groupManager;
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/group/GroupInfo.java b/src/main/java/org/apache/hadoop/hbase/group/GroupInfo.java
new file mode 100644
index 0000000..dc30b7b
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/group/GroupInfo.java
@@ -0,0 +1,197 @@
+/**
+ * Copyright The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.group;
+
+import java.io.Serializable;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Set;
+
+import com.google.common.collect.Sets;
+import org.codehaus.jackson.annotate.JsonCreator;
+import org.codehaus.jackson.annotate.JsonProperty;
+
+/**
+ * Stores the group information of region server groups.
+ */
+public class GroupInfo implements Serializable {
+
+	public static final String DEFAULT_GROUP = "default";
+  public static final String OFFLINE_DEFAULT_GROUP = "_offline_default";
+  public static final String TRANSITION_GROUP_PREFIX = "_transition_";
+	public static final String GROUP_KEY = "rs_group";
+
+  private String name;
+  private Set<String> servers;
+  private Set<String> tables;
+
+  public GroupInfo(String name) {
+		this.name = name;
+    this.servers = new HashSet<String>();
+    this.tables = new HashSet<String>();
+	}
+
+  //constructor for jackson
+  @JsonCreator
+  private GroupInfo(@JsonProperty("name") String name,
+                    @JsonProperty("servers") Set<String> servers,
+                    @JsonProperty("tables") Set<String> tables) {
+		this.name = name;
+    this.servers = servers;
+    this.tables = tables;
+	}
+
+  public GroupInfo(GroupInfo src) {
+    name = src.getName();
+    servers = Sets.newHashSet(src.getServers());
+    tables = Sets.newHashSet(src.getTables());
+  }
+
+	/**
+	 * Get group name.
+	 *
+	 * @return
+	 */
+	public String getName() {
+		return name;
+	}
+
+	/**
+	 * Adds the server to the group.
+	 *
+	 * @param hostPort the server
+	 */
+	public void addServer(String hostPort){
+		this.servers.add(hostPort);
+	}
+
+	/**
+	 * Adds a group of servers.
+	 *
+	 * @param hostPort the servers
+	 */
+	public void addAllServers(Collection<String> hostPort){
+		this.servers.addAll(hostPort);
+	}
+
+	public boolean containsServer(String hostPort) {
+    return servers.contains(hostPort);
+	}
+
+	/**
+	 * Checks based of equivalence of host name and port.
+	 *
+	 * @param serverList The list to check for containment.
+	 * @return true, if successful
+	 */
+	public boolean containsServer(Set<String> serverList) {
+		if (serverList.size() == 0) {
+			return false;
+		} else {
+			boolean contains = true;
+			for (String hostPort : serverList) {
+				contains = contains && this.getServers().contains(hostPort);
+				if (!contains)
+					return contains;
+			}
+			return contains;
+		}
+	}
+
+
+	/**
+	 * Get a copy of servers.
+	 *
+	 * @return
+	 */
+	public Set<String> getServers() {
+		return Collections.unmodifiableSet(this.servers);
+	}
+
+	/**
+	 * Remove a server from this group.
+	 *
+	 * @param hostPort
+	 */
+	public boolean removeServer(String hostPort) {
+    return this.servers.remove(hostPort);
+	}
+
+  /**
+   * Set of tables that are members of this group
+   * @return
+   */
+  public Set<String> getTables() {
+    return Collections.unmodifiableSet(tables);
+  }
+
+  public void addTable(String table) {
+    tables.add(table);
+  }
+
+  public void addAllTables(Collection<String> arg) {
+    tables.addAll(arg);
+  }
+
+  public boolean containsTable(String table) {
+    return tables.contains(table);
+  }
+
+  public boolean removeTable(String table) {
+    return tables.remove(table);
+  }
+
+  @Override
+	public String toString() {
+		StringBuffer sb = new StringBuffer();
+		sb.append("{GroupName:");
+		sb.append(this.name);
+		sb.append("-");
+		sb.append(" Severs:");
+		sb.append(this.servers+ "}");
+		return sb.toString();
+
+	}
+
+  @Override
+  public boolean equals(Object o) {
+    if (this == o) return true;
+    if (o == null || getClass() != o.getClass()) return false;
+
+    GroupInfo groupInfo = (GroupInfo) o;
+
+    if (!name.equals(groupInfo.name)) return false;
+    if (!servers.equals(groupInfo.servers)) return false;
+    if (!tables.equals(groupInfo.tables)) return false;
+
+    return true;
+  }
+
+  @Override
+  public int hashCode() {
+    int result = servers.hashCode();
+    result = 31 * result + tables.hashCode();
+    result = 31 * result + name.hashCode();
+    return result;
+  }
+
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/group/GroupInfoManager.java b/src/main/java/org/apache/hadoop/hbase/group/GroupInfoManager.java
new file mode 100644
index 0000000..c2950b4
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/group/GroupInfoManager.java
@@ -0,0 +1,120 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.group;
+
+import org.apache.hadoop.hbase.util.Bytes;
+
+import java.io.IOException;
+import java.util.List;
+import java.util.Set;
+
+public interface GroupInfoManager {
+  public static final String GROUP_TABLE_NAME = "_GROUP_";
+  public static final byte[] GROUP_TABLE_NAME_BYTES = Bytes.toBytes(GROUP_TABLE_NAME);
+  public static final byte[] SERVER_FAMILY_BYTES = Bytes.toBytes("servers");
+  public static final byte[] TABLE_FAMILY_BYTES = Bytes.toBytes("tables");
+  public static final byte[] INFO_FAMILY_BYTES = Bytes.toBytes("info");
+
+  /**
+   * Adds the group.
+   *
+   * @param groupInfo the group name
+   * @throws java.io.IOException Signals that an I/O exception has occurred.
+   */
+  void addGroup(GroupInfo groupInfo) throws IOException;
+
+  /**
+   * Remove a region server group.
+   *
+   * @param groupName the group name
+   * @throws java.io.IOException Signals that an I/O exception has occurred.
+   */
+  void removeGroup(String groupName) throws IOException;
+
+  /**
+   * move servers to a new group.
+   * @param hostPort list of servers, must be part of the same group
+   * @param srcGroup
+   * @param dstGroup
+   * @return
+   * @throws IOException
+   */
+  boolean moveServers(Set<String> hostPort, String srcGroup, String dstGroup) throws IOException;
+
+  /**
+   * Gets the group info of server.
+   *
+   * @param hostPort the server
+   * @return An instance of GroupInfo.
+   */
+  GroupInfo getGroupOfServer(String hostPort) throws IOException;
+
+  /**
+   * Gets the group information.
+   *
+   * @param groupName the group name
+   * @return An instance of GroupInfo
+   */
+  GroupInfo getGroup(String groupName) throws IOException;
+
+  /**
+   * Get the group membership of a table
+   * @param tableName
+   * @return
+   * @throws IOException
+   */
+	String getGroupOfTable(String tableName) throws IOException;
+
+  /**
+   * Set the group membership of a table
+   *
+   *
+   * @param tableName
+   * @param groupName
+   * @return
+   * @throws IOException
+   */
+  void moveTables(Set<String> tableName, String groupName) throws IOException;
+
+  /**
+   * List the groups
+   *
+   * @return
+   * @throws IOException
+   */
+  List<GroupInfo> listGroups() throws IOException;
+
+  /**
+   * Refresh/reload the group information from
+   * the persistent store
+   *
+   * @throws IOException
+   */
+  void refresh() throws IOException;
+
+  /**
+   * Wether the manager is able to fully
+   * return group metadata
+   *
+   * @return
+   */
+  boolean isOnline();
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/group/GroupInfoManagerImpl.java b/src/main/java/org/apache/hadoop/hbase/group/GroupInfoManagerImpl.java
new file mode 100644
index 0000000..2aa0ef6
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/group/GroupInfoManagerImpl.java
@@ -0,0 +1,474 @@
+/**
+ * Copyright 2009 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.group;
+
+import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.DoNotRetryIOException;
+import org.apache.hadoop.hbase.HColumnDescriptor;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.client.Delete;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.MetaScanner;
+import org.apache.hadoop.hbase.client.Put;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.master.MasterServices;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Writables;
+import org.apache.hadoop.hbase.zookeeper.ZKUtil;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
+import org.apache.zookeeper.KeeperException;
+import org.codehaus.jackson.map.ObjectMapper;
+import org.codehaus.jackson.type.TypeReference;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.atomic.AtomicInteger;
+
+public class GroupInfoManagerImpl implements GroupInfoManager {
+	private static final Log LOG = LogFactory.getLog(GroupInfoManagerImpl.class);
+  private static final String groupZNode = "groupInfo";
+
+	//Access to this map should always be synchronized.
+	private Map<String, GroupInfo> groupMap;
+  private Map<String, GroupInfo> tableMap;
+  private MasterServices master;
+  private HTable table;
+  private ZooKeeperWatcher watcher;
+  private GroupStartupWorker groupStartupWorker;
+
+  public GroupInfoManagerImpl(MasterServices master) throws IOException {
+		this.groupMap = new ConcurrentHashMap<String, GroupInfo>();
+		this.tableMap = new ConcurrentHashMap<String, GroupInfo>();
+    this.master = master;
+    this.watcher = master.getZooKeeper();
+    groupStartupWorker = new GroupStartupWorker(this, master, GROUP_TABLE_NAME_BYTES);
+    refresh();
+    groupStartupWorker.start();
+  }
+
+	/**
+	 * Adds the group.
+	 *
+	 * @param groupInfo the group name
+	 * @throws java.io.IOException Signals that an I/O exception has occurred.
+	 */
+  @Override
+  public synchronized void addGroup(GroupInfo groupInfo) throws IOException {
+		if (groupMap.get(groupInfo.getName()) != null ||
+        groupInfo.getName().equals(GroupInfo.DEFAULT_GROUP)) {
+      throw new DoNotRetryIOException("Group already exists: "+groupInfo.getName());
+    }
+    groupMap.put(groupInfo.getName(), groupInfo);
+    try {
+      flushConfig();
+    } catch (IOException e) {
+      groupMap.remove(groupInfo.getName());
+      throw e;
+    }
+	}
+
+  @Override
+  public synchronized boolean moveServers(Set<String> hostPort, String srcGroup, String dstGroup) throws IOException {
+    GroupInfo src = new GroupInfo(getGroup(srcGroup));
+    GroupInfo dst = new GroupInfo(getGroup(dstGroup));
+    boolean foundOne = false;
+    for(String el: hostPort) {
+      foundOne = foundOne || src.removeServer(el);
+      dst.addServer(el);
+    }
+
+    Map<String,GroupInfo> newMap = Maps.newHashMap(groupMap);
+    if (!src.getName().equals(GroupInfo.DEFAULT_GROUP)) {
+      newMap.put(src.getName(), src);
+    }
+    if (!dst.getName().equals(GroupInfo.DEFAULT_GROUP)) {
+      newMap.put(dst.getName(), dst);
+    }
+    flushConfig(newMap);
+    groupMap = newMap;
+    return foundOne;
+  }
+
+  /**
+	 * Gets the group info of server.
+	 *
+	 * @param hostPort the server
+	 * @return An instance of GroupInfo.
+	 */
+  @Override
+  public synchronized GroupInfo getGroupOfServer(String hostPort) throws IOException {
+		for(GroupInfo info : groupMap.values()){
+			if (info.containsServer(hostPort)){
+				return info;
+			}
+		}
+		return getGroup(GroupInfo.DEFAULT_GROUP);
+	}
+
+	/**
+	 * Gets the group information.
+	 *
+	 * @param groupName the group name
+	 * @return An instance of GroupInfo
+	 */
+  @Override
+  public synchronized GroupInfo getGroup(String groupName) throws IOException {
+		if (groupName.equalsIgnoreCase(GroupInfo.DEFAULT_GROUP)) {
+			GroupInfo defaultInfo = new GroupInfo(GroupInfo.DEFAULT_GROUP);
+      List<ServerName> unassignedServers =
+          difference(getOnlineRS(),getAssignedServers());
+      for(ServerName serverName: unassignedServers) {
+        defaultInfo.addServer(serverName.getHostAndPort());
+      }
+      for(String tableName: master.getTableDescriptors().getAll().keySet()) {
+        if (!tableMap.containsKey(tableName)) {
+          defaultInfo.addTable(tableName);
+        }
+      }
+      for(String tableName: GroupBasedLoadBalancer.SPECIAL_TABLES) {
+        if (!tableMap.containsKey(tableName)) {
+          defaultInfo.addTable(tableName);
+        }
+      }
+			return defaultInfo;
+		} else {
+			return this.groupMap.get(groupName);
+		}
+	}
+
+  @Override
+  public synchronized String getGroupOfTable(String tableName) throws IOException {
+    if (tableMap.containsKey(tableName)) {
+      return tableMap.get(tableName).getName();
+    }
+    return GroupInfo.DEFAULT_GROUP;
+  }
+
+  @Override
+  public synchronized void moveTables(Set<String> tableNames, String groupName) throws IOException {
+    for(String tableName: tableNames) {
+      moveTable(tableName, groupName);
+    }
+    flushConfig();
+  }
+
+  private synchronized void moveTable(String tableName, String groupName) throws IOException {
+    if (!GroupInfo.DEFAULT_GROUP.equals(groupName) && !groupMap.containsKey(groupName)) {
+      throw new DoNotRetryIOException("Group does not exist");
+    }
+    if (tableMap.containsKey(tableName)) {
+      tableMap.get(tableName).removeTable(tableName);
+      tableMap.remove(tableName);
+    }
+    if (!GroupInfo.DEFAULT_GROUP.equals(groupName)) {
+      groupMap.get(groupName).addTable(tableName);
+      tableMap.put(tableName, groupMap.get(groupName));
+    }
+    flushConfig();
+  }
+
+
+  /**
+	 * Delete a region server group.
+	 *
+	 * @param groupName the group name
+	 * @throws IOException Signals that an I/O exception has occurred.
+	 */
+  @Override
+  public synchronized void removeGroup(String groupName) throws IOException {
+    GroupInfo group = null;
+    if (!groupMap.containsKey(groupName) || groupName.equals(GroupInfo.DEFAULT_GROUP)) {
+      throw new IllegalArgumentException("Group "+groupName+" does not exist or is default group");
+    }
+    try {
+      group = groupMap.remove(groupName);
+      table.delete(new Delete(Bytes.toBytes(groupName)));
+    } catch (IOException e) {
+      groupMap.put(groupName, group);
+      throw e;
+    }
+	}
+
+  @Override
+  public synchronized List<GroupInfo> listGroups() throws IOException {
+    List<GroupInfo> list = Lists.newLinkedList(groupMap.values());
+    list.add(getGroup(GroupInfo.DEFAULT_GROUP));
+    return list;
+  }
+
+  @Override
+  public boolean isOnline() {
+    return groupStartupWorker.isOnline();
+  }
+
+  @Override
+  public synchronized void refresh() throws IOException {
+    refresh(false);
+  }
+
+  private synchronized void refresh(boolean skipCheck) throws IOException {
+    List<GroupInfo> groupList = new LinkedList<GroupInfo>();
+    if (skipCheck || isOnline()) {
+      if (table == null) {
+        table = new HTable(master.getConfiguration(), GROUP_TABLE_NAME_BYTES);
+      }
+      for(Result result: table.getScanner(new Scan())) {
+        GroupInfo group =
+            new GroupInfo(Bytes.toString(result.getRow()));
+        for(byte[] server: result.getFamilyMap(SERVER_FAMILY_BYTES).keySet()) {
+          group.addServer(Bytes.toString(server));
+        }
+        for(byte[] table: result.getFamilyMap(TABLE_FAMILY_BYTES).keySet()) {
+          group.addTable(Bytes.toString(table));
+        }
+        groupList.add(group);
+      }
+    }
+    //Overwrite and info stored by table, this takes precedence
+    String groupPath = ZKUtil.joinZNode(watcher.baseZNode,groupZNode);
+    try {
+      if(ZKUtil.checkExists(watcher,groupPath) != -1) {
+        byte[] data = ZKUtil.getData(watcher, groupPath);
+        ObjectMapper mapper = new ObjectMapper();
+        LOG.debug("Reading ZK GroupInfo:"+Bytes.toString(data));
+        groupList.addAll(
+            (List<GroupInfo>) mapper.readValue(data, new TypeReference<List<GroupInfo>>() {
+            }));
+      }
+    } catch (KeeperException e) {
+      throw new IOException("Failed to write to groupZNode",e);
+    }
+    //populate the data
+    this.groupMap.clear();
+    this.tableMap.clear();
+    for (GroupInfo group : groupList) {
+      if(!group.getName().equals(GroupInfo.OFFLINE_DEFAULT_GROUP) || !isOnline()) {
+        groupMap.put(group.getName(), group);
+        for(String table: group.getTables()) {
+          tableMap.put(table, group);
+        }
+      }
+    }
+	}
+
+	/**
+	 * Write the configuration to HDFS.
+	 *
+	 * @throws IOException
+	 */
+	private synchronized void flushConfig() throws IOException {
+    flushConfig(groupMap);
+	}
+
+	private synchronized void flushConfig(Map<String,GroupInfo> map) throws IOException {
+    List<GroupInfo> zGroup = new LinkedList<GroupInfo>();
+    List<Put> puts = new LinkedList<Put>();
+    for(GroupInfo groupInfo : map.values()) {
+      Put put = new Put(Bytes.toBytes(groupInfo.getName()));
+      put.add(INFO_FAMILY_BYTES, Bytes.toBytes("created"),
+          Bytes.toBytes(System.currentTimeMillis()));
+      for(String server: groupInfo.getServers()) {
+        put.add(SERVER_FAMILY_BYTES, Bytes.toBytes(server), new byte[0]);
+      }
+      if (put.size() > 0) {
+        puts.add(put);
+      }
+      for(String special: GroupBasedLoadBalancer.SPECIAL_TABLES) {
+        if (groupInfo.getTables().contains(special)) {
+          zGroup.add(groupInfo);
+          break;
+        }
+      }
+    }
+    //copy default group to offline group
+    GroupInfo defaultGroup = getGroup(GroupInfo.DEFAULT_GROUP);
+    GroupInfo offlineGroup = new GroupInfo(GroupInfo.OFFLINE_DEFAULT_GROUP);
+    offlineGroup.addAllServers(defaultGroup.getServers());
+    offlineGroup.addAllTables(defaultGroup.getTables());
+    zGroup.add(offlineGroup);
+    //Write zk data first since that's what we'll read first
+    String groupPath = ZKUtil.joinZNode(watcher.baseZNode,groupZNode);
+    try {
+      ObjectMapper mapper = new ObjectMapper();
+      ByteArrayOutputStream bos = new ByteArrayOutputStream();
+      mapper.writeValue(bos, zGroup);
+      LOG.debug("Writing ZK GroupInfo:"+Bytes.toString(bos.toByteArray()));
+      ZKUtil.createSetData(watcher, groupPath, bos.toByteArray());
+    } catch (KeeperException e) {
+      throw new IOException("Failed to write to groupZNode",e);
+    }
+    if (puts.size() > 0) {
+      table.put(puts);
+    }
+  }
+
+  private List<ServerName> getOnlineRS() throws IOException{
+    if (master != null) {
+      return master.getServerManager().getOnlineServersList();
+    }
+    try {
+      List<ServerName> servers = new LinkedList<ServerName>();
+      for (String el: ZKUtil.listChildrenNoWatch(watcher, watcher.rsZNode)) {
+        servers.add(ServerName.parseServerName(el));
+      }
+      return servers;
+    } catch (KeeperException e) {
+      throw new IOException("Failed to retrieve server list for zookeeper", e);
+    }
+  }
+
+  private List<ServerName> getAssignedServers(){
+    List<ServerName> assignedServers = Lists.newArrayList();
+    for(GroupInfo gInfo : groupMap.values()){
+      for(String hostPort: gInfo.getServers()) {
+        assignedServers.add(ServerName.parseServerName(hostPort));
+      }
+    }
+    return assignedServers;
+  }
+
+	List<ServerName> difference(Collection<ServerName> onlineServers,
+			Collection<ServerName> servers) {
+		if (servers.size() == 0){
+			return Lists.newArrayList(onlineServers);
+		} else {
+			ArrayList<ServerName> finalList = new ArrayList<ServerName>();
+			for (ServerName olServer : onlineServers) {
+				ServerName actual = ServerName.findServerWithSameHostnamePort(
+						servers, olServer);
+				if (actual == null) {
+					finalList.add(olServer);
+				}
+			}
+			return finalList;
+		}
+	}
+
+  private static class GroupStartupWorker extends Thread {
+    private static final Log LOG = LogFactory.getLog(GroupStartupWorker.class);
+
+    private Configuration conf;
+    private volatile boolean isOnline = false;
+    private byte[] tableName;
+    private MasterServices masterServices;
+    private GroupInfoManagerImpl groupInfoManager;
+
+    public GroupStartupWorker(GroupInfoManagerImpl groupInfoManager,
+                              MasterServices masterServices, byte[] tableName) {
+      this.conf = masterServices.getConfiguration();
+      this.tableName = tableName;
+      this.masterServices = masterServices;
+      this.groupInfoManager = groupInfoManager;
+      setName(GroupStartupWorker.class.getName()+"-"+masterServices.getServerName());
+    }
+
+    @Override
+    public void run() {
+      waitForGroupTableOnline();
+      isOnline = true;
+      LOG.info("GroupBasedLoadBalancer is now online");
+      while(masterServices.getAssignmentManager().getRegionsInTransition().size() > 0) {
+        try {
+          Thread.sleep(100);
+        } catch (InterruptedException e) {
+          LOG.info("Sleep Interrupted", e);
+        }
+      }
+    }
+
+    public void waitForGroupTableOnline() {
+      final AtomicInteger regionCount = new AtomicInteger(0);
+      final AtomicBoolean found = new AtomicBoolean(false);
+      int assignCount = 0;
+      while(!found.get()) {
+        regionCount.set(0);
+        found.set(true);
+        try {
+          MetaScanner.MetaScannerVisitor visitor = new MetaScanner.MetaScannerVisitorBase() {
+            @Override
+            public boolean processRow(Result row) throws IOException {
+              byte[] value = row.getValue(HConstants.CATALOG_FAMILY,
+                  HConstants.REGIONINFO_QUALIFIER);
+              HRegionInfo info = Writables.getHRegionInfoOrNull(value);
+              if (info != null) {
+                if (Bytes.equals(tableName, info.getTableName())) {
+                  value = row.getValue(HConstants.CATALOG_FAMILY,
+                      HConstants.SERVER_QUALIFIER);
+                  if (value == null) {
+                    found.set(false);
+                    return false;
+                  }
+                  regionCount.incrementAndGet();
+                }
+              }
+              return true;
+            }
+          };
+          MetaScanner.metaScan(conf, visitor);
+          assignCount =
+              masterServices.getAssignmentManager().getRegionsOfTable(GROUP_TABLE_NAME_BYTES).size();
+          if (regionCount.get() < 1) {
+            HBaseAdmin admin = new HBaseAdmin(conf);
+            HTableDescriptor desc = new HTableDescriptor(tableName);
+            desc.addFamily(new HColumnDescriptor(SERVER_FAMILY_BYTES));
+            desc.addFamily(new HColumnDescriptor(INFO_FAMILY_BYTES));
+            admin.createTable(desc);
+          }
+          LOG.info("isOnline: "+found.get()+", regionCount: "+regionCount.get()+", assignCount: "+assignCount);
+          found.set(found.get() && assignCount == regionCount.get() && regionCount.get() > 0);
+          if (found.get()) {
+            groupInfoManager.refresh(true);
+          }
+        } catch(Exception e) {
+          found.set(false);
+          LOG.info("Failed to perform check",e);
+        }
+        try {
+          Thread.sleep(100);
+        } catch (InterruptedException e) {
+          LOG.info("Sleep interrupted", e);
+        }
+      }
+    }
+
+    public boolean isOnline() {
+      return isOnline;
+    }
+  }
+
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/group/GroupMasterObserver.java b/src/main/java/org/apache/hadoop/hbase/group/GroupMasterObserver.java
new file mode 100644
index 0000000..ccfaac5
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/group/GroupMasterObserver.java
@@ -0,0 +1,56 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.group;
+
+import com.google.common.collect.Sets;
+import org.apache.hadoop.hbase.CoprocessorEnvironment;
+import org.apache.hadoop.hbase.coprocessor.BaseMasterObserver;
+import org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment;
+import org.apache.hadoop.hbase.coprocessor.ObserverContext;
+import org.apache.hadoop.hbase.util.Bytes;
+
+import java.io.IOException;
+
+public class GroupMasterObserver extends BaseMasterObserver {
+
+    private MasterCoprocessorEnvironment menv;
+
+  @Override
+  public void start(CoprocessorEnvironment ctx) throws IOException {
+    menv = (MasterCoprocessorEnvironment)ctx;
+  }
+
+  @Override
+  public void postDeleteTable(ObserverContext<MasterCoprocessorEnvironment> ctx, byte[] tableName) throws IOException {
+    String table = Bytes.toString(tableName);
+    String groupName = getGroupInfoManager().getGroupOfTable(table);
+    if (!GroupInfo.DEFAULT_GROUP.equals(groupName)) {
+      getGroupInfoManager().moveTables(Sets.newHashSet(table), GroupInfo.DEFAULT_GROUP);
+    }
+  }
+
+  private GroupBasedLoadBalancer getBalancer() {
+    return (GroupBasedLoadBalancer)menv.getMasterServices().getLoadBalancer();
+  }
+
+  private GroupInfoManager getGroupInfoManager() throws IOException {
+    return ((GroupBasedLoadBalancer)menv.getMasterServices().getLoadBalancer()).getGroupInfoManager();
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/group/GroupMoveServerWorker.java b/src/main/java/org/apache/hadoop/hbase/group/GroupMoveServerWorker.java
new file mode 100644
index 0000000..bd3500c
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/group/GroupMoveServerWorker.java
@@ -0,0 +1,169 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.group;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.DoNotRetryIOException;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.Server;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.master.MasterServices;
+
+import java.io.IOException;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+public class GroupMoveServerWorker implements Runnable {
+	private static final Log LOG = LogFactory.getLog(GroupMoveServerWorker.class);
+
+  private MasterServices master;
+  private MoveServerPlan plan;
+  private String transGroup;
+  private String sourceGroup;
+  private GroupInfoManager groupManager;
+  private Map<String,String> serversInTransition;
+  private volatile boolean success;
+
+  public GroupMoveServerWorker(Server master, Map<String, String> serversInTransition,
+                               GroupInfoManager groupManager, MoveServerPlan plan) throws IOException {
+    this.serversInTransition = serversInTransition;
+    this.groupManager = groupManager;
+    this.master = (MasterServices)master;
+    this.plan = plan;
+
+    synchronized (serversInTransition) {
+      //check server list
+      sourceGroup = groupManager.getGroupOfServer(plan.getServers().iterator().next()).getName();
+      for(String server: plan.getServers()) {
+        if (serversInTransition.containsKey(server)) {
+          throw new DoNotRetryIOException("Server list contains a server that is already being moved: "+server);
+        }
+        String tmpGroup = groupManager.getGroupOfServer(server).getName();
+        if (sourceGroup != null && !tmpGroup.equals(sourceGroup)) {
+          throw new DoNotRetryIOException("Move server request should only come from one source group");
+        }
+      }
+      //update the servers as in transition
+      for(String server: plan.getServers()) {
+        serversInTransition.put(server, plan.getTargetGroup());
+      }
+      if (!sourceGroup.startsWith(GroupInfo.TRANSITION_GROUP_PREFIX)) {
+        transGroup = GroupInfo.TRANSITION_GROUP_PREFIX+
+            System.currentTimeMillis()+"_"+sourceGroup+"-"+plan.getTargetGroup();
+        groupManager.addGroup(new GroupInfo(transGroup));
+      }
+    }
+    groupManager.moveServers(plan.getServers(), sourceGroup, transGroup!=null?transGroup:plan.getTargetGroup());
+  }
+
+  @Override
+  public void run() {
+    String name = "GroupMoveServer-"+transGroup+"-"+plan.getTargetGroup();
+    Thread.currentThread().setName(name);
+    try {
+      boolean found;
+      do {
+        found = false;
+        for(String rs: plan.getServers()) {
+          List<HRegionInfo> regions = getOnlineRegions(rs);
+          LOG.info("Unassigining "+regions.size()+" from server "+rs);
+          master.getAssignmentManager().unassign(regions);
+          found = found || regions.size() > 0;
+        }
+        try {
+          Thread.sleep(1000);
+        } catch (InterruptedException e) {
+          LOG.warn("Sleep interrupted", e);
+        }
+      } while(found);
+      success = true;
+      LOG.info("Move server done: "+sourceGroup+"->"+plan.getTargetGroup());
+    } catch(Exception e) {
+      success = false;
+      LOG.error("Caught exception while running", e);
+    }
+    if (success) {
+      try {
+        complete();
+      } catch (IOException e) {
+        success = false;
+        LOG.error("Failed to complete move", e);
+      }
+    }
+  }
+
+  private List<HRegionInfo> getOnlineRegions(String hostPort) throws IOException {
+    List<HRegionInfo> regions = new LinkedList<HRegionInfo>();
+    for(Map.Entry<ServerName, List<HRegionInfo>> el:
+        master.getAssignmentManager().getAssignments().entrySet()) {
+      if (el.getKey().getHostAndPort().equals(hostPort)) {
+        regions.addAll(el.getValue());
+      }
+    }
+    return regions;
+  }
+
+  public static class MoveServerPlan {
+    private Set<String> servers;
+    private String targetGroup;
+
+    public MoveServerPlan(Set<String> servers, String targetGroup) {
+      this.servers = servers;
+      this.targetGroup = targetGroup;
+    }
+
+    public Set<String> getServers() {
+      return servers;
+    }
+
+    public String getTargetGroup() {
+      return targetGroup;
+    }
+  }
+
+  public void complete() throws IOException {
+    String tmpSourceGroup = sourceGroup;
+    if (transGroup != null) {
+      tmpSourceGroup = transGroup;
+      LOG.debug("Moving "+plan.getServers().size()+
+          " servers from transition group: "+transGroup+" to final group: "+plan.getTargetGroup());
+    }
+    try {
+      if (success) {
+        groupManager.moveServers(plan.getServers(), tmpSourceGroup, plan.getTargetGroup());
+        if (transGroup != null) {
+          groupManager.removeGroup(transGroup);
+        }
+        LOG.debug("Move done "+plan.getServers().size()+
+            " servers from transition group: "+transGroup+" to final group: "+plan.getTargetGroup());
+      }
+    } finally {
+      //remove servers in transition
+      synchronized(serversInTransition) {
+        for(String server: plan.getServers()) {
+          serversInTransition.remove(server);
+        }
+      }
+    }
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java b/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java
index 503061d..f744757 100644
--- a/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java
+++ b/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java
@@ -45,6 +45,7 @@ import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.Chore;
 import org.apache.hadoop.hbase.HConstants;
@@ -176,7 +177,7 @@ public class AssignmentManager extends ZooKeeperListener {
 
   //Thread pool executor service for timeout monitor
   private java.util.concurrent.ExecutorService threadPoolExecutorService;
-  
+
   private List<EventType> ignoreStatesRSOffline = Arrays.asList(new EventType[]{
       EventType.RS_ZK_REGION_FAILED_OPEN, EventType.RS_ZK_REGION_CLOSED });
 
@@ -186,8 +187,8 @@ public class AssignmentManager extends ZooKeeperListener {
    */
   private volatile boolean failover = false;
 
-  // Set holding all the regions which got processed while RIT was not 
-  // populated during master failover. 
+  // Set holding all the regions which got processed while RIT was not
+  // populated during master failover.
   private Map<String, HRegionInfo> failoverProcessedRegions =
     new HashMap<String, HRegionInfo>();
 
@@ -199,7 +200,7 @@ public class AssignmentManager extends ZooKeeperListener {
    * @param catalogTracker
    * @param service
    * @throws KeeperException
-   * @throws IOException 
+   * @throws IOException
    */
   public AssignmentManager(Server master, ServerManager serverManager,
       CatalogTracker catalogTracker, final LoadBalancer balancer,
@@ -226,7 +227,7 @@ public class AssignmentManager extends ZooKeeperListener {
     this.balancer = balancer;
     this.threadPoolExecutorService = Executors.newCachedThreadPool();
   }
-  
+
   void startTimeOutMonitor() {
     Threads.setDaemonThreadRunning(timeoutMonitor.getThread(), master.getServerName()
         + ".timeoutMonitor");
@@ -275,8 +276,8 @@ public class AssignmentManager extends ZooKeeperListener {
 
   /**
    * Add a regionPlan for the specified region.
-   * @param encodedName 
-   * @param plan 
+   * @param encodedName
+   * @param plan
    */
   public void addPlan(String encodedName, RegionPlan plan) {
     synchronized (regionPlans) {
@@ -382,7 +383,7 @@ public class AssignmentManager extends ZooKeeperListener {
 
   /**
    * Process all regions that are in transition in zookeeper and also
-   * processes the list of dead servers by scanning the META. 
+   * processes the list of dead servers by scanning the META.
    * Used by master joining an cluster.
    * @param deadServers
    *          Map of dead servers and their regions. Can be null.
@@ -395,7 +396,7 @@ public class AssignmentManager extends ZooKeeperListener {
   throws KeeperException, IOException, InterruptedException {
     List<String> nodes = ZKUtil.listChildrenAndWatchForNewChildren(watcher,
       watcher.assignmentZNode);
-    
+
     if (nodes == null) {
       String errorMessage = "Failed to get the children from ZK";
       master.abort(errorMessage, new IOException(errorMessage));
@@ -480,7 +481,7 @@ public class AssignmentManager extends ZooKeeperListener {
    * up in zookeeper.
    * @param encodedRegionName Region to process failover for.
    * @param regionInfo If null we'll go get it from meta table.
-   * @param deadServers Can be null 
+   * @param deadServers Can be null
    * @return True if we processed <code>regionInfo</code> as a RIT.
    * @throws KeeperException
    * @throws IOException
@@ -495,7 +496,7 @@ public class AssignmentManager extends ZooKeeperListener {
     if (data == null) return false;
     HRegionInfo hri = regionInfo;
     if (hri == null) {
-      if ((hri = getHRegionInfo(data)) == null) return false; 
+      if ((hri = getHRegionInfo(data)) == null) return false;
     }
     processRegionsInTransition(data, hri, deadServers, stat.getVersion());
     return true;
@@ -612,7 +613,7 @@ public class AssignmentManager extends ZooKeeperListener {
       }
     }
   }
-  
+
 
   /**
    * Put the region <code>hri</code> into an offline state up in zk.
@@ -819,7 +820,7 @@ public class AssignmentManager extends ZooKeeperListener {
           this.executorService.submit(new ClosedRegionHandler(master,
             this, regionState.getRegion()));
           break;
-          
+
         case RS_ZK_REGION_FAILED_OPEN:
           hri = checkIfInFailover(regionState, encodedName, data);
           if (hri != null) {
@@ -841,7 +842,7 @@ public class AssignmentManager extends ZooKeeperListener {
           // Handle this the same as if it were opened and then closed.
           regionState.update(RegionState.State.CLOSED,
               data.getStamp(), data.getOrigin());
-          // When there are more than one region server a new RS is selected as the 
+          // When there are more than one region server a new RS is selected as the
           // destination and the same is updated in the regionplan. (HBASE-5546)
           getRegionPlan(regionState, sn, true);
           this.executorService.submit(new ClosedRegionHandler(master,
@@ -849,7 +850,7 @@ public class AssignmentManager extends ZooKeeperListener {
           break;
 
         case RS_ZK_REGION_OPENING:
-          hri = checkIfInFailover(regionState, encodedName, data);       
+          hri = checkIfInFailover(regionState, encodedName, data);
           if (hri != null) {
             regionState = new RegionState(hri, RegionState.State.OPENING, data
                 .getStamp(), data.getOrigin());
@@ -924,11 +925,11 @@ public class AssignmentManager extends ZooKeeperListener {
     }
     return null;
   }
-  
+
   /**
    * Gets the HRegionInfo from the META table
    * @param  data
-   * @return HRegionInfo hri for the region 
+   * @return HRegionInfo hri for the region
    */
   private HRegionInfo getHRegionInfo(RegionTransitionData data) {
     Pair<HRegionInfo, ServerName> p = null;
@@ -1216,13 +1217,13 @@ public class AssignmentManager extends ZooKeeperListener {
       ServerName oldSn = this.regions.get(regionInfo);
       if (oldSn != null) LOG.warn("Overwriting " + regionInfo.getEncodedName() +
         " on " + oldSn + " with " + sn);
-      
+
       if (isServerOnline(sn)) {
         this.regions.put(regionInfo, sn);
         addToServers(sn, regionInfo);
         this.regions.notifyAll();
       } else {
-        LOG.info("The server is not in online servers, ServerName=" + 
+        LOG.info("The server is not in online servers, ServerName=" +
           sn.getServerName() + ", region=" + regionInfo.getEncodedName());
       }
     }
@@ -1369,7 +1370,7 @@ public class AssignmentManager extends ZooKeeperListener {
    */
   public void assign(HRegionInfo region, boolean setOfflineInZK,
       boolean forceNewPlan, boolean hijack) {
-    // If hijack is true do not call disableRegionIfInRIT as 
+    // If hijack is true do not call disableRegionIfInRIT as
     // we have not yet moved the znode to OFFLINE state.
     if (!hijack && isDisabledorDisablingRegionInRIT(region)) {
       return;
@@ -1413,7 +1414,7 @@ public class AssignmentManager extends ZooKeeperListener {
           destination));
     }
     this.addPlans(plans);
-    
+
     // Presumption is that only this thread will be updating the state at this
     // time; i.e. handlers on backend won't be trying to set it to OPEN, etc.
     AtomicInteger counter = new AtomicInteger(0);
@@ -1636,11 +1637,11 @@ public class AssignmentManager extends ZooKeeperListener {
           }
         }
       }
-      
+
       if (setOfflineInZK && versionOfOfflineNode == -1) {
         return;
       }
-      
+
       if (this.master.isStopped()) {
         LOG.debug("Server stopped; skipping assign of " + state);
         return;
@@ -1653,7 +1654,7 @@ public class AssignmentManager extends ZooKeeperListener {
       }
       try {
         LOG.debug("Assigning region " + state.getRegion().getRegionNameAsString() +
-          " to " + plan.getDestination().toString());
+          " to " + plan.getDestination());
         // Transition RegionState to PENDING_OPEN
         state.update(RegionState.State.PENDING_OPEN, System.currentTimeMillis(),
             plan.getDestination());
@@ -1753,38 +1754,38 @@ public class AssignmentManager extends ZooKeeperListener {
 
   /**
    * Set region as OFFLINED up in zookeeper
-   * 
+   *
    * @param state
    * @param hijack
    *          - true if needs to be hijacked and reassigned, false otherwise.
-   * @param regionAlreadyInTransitionException  
-   *          - true if we need to retry assignment because of RegionAlreadyInTransitionException.       
+   * @param regionAlreadyInTransitionException
+   *          - true if we need to retry assignment because of RegionAlreadyInTransitionException.
    * @return the version of the offline node if setting of the OFFLINE node was
    *         successful, -1 otherwise.
    */
   int setOfflineInZooKeeper(final RegionState state, boolean hijack,
       boolean regionAlreadyInTransitionException) {
     // In case of reassignment the current state in memory need not be
-    // OFFLINE. 
+    // OFFLINE.
     if (!hijack && !state.isClosed() && !state.isOffline()) {
       if (!regionAlreadyInTransitionException ) {
         String msg = "Unexpected state : " + state + " .. Cannot transit it to OFFLINE.";
         this.master.abort(msg, new IllegalStateException(msg));
         return -1;
-      } 
+      }
       LOG.debug("Unexpected state : " + state
           + " but retrying to assign because RegionAlreadyInTransitionException.");
     }
     boolean allowZNodeCreation = false;
     // Under reassignment if the current state is PENDING_OPEN
     // or OPENING then refresh the in-memory state to PENDING_OPEN. This is
-    // important because if the region was in 
+    // important because if the region was in
     // RS_OPENING state for a long time the master will try to force the znode
     // to OFFLINE state meanwhile the RS could have opened the corresponding
     // region and the state in znode will be RS_ZK_REGION_OPENED.
     // For all other cases we can change the in-memory state to OFFLINE.
     if (hijack &&
-        (state.getState().equals(RegionState.State.PENDING_OPEN) || 
+        (state.getState().equals(RegionState.State.PENDING_OPEN) ||
             state.getState().equals(RegionState.State.OPENING))) {
       state.update(RegionState.State.PENDING_OPEN);
       allowZNodeCreation = false;
@@ -1795,7 +1796,7 @@ public class AssignmentManager extends ZooKeeperListener {
     int versionOfOfflineNode = -1;
     try {
       // get the version after setting the znode to OFFLINE
-      versionOfOfflineNode = ZKAssign.createOrForceNodeOffline(master.getZooKeeper(), 
+      versionOfOfflineNode = ZKAssign.createOrForceNodeOffline(master.getZooKeeper(),
           state.getRegion(), this.master.getServerName(),
           hijack, allowZNodeCreation);
       if (versionOfOfflineNode == -1) {
@@ -1831,7 +1832,7 @@ public class AssignmentManager extends ZooKeeperListener {
     } catch (KeeperException e) {
       if (e instanceof NodeExistsException) {
         LOG.warn("Node for " + state.getRegion() + " already exists");
-      } else { 
+      } else {
         master.abort("Unexpected ZK exception creating/setting node OFFLINE", e);
       }
       return false;
@@ -1904,7 +1905,7 @@ public class AssignmentManager extends ZooKeeperListener {
           || drainingServers.contains(existingPlan.getDestination())) {
         newPlan = true;
         randomPlan = new RegionPlan(state.getRegion(), null, balancer
-            .randomAssignment(servers));
+            .randomAssignment(state.getRegion(), servers));
         this.regionPlans.put(encodedName, randomPlan);
       }
     }
@@ -2064,8 +2065,8 @@ public class AssignmentManager extends ZooKeeperListener {
         state = new RegionState(region, RegionState.State.PENDING_CLOSE);
         regionsInTransition.put(encodedName, state);
       } else if (force && (state.isPendingClose() || state.isClosing())) {
-        LOG.debug("Attempting to unassign region " + region.getRegionNameAsString() + 
-          " which is already " + state.getState()  + 
+        LOG.debug("Attempting to unassign region " + region.getRegionNameAsString() +
+          " which is already " + state.getState()  +
           " but forcing to send a CLOSE RPC again ");
         state.update(state.getState());
       } else {
@@ -2074,7 +2075,7 @@ public class AssignmentManager extends ZooKeeperListener {
           "already in transition (" + state.getState() + ", force=" + force + ")");
         return;
       }
-    } 
+    }
     // Send CLOSE RPC
     ServerName server = null;
     synchronized (this.regions) {
@@ -2148,9 +2149,9 @@ public class AssignmentManager extends ZooKeeperListener {
       // Presume retry or server will expire.
     }
   }
-  
+
   /**
-   * 
+   *
    * @param region regioninfo of znode to be deleted.
    */
   public void deleteClosingOrClosedNode(HRegionInfo region) {
@@ -2249,7 +2250,7 @@ public class AssignmentManager extends ZooKeeperListener {
 
   /**
    * Assigns all user regions to online servers. Use round-robin assignment.
-   * 
+   *
    * @param regions
    * @throws IOException
    * @throws InterruptedException
@@ -2290,7 +2291,7 @@ public class AssignmentManager extends ZooKeeperListener {
     boolean isTableEnabled = this.zkTable.isEnabledTable(tableName);
     if (!isTableEnabled) {
       setEnabledTable(tableName);
-    }    
+    }
   }
 
   /**
@@ -2533,7 +2534,7 @@ public class AssignmentManager extends ZooKeeperListener {
     // Region assignment from META
     List<Result> results = MetaReader.fullScan(this.catalogTracker);
     // Get any new but slow to checkin region server that joined the cluster
-    Set<ServerName> onlineServers = serverManager.getOnlineServers().keySet();    
+    Set<ServerName> onlineServers = serverManager.getOnlineServers().keySet();
     // Map of offline servers and their regions to be returned
     Map<ServerName, List<Pair<HRegionInfo,Result>>> offlineServers =
       new TreeMap<ServerName, List<Pair<HRegionInfo, Result>>>();
@@ -2590,7 +2591,7 @@ public class AssignmentManager extends ZooKeeperListener {
           byte[] data = ZKUtil.getDataNoWatch(this.watcher, node, stat);
           // If znode does not exist dont consider this region
           if (data == null) {
-            LOG.debug("Region "+ regionInfo.getRegionNameAsString() + " split is completed. " 
+            LOG.debug("Region "+ regionInfo.getRegionNameAsString() + " split is completed. "
                 + "Hence need not add to regions list");
             continue;
           }
@@ -2633,14 +2634,14 @@ public class AssignmentManager extends ZooKeeperListener {
     } else if (checkIfRegionsBelongsToEnabling(regionInfo)) {
       enablingTables.add(disablingTableName);
       return true;
-    } 
+    }
     return false;
   }
 
   /**
    * Recover the tables that were not fully moved to DISABLED state. These
    * tables are in DISABLING state when the master restarted/switched.
-   * 
+   *
    * @param disablingTables
    * @return
    * @throws KeeperException
@@ -2670,7 +2671,7 @@ public class AssignmentManager extends ZooKeeperListener {
   /**
    * Recover the tables that are not fully moved to ENABLED state. These tables
    * are in ENABLING state when the master restarted/switched
-   * 
+   *
    * @param enablingTables
    * @param isWatcherCreated
    * @throws KeeperException
@@ -2717,10 +2718,10 @@ public class AssignmentManager extends ZooKeeperListener {
    * Processes list of dead servers from result of META scan and regions in RIT
    * <p>
    * This is used for failover to recover the lost regions that belonged to
-   * RegionServers which failed while there was no active master or regions 
+   * RegionServers which failed while there was no active master or regions
    * that were in RIT.
    * <p>
-   * 
+   *
    * @param deadServers
    *          The list of dead servers which failed while there was no active
    *          master. Can be null.
@@ -2734,7 +2735,7 @@ public class AssignmentManager extends ZooKeeperListener {
       List<String> nodes) throws IOException, KeeperException {
     if (null != deadServers) {
       Set<ServerName> actualDeadServers = this.serverManager.getDeadServers();
-      for (Map.Entry<ServerName, List<Pair<HRegionInfo, Result>>> deadServer : 
+      for (Map.Entry<ServerName, List<Pair<HRegionInfo, Result>>> deadServer :
         deadServers.entrySet()) {
         // skip regions of dead servers because SSH will process regions during rs expiration.
         // see HBASE-5916
@@ -2758,7 +2759,7 @@ public class AssignmentManager extends ZooKeeperListener {
             // we consider that this region is being handled.
             // So we should skip it and process it in
             // processRegionsInTransition.
-            if (data != null && data.getOrigin() != null && 
+            if (data != null && data.getOrigin() != null &&
                 serverManager.isServerOnline(data.getOrigin())) {
               LOG.info("The region " + regionInfo.getEncodedName()
                   + "is being handled on " + data.getOrigin());
@@ -2894,7 +2895,7 @@ public class AssignmentManager extends ZooKeeperListener {
    */
   public List<HRegionInfo> getRegionsOfTable(byte[] tableName) {
     List<HRegionInfo> tableRegions = new ArrayList<HRegionInfo>();
-    // boundary needs to have table's name but regionID 0 so that it is sorted 
+    // boundary needs to have table's name but regionID 0 so that it is sorted
     // before all table's regions.
     HRegionInfo boundary =
       new HRegionInfo(tableName, null, null, false, 0L);
@@ -3057,7 +3058,7 @@ public class AssignmentManager extends ZooKeeperListener {
       }
     }
   }
-  
+
   private void processOpeningState(HRegionInfo regionInfo) {
     LOG.info("Region has been OPENING for too " + "long, reassigning region="
         + regionInfo.getRegionNameAsString());
@@ -3222,7 +3223,7 @@ public class AssignmentManager extends ZooKeeperListener {
    * Can't let out original since it can change and at least the loadbalancer
    * wants to iterate this exported list.  We need to synchronize on regions
    * since all access to this.servers is under a lock on this.regions.
-   * 
+   *
    * @return A clone of current assignments by table.
    */
   Map<String, Map<ServerName, List<HRegionInfo>>> getAssignmentsByTable() {
@@ -3265,13 +3266,14 @@ public class AssignmentManager extends ZooKeeperListener {
     }
     return result;
   }
-  
+
   /**
    * @return A clone of current assignments. Note, this is assignments only.
    * If a new server has come in and it has no regions, it will not be included
    * in the returned Map.
    */
-  Map<ServerName, List<HRegionInfo>> getAssignments() {
+  @InterfaceAudience.Private
+  public Map<ServerName, List<HRegionInfo>> getAssignments() {
     // This is an EXPENSIVE clone.  Cloning though is the safest thing to do.
     // Can't let out original since it can change and at least the loadbalancer
     // wants to iterate this exported list.  We need to synchronize on regions
@@ -3435,7 +3437,7 @@ public class AssignmentManager extends ZooKeeperListener {
     public boolean isSplitting() {
       return state == State.SPLITTING;
     }
- 
+
     public boolean isSplit() {
       return state == State.SPLIT;
     }
@@ -3449,12 +3451,12 @@ public class AssignmentManager extends ZooKeeperListener {
     }
 
     /**
-     * A slower (but more easy-to-read) stringification 
+     * A slower (but more easy-to-read) stringification
      */
     public String toDescriptiveString() {
       long lstamp = stamp.get();
       long relTime = System.currentTimeMillis() - lstamp;
-      
+
       return region.getRegionNameAsString()
         + " state=" + state
         + ", ts=" + new Date(lstamp) + " (" + (relTime/1000) + "s ago)"
@@ -3481,10 +3483,10 @@ public class AssignmentManager extends ZooKeeperListener {
     this.timeoutMonitor.interrupt();
     this.timerUpdater.interrupt();
   }
-  
+
   /**
    * Check whether the RegionServer is online.
-   * @param serverName 
+   * @param serverName
    * @return True if online.
    */
   public boolean isServerOnline(ServerName serverName) {
diff --git a/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java
index 82a33e0..a5af1e1 100644
--- a/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java
+++ b/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java
@@ -43,7 +43,6 @@ import org.apache.hadoop.hbase.HDFSBlocksDistribution;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.ServerName;
-import org.apache.hadoop.hbase.TableExistsException;
 import org.apache.hadoop.hbase.regionserver.HRegion;
 import org.apache.hadoop.hbase.util.Bytes;
 
@@ -118,7 +117,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
 
 
    RegionInfoComparator riComparator = new RegionInfoComparator();
-   
+
    private class RegionPlanComparator implements Comparator<RegionPlan> {
     @Override
     public int compare(RegionPlan l, RegionPlan r) {
@@ -141,21 +140,21 @@ public class DefaultLoadBalancer implements LoadBalancer {
    * have either floor(average) or ceiling(average) regions.
    *
    * HBASE-3609 Modeled regionsToMove using Guava's MinMaxPriorityQueue so that
-   *   we can fetch from both ends of the queue. 
-   * At the beginning, we check whether there was empty region server 
+   *   we can fetch from both ends of the queue.
+   * At the beginning, we check whether there was empty region server
    *   just discovered by Master. If so, we alternately choose new / old
    *   regions from head / tail of regionsToMove, respectively. This alternation
    *   avoids clustering young regions on the newly discovered region server.
    *   Otherwise, we choose new regions from head of regionsToMove.
-   *   
+   *
    * Another improvement from HBASE-3609 is that we assign regions from
    *   regionsToMove to underloaded servers in round-robin fashion.
    *   Previously one underloaded server would be filled before we move onto
    *   the next underloaded server, leading to clustering of young regions.
-   *   
+   *
    * Finally, we randomly shuffle underloaded servers so that they receive
    *   offloaded regions relatively evenly across calls to balanceCluster().
-   *         
+   *
    * The algorithm is currently implemented as such:
    *
    * <ol>
@@ -289,7 +288,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
       List<HRegionInfo> regions = server.getValue();
       int numToOffload = Math.min(regionCount - max, regions.size());
       // account for the out-of-band regions which were assigned to this server
-      // after some other region server crashed 
+      // after some other region server crashed
       Collections.sort(regions, riComparator);
       int numTaken = 0;
       for (int i = 0; i <= numToOffload; ) {
@@ -587,7 +586,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
     // Group all of the old assignments by their hostname.
     // We can't group directly by ServerName since the servers all have
     // new start-codes.
-    
+
     // Group the servers by their hostname. It's possible we have multiple
     // servers on the same host on different ports.
     ArrayListMultimap<String, ServerName> serversByHostname =
@@ -595,20 +594,20 @@ public class DefaultLoadBalancer implements LoadBalancer {
     for (ServerName server : servers) {
       serversByHostname.put(server.getHostname(), server);
     }
-    
+
     // Now come up with new assignments
     Map<ServerName, List<HRegionInfo>> assignments =
       new TreeMap<ServerName, List<HRegionInfo>>();
-    
+
     for (ServerName server : servers) {
       assignments.put(server, new ArrayList<HRegionInfo>());
     }
-    
+
     // Collection of the hostnames that used to have regions
     // assigned, but for which we no longer have any RS running
     // after the cluster restart.
     Set<String> oldHostsNoLongerPresent = Sets.newTreeSet();
-    
+
     int numRandomAssignments = 0;
     int numRetainedAssigments = 0;
     for (Map.Entry<HRegionInfo, ServerName> entry : regions.entrySet()) {
@@ -637,7 +636,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
         numRetainedAssigments++;
       }
     }
-    
+
     String randomAssignMsg = "";
     if (numRandomAssignments > 0) {
       randomAssignMsg = numRandomAssignments + " regions were assigned " +
@@ -645,7 +644,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
       		"longer present in the cluster. These hosts were:\n  " +
           Joiner.on("\n  ").join(oldHostsNoLongerPresent);
     }
-    
+
     LOG.info("Reassigned " + regions.size() + " regions. " +
         numRetainedAssigments + " retained the pre-restart assignment. " +
         randomAssignMsg);
@@ -680,7 +679,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
       LOG.debug("IOException during HDFSBlocksDistribution computation. for " +
         "region = " + region.getEncodedName() , ioe);
     }
-    
+
     return topServerNames;
   }
 
@@ -712,7 +711,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
    * order as input hosts.
    * @param hosts the list of hosts
    * @return ServerName list
-   */  
+   */
   private List<ServerName> mapHostNameToServerName(List<String> hosts) {
     if ( hosts == null || status == null) {
       return null;
@@ -768,7 +767,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
     return assignments;
   }
 
-  public ServerName randomAssignment(List<ServerName> servers) {
+  public ServerName randomAssignment(HRegionInfo region, List<ServerName> servers) {
     if (servers == null || servers.isEmpty()) {
       LOG.warn("Wanted to do random assignment but no servers to assign to");
       return null;
@@ -776,4 +775,8 @@ public class DefaultLoadBalancer implements LoadBalancer {
     return servers.get(RANDOM.nextInt(servers.size()));
   }
 
+  @Override
+  public void configure() throws IOException {
+  }
+
 }
diff --git a/src/main/java/org/apache/hadoop/hbase/master/HMaster.java b/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
index 0cf1eba..08e21d3 100644
--- a/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
+++ b/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
@@ -42,6 +42,7 @@ import java.util.concurrent.atomic.AtomicReference;
 import javax.management.ObjectName;
 
 import com.google.common.collect.ClassToInstanceMap;
+import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.MutableClassToInstanceMap;
 import org.apache.commons.logging.Log;
@@ -184,7 +185,7 @@ Server {
   private CatalogTracker catalogTracker;
   // Cluster status zk tracker and local setter
   private ClusterStatusTracker clusterStatusTracker;
-  
+
   // buffer for "fatal error" notices from region servers
   // in the cluster. This is only used for assisting
   // operations/debugging.
@@ -262,7 +263,7 @@ Server {
     // Creation of a HSA will force a resolve.
     InetSocketAddress initialIsa = new InetSocketAddress(hostname, port);
     if (initialIsa.getAddress() == null) {
-      throw new IllegalArgumentException("Failed resolve of " + this.isa);
+      throw new IllegalArgumentException("Failed resolve of " + initialIsa);
     }
     int numHandlers = conf.getInt("hbase.master.handler.count",
       conf.getInt("hbase.regionserver.handler.count", 25));
@@ -325,7 +326,7 @@ Server {
         "(Also watching cluster state node)");
       Thread.sleep(c.getInt("zookeeper.session.timeout", 180 * 1000));
     }
-    
+
   }
 
   /**
@@ -363,7 +364,7 @@ Server {
       }
     } catch (Throwable t) {
       // HBASE-5680: Likely hadoop23 vs hadoop 20.x/1.x incompatibility
-      if (t instanceof NoClassDefFoundError && 
+      if (t instanceof NoClassDefFoundError &&
           t.getMessage().contains("org/apache/hadoop/hdfs/protocol/FSConstants$SafeModeAction")) {
           // improved error message for this special case
           abort("HBase is having a problem with its Hadoop jars.  You may need to "
@@ -375,7 +376,7 @@ Server {
       }
     } finally {
       startupStatus.cleanup();
-      
+
       stopChores();
       // Wait for all the remaining region servers to report in IFF we were
       // running a cluster shutdown AND we were NOT aborting.
@@ -397,7 +398,7 @@ Server {
 
   /**
    * Try becoming active master.
-   * @param startupStatus 
+   * @param startupStatus
    * @return True if we could successfully become the active master.
    * @throws InterruptedException
    */
@@ -476,7 +477,7 @@ Server {
    * <li>Ensure assignment of root and meta regions<li>
    * <li>Handle either fresh cluster start or master failover</li>
    * </ol>
-   * @param masterRecovery 
+   * @param masterRecovery
    *
    * @throws IOException
    * @throws InterruptedException
@@ -513,7 +514,7 @@ Server {
 
     status.setStatus("Initializing ZK system trackers");
     initializeZKBasedSystemTrackers();
-    
+
     if (!masterRecovery) {
       // initialize master side coprocessors before we start handling requests
       status.setStatus("Initializing master coprocessors");
@@ -542,6 +543,10 @@ Server {
     status.setStatus("Splitting logs after master startup");
     splitLogAfterStartup(this.fileSystemManager);
 
+    this.balancer.setClusterStatus(getClusterStatus());
+    this.balancer.setMasterServices(this);
+    this.balancer.configure();
+
     // Make sure root and meta assigned before proceeding.
     assignRootAndMeta(status);
     enableServerShutdownHandler();
@@ -557,9 +562,6 @@ Server {
     status.setStatus("Starting assignment manager");
     this.assignmentManager.joinCluster();
 
-    this.balancer.setClusterStatus(getClusterStatus());
-    this.balancer.setMasterServices(this);
-
     // Fixing up missing daughters if any
     status.setStatus("Fixing up missing daughters");
     fixupDaughters(status);
@@ -582,7 +584,7 @@ Server {
     // removing dead server with same hostname and port of rs which is trying to check in before
     // master initialization. See HBASE-5916.
     this.serverManager.clearDeadServersWithSameHostNameAndPortOfOnlineServer();
-    
+
     if (!masterRecovery) {
       if (this.cpHost != null) {
         // don't let cp initialization errors kill the master
@@ -594,11 +596,11 @@ Server {
       }
     }
   }
-  
+
   /**
    * If ServerShutdownHandler is disabled, we enable it and expire those dead
    * but not expired servers.
-   * 
+   *
    * @throws IOException
    */
   private void enableServerShutdownHandler() throws IOException {
@@ -607,7 +609,7 @@ Server {
       this.serverManager.expireDeadNotExpiredServers();
     }
   }
-  
+
   /**
    * Useful for testing purpose also where we have
    * master restart scenarios.
@@ -833,7 +835,7 @@ Server {
    *  need to install an unexpected exception handler.
    */
   private void startServiceThreads() throws IOException{
- 
+
    // Start the executor service pools
    this.executorService.startExecutorService(ExecutorType.MASTER_OPEN_REGION,
       conf.getInt("hbase.master.executor.openregion.threads", 5));
@@ -843,7 +845,7 @@ Server {
       conf.getInt("hbase.master.executor.serverops.threads", 3));
    this.executorService.startExecutorService(ExecutorType.MASTER_META_SERVER_OPERATIONS,
       conf.getInt("hbase.master.executor.serverops.threads", 5));
-   
+
    // We depend on there being only one instance of this executor running
    // at a time.  To do concurrency, would need fencing of enable/disable of
    // tables.
@@ -874,7 +876,7 @@ Server {
      this.infoServer.setAttribute(MASTER, this);
      this.infoServer.start();
     }
-   
+
     // Start allowing requests to happen.
     this.rpcServer.openServer();
     if (LOG.isDebugEnabled()) {
@@ -1092,11 +1094,11 @@ Server {
         newValue = this.cpHost.preBalanceSwitch(newValue);
       }
       if (mode == BalanceSwitchMode.SYNC) {
-        synchronized (this.balancer) {        
+        synchronized (this.balancer) {
           this.balanceSwitch = newValue;
         }
       } else {
-        this.balanceSwitch = newValue;        
+        this.balanceSwitch = newValue;
       }
       LOG.info("BalanceSwitch=" + newValue);
       if (this.cpHost != null) {
@@ -1105,14 +1107,14 @@ Server {
     } catch (IOException ioe) {
       LOG.warn("Error flipping balance switch", ioe);
     }
-    return oldValue;    
+    return oldValue;
   }
-  
+
   @Override
   public boolean synchronousBalanceSwitch(final boolean b) {
     return switchBalancer(b, BalanceSwitchMode.SYNC);
   }
-  
+
   @Override
   public boolean balanceSwitch(final boolean b) {
     return switchBalancer(b, BalanceSwitchMode.ASYNC);
@@ -1140,15 +1142,15 @@ Server {
       LOG.info("Passed destination servername is null or empty so choosing a server at random");
       List<ServerName> destServers = this.serverManager.getOnlineServersList();
       destServers.remove(p.getSecond());
-      // If i have only one RS then destination can be null.
-      dest = balancer.randomAssignment(destServers);
+      dest = balancer.randomAssignment(p.getFirst(), destServers);
     } else {
-      dest = new ServerName(Bytes.toString(destServerName));
+      ServerName candidate = new ServerName(Bytes.toString(destServerName));
+      dest = balancer.randomAssignment(p.getFirst(), Lists.newArrayList(candidate));
     }
     
     // Now we can do the move
     RegionPlan rp = new RegionPlan(p.getFirst(), p.getSecond(), dest);
-    
+
     try {
       if (this.cpHost != null) {
         if (this.cpHost.preMove(p.getFirst(), p.getSecond(), dest)) {
@@ -1235,7 +1237,7 @@ Server {
    * @return Pair indicating the number of regions updated Pair.getFirst is the
    *         regions that are yet to be updated Pair.getSecond is the total number
    *         of regions of the table
-   * @throws IOException 
+   * @throws IOException
    */
   public Pair<Integer, Integer> getAlterStatus(byte[] tableName)
   throws IOException {
@@ -1583,7 +1585,7 @@ Server {
   public AssignmentManager getAssignmentManager() {
     return this.assignmentManager;
   }
-  
+
   public MemoryBoundedLogMessageBuffer getRegionServerFatalLogBuffer() {
     return rsFatals;
   }
@@ -1647,13 +1649,13 @@ Server {
   public boolean isAborted() {
     return this.abort;
   }
-  
+
   void checkInitialized() throws PleaseHoldException {
     if (!this.initialized) {
       throw new PleaseHoldException("Master is initializing");
     }
   }
-  
+
   /**
    * Report whether this master is currently the active master or not.
    * If not active master, we are parked on ZK waiting to become active.
@@ -1711,8 +1713,8 @@ Server {
       cpHost.postAssign(pair.getFirst());
     }
   }
-  
-  
+
+
 
   public void assignRegion(HRegionInfo hri) {
     assignmentManager.assign(hri, true);
@@ -1724,7 +1726,15 @@ Server {
     checkInitialized();
     Pair<HRegionInfo, ServerName> pair =
       MetaReader.getRegion(this.catalogTracker, regionName);
-    if (pair == null) throw new UnknownRegionException(Bytes.toString(regionName));
+    if (Bytes.equals(HRegionInfo.ROOT_REGIONINFO.getRegionName(),regionName)) {
+      try {
+        pair = new Pair<HRegionInfo, ServerName>(HRegionInfo.ROOT_REGIONINFO, this.catalogTracker.getRootLocation());
+      } catch (InterruptedException e) {
+        throw new IOException(e);
+      }
+    }
+    if (pair == null) throw new UnknownRegionException(
+        Bytes.toString(HRegionInfo.ROOT_REGIONINFO.getRegionName())+"<-->"+Bytes.toString(regionName));
     HRegionInfo hri = pair.getFirst();
     if (cpHost != null) {
       if (cpHost.preUnassign(hri, force)) {
@@ -1743,7 +1753,7 @@ Server {
   }
 
   /**
-   * Get HTD array for given tables 
+   * Get HTD array for given tables
    * @param tableNames
    * @return HTableDescriptor[]
    */
@@ -1787,6 +1797,11 @@ Server {
   }
 
   @Override
+  public LoadBalancer getLoadBalancer() {
+    return balancer;
+  }
+
+  @Override
   public ExecResult execCoprocessor(Exec call) throws IOException {
     Class<? extends CoprocessorProtocol> protocol = call.getProtocol();
     if (protocol == null) {
diff --git a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java
index 7d2dd74..8093378 100644
--- a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java
+++ b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java
@@ -24,6 +24,7 @@ import org.apache.hadoop.hbase.ClusterStatus;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.ServerName;
 
+import java.io.IOException;
 import java.util.List;
 import java.util.Map;
 
@@ -59,6 +60,13 @@ public interface LoadBalancer extends Configurable {
   public void setMasterServices(MasterServices masterServices);
 
   /**
+   * Configure the load balancer. Must be called after setters.
+   *
+   * @throws IOException Signals that an I/O exception has occurred.
+   */
+  public void configure() throws IOException;
+
+  /**
    * Perform the major balance operation
    * @param clusterState
    * @return List of plans
@@ -91,8 +99,9 @@ public interface LoadBalancer extends Configurable {
 
   /**
    * Get a random region server from the list
+   * @param region
    * @param servers
    * @return Servername
    */
-  public ServerName randomAssignment(List<ServerName> servers);
+  public ServerName randomAssignment(HRegionInfo region, List<ServerName> servers);
 }
diff --git a/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java b/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java
index 8be3c75..d0791eb 100644
--- a/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java
+++ b/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java
@@ -105,4 +105,9 @@ public interface MasterServices extends Server {
    */
   public <T extends CoprocessorProtocol> boolean registerProtocol(
       Class<T> protocol, T handler);
+
+  /**
+   * @return load balancer
+   */
+  public LoadBalancer getLoadBalancer();
 }
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java b/src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java
index 6e92149..ce65389 100644
--- a/src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java
@@ -157,7 +157,7 @@ public class TestAssignmentManager {
 
   /**
    * Test a balance going on at same time as a master failover
-   * 
+   *
    * @throws IOException
    * @throws KeeperException
    * @throws InterruptedException
@@ -402,7 +402,7 @@ public class TestAssignmentManager {
 
   /**
    * To test closed region handler to remove rit and delete corresponding znode if region in pending
-   * close or closing while processing shutdown of a region server.(HBASE-5927). 
+   * close or closing while processing shutdown of a region server.(HBASE-5927).
    * @throws KeeperException
    * @throws IOException
    */
@@ -412,7 +412,7 @@ public class TestAssignmentManager {
     testCaseWithPartiallyDisabledState(TableState.DISABLING);
     testCaseWithPartiallyDisabledState(TableState.DISABLED);
   }
-  
+
   /**
    * To test if the split region is removed from RIT if the region was in SPLITTING state
    * but the RS has actually completed the splitting in META but went down. See HBASE-6070
@@ -446,7 +446,7 @@ public class TestAssignmentManager {
     am.regionsInTransition.put(REGIONINFO.getEncodedName(), new RegionState(REGIONINFO,
         State.SPLITTING, System.currentTimeMillis(), SERVERNAME_A));
     am.getZKTable().setEnabledTable(REGIONINFO.getTableNameAsString());
-    
+
     RegionTransitionData data = new RegionTransitionData(EventType.RS_ZK_REGION_SPLITTING,
         REGIONINFO.getRegionName(), SERVERNAME_A);
     String node = ZKAssign.getNodeName(this.watcher, REGIONINFO.getEncodedName());
@@ -454,11 +454,11 @@ public class TestAssignmentManager {
     ZKUtil.createAndWatch(this.watcher, node, data.getBytes());
 
     try {
-      
+
       processServerShutdownHandler(ct, am, regionSplitDone);
       // check znode deleted or not.
       // In both cases the znode should be deleted.
-      
+
       if(regionSplitDone){
         assertTrue("Region state of region in SPLITTING should be removed from rit.",
             am.regionsInTransition.isEmpty());
@@ -501,7 +501,7 @@ public class TestAssignmentManager {
     } else {
       am.getZKTable().setDisabledTable(REGIONINFO.getTableNameAsString());
     }
-    
+
     RegionTransitionData data = new RegionTransitionData(EventType.M_ZK_REGION_CLOSING,
         REGIONINFO.getRegionName(), SERVERNAME_A);
     String node = ZKAssign.getNodeName(this.watcher, REGIONINFO.getEncodedName());
@@ -576,7 +576,7 @@ public class TestAssignmentManager {
    * @param hri Region to serialize into HRegionInfo
    * @return A mocked up Result that fakes a Get on a row in the
    * <code>.META.</code> table.
-   * @throws IOException 
+   * @throws IOException
    */
   private Result getMetaTableRowResult(final HRegionInfo hri,
       final ServerName sn)
@@ -595,13 +595,13 @@ public class TestAssignmentManager {
       Bytes.toBytes(sn.getStartcode())));
     return new Result(kvs);
   }
-  
+
   /**
    * @param sn ServerName to use making startcode and server in meta
    * @param hri Region to serialize into HRegionInfo
    * @return A mocked up Result that fakes a Get on a row in the
    * <code>.META.</code> table.
-   * @throws IOException 
+   * @throws IOException
    */
   private Result getMetaTableRowResultAsSplitRegion(final HRegionInfo hri, final ServerName sn)
       throws IOException {
@@ -663,12 +663,12 @@ public class TestAssignmentManager {
       am.shutdown();
     }
   }
-  
+
   /**
    * Tests the processDeadServersAndRegionsInTransition should not fail with NPE
    * when it failed to get the children. Let's abort the system in this
    * situation
-   * @throws ServiceException 
+   * @throws ServiceException
    */
   @Test(timeout = 5000)
   public void testProcessDeadServersAndRegionsInTransitionShouldNotFailWithNPE()
@@ -708,8 +708,8 @@ public class TestAssignmentManager {
    * @param region region to be created as offline
    * @param serverName server event originates from
    * @return Version of znode created.
-   * @throws KeeperException 
-   * @throws IOException 
+   * @throws KeeperException
+   * @throws IOException
    */
   // Copied from SplitTransaction rather than open the method over there in
   // the regionserver package.
@@ -789,9 +789,9 @@ public class TestAssignmentManager {
         server, manager, ct, balancer, executor);
     return am;
   }
-  
+
   /**
-   * TestCase verifies that the regionPlan is updated whenever a region fails to open 
+   * TestCase verifies that the regionPlan is updated whenever a region fails to open
    * and the master tries to process RS_ZK_FAILED_OPEN state.(HBASE-5546).
    */
   @Test
@@ -845,11 +845,11 @@ public class TestAssignmentManager {
       am.shutdown();
     }
   }
-  
+
   /**
    * Test verifies whether assignment is skipped for regions of tables in DISABLING state during
    * clean cluster startup. See HBASE-6281.
-   * 
+   *
    * @throws KeeperException
    * @throws IOException
    * @throws Exception
@@ -903,12 +903,12 @@ public class TestAssignmentManager {
     }
 
     @Override
-    public ServerName randomAssignment(List<ServerName> servers) {
-      ServerName randomServerName = super.randomAssignment(servers);
+    public ServerName randomAssignment(HRegionInfo region, List<ServerName> servers) {
+      ServerName randomServerName = super.randomAssignment(region, servers);
       this.gate.set(true);
       return randomServerName;
     }
-    
+
     @Override
     public Map<ServerName, List<HRegionInfo>> retainAssignment(
         Map<HRegionInfo, ServerName> regions, List<ServerName> servers) {
@@ -956,19 +956,19 @@ public class TestAssignmentManager {
       while (this.gate.get()) Threads.sleep(1);
       super.processRegionsInTransition(data, regionInfo, deadServers, expectedVersion);
     }
-    
+
     @Override
     public void assign(HRegionInfo region, boolean setOfflineInZK, boolean forceNewPlan,
         boolean hijack) {
       assignInvoked = true;
       super.assign(region, setOfflineInZK, forceNewPlan, hijack);
     }
-    
+
     @Override
     public ServerName getRegionServerOfRegion(HRegionInfo hri) {
       return SERVERNAME_A;
     }
-    
+
     /** reset the watcher */
     void setWatcher(ZooKeeperWatcher watcher) {
       this.watcher = watcher;
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java b/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java
index c83d4ba..45d40fa 100644
--- a/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java
@@ -285,6 +285,11 @@ public class TestCatalogJanitor {
     public <T extends CoprocessorProtocol> boolean registerProtocol(Class<T> protocol, T handler) {
       return false;
     }
+
+    @Override
+    public LoadBalancer getLoadBalancer() {
+      return null;
+    }
   }
 
   @Test
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestGroupBasedLoadBalancer.java b/src/test/java/org/apache/hadoop/hbase/master/TestGroupBasedLoadBalancer.java
new file mode 100644
index 0000000..4370f51
--- /dev/null
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestGroupBasedLoadBalancer.java
@@ -0,0 +1,569 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.TreeMap;
+import java.util.TreeSet;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MediumTests;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.TableDescriptors;
+import org.apache.hadoop.hbase.group.GroupBasedLoadBalancer;
+import org.apache.hadoop.hbase.group.GroupInfo;
+import org.apache.hadoop.hbase.group.GroupInfoManager;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+import org.mockito.Mockito;
+
+import com.google.common.collect.ArrayListMultimap;
+import com.google.common.collect.Lists;
+import org.mockito.invocation.InvocationOnMock;
+import org.mockito.stubbing.Answer;
+
+@Category(MediumTests.class)
+public class TestGroupBasedLoadBalancer {
+
+    private static final Log LOG = LogFactory.getLog(TestGroupBasedLoadBalancer.class);
+    private static GroupBasedLoadBalancer loadBalancer;
+    private static Random rand;
+
+    static String[]  groups = new String[] { GroupInfo.DEFAULT_GROUP, "dg2", "dg3",
+            "dg4" };
+    static String[] tables = new String[] { "dt1", "dt2", "dt3", "dt4" };
+    static List<ServerName> servers;
+    static Map<String, GroupInfo> groupMap;
+    static Map<String, String> tableMap;
+    static List<HTableDescriptor> tableDescs;
+    int[] regionAssignment = new int[] { 2, 5, 7, 10, 4, 3, 1 };
+    static int regionId = 0;
+
+    @BeforeClass
+    public static void beforeAllTests() throws Exception {
+        rand = new Random();
+        servers = generatedServers(7);
+        groupMap = constructGroupInfo(servers, groups);
+        tableMap = new HashMap<String, String>();
+        tableDescs = constructTableDesc();
+        Configuration conf = HBaseConfiguration.create();
+        conf.set("hbase.regions.slop", "0");
+        loadBalancer = new GroupBasedLoadBalancer(getMockedGroupInfoManager());
+        loadBalancer.setMasterServices(getMockedMaster());
+        loadBalancer.setConf(conf);
+        loadBalancer.configure();
+    }
+
+    /**
+     * Test the load balancing algorithm.
+     *
+     * Invariant is that all servers of the group should be hosting either floor(average) or
+     * ceiling(average)
+     *
+     * @throws Exception
+     */
+    @Test
+    public void testBalanceCluster() throws Exception {
+        Map<ServerName, List<HRegionInfo>> servers = mockClusterServers();
+        ArrayListMultimap<String, ServerAndLoad> list = convertToGroupBasedMap(servers);
+        LOG.info("Mock Cluster :  " + printStats(list));
+        List<RegionPlan> plans = loadBalancer.balanceCluster(servers);
+        ArrayListMultimap<String, ServerAndLoad> balancedCluster = reconcile(
+                                                    list, plans);
+        LOG.info("Mock Balance : " + printStats(balancedCluster));
+        assertClusterAsBalanced(balancedCluster);
+    }
+
+    /**
+     * Invariant is that all servers of a group have load between floor(avg) and
+     * ceiling(avg) number of regions.
+     */
+    private void assertClusterAsBalanced(
+            ArrayListMultimap<String, ServerAndLoad> groupLoadMap) {
+        for (String gName : groupLoadMap.keySet()) {
+            List<ServerAndLoad> groupLoad = groupLoadMap.get(gName);
+            int numServers = groupLoad.size();
+            int numRegions = 0;
+            int maxRegions = 0;
+            int minRegions = Integer.MAX_VALUE;
+            for (ServerAndLoad server : groupLoad) {
+                int nr = server.getLoad();
+                if (nr > maxRegions) {
+                    maxRegions = nr;
+                }
+                if (nr < minRegions) {
+                    minRegions = nr;
+                }
+                numRegions += nr;
+            }
+            if (maxRegions - minRegions < 2) {
+                // less than 2 between max and min, can't balance
+                return;
+            }
+            int min = numRegions / numServers;
+            int max = numRegions % numServers == 0 ? min : min + 1;
+
+            for (ServerAndLoad server : groupLoad) {
+                assertTrue(server.getLoad() <= max);
+                assertTrue(server.getLoad() >= min);
+            }
+        }
+    }
+
+    /**
+     * Tests immediate assignment.
+     *
+     * Invariant is that all regions have an assignment.
+     *
+     * @throws Exception
+     */
+    @Test
+    public void testImmediateAssignment() throws Exception {
+        List<HRegionInfo> regions = randomRegions(20);
+        Map<HRegionInfo, ServerName> assignments = loadBalancer
+                .immediateAssignment(regions, servers);
+        assertImmediateAssignment(regions, servers, assignments);
+    }
+
+    /**
+     * All regions have an assignment.
+     *
+     * @param regions
+     * @param servers
+     * @param assignments
+     * @throws IOException
+     * @throws FileNotFoundException
+     */
+    private void assertImmediateAssignment(List<HRegionInfo> regions,
+            List<ServerName> servers, Map<HRegionInfo, ServerName> assignments)
+            throws FileNotFoundException, IOException {
+        for (HRegionInfo region : regions) {
+            assertTrue(assignments.containsKey(region));
+            ServerName server = assignments.get(region);
+            String tableName = region.getTableNameAsString();
+
+            String groupName =
+                loadBalancer.getGroupInfoManager().getGroupOfTable(tableName);
+            assertTrue(StringUtils.isNotEmpty(groupName));
+            GroupInfo gInfo = getMockedGroupInfoManager().getGroup(groupName);
+            assertTrue("Region is not correctly assigned to group servers.",
+                    gInfo.containsServer(server.getHostAndPort()));
+        }
+    }
+
+    /**
+     * Tests the bulk assignment used during cluster startup.
+     *
+     * Round-robin. Should yield a balanced cluster so same invariant as the
+     * load balancer holds, all servers holding either floor(avg) or
+     * ceiling(avg).
+     *
+     * @throws Exception
+     */
+    @Test
+    public void testBulkAssignment() throws Exception {
+        List<HRegionInfo> regions = randomRegions(25);
+        Map<ServerName, List<HRegionInfo>> assignments = loadBalancer
+                .roundRobinAssignment(regions, servers);
+        assertTrue(assignments.keySet().size() == servers.size());
+        for (ServerName sn : assignments.keySet()) {
+            List<HRegionInfo> regionAssigned = assignments.get(sn);
+            for (HRegionInfo region : regionAssigned) {
+                String tableName = region.getTableNameAsString();
+                String groupName =
+                    getMockedGroupInfoManager().getGroupOfTable(tableName);
+                assertTrue(StringUtils.isNotEmpty(groupName));
+                GroupInfo gInfo = getMockedGroupInfoManager().getGroup(
+                        groupName);
+                assertTrue(
+                        "Region is not correctly assigned to group servers.",
+                        gInfo.containsServer(sn.getHostAndPort()));
+            }
+        }
+        ArrayListMultimap<String, ServerAndLoad> loadMap = convertToGroupBasedMap(assignments);
+        assertClusterAsBalanced(loadMap);
+    }
+
+    /**
+     * Test the cluster startup bulk assignment which attempts to retain
+     * assignment info.
+     *
+     * @throws Exception
+     */
+    @Test
+    public void testRetainAssignment() throws Exception {
+        // Test simple case where all same servers are there
+        Map<ServerName, List<HRegionInfo>> currentAssignments = mockClusterServers();
+        Map<HRegionInfo, ServerName> inputForTest = new HashMap<HRegionInfo, ServerName>();
+        for (ServerName sn : currentAssignments.keySet()) {
+            for (HRegionInfo region : currentAssignments.get(sn)) {
+                inputForTest.put(region, sn);
+            }
+        }
+        Map<ServerName, List<HRegionInfo>> newAssignment = loadBalancer
+                .retainAssignment(inputForTest, servers);
+        assertRetainedAssignment(inputForTest, servers, newAssignment);
+    }
+
+    /**
+     * Asserts a valid retained assignment plan.
+     * <p>
+     * Must meet the following conditions:
+     * <ul>
+     * <li>Every input region has an assignment, and to an online server
+     * <li>If a region had an existing assignment to a server with the same
+     * address a a currently online server, it will be assigned to it
+     * </ul>
+     *
+     * @param existing
+     * @param groupBasedLoad
+     * @param assignment
+     * @throws IOException
+     * @throws FileNotFoundException
+     */
+    private void assertRetainedAssignment(
+            Map<HRegionInfo, ServerName> existing, List<ServerName> servers,
+            Map<ServerName, List<HRegionInfo>> assignment)
+            throws FileNotFoundException, IOException {
+        // Verify condition 1, every region assigned, and to online server
+        Set<ServerName> onlineServerSet = new TreeSet<ServerName>(servers);
+        Set<HRegionInfo> assignedRegions = new TreeSet<HRegionInfo>();
+        for (Map.Entry<ServerName, List<HRegionInfo>> a : assignment.entrySet()) {
+            assertTrue(
+                    "Region assigned to server that was not listed as online",
+                    onlineServerSet.contains(a.getKey()));
+            for (HRegionInfo r : a.getValue())
+                assignedRegions.add(r);
+        }
+        assertEquals(existing.size(), assignedRegions.size());
+
+        // Verify condition 2, every region must be assigned to correct server.
+        Set<String> onlineHostNames = new TreeSet<String>();
+        for (ServerName s : servers) {
+            onlineHostNames.add(s.getHostname());
+        }
+
+        for (Map.Entry<ServerName, List<HRegionInfo>> a : assignment.entrySet()) {
+            ServerName currentServer = a.getKey();
+            for (HRegionInfo r : a.getValue()) {
+                ServerName oldAssignedServer = existing.get(r);
+                String tableName = r.getTableNameAsString();
+                String groupName =
+                    getMockedGroupInfoManager().getGroupOfTable(tableName);
+                assertTrue(StringUtils.isNotEmpty(groupName));
+                GroupInfo gInfo = getMockedGroupInfoManager().getGroup(
+                        groupName);
+                assertTrue(
+                        "Region is not correctly assigned to group servers.",
+                        gInfo.containsServer(currentServer.getHostAndPort()));
+                if (oldAssignedServer != null
+                        && onlineHostNames.contains(oldAssignedServer
+                                .getHostname())) {
+                    // this region was previously assigned somewhere, and that
+                    // host is still around, then the host must have been is a
+                    // different group.
+                    if (oldAssignedServer.getHostAndPort().equals(
+                            currentServer.getHostAndPort()) == false) {
+                        assertFalse(gInfo.containsServer(oldAssignedServer
+                                .getHostAndPort()));
+                    }
+                }
+            }
+        }
+    }
+
+    private String printStats(
+            ArrayListMultimap<String, ServerAndLoad> groupBasedLoad) {
+        StringBuffer sb = new StringBuffer();
+        sb.append("\n");
+        for (String groupName : groupBasedLoad.keySet()) {
+            sb.append("Stats for group: " + groupName);
+            sb.append("\n");
+            sb.append(groupMap.get(groupName).getServers());
+            sb.append("\n");
+            List<ServerAndLoad> groupLoad = groupBasedLoad.get(groupName);
+            int numServers = groupLoad.size();
+            int totalRegions = 0;
+            sb.append("Per Server Load: \n");
+            for (ServerAndLoad sLoad : groupLoad) {
+                sb.append("Server :" + sLoad.getServerName() + " Load : "
+                        + sLoad.getLoad() + "\n");
+                totalRegions += sLoad.getLoad();
+            }
+            sb.append(" Group Statistics : \n");
+            float average = (float) totalRegions / numServers;
+            int max = (int) Math.ceil(average);
+            int min = (int) Math.floor(average);
+            sb.append("[srvr=" + numServers + " rgns=" + totalRegions + " avg="
+                    + average + " max=" + max + " min=" + min + "]");
+            sb.append("\n");
+            sb.append("===============================");
+            sb.append("\n");
+        }
+        return sb.toString();
+    }
+
+    private ArrayListMultimap<String, ServerAndLoad> convertToGroupBasedMap(
+            final Map<ServerName, List<HRegionInfo>> serversMap) throws IOException {
+        ArrayListMultimap<String, ServerAndLoad> loadMap = ArrayListMultimap
+                .create();
+        for (GroupInfo gInfo : getMockedGroupInfoManager().listGroups()) {
+            Set<String> groupServers = gInfo.getServers();
+            for (String hostAndPort : groupServers) {
+                ServerName actual = ServerName.findServerWithSameHostnamePort(
+                        servers, ServerName.parseServerName(hostAndPort));
+                List<HRegionInfo> regions = serversMap.get(actual);
+                assertTrue("No load for " + actual, regions != null);
+                loadMap.put(gInfo.getName(),
+                        new ServerAndLoad(actual, regions.size()));
+            }
+        }
+        return loadMap;
+    }
+
+  private ArrayListMultimap<String, ServerAndLoad> reconcile(
+      ArrayListMultimap<String, ServerAndLoad> previousLoad,
+      List<RegionPlan> plans) {
+    ArrayListMultimap<String, ServerAndLoad> result = ArrayListMultimap
+        .create();
+    result.putAll(previousLoad);
+    if (plans != null) {
+      for (RegionPlan plan : plans) {
+        ServerName source = plan.getSource();
+        updateLoad(result, source, -1);
+        ServerName destination = plan.getDestination();
+        updateLoad(result, destination, +1);
+      }
+    }
+    return result;
+  }
+
+  private void updateLoad(
+      ArrayListMultimap<String, ServerAndLoad> previousLoad,
+      final ServerName sn, final int diff) {
+    for (String groupName : previousLoad.keySet()) {
+      ServerAndLoad newSAL = null;
+      ServerAndLoad oldSAL = null;
+      for (ServerAndLoad sal : previousLoad.get(groupName)) {
+        if (ServerName.isSameHostnameAndPort(sn, sal.getServerName())) {
+          oldSAL = sal;
+          newSAL = new ServerAndLoad(sn, sal.getLoad() + diff);
+          break;
+        }
+      }
+      if (newSAL != null) {
+        previousLoad.remove(groupName, oldSAL);
+        previousLoad.put(groupName, newSAL);
+        break;
+      }
+    }
+  }
+
+    private Map<ServerName, List<HRegionInfo>> mockClusterServers() throws IOException {
+        assertTrue(servers.size() == regionAssignment.length);
+        Map<ServerName, List<HRegionInfo>> assignment = new TreeMap<ServerName, List<HRegionInfo>>();
+        for (int i = 0; i < servers.size(); i++) {
+            int numRegions = regionAssignment[i];
+            List<HRegionInfo> regions = assignedRegions(numRegions, servers.get(i));
+            assignment.put(servers.get(i), regions);
+        }
+        return assignment;
+    }
+
+    /**
+     * Generated a list of regions evenly distributed between the tables.
+     *
+     * @param numRegions The number of regions to be generated.
+     * @return List of HRegionInfo.
+     */
+    private List<HRegionInfo> randomRegions(int numRegions) {
+        List<HRegionInfo> regions = new ArrayList<HRegionInfo>(numRegions);
+        byte[] start = new byte[16];
+        byte[] end = new byte[16];
+        rand.nextBytes(start);
+        rand.nextBytes(end);
+        int regionIdx = rand.nextInt(tables.length);
+        for (int i = 0; i < numRegions; i++) {
+            Bytes.putInt(start, 0, numRegions << 1);
+            Bytes.putInt(end, 0, (numRegions << 1) + 1);
+            int tableIndex = (i + regionIdx) % tables.length;
+            HRegionInfo hri = new HRegionInfo(
+                    Bytes.toBytes(tables[tableIndex]), start, end, false,
+                    regionId++);
+            regions.add(hri);
+        }
+        return regions;
+    }
+
+    /**
+     * Generated assigned regions to a given server using group information.
+     *
+     * @param numRegions the num regions to generate
+     * @param sn the servername
+     * @return the list
+     * @throws IOException Signals that an I/O exception has occurred.
+     */
+    private List<HRegionInfo> assignedRegions(int numRegions, ServerName sn) throws IOException {
+      List<HRegionInfo> regions = new ArrayList<HRegionInfo>(numRegions);
+      byte[] start = new byte[16];
+      byte[] end = new byte[16];
+      for (int i = 0; i < numRegions; i++) {
+          Bytes.putInt(start, 0, numRegions << 1);
+          Bytes.putInt(end, 0, (numRegions << 1) + 1);
+          String tableName = getTableName(sn);
+          HRegionInfo hri = new HRegionInfo(
+                  Bytes.toBytes(tableName), start, end, false,
+                  regionId++);
+          regions.add(hri);
+      }
+      return regions;
+  }
+
+    private static List<ServerName> generatedServers(int numServers) {
+        List<ServerName> servers = new ArrayList<ServerName>(numServers);
+        for (int i = 0; i < numServers; i++) {
+            String host = "server" + rand.nextInt(100000);
+            int port = rand.nextInt(60000);
+            servers.add(new ServerName(host, port, -1));
+        }
+        return servers;
+    }
+
+    /**
+     * Construct group info, with each group have atleast one server.
+     *
+     * @param servers the servers
+     * @param groups the groups
+     * @return the map
+     */
+    private static Map<String, GroupInfo> constructGroupInfo(
+            List<ServerName> servers, String[] groups) {
+        assertTrue(servers != null);
+        assertTrue(servers.size() >= groups.length);
+        int index = 0;
+        Map<String, GroupInfo> groupMap = new HashMap<String, GroupInfo>();
+        for (String grpName : groups) {
+            TreeSet<String> hostAndPort = new TreeSet<String>();
+            hostAndPort.add(servers.get(index).getHostAndPort());
+            GroupInfo groupInfo = new GroupInfo(grpName);
+            groupInfo.addAllServers(hostAndPort);
+            groupMap.put(grpName, groupInfo);
+            index++;
+        }
+        while (index < servers.size()) {
+            int grpIndex = rand.nextInt(groups.length);
+            groupMap.get(groups[grpIndex]).addServer(
+                    servers.get(index).getHostAndPort());
+            index++;
+        }
+        return groupMap;
+    }
+
+    /**
+     * Construct table descriptors evenly distributed between the groups.
+     *
+     * @return the list
+     */
+    private static List<HTableDescriptor> constructTableDesc() {
+        List<HTableDescriptor> tds = Lists.newArrayList();
+        int index = rand.nextInt(groups.length);
+        for (int i = 0; i < tables.length; i++) {
+            HTableDescriptor htd = new HTableDescriptor(tables[i]);
+            int grpIndex = (i + index) % groups.length ;
+            String groupName = groups[grpIndex];
+            tableMap.put(tables[i], groupName);
+            tds.add(htd);
+        }
+        return tds;
+    }
+
+    private static MasterServices getMockedMaster() throws IOException {
+        TableDescriptors tds = Mockito.mock(TableDescriptors.class);
+        Mockito.when(tds.get(tables[0])).thenReturn(tableDescs.get(0));
+        Mockito.when(tds.get(tables[1])).thenReturn(tableDescs.get(1));
+        Mockito.when(tds.get(tables[2])).thenReturn(tableDescs.get(2));
+        Mockito.when(tds.get(tables[3])).thenReturn(tableDescs.get(3));
+        MasterServices services = Mockito.mock(HMaster.class);
+        Mockito.when(services.getTableDescriptors()).thenReturn(tds);
+        AssignmentManager am = Mockito.mock(AssignmentManager.class);
+        Mockito.when(services.getAssignmentManager()).thenReturn(am);
+        return services;
+    }
+
+    private static GroupInfoManager getMockedGroupInfoManager() throws IOException {
+        GroupInfoManager gm = Mockito.mock(GroupInfoManager.class);
+        Mockito.when(gm.getGroup(groups[0])).thenReturn(
+                groupMap.get(groups[0]));
+        Mockito.when(gm.getGroup(groups[1])).thenReturn(
+                groupMap.get(groups[1]));
+        Mockito.when(gm.getGroup(groups[2])).thenReturn(
+                groupMap.get(groups[2]));
+        Mockito.when(gm.getGroup(groups[3])).thenReturn(
+                groupMap.get(groups[3]));
+        Mockito.when(gm.listGroups()).thenReturn(
+                Lists.newLinkedList(groupMap.values()));
+        Mockito.when(gm.isOnline()).thenReturn(true);
+        Mockito.when(gm.getGroupOfTable(Mockito.anyString())).thenAnswer(new Answer<String>() {
+          @Override
+          public String answer(InvocationOnMock invocation) throws Throwable {
+            return tableMap.get(invocation.getArguments()[0]);
+          }
+        });
+        return gm;
+    }
+
+    private String getTableName(ServerName sn) throws IOException{
+      String tableName = null;
+      GroupInfoManager gm = getMockedGroupInfoManager();
+      GroupInfo groupOfServer = null;
+      for(GroupInfo gInfo : gm.listGroups()){
+        if(gInfo.containsServer(sn.getHostAndPort())){
+          groupOfServer = gInfo;
+          break;
+        }
+      }
+
+      for(HTableDescriptor desc : tableDescs){
+       if(gm.getGroupOfTable(desc.getNameAsString()).endsWith(groupOfServer.getName())){
+         tableName = desc.getNameAsString();
+       }
+      }
+      return tableName;
+    }
+}
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestGroups.java b/src/test/java/org/apache/hadoop/hbase/master/TestGroups.java
new file mode 100644
index 0000000..3c0cfa7
--- /dev/null
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestGroups.java
@@ -0,0 +1,248 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+
+import com.google.common.collect.Sets;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MediumTests;
+import org.apache.hadoop.hbase.MiniHBaseCluster;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.group.GroupAdminClient;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.group.GroupAdminEndpoint;
+import org.apache.hadoop.hbase.group.GroupBasedLoadBalancer;
+import org.apache.hadoop.hbase.group.GroupInfo;
+import org.apache.hadoop.hbase.group.GroupInfoManager;
+import org.apache.hadoop.hbase.group.GroupMasterObserver;
+import org.apache.hadoop.hbase.ipc.HRegionInterface;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+
+@Category(MediumTests.class)
+public class TestGroups {
+	private static HBaseTestingUtility TEST_UTIL;
+	private static HMaster master;
+	private static Random rand;
+  private static HBaseAdmin admin;
+	private static String groupPrefix = "Group-";
+	private static String tablePrefix = "TABLE-";
+	private static String familyPrefix = "FAMILY-";
+
+	@BeforeClass
+	public static void setUp() throws Exception {
+		TEST_UTIL = new HBaseTestingUtility();
+		TEST_UTIL.getConfiguration().set(
+				HConstants.HBASE_MASTER_LOADBALANCER_CLASS,
+				GroupBasedLoadBalancer.class.getName());
+    TEST_UTIL.getConfiguration().set("hbase.coprocessor.master.classes",
+        GroupMasterObserver.class.getName()+","+
+        GroupAdminEndpoint.class.getName());
+		TEST_UTIL.startMiniCluster(4);
+		MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
+		master = cluster.getMaster();
+		rand = new Random();
+    admin = TEST_UTIL.getHBaseAdmin();
+    //wait till the balancer is in online mode
+    while(!((GroupBasedLoadBalancer)master.getLoadBalancer()).isOnline()) {
+      Thread.sleep(100);
+    }
+	}
+
+	@AfterClass
+	public static void tearDown() throws Exception {
+		TEST_UTIL.shutdownMiniCluster();
+	}
+
+  @After
+  public void afterMethod() throws Exception {
+		GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+    for(GroupInfo group: groupAdmin.listGroups()) {
+      if(!group.getName().equals(GroupInfo.DEFAULT_GROUP)) {
+        removeGroup(groupAdmin, group.getName());
+      }
+    }
+    for(HTableDescriptor table: TEST_UTIL.getHBaseAdmin().listTables()) {
+      if(!table.isMetaRegion() && !table.isRootRegion() &&
+          !Bytes.equals(table.getName(), GroupInfoManager.GROUP_TABLE_NAME_BYTES)) {
+        TEST_UTIL.deleteTable(table.getName());
+      }
+    }
+  }
+
+	@Test
+	public void testBasicStartUp() throws IOException {
+		GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+		GroupInfo defaultInfo = groupAdmin.getGroupInfo(GroupInfo.DEFAULT_GROUP);
+		assertEquals(4, defaultInfo.getServers().size());
+		// Assignment of root and meta regions.
+		assertEquals(3, groupAdmin.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP).size());
+	}
+
+	@Test
+	public void testSimpleRegionServerMove() throws IOException,
+			InterruptedException {
+		GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+		GroupInfo appInfo = addGroup(groupAdmin, groupPrefix + rand.nextInt(), 1);
+		GroupInfo adminInfo = addGroup(groupAdmin, groupPrefix + rand.nextInt(), 1);
+    GroupInfo dInfo = groupAdmin.getGroupInfo(GroupInfo.DEFAULT_GROUP);
+		// Force the group info manager to read group information from disk.
+		assertTrue(groupAdmin.listGroups().size() == 3);
+		assertTrue(adminInfo.getServers().size() == 1);
+		assertTrue(appInfo.getServers().size() == 1);
+		assertTrue(dInfo.getServers().size() == 2);
+		groupAdmin.moveServers(appInfo.getServers(),
+        GroupInfo.DEFAULT_GROUP);
+		groupAdmin.removeGroup(appInfo.getName());
+		groupAdmin.moveServers(adminInfo.getServers(),
+        GroupInfo.DEFAULT_GROUP);
+		groupAdmin.removeGroup(adminInfo.getName());
+		assertTrue(groupAdmin.listGroups().size() == 1);
+	}
+
+	@Test
+	public void testTableMove() throws IOException, InterruptedException {
+		String tableName = tablePrefix + rand.nextInt();
+		byte[] TABLENAME = Bytes.toBytes(tableName);
+		byte[] FAMILYNAME = Bytes.toBytes(familyPrefix + rand.nextInt());
+		GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+		GroupInfo newGroup = addGroup(groupAdmin, groupPrefix + rand.nextInt(), 2);
+    int currMetaCount = TEST_UTIL.getMetaTableRows().size();
+		HTable ht = TEST_UTIL.createTable(TABLENAME, FAMILYNAME);
+		assertTrue(TEST_UTIL.createMultiRegions(master.getConfiguration(), ht,
+				FAMILYNAME, 4) == 4);
+		TEST_UTIL.waitUntilAllRegionsAssigned(currMetaCount+4);
+		assertTrue(master.getAssignmentManager().getZKTable()
+				.isEnabledTable(Bytes.toString(TABLENAME)));
+		List<HRegionInfo> regionList = TEST_UTIL.getHBaseAdmin()
+				.getTableRegions(TABLENAME);
+		assertTrue(regionList.size() > 0);
+		GroupInfo tableGrp = groupAdmin.getGroupInfoOfTable(tableName);
+		assertTrue(tableGrp.getName().equals(GroupInfo.DEFAULT_GROUP));
+
+    //change table's group
+    admin.disableTable(TABLENAME);
+    groupAdmin.moveTables(Sets.newHashSet(Bytes.toString(TABLENAME)), newGroup.getName());
+    admin.enableTable(TABLENAME);
+
+    //verify group change
+		assertEquals(newGroup.getName(),
+        groupAdmin.getGroupInfoOfTable(Bytes.toString(TABLENAME)).getName());
+
+		Map<String, Map<ServerName, List<HRegionInfo>>> tableRegionAssignMap = master
+				.getAssignmentManager().getAssignmentsByTable();
+		assertEquals(2, tableRegionAssignMap.keySet().size());
+		Map<ServerName, List<HRegionInfo>> serverMap = tableRegionAssignMap
+				.get(tableName);
+		for (ServerName rs : serverMap.keySet()) {
+			if (serverMap.get(rs).size() > 0) {
+				assertTrue(newGroup.containsServer(rs.getHostAndPort()));
+			}
+		}
+    removeGroup(groupAdmin, newGroup.getName());
+		TEST_UTIL.deleteTable(TABLENAME);
+		tableRegionAssignMap = master.getAssignmentManager()
+				.getAssignmentsByTable();
+		assertEquals(1, tableRegionAssignMap.size());
+	}
+
+	@Test
+	public void testRegionMove() throws IOException, InterruptedException {
+		GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+		GroupInfo newGroup = addGroup(groupAdmin, groupPrefix + rand.nextInt(), 1);
+		String tableNameOne = tablePrefix + rand.nextInt();
+		byte[] tableOneBytes = Bytes.toBytes(tableNameOne);
+		byte[] familyOneBytes = Bytes.toBytes(familyPrefix + rand.nextInt());
+		HTable ht = TEST_UTIL.createTable(tableOneBytes, familyOneBytes);
+		// All the regions created below will be assigned to the default group.
+    int curMetaCount = TEST_UTIL.getMetaTableRows().size();
+    assertTrue(TEST_UTIL.createMultiRegions(master.getConfiguration(), ht, familyOneBytes, 5) == 5);
+    while (groupAdmin.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP).size() < (curMetaCount + 5)) {
+      Thread.sleep(100);
+    }
+		List<HRegionInfo> regions = groupAdmin
+				.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP);
+		HRegionInfo region = regions.get(regions.size()-1);
+		// Lets move this region to newGroupName group.
+		ServerName tobeAssigned =
+        ServerName.parseServerName(newGroup.getServers().iterator().next());
+		master.move(region.getEncodedNameAsBytes(),
+        Bytes.toBytes(tobeAssigned.toString()));
+    while (groupAdmin.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP).size() != regions.size()) {
+      Thread.sleep(100);
+    }
+    //verify that region was never assigned to the server
+		List<HRegionInfo> updatedRegions = groupAdmin.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP);
+    assertTrue(regions.size() + "!=" + updatedRegions.size(),regions.size() == updatedRegions.size());
+    HRegionInterface rs = admin.getConnection().getHRegionConnection(tobeAssigned.getHostname(),
+      tobeAssigned.getPort());
+		assertFalse(rs.getOnlineRegions().contains(region));
+	}
+
+	static GroupInfo addGroup(GroupAdminClient gAdmin, String groupName,
+			int serverCount) throws IOException, InterruptedException {
+		GroupInfo defaultInfo = gAdmin
+				.getGroupInfo(GroupInfo.DEFAULT_GROUP);
+		assertTrue(defaultInfo != null);
+		assertTrue(defaultInfo.getServers().size() >= serverCount);
+		gAdmin.addGroup(groupName);
+
+    Set<String> set = new HashSet<String>();
+    for(String server: defaultInfo.getServers()) {
+      if(set.size() == serverCount) {
+        break;
+      }
+      set.add(server);
+    }
+    gAdmin.moveServers(set, groupName);
+    GroupInfo result = gAdmin.getGroupInfo(groupName);
+		assertTrue(result.getServers().size() >= serverCount);
+    return result;
+	}
+
+  static void removeGroup(GroupAdminClient groupAdmin, String groupName) throws IOException {
+    for(String table: groupAdmin.listTablesOfGroup(groupName)) {
+      byte[] bTable = Bytes.toBytes(table);
+      admin.disableTable(bTable);
+      groupAdmin.moveTables(Sets.newHashSet(table), GroupInfo.DEFAULT_GROUP);
+      admin.enableTable(bTable);
+    }
+    groupAdmin.removeGroup(groupName);
+  }
+
+}
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestGroupsOfflineMode.java b/src/test/java/org/apache/hadoop/hbase/master/TestGroupsOfflineMode.java
new file mode 100644
index 0000000..d480ebf
--- /dev/null
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestGroupsOfflineMode.java
@@ -0,0 +1,165 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import com.google.common.collect.Sets;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MediumTests;
+import org.apache.hadoop.hbase.MiniHBaseCluster;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.group.GroupAdminClient;
+import org.apache.hadoop.hbase.group.GroupAdminEndpoint;
+import org.apache.hadoop.hbase.group.GroupBasedLoadBalancer;
+import org.apache.hadoop.hbase.group.GroupInfo;
+import org.apache.hadoop.hbase.group.GroupInfoManager;
+import org.apache.hadoop.hbase.group.GroupMasterObserver;
+import org.apache.hadoop.hbase.ipc.HRegionInterface;
+import org.apache.hadoop.hbase.regionserver.HRegionServer;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+import org.mortbay.log.Log;
+
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
+@Category(MediumTests.class)
+public class TestGroupsOfflineMode {
+	private static final org.apache.commons.logging.Log LOG = LogFactory.getLog(TestGroupsOfflineMode.class);
+	private static HBaseTestingUtility TEST_UTIL;
+	private static HMaster master;
+  private static HBaseAdmin admin;
+  private static MiniHBaseCluster cluster;
+
+	@BeforeClass
+	public static void setUp() throws Exception {
+		TEST_UTIL = new HBaseTestingUtility();
+		TEST_UTIL.getConfiguration().set(
+				HConstants.HBASE_MASTER_LOADBALANCER_CLASS,
+				GroupBasedLoadBalancer.class.getName());
+    TEST_UTIL.getConfiguration().set("hbase.coprocessor.master.classes",
+        GroupMasterObserver.class.getName()+","+
+        GroupAdminEndpoint.class.getName());
+		TEST_UTIL.getConfiguration().set(
+				ServerManager.WAIT_ON_REGIONSERVERS_MINTOSTART,
+				"1");
+		TEST_UTIL.startMiniCluster(2, 3);
+		cluster = TEST_UTIL.getHBaseCluster();
+		master = cluster.getMaster();
+    master.balanceSwitch(false);
+    admin = TEST_UTIL.getHBaseAdmin();
+    //wait till the balancer is in online mode
+    while(!((GroupBasedLoadBalancer)master.getLoadBalancer()).isOnline() ||
+          cluster.getMaster().getServerManager().getOnlineServers().size() < 2) {
+      Thread.sleep(100);
+    }
+	}
+
+	@AfterClass
+	public static void tearDown() throws Exception {
+		TEST_UTIL.shutdownMiniCluster();
+	}
+
+  @Test
+  public void testOffline() throws IOException, InterruptedException {
+    //table should be after group table name
+    //so it gets assigned later
+    String failoverTable = GroupInfoManager.GROUP_TABLE_NAME+"1";
+    TEST_UTIL.createTable(Bytes.toBytes(failoverTable), Bytes.toBytes("f"));
+
+    //adding testTable to special group so it gets assigned during offline mode
+    GroupBasedLoadBalancer.SPECIAL_TABLES.add(failoverTable);
+
+    GroupAdminClient groupAdmin = new GroupAdminClient(TEST_UTIL.getConfiguration());
+
+    HRegionServer killRS = cluster.getRegionServer(0);
+    HRegionServer groupRS = cluster.getRegionServer(1);
+    HRegionServer failoverRS = cluster.getRegionServer(2);
+
+    String newGroup =  "my_group";
+    groupAdmin.addGroup(newGroup);
+    for(HRegionInfo  regionInfo:
+        cluster.getMaster().getAssignmentManager().getAssignments().get(failoverRS.getServerName())) {
+      cluster.getMaster().move(regionInfo.getEncodedNameAsBytes(),
+          Bytes.toBytes(killRS.getServerName().getServerName()));
+    }
+    LOG.info("Waiting for region unassignments on failover RS...");
+    while(cluster.getMaster().getAssignmentManager().getAssignments().get(failoverRS.getServerName()).size() > 0) {
+      Thread.sleep(100);
+    }
+
+    groupAdmin.moveServers(Sets.newHashSet(groupRS.getServerName().getHostAndPort()), newGroup);
+    //move server to group and make sure all tables are assigned
+    while (groupRS.getOnlineRegions().size() > 0 ||
+        groupAdmin.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP).size() != TEST_UTIL.getMetaTableRows().size()+2) {
+      Thread.sleep(100);
+    }
+    //move table to group and wait
+    groupAdmin.moveTables(Sets.newHashSet(GroupInfoManager.GROUP_TABLE_NAME), newGroup);
+    LOG.info("Waiting for move table...");
+    while (groupRS.getOnlineRegions().size() < 1) {
+      Thread.sleep(100);
+    }
+    groupRS.stop("die");
+    //race condition here
+    TEST_UTIL.getHBaseCluster().getMaster().stopMaster();
+    LOG.info("Waiting for offline mode...");
+    while(TEST_UTIL.getHBaseCluster().getMaster() == null ||
+        !TEST_UTIL.getHBaseCluster().getMaster().isActiveMaster() ||
+        TEST_UTIL.getHBaseCluster().getMaster().getServerManager().getOnlineServers().size() > 2 ||
+        !TEST_UTIL.getHBaseCluster().getMaster().isInitialized()) {
+      Thread.sleep(100);
+    }
+
+    //make sure balancer is in offline mode, since this is what we're testing
+    assertFalse(((GroupBasedLoadBalancer)TEST_UTIL.getHBaseCluster().getMaster().getLoadBalancer()).isOnline());
+    //verify the group affiliation that's loaded from ZK instead of tables
+    assertEquals(newGroup, groupAdmin.getGroupInfoOfTable(GroupInfoManager.GROUP_TABLE_NAME).getName());
+    assertEquals(GroupInfo.OFFLINE_DEFAULT_GROUP, groupAdmin.getGroupInfoOfTable(failoverTable).getName());
+
+    //kill final regionserver to see the failover happens for all tables
+    //except GROUP table since it's group does not have any online RS
+    killRS.stop("die");
+    master = TEST_UTIL.getHBaseCluster().getMaster();
+    LOG.info("Waiting for new table assignment...");
+    while(failoverRS.getOnlineRegions(Bytes.toBytes(failoverTable)).size() < 1) {
+      Thread.sleep(100);
+    }
+    assertEquals(0, failoverRS.getOnlineRegions(GroupInfoManager.GROUP_TABLE_NAME_BYTES).size());
+  }
+
+}
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestGroupsWithDeadServers.java b/src/test/java/org/apache/hadoop/hbase/master/TestGroupsWithDeadServers.java
new file mode 100644
index 0000000..e791717
--- /dev/null
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestGroupsWithDeadServers.java
@@ -0,0 +1,202 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import static org.junit.Assert.*;
+
+import java.io.IOException;
+import java.util.List;
+import java.util.Random;
+import java.util.Set;
+import java.util.TreeSet;
+
+import com.google.common.collect.Sets;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.LargeTests;
+import org.apache.hadoop.hbase.MiniHBaseCluster;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.group.GroupAdminClient;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.ResultScanner;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.group.GroupAdminEndpoint;
+import org.apache.hadoop.hbase.group.GroupBasedLoadBalancer;
+import org.apache.hadoop.hbase.group.GroupInfo;
+import org.apache.hadoop.hbase.group.GroupMasterObserver;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.JVMClusterUtil;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+
+@Category(LargeTests.class)
+public class TestGroupsWithDeadServers {
+	private static HBaseTestingUtility TEST_UTIL;
+	private static HMaster master;
+	private static Random rand;
+  private static HBaseAdmin admin;
+
+	@BeforeClass
+	public static void setUp() throws Exception {
+		TEST_UTIL = new HBaseTestingUtility();
+		TEST_UTIL.getConfiguration().set(
+				HConstants.HBASE_MASTER_LOADBALANCER_CLASS,
+				GroupBasedLoadBalancer.class.getName());
+    TEST_UTIL.getConfiguration().set("hbase.coprocessor.master.classes",
+        GroupMasterObserver.class.getName()+","+
+        GroupAdminEndpoint.class.getName());
+		TEST_UTIL.getConfiguration().setInt(
+				"hbase.master.assignment.timeoutmonitor.period", 2000);
+		TEST_UTIL.getConfiguration().setInt(
+				"hbase.master.assignment.timeoutmonitor.timeout", 5000);
+		TEST_UTIL.startMiniCluster(4);
+		MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
+		master = cluster.getMaster();
+		rand = new Random();
+    admin = TEST_UTIL.getHBaseAdmin();
+    while(!((GroupBasedLoadBalancer)master.getLoadBalancer()).isOnline()) {
+      Thread.sleep(100);
+    }
+	}
+
+	@AfterClass
+	public static void tearDown() throws Exception {
+		TEST_UTIL.shutdownMiniCluster();
+	}
+
+	@Test
+	public void testGroupWithOnlineServers() throws IOException, InterruptedException{
+    GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+		String newRSGroup = "group-" + rand.nextInt();
+		String tableNameTwo = "TABLE-" + rand.nextInt();
+		byte[] tableTwoBytes = Bytes.toBytes(tableNameTwo);
+		String familyName = "family" + rand.nextInt();
+		byte[] familyTwoBytes = Bytes.toBytes(familyName);
+    int baseNumRegions = TEST_UTIL.getMetaTableRows().size();
+		int NUM_REGIONS = 4;
+
+		GroupInfo defaultInfo = groupAdmin.getGroupInfo(GroupInfo.DEFAULT_GROUP);
+		assertTrue(defaultInfo.getServers().size() == 4);
+		TestGroups.addGroup(groupAdmin, newRSGroup, 2);
+		defaultInfo = groupAdmin.getGroupInfo(GroupInfo.DEFAULT_GROUP);
+		assertTrue(defaultInfo.getServers().size() == 2);
+		assertTrue(groupAdmin.getGroupInfo(newRSGroup).getServers().size() == 2);
+		HTable ht = TEST_UTIL.createTable(tableTwoBytes, familyTwoBytes);
+		// All the regions created below will be assigned to the default group.
+		assertTrue(TEST_UTIL.createMultiRegions(master.getConfiguration(), ht,
+				familyTwoBytes, NUM_REGIONS) == NUM_REGIONS);
+		TEST_UTIL.waitUntilAllRegionsAssigned(baseNumRegions+NUM_REGIONS);
+		List<HRegionInfo> regions = groupAdmin.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP);
+		assertTrue(regions.size() >= NUM_REGIONS);
+    //move table to new group
+    admin.disableTable(tableNameTwo);
+    groupAdmin.moveTables(Sets.newHashSet(tableNameTwo), newRSGroup);
+    admin.enableTable(tableTwoBytes);
+
+		TEST_UTIL.waitUntilAllRegionsAssigned(baseNumRegions+NUM_REGIONS);
+		//Move the ROOT and META regions to default group.
+		ServerName serverForRoot =
+        ServerName.findServerWithSameHostnamePort(master.getServerManager().getOnlineServersList(),
+            ServerName.parseServerName(defaultInfo.getServers().iterator().next()));
+		master.move(HRegionInfo.ROOT_REGIONINFO.getEncodedNameAsBytes(), Bytes.toBytes(serverForRoot.toString()));
+		master.move(HRegionInfo.FIRST_META_REGIONINFO.getEncodedNameAsBytes(), Bytes.toBytes(serverForRoot.toString()));
+		while (master.getAssignmentManager().isRegionsInTransition()){
+			Thread.sleep(10);
+		}
+		List<HRegionInfo> newGrpRegions = groupAdmin.listOnlineRegionsOfGroup(newRSGroup);
+		assertTrue(newGrpRegions.size() == NUM_REGIONS);
+		MiniHBaseCluster hbaseCluster = TEST_UTIL.getHBaseCluster();
+		// Now we kill all the region servers in the new group.
+		Set<String> serverNames = groupAdmin.getGroupInfo(newRSGroup).getServers();
+		for (String sName : serverNames) {
+			int serverNumber = getServerNumber(
+					hbaseCluster.getRegionServerThreads(), sName);
+			assert (serverNumber != -1);
+			hbaseCluster.stopRegionServer(serverNumber, false);
+		}
+		//wait till all the regions come transition state.
+    int tries = 10;
+		while (groupAdmin.listOnlineRegionsOfGroup(newRSGroup).size() != 0 && tries-- > 0){
+			Thread.sleep(100);
+		}
+		newGrpRegions = groupAdmin.listOnlineRegionsOfGroup(newRSGroup);
+    assertTrue("Number of online regions in" + newRSGroup + " " + newGrpRegions.size(),
+      newGrpRegions.size() == 0);
+		regions = groupAdmin.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP);
+		assertEquals(3, regions.size());
+		startServersAndMove(groupAdmin, 1, newRSGroup);
+		while(master.getAssignmentManager().isRegionsInTransition()){
+			Thread.sleep(5);
+		}
+		scanTableForPositiveResults(ht);
+		newGrpRegions = groupAdmin.listOnlineRegionsOfGroup(newRSGroup);
+		assertTrue(newGrpRegions.size() == NUM_REGIONS);
+	}
+
+	private int getServerNumber(List<JVMClusterUtil.RegionServerThread> servers, String sName){
+		int i = 0;
+		for(JVMClusterUtil.RegionServerThread rs : servers){
+			if(sName.equals(rs.getRegionServer().getServerName().getHostAndPort())){
+				return i;
+			}
+			i++;
+		}
+		return -1;
+	}
+	
+	private void scanTableForPositiveResults(HTable ht) throws IOException{
+		ResultScanner s = null;
+		try {
+			Scan scan = new Scan();
+			s = ht.getScanner(scan);
+		} finally {
+			if (s != null) {
+				s.close();
+			}
+		}
+	}
+
+	private void startServersAndMove(GroupAdminClient groupAdmin, int numServers,
+			String groupName) throws IOException, InterruptedException {
+		MiniHBaseCluster hbaseCluster = TEST_UTIL.getHBaseCluster();
+		ServerName newServer;
+		for (int i = 0; i < numServers; i++) {
+			newServer = hbaseCluster.startRegionServer().getRegionServer()
+					.getServerName();
+			// Make sure that the server manager reports the new online servers.
+			while (ServerName.findServerWithSameHostnamePort(master
+					.getServerManager().getOnlineServersList(), newServer) == null) {
+				Thread.sleep(5);
+			}
+			assertTrue(groupAdmin.getGroupInfo(GroupInfo.DEFAULT_GROUP)
+          .containsServer(newServer.getHostAndPort()));
+      Set<String> set = new TreeSet<String>();
+      set.add(newServer.getHostAndPort());
+			groupAdmin.moveServers(set, groupName);
+			assertTrue(groupAdmin.getGroupInfo(groupName).containsServer(
+          newServer.getHostAndPort()));
+		}
+	}
+
+}
