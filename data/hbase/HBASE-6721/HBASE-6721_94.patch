diff --git a/security/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java b/security/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java
index b82ad5d..ddc3dc2 100644
--- a/security/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java
+++ b/security/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java
@@ -377,7 +377,7 @@ public class AccessController extends BaseRegionObserver
    * @throws IOException if obtaining the current user fails
    * @throws AccessDeniedException if user has no authorization
    */
-  private void requirePermission(byte[] tableName, byte[] family, byte[] qualifier,
+  public void requirePermission(byte[] tableName, byte[] family, byte[] qualifier,
       Action... permissions) throws IOException {
     User user = getActiveUser();
     AuthResult result = null;
diff --git a/security/src/main/java/org/apache/hadoop/hbase/security/access/SecureGroupAdminEndpoint.java b/security/src/main/java/org/apache/hadoop/hbase/security/access/SecureGroupAdminEndpoint.java
new file mode 100644
index 0000000..51b2739
--- /dev/null
+++ b/security/src/main/java/org/apache/hadoop/hbase/security/access/SecureGroupAdminEndpoint.java
@@ -0,0 +1,63 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.security.access;
+
+import org.apache.hadoop.hbase.CoprocessorEnvironment;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment;
+import org.apache.hadoop.hbase.master.GroupAdminEndpoint;
+import org.apache.hadoop.hbase.master.GroupAdminProtocol;
+import org.apache.hadoop.hbase.master.GroupInfo;
+
+import java.io.IOException;
+import java.util.Set;
+
+public class SecureGroupAdminEndpoint extends GroupAdminEndpoint implements GroupAdminProtocol{
+  private MasterCoprocessorEnvironment menv;
+
+  @Override
+  public void start(CoprocessorEnvironment env) {
+    super.start(env);
+    menv = (MasterCoprocessorEnvironment)env;
+  }
+
+  @Override
+  public void moveServers(Set<String> hostPorts, String dstGroup) throws IOException {
+    getAccessController().requirePermission(HConstants.ROOT_TABLE_NAME, null, null, Permission.Action.ADMIN);
+    super.moveServers(hostPorts, dstGroup);
+  }
+
+  @Override
+  public void removeGroup(String groupName) throws IOException {
+    getAccessController().requirePermission(HConstants.ROOT_TABLE_NAME, null, null, Permission.Action.ADMIN);
+    super.removeGroup(groupName);
+  }
+
+  @Override
+  public void addGroup(String groupName) throws IOException {
+    getAccessController().requirePermission(HConstants.ROOT_TABLE_NAME, null, null, Permission.Action.ADMIN);
+    super.addGroup(groupName);
+  }
+
+  private AccessController getAccessController() {
+    return (AccessController)menv.getMasterServices()
+        .getCoprocessorHost().findCoprocessor(AccessController.class.getName());
+  }
+}
diff --git a/security/src/test/java/org/apache/hadoop/hbase/security/access/TestSecureGroupAdminEndpoint.java b/security/src/test/java/org/apache/hadoop/hbase/security/access/TestSecureGroupAdminEndpoint.java
new file mode 100644
index 0000000..997da77
--- /dev/null
+++ b/security/src/test/java/org/apache/hadoop/hbase/security/access/TestSecureGroupAdminEndpoint.java
@@ -0,0 +1,238 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.security.access;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.Coprocessor;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.LargeTests;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException;
+import org.apache.hadoop.hbase.master.GroupAdmin;
+import org.apache.hadoop.hbase.master.GroupBasedLoadBalancer;
+import org.apache.hadoop.hbase.master.GroupInfo;
+import org.apache.hadoop.hbase.master.MasterCoprocessorHost;
+import org.apache.hadoop.hbase.security.AccessDeniedException;
+import org.apache.hadoop.hbase.security.User;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+
+import java.io.IOException;
+import java.security.PrivilegedExceptionAction;
+import java.util.Set;
+import java.util.TreeSet;
+import java.util.concurrent.atomic.AtomicLong;
+
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
+/**
+ * Performs authorization checks for common operations, according to different
+ * levels of authorized users.
+ */
+@Category(LargeTests.class)
+@SuppressWarnings("rawtypes")
+public class TestSecureGroupAdminEndpoint {
+  private static HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
+  private static Configuration conf;
+
+  // user with all permissions
+  private static User SUPERUSER;
+  // user granted with all global permission
+  private static User USER_ADMIN;
+  // user with rw permissions
+  private static User USER_RW;
+  // user with read-only permissions
+  private static User USER_RO;
+  // user is table owner. will have all permissions on table
+  private static User USER_OWNER;
+  // user with create table permissions alone
+  private static User USER_CREATE;
+  // user with no permissions
+  private static User USER_NONE;
+
+  private static AccessController ACCESS_CONTROLLER;
+  private static SecureGroupAdminEndpoint GROUP_ENDPOINT;
+
+  @BeforeClass
+  public static void setupBeforeClass() throws Exception {
+    // setup configuration
+    conf = TEST_UTIL.getConfiguration();
+    SecureTestUtil.enableSecurity(conf);
+		TEST_UTIL.getConfiguration().set(
+				HConstants.HBASE_MASTER_LOADBALANCER_CLASS,
+				GroupBasedLoadBalancer.class.getName());
+    conf.set("hbase.coprocessor.master.classes",
+        conf.get("hbase.coprocessor.master.classes")+","+SecureGroupAdminEndpoint.class.getName());
+
+    TEST_UTIL.startMiniCluster(1,2);
+    MasterCoprocessorHost cpHost = TEST_UTIL.getMiniHBaseCluster().getMaster().getCoprocessorHost();
+    cpHost.load(AccessController.class, Coprocessor.PRIORITY_HIGHEST, conf);
+    ACCESS_CONTROLLER = (AccessController) cpHost.findCoprocessor(AccessController.class.getName());
+    GROUP_ENDPOINT = (SecureGroupAdminEndpoint)
+        TEST_UTIL.getMiniHBaseCluster().getMaster()
+           .getCoprocessorHost().findCoprocessor(SecureGroupAdminEndpoint.class.getName());
+    // Wait for the ACL table to become available
+    TEST_UTIL.waitTableAvailable(AccessControlLists.ACL_TABLE_NAME, 5000);
+
+
+
+    // create a set of test users
+    SUPERUSER = User.createUserForTesting(conf, "admin", new String[] { "supergroup" });
+    USER_ADMIN = User.createUserForTesting(conf, "admin2", new String[0]);
+    USER_NONE = User.createUserForTesting(conf, "nouser", new String[0]);
+
+    // initialize access control
+    HTable meta = new HTable(conf, AccessControlLists.ACL_TABLE_NAME);
+    AccessControllerProtocol protocol =
+        meta.coprocessorProxy(AccessControllerProtocol.class, HConstants.EMPTY_START_ROW);
+
+    protocol.grant(new UserPermission(Bytes.toBytes(USER_ADMIN.getShortName()),
+        Permission.Action.ADMIN, Permission.Action.CREATE, Permission.Action.READ,
+        Permission.Action.WRITE));
+  }
+
+  @AfterClass
+  public static void tearDownAfterClass() throws Exception {
+    TEST_UTIL.shutdownMiniCluster();
+  }
+
+  public void verifyAllowed(User user, PrivilegedExceptionAction... actions) throws Exception {
+    for (PrivilegedExceptionAction action : actions) {
+      try {
+        user.runAs(action);
+      } catch (AccessDeniedException ade) {
+        fail("Expected action to pass for user '" + user.getShortName() + "' but was denied");
+      }
+    }
+  }
+
+  public void verifyAllowed(PrivilegedExceptionAction action, User... users) throws Exception {
+    for (User user : users) {
+      verifyAllowed(user, action);
+    }
+  }
+
+  public void verifyDenied(User user, PrivilegedExceptionAction... actions) throws Exception {
+    for (PrivilegedExceptionAction action : actions) {
+      try {
+        user.runAs(action);
+        fail("Expected AccessDeniedException for user '" + user.getShortName() + "'");
+      } catch (RetriesExhaustedWithDetailsException e) {
+        // in case of batch operations, and put, the client assembles a
+        // RetriesExhaustedWithDetailsException instead of throwing an
+        // AccessDeniedException
+        boolean isAccessDeniedException = false;
+        for (Throwable ex : e.getCauses()) {
+          if (ex instanceof AccessDeniedException) {
+            isAccessDeniedException = true;
+            break;
+          }
+        }
+        if (!isAccessDeniedException) {
+          fail("Not receiving AccessDeniedException for user '" + user.getShortName() + "'");
+        }
+      } catch (AccessDeniedException ade) {
+        // expected result
+      }
+    }
+  }
+
+  public void verifyDenied(PrivilegedExceptionAction action, User... users) throws Exception {
+    for (User user : users) {
+      verifyDenied(user, action);
+    }
+  }
+
+  @Test
+  public void testGetAddRemove() throws Exception {
+    final AtomicLong counter = new AtomicLong(0);
+
+    PrivilegedExceptionAction getGroup = new PrivilegedExceptionAction() {
+      public Object run() throws Exception {
+        GROUP_ENDPOINT.getGroup("default");
+        return null;
+      }
+    };
+    verifyAllowed(getGroup, SUPERUSER, USER_ADMIN, USER_NONE);
+
+    PrivilegedExceptionAction addGroup = new PrivilegedExceptionAction() {
+      public Object run() throws Exception {
+        GROUP_ENDPOINT.addGroup("testGetAddRemove"+counter.incrementAndGet());
+        return null;
+      }
+    };
+    verifyDenied(addGroup, USER_NONE);
+    verifyAllowed(addGroup, SUPERUSER, USER_ADMIN);
+
+    PrivilegedExceptionAction removeGroup = new PrivilegedExceptionAction() {
+      public Object run() throws Exception {
+        GROUP_ENDPOINT.removeGroup("testGetAddRemove"+counter.getAndDecrement());
+        return null;
+      }
+    };
+    verifyAllowed(removeGroup, SUPERUSER, USER_ADMIN);
+    verifyDenied(removeGroup, USER_NONE);
+  }
+
+  @Test
+  public void testMoveServer() throws Exception {
+    final AtomicLong counter = new AtomicLong(0);
+    Set<String> servers = new TreeSet<String>();
+    for(int i=1;i<=100;i++) {
+      GROUP_ENDPOINT.addGroup("testMoveServer_"+i);
+    }
+
+    PrivilegedExceptionAction action = new PrivilegedExceptionAction() {
+      public Object run() throws Exception {
+        String hostPort;
+        Set<String> set = new TreeSet<String>();
+        hostPort = TEST_UTIL.getMiniHBaseCluster().getRegionServer(1).getServerName().getHostAndPort();
+        set.add(hostPort);
+        GROUP_ENDPOINT.moveServers(set, "testMoveServer_" + counter.incrementAndGet());
+        waitForTransitions(GROUP_ENDPOINT);
+        return null;
+      }
+    };
+    verifyAllowed(action, SUPERUSER, USER_ADMIN);
+    verifyDenied(action, USER_NONE);
+  }
+
+  @Test
+  public void testListGroups() throws Exception {
+    PrivilegedExceptionAction action = new PrivilegedExceptionAction() {
+      public Object run() throws Exception {
+        GROUP_ENDPOINT.listGroups();
+        return null;
+      }
+    };
+    verifyAllowed(action, SUPERUSER, USER_ADMIN,USER_NONE);
+  }
+
+  private static void waitForTransitions(GroupAdmin gAdmin) throws IOException, InterruptedException {
+    while(gAdmin.listServersInTransition().size()>0) {
+      Thread.sleep(1000);
+    }
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
index f84c69f..cb9961f 100644
--- a/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
+++ b/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
@@ -89,7 +89,7 @@ public class HBaseAdmin implements Abortable, Closeable {
   // want to wait a long time.
   private final int retryLongerMultiplier;
   private boolean aborted;
-  
+
   /**
    * Constructor
    *
@@ -191,7 +191,7 @@ public class HBaseAdmin implements Abortable, Closeable {
     this.aborted = true;
     throw new RuntimeException(why, e);
   }
-  
+
   @Override
   public boolean isAborted(){
     return this.aborted;
@@ -598,7 +598,7 @@ public class HBaseAdmin implements Abortable, Closeable {
         // continue
       }
     }
-    
+
     if (tableExists) {
       throw new IOException("Retries exhausted, it took too long to wait"+
         " for the table " + Bytes.toString(tableName) + " to be deleted.");
@@ -1116,7 +1116,7 @@ public class HBaseAdmin implements Abortable, Closeable {
    * servername is provided then based on the online regions in the specified
    * regionserver the specified region will be closed. The master will not be
    * informed of the close. Note that the regionname is the encoded regionname.
-   * 
+   *
    * @param encodedRegionName
    *          The encoded region name; i.e. the hash that makes up the region
    *          name suffix: e.g. if regionname is
@@ -1673,7 +1673,7 @@ public class HBaseAdmin implements Abortable, Closeable {
    * @param tableName the name of the table
    * @return Ordered list of {@link HRegionInfo}.
    * @throws IOException
-   */  
+   */
   public List<HRegionInfo> getTableRegions(final byte[] tableName)
   throws IOException {
     CatalogTracker ct = getCatalogTracker();
@@ -1685,7 +1685,7 @@ public class HBaseAdmin implements Abortable, Closeable {
     }
     return Regions;
   }
-  
+
   public void close() throws IOException {
     if (this.connection != null) {
       this.connection.close();
@@ -1705,14 +1705,14 @@ public class HBaseAdmin implements Abortable, Closeable {
 
   /**
    * Roll the log writer. That is, start writing log messages to a new file.
-   * 
+   *
    * @param serverName
    *          The servername of the regionserver. A server name is made of host,
    *          port and startcode. This is mandatory. Here is an example:
    *          <code> host187.example.com,60020,1289493121758</code>
    * @return If lots of logs, flush the returned regions so next time through
    * we can clean logs. Returns null if nothing to flush.  Names are actual
-   * region names as returned by {@link HRegionInfo#getEncodedName()}  
+   * region names as returned by {@link HRegionInfo#getEncodedName()}
    * @throws IOException if a remote or network exception occurs
    * @throws FailedLogCloseException
    */
diff --git a/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java b/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java
index c9acee3..96a9492 100644
--- a/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java
+++ b/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java
@@ -128,6 +128,7 @@ public abstract class EventHandler implements Runnable, Comparable<Runnable> {
     C_M_DELETE_FAMILY         (45),   // Client asking Master to delete family of table
     C_M_MODIFY_FAMILY         (46),   // Client asking Master to modify family of table
     C_M_CREATE_TABLE          (47),   // Client asking Master to create a table
+    C_M_GROUP_MOVE_SERVER     (48),   // Client asking master to move server from one group to another
 
     // Updates from master to ZK. This is done by the master and there is
     // nothing to process by either Master or RS
diff --git a/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java b/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java
index 012dc0c..9b3cde8 100644
--- a/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java
+++ b/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java
@@ -126,6 +126,7 @@ public class ExecutorService {
 
       case RS_ZK_REGION_SPLIT:
       case M_SERVER_SHUTDOWN:
+      case C_M_GROUP_MOVE_SERVER:
         return ExecutorType.MASTER_SERVER_OPERATIONS;
 
       case M_META_SERVER_SHUTDOWN:
@@ -157,7 +158,6 @@ public class ExecutorService {
 
       case M_RS_CLOSE_META:
         return ExecutorType.RS_CLOSE_META;
-
       default:
         throw new RuntimeException("Unhandled event type " + type);
     }
@@ -269,7 +269,7 @@ public class ExecutorService {
     }
     return ret;
   }
-  
+
   /**
    * Executor instance.
    */
diff --git a/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java b/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java
index e275b81..bca48a0 100644
--- a/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java
+++ b/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java
@@ -167,7 +167,7 @@ public class AssignmentManager extends ZooKeeperListener {
 
   //Thread pool executor service for timeout monitor
   private java.util.concurrent.ExecutorService threadPoolExecutorService;
-  
+
   private List<EventType> ignoreStatesRSOffline = Arrays.asList(new EventType[]{
       EventType.RS_ZK_REGION_FAILED_OPEN, EventType.RS_ZK_REGION_CLOSED });
 
@@ -177,8 +177,8 @@ public class AssignmentManager extends ZooKeeperListener {
    */
   private volatile boolean failover = false;
 
-  // Set holding all the regions which got processed while RIT was not 
-  // populated during master failover. 
+  // Set holding all the regions which got processed while RIT was not
+  // populated during master failover.
   private Map<String, HRegionInfo> failoverProcessedRegions =
     new HashMap<String, HRegionInfo>();
 
@@ -190,7 +190,7 @@ public class AssignmentManager extends ZooKeeperListener {
    * @param catalogTracker
    * @param service
    * @throws KeeperException
-   * @throws IOException 
+   * @throws IOException
    */
   public AssignmentManager(Server master, ServerManager serverManager,
       CatalogTracker catalogTracker, final LoadBalancer balancer,
@@ -213,7 +213,7 @@ public class AssignmentManager extends ZooKeeperListener {
     this.balancer = balancer;
     this.threadPoolExecutorService = Executors.newCachedThreadPool();
   }
-  
+
   void startTimeOutMonitor() {
     Threads.setDaemonThreadRunning(timeoutMonitor.getThread(), master.getServerName()
         + ".timeoutMonitor");
@@ -262,8 +262,8 @@ public class AssignmentManager extends ZooKeeperListener {
 
   /**
    * Add a regionPlan for the specified region.
-   * @param encodedName 
-   * @param plan 
+   * @param encodedName
+   * @param plan
    */
   public void addPlan(String encodedName, RegionPlan plan) {
     synchronized (regionPlans) {
@@ -369,7 +369,7 @@ public class AssignmentManager extends ZooKeeperListener {
 
   /**
    * Process all regions that are in transition in zookeeper and also
-   * processes the list of dead servers by scanning the META. 
+   * processes the list of dead servers by scanning the META.
    * Used by master joining an cluster.
    * @param deadServers
    *          Map of dead servers and their regions. Can be null.
@@ -382,7 +382,7 @@ public class AssignmentManager extends ZooKeeperListener {
   throws KeeperException, IOException, InterruptedException {
     List<String> nodes = ZKUtil.listChildrenAndWatchForNewChildren(watcher,
       watcher.assignmentZNode);
-    
+
     if (nodes == null) {
       String errorMessage = "Failed to get the children from ZK";
       master.abort(errorMessage, new IOException(errorMessage));
@@ -467,7 +467,7 @@ public class AssignmentManager extends ZooKeeperListener {
    * up in zookeeper.
    * @param encodedRegionName Region to process failover for.
    * @param regionInfo If null we'll go get it from meta table.
-   * @param deadServers Can be null 
+   * @param deadServers Can be null
    * @return True if we processed <code>regionInfo</code> as a RIT.
    * @throws KeeperException
    * @throws IOException
@@ -482,7 +482,7 @@ public class AssignmentManager extends ZooKeeperListener {
     if (data == null) return false;
     HRegionInfo hri = regionInfo;
     if (hri == null) {
-      if ((hri = getHRegionInfo(data)) == null) return false; 
+      if ((hri = getHRegionInfo(data)) == null) return false;
     }
     processRegionsInTransition(data, hri, deadServers, stat.getVersion());
     return true;
@@ -599,7 +599,7 @@ public class AssignmentManager extends ZooKeeperListener {
       }
     }
   }
-  
+
 
   /**
    * Put the region <code>hri</code> into an offline state up in zk.
@@ -806,7 +806,7 @@ public class AssignmentManager extends ZooKeeperListener {
           this.executorService.submit(new ClosedRegionHandler(master,
             this, regionState.getRegion()));
           break;
-          
+
         case RS_ZK_REGION_FAILED_OPEN:
           hri = checkIfInFailover(regionState, encodedName, data);
           if (hri != null) {
@@ -828,7 +828,7 @@ public class AssignmentManager extends ZooKeeperListener {
           // Handle this the same as if it were opened and then closed.
           regionState.update(RegionState.State.CLOSED,
               data.getStamp(), data.getOrigin());
-          // When there are more than one region server a new RS is selected as the 
+          // When there are more than one region server a new RS is selected as the
           // destination and the same is updated in the regionplan. (HBASE-5546)
           getRegionPlan(regionState, sn, true);
           this.executorService.submit(new ClosedRegionHandler(master,
@@ -836,7 +836,7 @@ public class AssignmentManager extends ZooKeeperListener {
           break;
 
         case RS_ZK_REGION_OPENING:
-          hri = checkIfInFailover(regionState, encodedName, data);       
+          hri = checkIfInFailover(regionState, encodedName, data);
           if (hri != null) {
             regionState = new RegionState(hri, RegionState.State.OPENING, data
                 .getStamp(), data.getOrigin());
@@ -911,11 +911,11 @@ public class AssignmentManager extends ZooKeeperListener {
     }
     return null;
   }
-  
+
   /**
    * Gets the HRegionInfo from the META table
    * @param  data
-   * @return HRegionInfo hri for the region 
+   * @return HRegionInfo hri for the region
    */
   private HRegionInfo getHRegionInfo(RegionTransitionData data) {
     Pair<HRegionInfo, ServerName> p = null;
@@ -1203,13 +1203,13 @@ public class AssignmentManager extends ZooKeeperListener {
       ServerName oldSn = this.regions.get(regionInfo);
       if (oldSn != null) LOG.warn("Overwriting " + regionInfo.getEncodedName() +
         " on " + oldSn + " with " + sn);
-      
+
       if (isServerOnline(sn)) {
         this.regions.put(regionInfo, sn);
         addToServers(sn, regionInfo);
         this.regions.notifyAll();
       } else {
-        LOG.info("The server is not in online servers, ServerName=" + 
+        LOG.info("The server is not in online servers, ServerName=" +
           sn.getServerName() + ", region=" + regionInfo.getEncodedName());
       }
     }
@@ -1347,7 +1347,7 @@ public class AssignmentManager extends ZooKeeperListener {
    */
   public void assign(HRegionInfo region, boolean setOfflineInZK,
       boolean forceNewPlan, boolean hijack) {
-    // If hijack is true do not call disableRegionIfInRIT as 
+    // If hijack is true do not call disableRegionIfInRIT as
     // we have not yet moved the znode to OFFLINE state.
     if (!hijack && isDisabledorDisablingRegionInRIT(region)) {
       return;
@@ -1391,7 +1391,7 @@ public class AssignmentManager extends ZooKeeperListener {
           destination));
     }
     this.addPlans(plans);
-    
+
     // Presumption is that only this thread will be updating the state at this
     // time; i.e. handlers on backend won't be trying to set it to OPEN, etc.
     AtomicInteger counter = new AtomicInteger(0);
@@ -1614,11 +1614,11 @@ public class AssignmentManager extends ZooKeeperListener {
           }
         }
       }
-      
+
       if (setOfflineInZK && versionOfOfflineNode == -1) {
         return;
       }
-      
+
       if (this.master.isStopped()) {
         LOG.debug("Server stopped; skipping assign of " + state);
         return;
@@ -1731,38 +1731,38 @@ public class AssignmentManager extends ZooKeeperListener {
 
   /**
    * Set region as OFFLINED up in zookeeper
-   * 
+   *
    * @param state
    * @param hijack
    *          - true if needs to be hijacked and reassigned, false otherwise.
-   * @param regionAlreadyInTransitionException  
-   *          - true if we need to retry assignment because of RegionAlreadyInTransitionException.       
+   * @param regionAlreadyInTransitionException
+   *          - true if we need to retry assignment because of RegionAlreadyInTransitionException.
    * @return the version of the offline node if setting of the OFFLINE node was
    *         successful, -1 otherwise.
    */
   int setOfflineInZooKeeper(final RegionState state, boolean hijack,
       boolean regionAlreadyInTransitionException) {
     // In case of reassignment the current state in memory need not be
-    // OFFLINE. 
+    // OFFLINE.
     if (!hijack && !state.isClosed() && !state.isOffline()) {
       if (!regionAlreadyInTransitionException ) {
         String msg = "Unexpected state : " + state + " .. Cannot transit it to OFFLINE.";
         this.master.abort(msg, new IllegalStateException(msg));
         return -1;
-      } 
+      }
       LOG.debug("Unexpected state : " + state
           + " but retrying to assign because RegionAlreadyInTransitionException.");
     }
     boolean allowZNodeCreation = false;
     // Under reassignment if the current state is PENDING_OPEN
     // or OPENING then refresh the in-memory state to PENDING_OPEN. This is
-    // important because if the region was in 
+    // important because if the region was in
     // RS_OPENING state for a long time the master will try to force the znode
     // to OFFLINE state meanwhile the RS could have opened the corresponding
     // region and the state in znode will be RS_ZK_REGION_OPENED.
     // For all other cases we can change the in-memory state to OFFLINE.
     if (hijack &&
-        (state.getState().equals(RegionState.State.PENDING_OPEN) || 
+        (state.getState().equals(RegionState.State.PENDING_OPEN) ||
             state.getState().equals(RegionState.State.OPENING))) {
       state.update(RegionState.State.PENDING_OPEN);
       allowZNodeCreation = false;
@@ -1773,7 +1773,7 @@ public class AssignmentManager extends ZooKeeperListener {
     int versionOfOfflineNode = -1;
     try {
       // get the version after setting the znode to OFFLINE
-      versionOfOfflineNode = ZKAssign.createOrForceNodeOffline(master.getZooKeeper(), 
+      versionOfOfflineNode = ZKAssign.createOrForceNodeOffline(master.getZooKeeper(),
           state.getRegion(), this.master.getServerName(),
           hijack, allowZNodeCreation);
       if (versionOfOfflineNode == -1) {
@@ -1809,7 +1809,7 @@ public class AssignmentManager extends ZooKeeperListener {
     } catch (KeeperException e) {
       if (e instanceof NodeExistsException) {
         LOG.warn("Node for " + state.getRegion() + " already exists");
-      } else { 
+      } else {
         master.abort("Unexpected ZK exception creating/setting node OFFLINE", e);
       }
       return false;
@@ -1881,9 +1881,12 @@ public class AssignmentManager extends ZooKeeperListener {
           || existingPlan.getDestination() == null
           || drainingServers.contains(existingPlan.getDestination())) {
         newPlan = true;
-        randomPlan = new RegionPlan(state.getRegion(), null, balancer
-            .randomAssignment(servers));
-        this.regionPlans.put(encodedName, randomPlan);
+        ServerName newDestination =  balancer.randomAssignment(state.getRegion(), servers, null);
+				if (newDestination != null) {
+					randomPlan = new RegionPlan(state.getRegion(), null,
+							newDestination);
+					this.regionPlans.put(encodedName, randomPlan);
+				}
       }
     }
 
@@ -2042,8 +2045,8 @@ public class AssignmentManager extends ZooKeeperListener {
         state = new RegionState(region, RegionState.State.PENDING_CLOSE);
         regionsInTransition.put(encodedName, state);
       } else if (force && (state.isPendingClose() || state.isClosing())) {
-        LOG.debug("Attempting to unassign region " + region.getRegionNameAsString() + 
-          " which is already " + state.getState()  + 
+        LOG.debug("Attempting to unassign region " + region.getRegionNameAsString() +
+          " which is already " + state.getState()  +
           " but forcing to send a CLOSE RPC again ");
         state.update(state.getState());
       } else {
@@ -2052,7 +2055,7 @@ public class AssignmentManager extends ZooKeeperListener {
           "already in transition (" + state.getState() + ", force=" + force + ")");
         return;
       }
-    } 
+    }
     // Send CLOSE RPC
     ServerName server = null;
     synchronized (this.regions) {
@@ -2126,9 +2129,9 @@ public class AssignmentManager extends ZooKeeperListener {
       // Presume retry or server will expire.
     }
   }
-  
+
   /**
-   * 
+   *
    * @param region regioninfo of znode to be deleted.
    */
   public void deleteClosingOrClosedNode(HRegionInfo region) {
@@ -2227,7 +2230,7 @@ public class AssignmentManager extends ZooKeeperListener {
 
   /**
    * Assigns all user regions to online servers. Use round-robin assignment.
-   * 
+   *
    * @param regions
    * @throws IOException
    * @throws InterruptedException
@@ -2268,7 +2271,7 @@ public class AssignmentManager extends ZooKeeperListener {
     boolean isTableEnabled = this.zkTable.isEnabledTable(tableName);
     if (!isTableEnabled) {
       setEnabledTable(tableName);
-    }    
+    }
   }
 
   /**
@@ -2511,7 +2514,7 @@ public class AssignmentManager extends ZooKeeperListener {
     // Region assignment from META
     List<Result> results = MetaReader.fullScan(this.catalogTracker);
     // Get any new but slow to checkin region server that joined the cluster
-    Set<ServerName> onlineServers = serverManager.getOnlineServers().keySet();    
+    Set<ServerName> onlineServers = serverManager.getOnlineServers().keySet();
     // Map of offline servers and their regions to be returned
     Map<ServerName, List<Pair<HRegionInfo,Result>>> offlineServers =
       new TreeMap<ServerName, List<Pair<HRegionInfo, Result>>>();
@@ -2568,7 +2571,7 @@ public class AssignmentManager extends ZooKeeperListener {
           byte[] data = ZKUtil.getDataNoWatch(this.watcher, node, stat);
           // If znode does not exist dont consider this region
           if (data == null) {
-            LOG.debug("Region "+ regionInfo.getRegionNameAsString() + " split is completed. " 
+            LOG.debug("Region "+ regionInfo.getRegionNameAsString() + " split is completed. "
                 + "Hence need not add to regions list");
             continue;
           }
@@ -2611,14 +2614,14 @@ public class AssignmentManager extends ZooKeeperListener {
     } else if (checkIfRegionsBelongsToEnabling(regionInfo)) {
       enablingTables.add(disablingTableName);
       return true;
-    } 
+    }
     return false;
   }
 
   /**
    * Recover the tables that were not fully moved to DISABLED state. These
    * tables are in DISABLING state when the master restarted/switched.
-   * 
+   *
    * @param disablingTables
    * @return
    * @throws KeeperException
@@ -2648,7 +2651,7 @@ public class AssignmentManager extends ZooKeeperListener {
   /**
    * Recover the tables that are not fully moved to ENABLED state. These tables
    * are in ENABLING state when the master restarted/switched
-   * 
+   *
    * @param enablingTables
    * @param isWatcherCreated
    * @throws KeeperException
@@ -2695,10 +2698,10 @@ public class AssignmentManager extends ZooKeeperListener {
    * Processes list of dead servers from result of META scan and regions in RIT
    * <p>
    * This is used for failover to recover the lost regions that belonged to
-   * RegionServers which failed while there was no active master or regions 
+   * RegionServers which failed while there was no active master or regions
    * that were in RIT.
    * <p>
-   * 
+   *
    * @param deadServers
    *          The list of dead servers which failed while there was no active
    *          master. Can be null.
@@ -2712,7 +2715,7 @@ public class AssignmentManager extends ZooKeeperListener {
       List<String> nodes) throws IOException, KeeperException {
     if (null != deadServers) {
       Set<ServerName> actualDeadServers = this.serverManager.getDeadServers();
-      for (Map.Entry<ServerName, List<Pair<HRegionInfo, Result>>> deadServer : 
+      for (Map.Entry<ServerName, List<Pair<HRegionInfo, Result>>> deadServer :
         deadServers.entrySet()) {
         // skip regions of dead servers because SSH will process regions during rs expiration.
         // see HBASE-5916
@@ -2736,7 +2739,7 @@ public class AssignmentManager extends ZooKeeperListener {
             // we consider that this region is being handled.
             // So we should skip it and process it in
             // processRegionsInTransition.
-            if (data != null && data.getOrigin() != null && 
+            if (data != null && data.getOrigin() != null &&
                 serverManager.isServerOnline(data.getOrigin())) {
               LOG.info("The region " + regionInfo.getEncodedName()
                   + "is being handled on " + data.getOrigin());
@@ -2872,7 +2875,7 @@ public class AssignmentManager extends ZooKeeperListener {
    */
   public List<HRegionInfo> getRegionsOfTable(byte[] tableName) {
     List<HRegionInfo> tableRegions = new ArrayList<HRegionInfo>();
-    // boundary needs to have table's name but regionID 0 so that it is sorted 
+    // boundary needs to have table's name but regionID 0 so that it is sorted
     // before all table's regions.
     HRegionInfo boundary =
       new HRegionInfo(tableName, null, null, false, 0L);
@@ -3006,7 +3009,7 @@ public class AssignmentManager extends ZooKeeperListener {
       }
     }
   }
-  
+
   private void processOpeningState(HRegionInfo regionInfo) {
     LOG.info("Region has been OPENING for too " + "long, reassigning region="
         + regionInfo.getRegionNameAsString());
@@ -3171,7 +3174,7 @@ public class AssignmentManager extends ZooKeeperListener {
    * Can't let out original since it can change and at least the loadbalancer
    * wants to iterate this exported list.  We need to synchronize on regions
    * since all access to this.servers is under a lock on this.regions.
-   * 
+   *
    * @return A clone of current assignments by table.
    */
   Map<String, Map<ServerName, List<HRegionInfo>>> getAssignmentsByTable() {
@@ -3214,7 +3217,7 @@ public class AssignmentManager extends ZooKeeperListener {
     }
     return result;
   }
-  
+
   /**
    * @return A clone of current assignments. Note, this is assignments only.
    * If a new server has come in and it has no regions, it will not be included
@@ -3384,7 +3387,7 @@ public class AssignmentManager extends ZooKeeperListener {
     public boolean isSplitting() {
       return state == State.SPLITTING;
     }
- 
+
     public boolean isSplit() {
       return state == State.SPLIT;
     }
@@ -3398,12 +3401,12 @@ public class AssignmentManager extends ZooKeeperListener {
     }
 
     /**
-     * A slower (but more easy-to-read) stringification 
+     * A slower (but more easy-to-read) stringification
      */
     public String toDescriptiveString() {
       long lstamp = stamp.get();
       long relTime = System.currentTimeMillis() - lstamp;
-      
+
       return region.getRegionNameAsString()
         + " state=" + state
         + ", ts=" + new Date(lstamp) + " (" + (relTime/1000) + "s ago)"
@@ -3429,10 +3432,10 @@ public class AssignmentManager extends ZooKeeperListener {
   public void stop() {
     this.timeoutMonitor.interrupt();
   }
-  
+
   /**
    * Check whether the RegionServer is online.
-   * @param serverName 
+   * @param serverName
    * @return True if online.
    */
   public boolean isServerOnline(ServerName serverName) {
@@ -3458,4 +3461,8 @@ public class AssignmentManager extends ZooKeeperListener {
       this.master.abort(errorMsg, e);
     }
   }
+
+  public LoadBalancer getBalancer() {
+    return balancer;
+  }
 }
diff --git a/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java
index 9b132c0..4585530 100644
--- a/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java
+++ b/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java
@@ -43,7 +43,6 @@ import org.apache.hadoop.hbase.HDFSBlocksDistribution;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.ServerName;
-import org.apache.hadoop.hbase.TableExistsException;
 import org.apache.hadoop.hbase.regionserver.HRegion;
 import org.apache.hadoop.hbase.util.Bytes;
 
@@ -118,7 +117,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
 
 
    RegionInfoComparator riComparator = new RegionInfoComparator();
-   
+
    private class RegionPlanComparator implements Comparator<RegionPlan> {
     @Override
     public int compare(RegionPlan l, RegionPlan r) {
@@ -141,21 +140,21 @@ public class DefaultLoadBalancer implements LoadBalancer {
    * have either floor(average) or ceiling(average) regions.
    *
    * HBASE-3609 Modeled regionsToMove using Guava's MinMaxPriorityQueue so that
-   *   we can fetch from both ends of the queue. 
-   * At the beginning, we check whether there was empty region server 
+   *   we can fetch from both ends of the queue.
+   * At the beginning, we check whether there was empty region server
    *   just discovered by Master. If so, we alternately choose new / old
    *   regions from head / tail of regionsToMove, respectively. This alternation
    *   avoids clustering young regions on the newly discovered region server.
    *   Otherwise, we choose new regions from head of regionsToMove.
-   *   
+   *
    * Another improvement from HBASE-3609 is that we assign regions from
    *   regionsToMove to underloaded servers in round-robin fashion.
    *   Previously one underloaded server would be filled before we move onto
    *   the next underloaded server, leading to clustering of young regions.
-   *   
+   *
    * Finally, we randomly shuffle underloaded servers so that they receive
    *   offloaded regions relatively evenly across calls to balanceCluster().
-   *         
+   *
    * The algorithm is currently implemented as such:
    *
    * <ol>
@@ -286,7 +285,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
       List<HRegionInfo> regions = server.getValue();
       int numToOffload = Math.min(regionCount - max, regions.size());
       // account for the out-of-band regions which were assigned to this server
-      // after some other region server crashed 
+      // after some other region server crashed
       Collections.sort(regions, riComparator);
       int numTaken = 0;
       for (int i = 0; i <= numToOffload; ) {
@@ -576,7 +575,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
     // Group all of the old assignments by their hostname.
     // We can't group directly by ServerName since the servers all have
     // new start-codes.
-    
+
     // Group the servers by their hostname. It's possible we have multiple
     // servers on the same host on different ports.
     ArrayListMultimap<String, ServerName> serversByHostname =
@@ -584,20 +583,20 @@ public class DefaultLoadBalancer implements LoadBalancer {
     for (ServerName server : servers) {
       serversByHostname.put(server.getHostname(), server);
     }
-    
+
     // Now come up with new assignments
     Map<ServerName, List<HRegionInfo>> assignments =
       new TreeMap<ServerName, List<HRegionInfo>>();
-    
+
     for (ServerName server : servers) {
       assignments.put(server, new ArrayList<HRegionInfo>());
     }
-    
+
     // Collection of the hostnames that used to have regions
     // assigned, but for which we no longer have any RS running
     // after the cluster restart.
     Set<String> oldHostsNoLongerPresent = Sets.newTreeSet();
-    
+
     int numRandomAssignments = 0;
     int numRetainedAssigments = 0;
     for (Map.Entry<HRegionInfo, ServerName> entry : regions.entrySet()) {
@@ -626,7 +625,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
         numRetainedAssigments++;
       }
     }
-    
+
     String randomAssignMsg = "";
     if (numRandomAssignments > 0) {
       randomAssignMsg = numRandomAssignments + " regions were assigned " +
@@ -634,7 +633,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
       		"longer present in the cluster. These hosts were:\n  " +
           Joiner.on("\n  ").join(oldHostsNoLongerPresent);
     }
-    
+
     LOG.info("Reassigned " + regions.size() + " regions. " +
         numRetainedAssigments + " retained the pre-restart assignment. " +
         randomAssignMsg);
@@ -669,7 +668,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
       LOG.debug("IOException during HDFSBlocksDistribution computation. for " +
         "region = " + region.getEncodedName() , ioe);
     }
-    
+
     return topServerNames;
   }
 
@@ -701,7 +700,7 @@ public class DefaultLoadBalancer implements LoadBalancer {
    * order as input hosts.
    * @param hosts the list of hosts
    * @return ServerName list
-   */  
+   */
   private List<ServerName> mapHostNameToServerName(List<String> hosts) {
     if ( hosts == null || status == null) {
       return null;
@@ -757,12 +756,16 @@ public class DefaultLoadBalancer implements LoadBalancer {
     return assignments;
   }
 
-  public ServerName randomAssignment(List<ServerName> servers) {
-    if (servers == null || servers.isEmpty()) {
-      LOG.warn("Wanted to do random assignment but no servers to assign to");
-      return null;
-    }
-    return servers.get(RANDOM.nextInt(servers.size()));
+  public ServerName randomAssignment(HRegionInfo region, List<ServerName> servers, ServerName prefferedServer) {
+		if (prefferedServer == null) {
+			if (servers == null || servers.isEmpty()) {
+				LOG.warn("Wanted to do random assignment but no servers to assign to");
+				return null;
+			}
+			return servers.get(RANDOM.nextInt(servers.size()));
+		} else {
+			return prefferedServer;
+		}
   }
 
 }
diff --git a/src/main/java/org/apache/hadoop/hbase/master/GroupAdmin.java b/src/main/java/org/apache/hadoop/hbase/master/GroupAdmin.java
new file mode 100644
index 0000000..6097a1e
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/master/GroupAdmin.java
@@ -0,0 +1,110 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import org.apache.hadoop.hbase.HRegionInfo;
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+public interface GroupAdmin {
+  /**
+   * Get online regions of a region server group.
+   *
+   * @param groupName the name of the group
+   * @return list of online regions this group contains
+   */
+  List<HRegionInfo> listOnlineRegionsOfGroup(String groupName) throws IOException;
+
+  /**
+   * Get member tables of a group.
+   *
+   * @param groupName the name of the group
+   * @return list of table names
+   */
+  Collection<String> listTablesOfGroup(String groupName) throws IOException;
+
+  /**
+   * Gets the group information.
+   *
+   * @param groupName the group name
+   * @return An instance of GroupInfo
+   */
+  GroupInfo getGroup(String groupName) throws IOException;
+
+  /**
+   * Gets the group info of table.
+   *
+   * @param tableName the table name
+   * @return An instance of GroupInfo.
+   */
+  GroupInfo getGroupInfoOfTable(byte[] tableName) throws IOException;
+
+  /**
+   * Move a set of serves to another group
+   *
+   * @param server the server
+   * @param targetGroup the target group
+   * @throws java.io.IOException Signals that an I/O exception has occurred.
+   * @throws InterruptedException the interrupted exception
+   */
+  void moveServers(Set<String> server, String targetGroup)
+      throws IOException, InterruptedException;
+
+
+  /**
+   * Add a new group
+   * @param name name of the group
+   * @throws IOException
+   */
+  void addGroup(String name) throws IOException;
+
+  /**
+   * Remove a new group
+   * @param name name of the group
+   * @throws IOException
+   */
+  void removeGroup(String name) throws IOException;
+
+  /**
+   * Gets the existing groups.
+   *
+   * @return Collection of GroupInfo.
+   */
+  List<GroupInfo> listGroups() throws IOException;
+
+  /**
+   * Retrieve the GroupInfo a server is affiliated to
+   * @param hostPort
+   * @return
+   * @throws IOException
+   */
+  GroupInfo getGroupOfServer(String hostPort) throws IOException;
+
+  /**
+   * List servers that are currently being moved to a new group
+   * @return
+   * @throws IOException
+   */
+  Map<String, String> listServersInTransition() throws IOException;
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/GroupAdminClient.java b/src/main/java/org/apache/hadoop/hbase/master/GroupAdminClient.java
new file mode 100644
index 0000000..e34ab83
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/master/GroupAdminClient.java
@@ -0,0 +1,138 @@
+/**
+ * Copyright The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.DoNotRetryIOException;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MasterNotRunningException;
+import org.apache.hadoop.hbase.ZooKeeperConnectionException;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+
+/**
+ * This class is responsible for managing region server group information.
+ */
+public class GroupAdminClient implements GroupAdmin {
+  private GroupAdmin proxy;
+	private static final Log LOG = LogFactory.getLog(GroupAdminClient.class);
+  private int operationTimeout;
+
+  public GroupAdminClient(Configuration conf) throws ZooKeeperConnectionException, MasterNotRunningException {
+    proxy = new HBaseAdmin(conf).coprocessorProxy(GroupAdminProtocol.class);
+    operationTimeout = conf.getInt(HConstants.HBASE_CLIENT_OPERATION_TIMEOUT,
+            HConstants.DEFAULT_HBASE_CLIENT_OPERATION_TIMEOUT);
+  }
+
+  @Override
+  public List<HRegionInfo> listOnlineRegionsOfGroup(String groupName) throws IOException {
+    return proxy.listOnlineRegionsOfGroup(groupName);
+  }
+
+  @Override
+  public Collection<String> listTablesOfGroup(String groupName) throws IOException {
+    return proxy.listTablesOfGroup(groupName);
+  }
+
+  @Override
+  public GroupInfo getGroup(String groupName) throws IOException {
+    return proxy.getGroup(groupName);
+  }
+
+  @Override
+  public GroupInfo getGroupInfoOfTable(byte[] tableName) throws IOException {
+    return proxy.getGroupInfoOfTable(tableName);
+  }
+
+  @Override
+  public void moveServers(Set<String> servers, String targetGroup) throws IOException, InterruptedException {
+    proxy.moveServers(servers, targetGroup);
+    waitForTransitions(servers);
+  }
+
+  @Override
+  public void addGroup(String groupName) throws IOException {
+    proxy.addGroup(groupName);
+  }
+
+  @Override
+  public void removeGroup(String name) throws IOException {
+    proxy.removeGroup(name);
+  }
+
+  @Override
+  public List<GroupInfo> listGroups() throws IOException {
+    return proxy.listGroups();
+  }
+
+  @Override
+  public GroupInfo getGroupOfServer(String hostPort) throws IOException {
+    return proxy.getGroupOfServer(hostPort);
+  }
+
+  @Override
+  public Map<String, String> listServersInTransition() throws IOException {
+    return proxy.listServersInTransition();
+  }
+
+  /**
+   * Retrieve a table's group membership from the table descriptor
+   * @param desc
+   * @return
+   * @throws IOException
+   */
+  public String getGroupPropertyOfTable(HTableDescriptor desc) throws IOException {
+    return GroupInfo.getGroupString(desc);
+  }
+
+  /**
+   * Set's a table's group membership
+   * @param groupName group name the table is being assigned to
+   * @param desc table descriptor of the table
+   * @throws IOException
+   */
+  public void setGroupPropertyOfTable(String groupName, HTableDescriptor desc) throws IOException {
+    GroupInfo.setGroupString(groupName, desc);
+  }
+
+  private void waitForTransitions(Set<String> servers) throws IOException, InterruptedException {
+    long endTime = System.currentTimeMillis()+operationTimeout;
+    boolean found;
+    do {
+      found = false;
+      for(String server: proxy.listServersInTransition().keySet()) {
+        found = found || servers.contains(server);
+      }
+      Thread.sleep(1000);
+    } while(found && System.currentTimeMillis() <= endTime);
+    if(found) {
+      throw new DoNotRetryIOException("Operation timed out.");
+    }
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/GroupAdminEndpoint.java b/src/main/java/org/apache/hadoop/hbase/master/GroupAdminEndpoint.java
new file mode 100644
index 0000000..8646c61
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/master/GroupAdminEndpoint.java
@@ -0,0 +1,211 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.CoprocessorEnvironment;
+import org.apache.hadoop.hbase.DoNotRetryIOException;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.coprocessor.BaseEndpointCoprocessor;
+import org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment;
+import org.apache.hadoop.hbase.executor.EventHandler;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.NavigableSet;
+import java.util.Set;
+import java.util.TreeSet;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+
+public class GroupAdminEndpoint extends BaseEndpointCoprocessor implements GroupAdminProtocol, EventHandler.EventHandlerListener {
+	private static final Log LOG = LogFactory.getLog(GroupAdminClient.class);
+
+  private MasterCoprocessorEnvironment menv;
+  private MasterServices master;
+  private ConcurrentMap<String,String> serversInTransition =
+      new ConcurrentHashMap<String,String>();
+
+  @Override
+  public void start(CoprocessorEnvironment env) {
+    menv = (MasterCoprocessorEnvironment)env;
+    master = menv.getMasterServices();
+  }
+
+  @Override
+  public List<HRegionInfo> listOnlineRegionsOfGroup(String groupName) throws IOException {
+		List<HRegionInfo> regions = new ArrayList<HRegionInfo>();
+		if (groupName == null) {
+      throw new NullPointerException("groupName can't be null");
+    }
+
+    GroupInfo groupInfo = getGroupInfoManager().getGroup(groupName);
+    if (groupInfo == null) {
+			return null;
+		} else {
+			Set<String> servers = groupInfo.getServers();
+      for(ServerName serverName: master.getServerManager().getOnlineServersList()) {
+        String hostPort = serverName.getHostAndPort();
+        if(servers.contains(hostPort)) {
+          List<HRegionInfo> temp = getOnlineRegions(hostPort);
+          regions.addAll(temp);
+        }
+			}
+		}
+		return regions;
+	}
+
+  @Override
+  public Collection<String> listTablesOfGroup(String groupName) throws IOException {
+		Set<String> set = new HashSet<String>();
+		if (groupName == null) {
+      throw new NullPointerException("groupName can't be null");
+    }
+
+    GroupInfo groupInfo = getGroupInfoManager().getGroup(groupName);
+    if (groupInfo == null) {
+			return null;
+		} else {
+      HTableDescriptor[] tables = master.getTableDescriptors().getAll().values().toArray(new HTableDescriptor[0]);
+      for (HTableDescriptor table : tables) {
+        if(GroupInfo.getGroupString(table).equals(groupName))
+          set.add(table.getNameAsString());
+      }
+    }
+		return set;
+	}
+
+
+  @Override
+  public GroupInfo getGroup(String groupName) throws IOException {
+			return getGroupInfoManager().getGroup(groupName);
+	}
+
+
+  @Override
+  public GroupInfo getGroupInfoOfTable(byte[] tableName) throws IOException {
+		HTableDescriptor des;
+		GroupInfo tableRSGroup;
+    des =  master.getTableDescriptors().get(tableName);
+		String group = GroupInfo.getGroupString(des);
+		tableRSGroup = getGroupInfoManager().getGroup(group);
+		return tableRSGroup;
+	}
+
+  @Override
+  public void moveServers(Set<String> servers, String targetGroup)
+			throws IOException {
+		if ((servers == null) || (StringUtils.isEmpty(targetGroup))) {
+			throw new IOException(
+					"The region server or the target to move found to be null.");
+		}
+
+    GroupMoveServerHandler.MoveServerPlan plan =
+        new GroupMoveServerHandler.MoveServerPlan(servers, targetGroup);
+    GroupMoveServerHandler handler = null;
+    try {
+      handler = new GroupMoveServerHandler(master, serversInTransition, getGroupInfoManager(), plan);
+      handler.setListener(this);
+      master.getExecutorService().submit(handler);
+      LOG.info("GroupMoveServerHanndlerSubmitted: "+plan.getTargetGroup());
+    } catch(Exception e) {
+      LOG.error("Failed to submit GroupMoveServerHandler", e);
+      if(handler != null) {
+        handler.complete();
+      }
+      throw new DoNotRetryIOException("Failed to submit GroupMoveServerHandler",e);
+    }
+	}
+
+  @Override
+  public void addGroup(String name) throws IOException {
+    getGroupInfoManager().addGroup(new GroupInfo(name, new HashSet<String>()));
+  }
+
+  @Override
+  public void removeGroup(String name) throws IOException {
+    GroupInfoManager manager = getGroupInfoManager();
+    synchronized (manager) {
+      if(listTablesOfGroup(name).size() > 0) {
+        throw new DoNotRetryIOException("Group must have no associated tables.");
+      }
+      manager.removeGroup(name);
+    }
+
+  }
+
+  @Override
+  public List<GroupInfo> listGroups() throws IOException {
+    return getGroupInfoManager().listGroups();
+  }
+
+  @Override
+  public GroupInfo getGroupOfServer(String hostPort) throws IOException {
+    return getGroupInfoManager().getGroupOfServer(hostPort);
+  }
+
+  @Override
+  public Map<String, String> listServersInTransition() throws IOException {
+    return Collections.unmodifiableMap(serversInTransition);
+  }
+
+  private GroupInfoManager getGroupInfoManager() {
+    return ((GroupBasedLoadBalancer)menv.getMasterServices().getAssignmentManager().getBalancer()).getGroupInfoManager();
+  }
+
+  private List<HRegionInfo> getOnlineRegions(String hostPort) throws IOException {
+    java.util.List<HRegionInfo> regions = new LinkedList<HRegionInfo>();
+    for(Map.Entry<ServerName, java.util.List<HRegionInfo>> el:
+        master.getAssignmentManager().getAssignments().entrySet()) {
+      if(el.getKey().getHostAndPort().equals(hostPort)) {
+        regions.addAll(el.getValue());
+      }
+    }
+    return regions;
+  }
+
+  @Override
+  public void beforeProcess(EventHandler event) {
+    //do nothing
+  }
+
+  @Override
+  public void afterProcess(EventHandler event) {
+    GroupMoveServerHandler h =
+        ((GroupMoveServerHandler)event);
+    try {
+      h.complete();
+    } catch (IOException e) {
+      LOG.error("Failed to complete GroupMoveServer with of "+h.getPlan().getServers().size()+
+          " servers to group "+h.getPlan().getTargetGroup());
+    }
+  }
+
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/GroupAdminProtocol.java b/src/main/java/org/apache/hadoop/hbase/master/GroupAdminProtocol.java
new file mode 100644
index 0000000..5d230e4
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/master/GroupAdminProtocol.java
@@ -0,0 +1,25 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import org.apache.hadoop.hbase.ipc.CoprocessorProtocol;
+
+public interface GroupAdminProtocol extends GroupAdmin, CoprocessorProtocol {
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/GroupBasedLoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/master/GroupBasedLoadBalancer.java
new file mode 100644
index 0000000..a1c79a0
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/master/GroupBasedLoadBalancer.java
@@ -0,0 +1,318 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.master;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.TreeMap;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.ClusterStatus;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.ServerName;
+
+import com.google.common.collect.ArrayListMultimap;
+
+public class GroupBasedLoadBalancer implements LoadBalancer {
+
+  private static final Log LOG = LogFactory
+      .getLog(GroupBasedLoadBalancer.class);
+  private Configuration config;
+  private ClusterStatus status;
+  private MasterServices services;
+  private GroupInfoManager groupManager;
+  private DefaultLoadBalancer internalBalancer = new DefaultLoadBalancer();
+
+  GroupBasedLoadBalancer() {
+  }
+
+  GroupBasedLoadBalancer(GroupInfoManager groupManager) {
+    this.groupManager = groupManager;
+  }
+
+  @Override
+  public Configuration getConf() {
+    return config;
+  }
+
+  @Override
+  public void setConf(Configuration conf) {
+    this.config = conf;
+    internalBalancer.setConf(conf);
+  }
+
+  @Override
+  public void setClusterStatus(ClusterStatus st) {
+    this.status = st;
+    internalBalancer.setClusterStatus(st);
+  }
+
+  @Override
+  public void setMasterServices(MasterServices masterServices) {
+    this.services = masterServices;
+    internalBalancer.setMasterServices(masterServices);
+    if (this.groupManager == null) {
+      try {
+        this.groupManager = new GroupInfoManagerImpl(
+            services.getConfiguration(), services);
+      } catch (IOException e) {
+        LOG.warn("IOException while creating GroupInfoManagerImpl.", e);
+      }
+    }
+  }
+
+  @Override
+  public List<RegionPlan> balanceCluster(
+      Map<ServerName, List<HRegionInfo>> clusterState) {
+    Map<ServerName,List<HRegionInfo>> correctedState = correctAssignments(clusterState);
+    List<RegionPlan> regionPlans = new ArrayList<RegionPlan>();
+    try {
+      for (GroupInfo info : groupManager.listGroups()) {
+        Map<ServerName, List<HRegionInfo>> groupClusterState = new HashMap<ServerName, List<HRegionInfo>>();
+        for (String sName : info.getServers()) {
+          ServerName actual = ServerName.findServerWithSameHostnamePort(
+              clusterState.keySet(), ServerName.parseServerName(sName));
+          if (actual != null) {
+            groupClusterState.put(actual, correctedState.get(actual));
+          }
+        }
+        List<RegionPlan> groupPlans = this.internalBalancer
+            .balanceCluster(groupClusterState);
+        if (groupPlans != null) {
+          regionPlans.addAll(groupPlans);
+        }
+      }
+    } catch (IOException exp) {
+      LOG.warn("Exception while balancing cluster.", exp);
+    }
+    return regionPlans;
+  }
+
+  @Override
+  public Map<ServerName, List<HRegionInfo>> roundRobinAssignment(
+      List<HRegionInfo> regions, List<ServerName> servers) {
+    try {
+      Map<ServerName, List<HRegionInfo>> assignments = new TreeMap<ServerName, List<HRegionInfo>>();
+      ArrayListMultimap<String, HRegionInfo> regionGroup = groupRegions(regions);
+      for (String groupKey : regionGroup.keys()) {
+        GroupInfo info = groupManager.getGroup(groupKey);
+        assignments.putAll(this.internalBalancer.roundRobinAssignment(
+            regionGroup.get(groupKey), getServerToAssign(info, servers)));
+      }
+      return assignments;
+    } catch (IOException e) {
+      LOG.error("Failed to access group store", e);
+      throw new IllegalStateException("Failed to access group store", e);
+    }
+  }
+
+  @Override
+  public Map<ServerName, List<HRegionInfo>> retainAssignment(
+      Map<HRegionInfo, ServerName> regions, List<ServerName> servers) {
+    try {
+      Map<ServerName, List<HRegionInfo>> assignments = new TreeMap<ServerName, List<HRegionInfo>>();
+      ArrayListMultimap<String, HRegionInfo> rGroup = ArrayListMultimap.create();
+      List<HRegionInfo> misplacedRegions = getMisplacedRegions(regions);
+      for (HRegionInfo region : regions.keySet()) {
+        if (misplacedRegions.contains(region) == false) {
+          String groupName = groupManager.getGroupPropertyOfTable(services
+              .getTableDescriptors().get(region.getTableNameAsString()));
+          rGroup.put(groupName, region);
+        }
+      }
+      // Now the "rGroup" map has only the regions which have correct
+      // assignments.
+      for (String key : rGroup.keys()) {
+        Map<HRegionInfo, ServerName> currentAssignmentMap = new TreeMap<HRegionInfo, ServerName>();
+        List<HRegionInfo> regionList = rGroup.get(key);
+        GroupInfo info = groupManager.getGroup(key);
+        List<ServerName> candidateList = getServerToAssign(info, servers);
+        for (HRegionInfo region : regionList) {
+          currentAssignmentMap.put(region, regions.get(region));
+        }
+        assignments.putAll(this.internalBalancer.retainAssignment(
+            currentAssignmentMap, candidateList));
+      }
+
+      for (HRegionInfo region : misplacedRegions) {
+        String groupName = groupManager.getGroupPropertyOfTable(services
+            .getTableDescriptors().get(region.getTableNameAsString()));
+        GroupInfo info = groupManager.getGroup(groupName);
+        List<ServerName> candidateList = getServerToAssign(info, servers);
+        ServerName server = this.internalBalancer.randomAssignment(region,
+            candidateList, null);
+        if (assignments.containsKey(server) == false) {
+          assignments.put(server, new ArrayList<HRegionInfo>());
+        }
+        assignments.get(server).add(region);
+      }
+      return assignments;
+    } catch (IOException e) {
+      LOG.error("Failed to access group store", e);
+      throw new IllegalStateException("Failed to access group store", e);
+    }
+  }
+
+  @Override
+  public Map<HRegionInfo, ServerName> immediateAssignment(
+      List<HRegionInfo> regions, List<ServerName> servers) {
+    try {
+      Map<HRegionInfo, ServerName> assignments = new TreeMap<HRegionInfo, ServerName>();
+      // Need to group regions by the group and servers and then call the
+      // internal load balancer.
+      ArrayListMultimap<String, HRegionInfo> regionGroups = groupRegions(regions);
+      for (String key : regionGroups.keys()) {
+        List<HRegionInfo> regionsOfSameGroup = regionGroups.get(key);
+        GroupInfo info = groupManager.getGroup(key);
+        List<ServerName> candidateList = getServerToAssign(info, servers);
+        assignments.putAll(this.internalBalancer.immediateAssignment(
+            regionsOfSameGroup, candidateList));
+      }
+      return assignments;
+    } catch (IOException e) {
+      LOG.error("Failed to access group store", e);
+      throw new IllegalStateException("Failed to access group store", e);
+    }
+  }
+
+  @Override
+  public ServerName randomAssignment(HRegionInfo region,
+      List<ServerName> servers, ServerName prefferedServer) {
+    try {
+      String tableName = region.getTableNameAsString();
+      List<ServerName> candidateList;
+      GroupInfo groupInfo = groupManager.getGroup(groupManager
+          .getGroupPropertyOfTable(services.getTableDescriptors()
+              .get(tableName)));
+      candidateList = getServerToAssign(groupInfo, servers);
+
+      if ((prefferedServer == null)
+          || (groupInfo.containsServer(prefferedServer.getHostAndPort()) == false)) {
+        return this.internalBalancer.randomAssignment(region, candidateList,
+            null);
+      } else {
+        return prefferedServer;
+      }
+    } catch (IOException e) {
+      LOG.error("Failed to access group store", e);
+      throw new IllegalStateException("Failed to access group store", e);
+    }
+  }
+
+  private List<ServerName> getServerToAssign(GroupInfo groupInfo,
+      List<ServerName> onlineServers) {
+    if (groupInfo != null) {
+      return filterServers(groupInfo.getServers(), onlineServers);
+    } else {
+      LOG.debug("Group Information found to be null. Some regions might be unassigned.");
+      return new ArrayList<ServerName>();
+    }
+  }
+
+  /**
+   * Filter servers based on the online servers.
+   *
+   * @param servers
+   *          the servers
+   * @param onlineServers
+   *          List of servers which are online.
+   * @return the list
+   */
+  private List<ServerName> filterServers(Collection<String> servers,
+      Collection<ServerName> onlineServers) {
+    ArrayList<ServerName> finalList = new ArrayList<ServerName>();
+    for (String server : servers) {
+      ServerName actual = ServerName.findServerWithSameHostnamePort(
+          onlineServers, ServerName.parseServerName(server));
+      if (actual != null) {
+        finalList.add(actual);
+      }
+    }
+    return finalList;
+  }
+
+  private ArrayListMultimap<String, HRegionInfo> groupRegions(
+      List<HRegionInfo> regionList) throws IOException {
+    ArrayListMultimap<String, HRegionInfo> regionGroup = ArrayListMultimap
+        .create();
+    for (HRegionInfo region : regionList) {
+      String groupName = groupManager.getGroupPropertyOfTable(services
+          .getTableDescriptors().get(region.getTableNameAsString()));
+      regionGroup.put(groupName, region);
+    }
+    return regionGroup;
+  }
+
+  private List<HRegionInfo> getMisplacedRegions(
+      Map<HRegionInfo, ServerName> regions) throws IOException {
+    List<HRegionInfo> misplacedRegions = new ArrayList<HRegionInfo>();
+    for (HRegionInfo region : regions.keySet()) {
+      ServerName assignedServer = regions.get(region);
+      GroupInfo info = groupManager.getGroup(groupManager
+          .getGroupPropertyOfTable(services.getTableDescriptors().get(
+              region.getTableNameAsString())));
+      if ((info == null)|| (!info.containsServer(assignedServer.getHostAndPort()))) {
+        misplacedRegions.add(region);
+      }
+    }
+    return misplacedRegions;
+  }
+
+  private Map<ServerName, List<HRegionInfo>> correctAssignments(
+       Map<ServerName, List<HRegionInfo>> existingAssignments){
+    Map<ServerName, List<HRegionInfo>> correctAssignments = new TreeMap<ServerName, List<HRegionInfo>>();
+    List<HRegionInfo> misplacedRegions = new ArrayList<HRegionInfo>();
+    for (ServerName sName : existingAssignments.keySet()) {
+      correctAssignments.put(sName, new ArrayList<HRegionInfo>());
+      List<HRegionInfo> regions = existingAssignments.get(sName);
+      for (HRegionInfo region : regions) {
+        GroupInfo info = null;
+        try {
+          info = groupManager.getGroup(groupManager
+            .getGroupPropertyOfTable(services.getTableDescriptors().get(
+                region.getTableNameAsString())));
+        }catch(IOException exp){
+          LOG.debug("Group information null for region of table " + region.getTableNameAsString(), exp);
+        }
+        if ((info == null) || (!info.containsServer(sName.getHostAndPort()))) {
+          // Misplaced region.
+          misplacedRegions.add(region);
+        } else {
+          correctAssignments.get(sName).add(region);
+        }
+      }
+    }
+
+    //unassign misplaced regions, so that they are assigned to correct groups.
+    this.services.getAssignmentManager().unassign(misplacedRegions);
+    return correctAssignments;
+  }
+
+  GroupInfoManager getGroupInfoManager() {
+    return groupManager;
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/GroupInfo.java b/src/main/java/org/apache/hadoop/hbase/master/GroupInfo.java
new file mode 100644
index 0000000..eebccfc
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/master/GroupInfo.java
@@ -0,0 +1,244 @@
+/**
+ * Copyright The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.master;
+
+import java.io.BufferedWriter;
+import java.io.IOException;
+import java.io.Serializable;
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.NavigableSet;
+import java.util.Set;
+
+import com.google.common.collect.Sets;
+import org.apache.commons.lang.StringUtils;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.util.Bytes;
+
+/**
+ * Stores the group information of region server groups.
+ */
+public class GroupInfo implements Serializable {
+
+	private Set<String> servers;
+	public static final String DEFAULT_GROUP = "default";
+  public static final String TRANSITION_GROUP_PREFIX = "_transition_";
+	public static final byte[] GROUP_KEY = Bytes.toBytes("rs_group");
+	private String name;
+
+  public GroupInfo() {
+    this.servers = new HashSet<String>();
+  }
+
+	public GroupInfo(String name, Set<String> servers) {
+		this.name = name;
+    this.servers = servers;
+	}
+
+  public GroupInfo(GroupInfo src) {
+    servers = Sets.newTreeSet(src.getServers());
+    name = src.getName();
+  }
+
+	/**
+	 * Get group name.
+	 *
+	 * @return
+	 */
+	public String getName() {
+		return name;
+	}
+
+	/**
+	 * Adds the server to the group.
+	 *
+	 * @param hostPort the server
+	 */
+	public void addServer(String hostPort){
+		this.servers.add(hostPort);
+	}
+
+	/**
+	 * Adds a group of servers.
+	 *
+	 * @param hostPort the servers
+	 */
+	public void addAll(Collection<String> hostPort){
+		this.servers.addAll(hostPort);
+	}
+
+	public boolean containsServer(String hostPort) {
+    return servers.contains(hostPort);
+	}
+
+	/**
+	 * Checks based of equivalence of host name and port.
+	 *
+	 * @param serverList The list to check for containment.
+	 * @return true, if successful
+	 */
+	public boolean containsServer(Set<String> serverList) {
+		if (serverList.size() == 0) {
+			return false;
+		} else {
+			boolean contains = true;
+			for (String hostPort : serverList) {
+				contains = contains && this.getServers().contains(hostPort);
+				if (!contains)
+					return contains;
+			}
+			return contains;
+		}
+	}
+
+
+	/**
+	 * Get a copy of servers.
+	 *
+	 * @return
+	 */
+	public Set<String> getServers() {
+		return this.servers;
+	}
+
+	/**
+	 * Write the group out.
+	 *
+	 * @param out
+	 * @throws IOException
+	 */
+	public void write(BufferedWriter out) throws IOException {
+		StringBuffer sb = new StringBuffer();
+		sb.append(getName());
+		sb.append("\t");
+		for (String sName : servers) {
+			if (sb.length() != (getName().length() + 1)) {
+				sb.append(",");
+			}
+			sb.append(sName);
+		}
+		out.write(sb.toString());
+		out.newLine();
+	}
+
+	public boolean readFields(String line) throws IOException {
+		boolean isWellFormed = false;
+		String[] groupSplit = line.split("\t");
+		switch(groupSplit.length) {
+		case 1: this.name = groupSplit[0].trim();
+				isWellFormed = true;
+				break;
+		case 2: this.name = groupSplit[0].trim();
+				String[] hostPortPairs = groupSplit[1].trim().split(",");
+				for (String sName : hostPortPairs) {
+					if (StringUtils.isNotEmpty(sName)) {
+						this.servers.add(sName);
+					}
+				}
+				isWellFormed = true;
+				break;
+		}
+
+		return isWellFormed;
+	}
+
+	/**
+	 * Remove a server from this group.
+	 *
+	 * @param hostPort
+	 */
+	public boolean removeServer(String hostPort) {
+    return this.servers.remove(hostPort);
+	}
+
+	/**
+	 * Get group attribute from a table descriptor.
+	 *
+	 * @param des
+	 * @return The group name of the table.
+	 */
+	public static String getGroupString(HTableDescriptor des) {
+		byte[] gbyte = des.getValue(GROUP_KEY);
+		if (gbyte != null) {
+			return Bytes.toString(des.getValue(GROUP_KEY));
+		} else {
+			return GroupInfo.DEFAULT_GROUP;
+    }
+	}
+
+
+	public static void setGroupString(String group, HTableDescriptor des) {
+    if(group.equals(DEFAULT_GROUP)) {
+      des.remove(group);
+    }
+    else {
+		  des.setValue(GROUP_KEY, Bytes.toBytes(group));
+    }
+	}
+
+	@Override
+	public String toString() {
+		StringBuffer sb = new StringBuffer();
+		sb.append("{GroupName:");
+		sb.append(this.name);
+		sb.append("-");
+		sb.append(" Severs:");
+		sb.append(this.servers+ "}");
+		return sb.toString();
+
+	}
+
+	@Override
+	public int hashCode() {
+		final int prime = 31;
+		int result = 1;
+		result = prime * result + ((name == null) ? 0 : name.hashCode());
+		result = prime * result
+				+ ((servers == null) ? 0 : servers.hashCode());
+		return result;
+	}
+
+	@Override
+	public boolean equals(Object obj) {
+		if (this == obj)
+			return true;
+		if (obj == null)
+			return false;
+		if (!(obj instanceof GroupInfo))
+			return false;
+		GroupInfo other = (GroupInfo) obj;
+		if (name == null) {
+			if (other.name != null)
+				return false;
+		} else if (!name.equals(other.name))
+			return false;
+		if (servers == null) {
+			if (other.servers != null)
+				return false;
+		} else if (servers.size() != other.getServers().size()){
+			return false;
+		}else if(!containsServer(other.getServers())){
+			return false;
+		}
+
+		return true;
+	}
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/GroupInfoManager.java b/src/main/java/org/apache/hadoop/hbase/master/GroupInfoManager.java
new file mode 100644
index 0000000..bb7b317
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/master/GroupInfoManager.java
@@ -0,0 +1,69 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.master;
+
+import org.apache.hadoop.hbase.HTableDescriptor;
+
+import java.io.IOException;
+import java.util.List;
+import java.util.Set;
+
+public interface GroupInfoManager {
+  /**
+   * Adds the group.
+   *
+   * @param groupInfo the group name
+   * @throws java.io.IOException Signals that an I/O exception has occurred.
+   */
+  void addGroup(GroupInfo groupInfo) throws IOException;
+
+  /**
+   * Remove a region server group.
+   *
+   * @param groupName the group name
+   * @throws java.io.IOException Signals that an I/O exception has occurred.
+   */
+  void removeGroup(String groupName) throws IOException;
+
+  boolean moveServers(Set<String> hostPort, String srcGroup, String dstGroup) throws IOException;
+
+  /**
+   * Gets the group info of server.
+   *
+   * @param hostPort the server
+   * @return An instance of GroupInfo.
+   */
+  GroupInfo getGroupOfServer(String hostPort) throws IOException;
+
+  /**
+   * Gets the group information.
+   *
+   * @param groupName the group name
+   * @return An instance of GroupInfo
+   */
+  GroupInfo getGroup(String groupName) throws IOException;
+
+  List<GroupInfo> listGroups() throws IOException;
+
+  String getGroupPropertyOfTable(HTableDescriptor desc) throws IOException;
+
+  void setGroupPropertyOfTable(String groupName, HTableDescriptor desc) throws IOException;
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/GroupInfoManagerImpl.java b/src/main/java/org/apache/hadoop/hbase/master/GroupInfoManagerImpl.java
new file mode 100644
index 0000000..ac9585b
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/master/GroupInfoManagerImpl.java
@@ -0,0 +1,340 @@
+/**
+ * Copyright 2009 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.master;
+
+import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.DoNotRetryIOException;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.FSUtils;
+import org.apache.hadoop.hbase.zookeeper.ZKUtil;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperListener;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
+import org.apache.zookeeper.KeeperException;
+import org.apache.zookeeper.ZooKeeper;
+
+import java.io.BufferedReader;
+import java.io.BufferedWriter;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.io.OutputStreamWriter;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.TreeSet;
+import java.util.concurrent.ConcurrentHashMap;
+
+public class GroupInfoManagerImpl implements GroupInfoManager {
+	private static final Log LOG = LogFactory.getLog(GroupInfoManagerImpl.class);
+
+  public static final String GROUP_INFO_FILE_NAME = ".rsgroupinfo";
+
+	//Access to this map should always be synchronized.
+	private Map<String, GroupInfo> groupMap;
+  private Path path;
+  private FileSystem fs;
+  private ZooKeeperWatcher watcher;
+  private MasterServices master;
+
+  public GroupInfoManagerImpl(Configuration conf, MasterServices master) throws IOException {
+		this.groupMap = new ConcurrentHashMap<String, GroupInfo>();
+		this.path = new Path(FSUtils.getRootDir(conf), GROUP_INFO_FILE_NAME);
+		this.fs = FSUtils.getRootDir(conf).getFileSystem(conf);
+    this.master = master;
+    this.watcher = master.getZooKeeper();
+    if(!fs.exists(path)) {
+      fs.createNewFile(path);
+    }
+    reloadConfig();
+  }
+
+	/**
+	 * Adds the group.
+	 *
+	 * @param groupInfo the group name
+	 * @throws java.io.IOException Signals that an I/O exception has occurred.
+	 */
+  @Override
+  public synchronized void addGroup(GroupInfo groupInfo) throws IOException {
+		if (groupMap.get(groupInfo.getName()) != null ||
+        groupInfo.getName().equals(GroupInfo.DEFAULT_GROUP)) {
+      throw new DoNotRetryIOException("Group already exists: "+groupInfo.getName());
+    }
+    groupMap.put(groupInfo.getName(), groupInfo);
+    try {
+      flushConfig();
+    } catch (IOException e) {
+      groupMap.remove(groupInfo.getName());
+      throw e;
+    }
+	}
+
+  @Override
+  public synchronized boolean moveServers(Set<String> hostPort, String srcGroup, String dstGroup) throws IOException {
+    GroupInfo src = new GroupInfo(getGroup(srcGroup));
+    GroupInfo dst = new GroupInfo(getGroup(dstGroup));
+    boolean foundOne = false;
+    for(String el: hostPort) {
+      foundOne = foundOne || src.removeServer(el);
+      dst.addServer(el);
+    }
+
+    Map<String,GroupInfo> newMap = Maps.newHashMap(groupMap);
+    if(!src.getName().equals(GroupInfo.DEFAULT_GROUP)) {
+      newMap.put(src.getName(), src);
+    }
+    if(!dst.getName().equals(GroupInfo.DEFAULT_GROUP)) {
+      newMap.put(dst.getName(), dst);
+    }
+    flushConfig(newMap);
+    groupMap = newMap;
+    return foundOne;
+  }
+
+  /**
+	 * Gets the group info of server.
+	 *
+	 * @param hostPort the server
+	 * @return An instance of GroupInfo.
+	 */
+  @Override
+  public synchronized GroupInfo getGroupOfServer(String hostPort) throws IOException {
+		for(GroupInfo info : groupMap.values()){
+			if(info.containsServer(hostPort)){
+				return info;
+			}
+		}
+		return getGroup(GroupInfo.DEFAULT_GROUP);
+	}
+
+	/**
+	 * Gets the group information.
+	 *
+	 * @param groupName the group name
+	 * @return An instance of GroupInfo
+	 */
+  @Override
+  public synchronized GroupInfo getGroup(String groupName) throws IOException {
+		if (groupName.equalsIgnoreCase(GroupInfo.DEFAULT_GROUP)) {
+			GroupInfo defaultInfo = new GroupInfo(GroupInfo.DEFAULT_GROUP, new TreeSet<String>());
+      List<ServerName> unassignedServers =
+          difference(getOnlineRS(),getAssignedServers());
+      for(ServerName serverName: unassignedServers) {
+        defaultInfo.addServer(serverName.getHostAndPort());
+      }
+			return defaultInfo;
+		} else {
+			return this.groupMap.get(groupName);
+		}
+	}
+
+
+
+	/**
+	 * Delete a region server group.
+	 *
+	 * @param groupName the group name
+	 * @throws IOException Signals that an I/O exception has occurred.
+	 */
+  @Override
+  public synchronized void removeGroup(String groupName) throws IOException {
+    GroupInfo group = null;
+    if(!groupMap.containsKey(groupName) || groupName.equals(GroupInfo.DEFAULT_GROUP)) {
+      throw new IllegalArgumentException("Group "+groupName+" does not exist or is default group");
+    }
+    synchronized (groupMap) {
+      try {
+        group = groupMap.remove(groupName);
+        flushConfig();
+      } catch (IOException e) {
+        groupMap.put(groupName, group);
+        throw e;
+      }
+    }
+	}
+
+  @Override
+  public synchronized List<GroupInfo> listGroups() throws IOException {
+    List<GroupInfo> list = Lists.newLinkedList(groupMap.values());
+    list.add(getGroup(GroupInfo.DEFAULT_GROUP));
+    return list;
+  }
+
+	/**
+	 * Read group configuration from HDFS.
+	 *
+	 * @throws IOException
+	 */
+	synchronized void reloadConfig() throws IOException {
+		List<GroupInfo> groupList;
+    FSDataInputStream in = fs.open(path);
+    try {
+      synchronized (groupMap) {
+        this.groupMap.clear();
+        groupList = readGroups(in);
+        for (GroupInfo group : groupList) {
+          groupMap.put(group.getName(), group);
+        }
+      }
+    } finally {
+      in.close();
+    }
+	}
+
+	/**
+	 * Write the configuration to HDFS.
+	 *
+	 * @throws IOException
+	 */
+	private synchronized void flushConfig() throws IOException {
+    flushConfig(groupMap);
+	}
+
+	private synchronized void flushConfig(Map<String,GroupInfo> map) throws IOException {
+		FSDataOutputStream output = null;
+		try {
+			output = fs.create(path, true);
+			List<GroupInfo> groups = Lists.newArrayList(map.values());
+			writeGroups(groups, output);
+		} finally {
+			output.close();
+		}
+	}
+
+	/**
+	 * Read a list of GroupInfo.
+	 *
+	 * @param in
+	 *            DataInput
+	 * @return
+	 * @throws IOException
+	 */
+	private static List<GroupInfo> readGroups(final FSDataInputStream in)
+			throws IOException {
+		List<GroupInfo> groupList = new ArrayList<GroupInfo>();
+		BufferedReader br = new BufferedReader(new InputStreamReader(in));
+		String line = null;
+		try {
+			while ((line = br.readLine()) != null && (line = line.trim()).length() > 0) {
+				GroupInfo group = new GroupInfo();
+				if (group.readFields(line)) {
+					if (group.getName().equalsIgnoreCase(GroupInfo.DEFAULT_GROUP))
+            throw new IOException("Config file contains default group!");
+          groupList.add(group);
+				}
+			}
+		} finally {
+			br.close();
+		}
+		return groupList;
+	}
+
+	/**
+	 * Write a list of group information out.
+	 *
+	 * @param groups
+	 * @param out
+	 * @throws IOException
+	 */
+	private static void writeGroups(Collection<GroupInfo> groups, FSDataOutputStream out)
+			throws IOException {
+		BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(out));
+		try {
+			for (GroupInfo group : groups) {
+        if (group.getName().equalsIgnoreCase(GroupInfo.DEFAULT_GROUP))
+          throw new IOException("Config file contains default group!");
+				group.write(bw);
+			}
+		} finally {
+			bw.close();
+		}
+	}
+
+  private List<ServerName> getOnlineRS() throws IOException{
+    if(master != null) {
+      return master.getServerManager().getOnlineServersList();
+    }
+    try {
+      List<ServerName> servers = new LinkedList<ServerName>();
+      for (String el: ZKUtil.listChildrenNoWatch(watcher, watcher.rsZNode)) {
+        servers.add(ServerName.parseServerName(el));
+      }
+      return servers;
+    } catch (KeeperException e) {
+      throw new IOException("Failed to retrieve server list for zookeeper", e);
+    }
+  }
+
+  private List<ServerName> getAssignedServers(){
+    List<ServerName> assignedServers = Lists.newArrayList();
+    for(GroupInfo gInfo : groupMap.values()){
+      for(String hostPort: gInfo.getServers()) {
+        assignedServers.add(ServerName.parseServerName(hostPort));
+      }
+    }
+    return assignedServers;
+  }
+
+	List<ServerName> difference(Collection<ServerName> onlineServers,
+			Collection<ServerName> servers) {
+		if(servers.size() == 0){
+			return Lists.newArrayList(onlineServers);
+		} else {
+			ArrayList<ServerName> finalList = new ArrayList<ServerName>();
+			for (ServerName olServer : onlineServers) {
+				ServerName actual = ServerName.findServerWithSameHostnamePort(
+						servers, olServer);
+				if (actual == null) {
+					finalList.add(olServer);
+				}
+			}
+			return finalList;
+		}
+	}
+
+  /**
+	 * Gets the group info of table.
+	 *
+	 * @param desc the table name
+	 * @return An instance of GroupInfo.
+	 */
+  //TODO move this to group admin?
+  public String getGroupPropertyOfTable(HTableDescriptor desc) throws IOException {
+		return GroupInfo.getGroupString(desc);
+	}
+
+  public void setGroupPropertyOfTable(String groupName, HTableDescriptor desc) throws IOException {
+		GroupInfo.setGroupString(groupName, desc);
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/GroupMasterObserver.java b/src/main/java/org/apache/hadoop/hbase/master/GroupMasterObserver.java
new file mode 100644
index 0000000..ce18c0d
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/master/GroupMasterObserver.java
@@ -0,0 +1,65 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import org.apache.hadoop.hbase.CoprocessorEnvironment;
+import org.apache.hadoop.hbase.DoNotRetryIOException;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.coprocessor.BaseMasterObserver;
+import org.apache.hadoop.hbase.coprocessor.MasterCoprocessorEnvironment;
+import org.apache.hadoop.hbase.coprocessor.ObserverContext;
+
+import java.io.IOException;
+import java.util.List;
+
+public class GroupMasterObserver extends BaseMasterObserver {
+
+    private MasterCoprocessorEnvironment menv;
+
+  @Override
+  public void start(CoprocessorEnvironment ctx) throws IOException {
+    menv = (MasterCoprocessorEnvironment)ctx;
+  }
+
+  @Override
+  public void preCreateTable(ObserverContext<MasterCoprocessorEnvironment> ctx, HTableDescriptor desc, HRegionInfo[] regions) throws IOException {
+    String groupName = GroupInfo.getGroupString(desc);
+    if(getGroupInfoManager().getGroup(groupName) == null) {
+      throw new DoNotRetryIOException("Group "+groupName+" does not exist.");
+    }
+  }
+
+  @Override
+  public void preModifyTable(ObserverContext<MasterCoprocessorEnvironment> ctx, byte[] tableName, HTableDescriptor htd) throws IOException {
+    MasterServices master = ctx.getEnvironment().getMasterServices();
+    String groupName = GroupInfo.getGroupString(htd);
+    if(getGroupInfoManager().getGroup(groupName) == null) {
+      throw new DoNotRetryIOException("Group "+groupName+" does not exist.");
+    }
+
+    List<HRegionInfo> tableRegionList = master.getAssignmentManager().getRegionsOfTable(tableName);
+    master.getAssignmentManager().unassign(tableRegionList);
+  }
+
+  private GroupInfoManager getGroupInfoManager() {
+    return ((GroupBasedLoadBalancer)menv.getMasterServices().getAssignmentManager().getBalancer()).getGroupInfoManager();
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/GroupMoveServerHandler.java b/src/main/java/org/apache/hadoop/hbase/master/GroupMoveServerHandler.java
new file mode 100644
index 0000000..f50d474
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/master/GroupMoveServerHandler.java
@@ -0,0 +1,165 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.DoNotRetryIOException;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.Server;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.executor.EventHandler;
+
+import java.io.IOException;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.NavigableSet;
+import java.util.Set;
+import java.util.TreeSet;
+
+public class GroupMoveServerHandler extends EventHandler {
+	private static final Log LOG = LogFactory.getLog(GroupMoveServerHandler.class);
+
+  private MasterServices master;
+  private MoveServerPlan plan;
+  private String transGroup;
+  private String sourceGroup;
+  private GroupInfoManager groupManager;
+  private Map<String,String> serversInTransition;
+  private volatile boolean success;
+
+  public GroupMoveServerHandler(Server master, Map<String,String> serversInTransition,
+                                GroupInfoManager groupManager, MoveServerPlan plan) throws IOException {
+    super(master, EventType.C_M_GROUP_MOVE_SERVER);
+    this.serversInTransition = serversInTransition;
+    this.groupManager = groupManager;
+    this.master = (MasterServices)server;
+    this.plan = plan;
+
+    synchronized (serversInTransition) {
+      //check server list
+      sourceGroup = groupManager.getGroupOfServer(plan.getServers().iterator().next()).getName();
+      for(String server: plan.getServers()) {
+        if(serversInTransition.containsKey(server)) {
+          throw new DoNotRetryIOException("Server list contains a server that is already being moved: "+server);
+        }
+        String tmpGroup = groupManager.getGroupOfServer(server).getName();
+        if(sourceGroup != null && !tmpGroup.equals(sourceGroup)) {
+          throw new DoNotRetryIOException("Move server request should only come from one source group");
+        }
+      }
+      //update the servers as in transition
+      for(String server: plan.getServers()) {
+        serversInTransition.put(server, plan.getTargetGroup());
+      }
+    }
+
+    if(!sourceGroup.startsWith(GroupInfo.TRANSITION_GROUP_PREFIX)) {
+      transGroup = GroupInfo.TRANSITION_GROUP_PREFIX+sourceGroup+"_TO_"+plan.getTargetGroup();
+      groupManager.addGroup(new GroupInfo(transGroup, new TreeSet<String>()));
+    }
+    groupManager.moveServers(plan.getServers(), sourceGroup, transGroup);
+  }
+
+  @Override
+  public void process() throws IOException {
+    try {
+      boolean found;
+      do {
+        found = false;
+        for(String rs: plan.getServers()) {
+          List<HRegionInfo> regions = getOnlineRegions(rs);
+          LOG.info("Unassigining "+regions.size()+" from server "+rs);
+          master.getAssignmentManager().unassign(regions);
+          found = found || regions.size() > 0;
+        }
+        try {
+          Thread.sleep(10000);
+        } catch (InterruptedException e) {
+          LOG.warn("Sleep interrupted", e);
+        }
+      } while(found);
+      success = true;
+      LOG.info("Move server done: "+sourceGroup+"->"+plan.getTargetGroup());
+    } catch(Exception e) {
+      success = false;
+      LOG.error("Caught exception while running", e);
+    }
+  }
+
+  private List<HRegionInfo> getOnlineRegions(String hostPort) throws IOException {
+    List<HRegionInfo> regions = new LinkedList<HRegionInfo>();
+    for(Map.Entry<ServerName, List<HRegionInfo>> el:
+        master.getAssignmentManager().getAssignments().entrySet()) {
+      if(el.getKey().getHostAndPort().equals(hostPort)) {
+        regions.addAll(el.getValue());
+      }
+    }
+    return regions;
+  }
+
+  public static class MoveServerPlan {
+    private Set<String> servers;
+    private String targetGroup;
+
+    public MoveServerPlan(Set<String> servers, String targetGroup) {
+      this.servers = servers;
+      this.targetGroup = targetGroup;
+    }
+
+    public Set<String> getServers() {
+      return servers;
+    }
+
+    public String getTargetGroup() {
+      return targetGroup;
+    }
+  }
+
+
+  public MoveServerPlan getPlan() {
+    return plan;
+  }
+
+  public void complete() throws IOException {
+    String tmpSourceGroup = sourceGroup;
+    if(transGroup != null) {
+      tmpSourceGroup = transGroup;
+      LOG.debug("Moving "+plan.getServers().size()+
+          " servers from transition group: "+transGroup+" to final group: "+plan.getTargetGroup());
+    }
+    try {
+      if(success) {
+        groupManager.moveServers(plan.getServers(), tmpSourceGroup, plan.getTargetGroup());
+        if(transGroup != null) {
+          groupManager.removeGroup(transGroup);
+        }
+      }
+    } finally {
+      //remove servers in transition
+      synchronized(serversInTransition) {
+        for(String server: plan.getServers()) {
+          serversInTransition.remove(server);
+        }
+      }
+    }
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/master/HMaster.java b/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
index 3cab49c..1367bbe 100644
--- a/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
+++ b/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
@@ -181,7 +181,7 @@ Server {
   private CatalogTracker catalogTracker;
   // Cluster status zk tracker and local setter
   private ClusterStatusTracker clusterStatusTracker;
-  
+
   // buffer for "fatal error" notices from region servers
   // in the cluster. This is only used for assisting
   // operations/debugging.
@@ -258,7 +258,7 @@ Server {
     // Creation of a HSA will force a resolve.
     InetSocketAddress initialIsa = new InetSocketAddress(hostname, port);
     if (initialIsa.getAddress() == null) {
-      throw new IllegalArgumentException("Failed resolve of " + this.isa);
+      throw new IllegalArgumentException("Failed resolve of " + initialIsa);
     }
     int numHandlers = conf.getInt("hbase.master.handler.count",
       conf.getInt("hbase.regionserver.handler.count", 25));
@@ -321,7 +321,7 @@ Server {
         "(Also watching cluster state node)");
       Thread.sleep(c.getInt("zookeeper.session.timeout", 180 * 1000));
     }
-    
+
   }
 
   /**
@@ -359,7 +359,7 @@ Server {
       }
     } catch (Throwable t) {
       // HBASE-5680: Likely hadoop23 vs hadoop 20.x/1.x incompatibility
-      if (t instanceof NoClassDefFoundError && 
+      if (t instanceof NoClassDefFoundError &&
           t.getMessage().contains("org/apache/hadoop/hdfs/protocol/FSConstants$SafeModeAction")) {
           // improved error message for this special case
           abort("HBase is having a problem with its Hadoop jars.  You may need to "
@@ -371,7 +371,7 @@ Server {
       }
     } finally {
       startupStatus.cleanup();
-      
+
       stopChores();
       // Wait for all the remaining region servers to report in IFF we were
       // running a cluster shutdown AND we were NOT aborting.
@@ -393,7 +393,7 @@ Server {
 
   /**
    * Try becoming active master.
-   * @param startupStatus 
+   * @param startupStatus
    * @return True if we could successfully become the active master.
    * @throws InterruptedException
    */
@@ -472,7 +472,7 @@ Server {
    * <li>Ensure assignment of root and meta regions<li>
    * <li>Handle either fresh cluster start or master failover</li>
    * </ol>
-   * @param masterRecovery 
+   * @param masterRecovery
    *
    * @throws IOException
    * @throws InterruptedException
@@ -509,7 +509,7 @@ Server {
 
     status.setStatus("Initializing ZK system trackers");
     initializeZKBasedSystemTrackers();
-    
+
     if (!masterRecovery) {
       // initialize master side coprocessors before we start handling requests
       status.setStatus("Initializing master coprocessors");
@@ -538,6 +538,9 @@ Server {
     status.setStatus("Splitting logs after master startup");
     splitLogAfterStartup(this.fileSystemManager);
 
+    this.balancer.setClusterStatus(getClusterStatus());
+    this.balancer.setMasterServices(this);
+
     // Make sure root and meta assigned before proceeding.
     assignRootAndMeta(status);
     enableServerShutdownHandler();
@@ -553,9 +556,6 @@ Server {
     status.setStatus("Starting assignment manager");
     this.assignmentManager.joinCluster();
 
-    this.balancer.setClusterStatus(getClusterStatus());
-    this.balancer.setMasterServices(this);
-
     // Fixing up missing daughters if any
     status.setStatus("Fixing up missing daughters");
     fixupDaughters(status);
@@ -578,7 +578,7 @@ Server {
     // removing dead server with same hostname and port of rs which is trying to check in before
     // master initialization. See HBASE-5916.
     this.serverManager.clearDeadServersWithSameHostNameAndPortOfOnlineServer();
-    
+
     if (!masterRecovery) {
       if (this.cpHost != null) {
         // don't let cp initialization errors kill the master
@@ -590,11 +590,11 @@ Server {
       }
     }
   }
-  
+
   /**
    * If ServerShutdownHandler is disabled, we enable it and expire those dead
    * but not expired servers.
-   * 
+   *
    * @throws IOException
    */
   private void enableServerShutdownHandler() throws IOException {
@@ -603,7 +603,7 @@ Server {
       this.serverManager.expireDeadNotExpiredServers();
     }
   }
-  
+
   /**
    * Useful for testing purpose also where we have
    * master restart scenarios.
@@ -829,7 +829,7 @@ Server {
    *  need to install an unexpected exception handler.
    */
   private void startServiceThreads() throws IOException{
- 
+
    // Start the executor service pools
    this.executorService.startExecutorService(ExecutorType.MASTER_OPEN_REGION,
       conf.getInt("hbase.master.executor.openregion.threads", 5));
@@ -839,7 +839,7 @@ Server {
       conf.getInt("hbase.master.executor.serverops.threads", 3));
    this.executorService.startExecutorService(ExecutorType.MASTER_META_SERVER_OPERATIONS,
       conf.getInt("hbase.master.executor.serverops.threads", 5));
-   
+
    // We depend on there being only one instance of this executor running
    // at a time.  To do concurrency, would need fencing of enable/disable of
    // tables.
@@ -863,7 +863,7 @@ Server {
      this.infoServer.setAttribute(MASTER, this);
      this.infoServer.start();
     }
-   
+
     // Start allowing requests to happen.
     this.rpcServer.openServer();
     if (LOG.isDebugEnabled()) {
@@ -1079,11 +1079,11 @@ Server {
         newValue = this.cpHost.preBalanceSwitch(newValue);
       }
       if (mode == BalanceSwitchMode.SYNC) {
-        synchronized (this.balancer) {        
+        synchronized (this.balancer) {
           this.balanceSwitch = newValue;
         }
       } else {
-        this.balanceSwitch = newValue;        
+        this.balanceSwitch = newValue;
       }
       LOG.info("BalanceSwitch=" + newValue);
       if (this.cpHost != null) {
@@ -1092,14 +1092,14 @@ Server {
     } catch (IOException ioe) {
       LOG.warn("Error flipping balance switch", ioe);
     }
-    return oldValue;    
+    return oldValue;
   }
-  
+
   @Override
   public boolean synchronousBalanceSwitch(final boolean b) {
     return switchBalancer(b, BalanceSwitchMode.SYNC);
   }
-  
+
   @Override
   public boolean balanceSwitch(final boolean b) {
     return switchBalancer(b, BalanceSwitchMode.ASYNC);
@@ -1122,20 +1122,15 @@ Server {
       this.assignmentManager.getAssignment(encodedRegionName);
     if (p == null)
       throw new UnknownRegionException(Bytes.toStringBinary(encodedRegionName));
-    ServerName dest = null;
-    if (destServerName == null || destServerName.length == 0) {
-      LOG.info("Passed destination servername is null or empty so choosing a server at random");
-      List<ServerName> destServers = this.serverManager.getOnlineServersList();
-      destServers.remove(p.getSecond());
-      // If i have only one RS then destination can be null.
-      dest = balancer.randomAssignment(destServers);
+    ServerName prefferedServer;
+    if(destServerName == null || destServerName.length == 0){
+    	prefferedServer = null;
     } else {
-      dest = new ServerName(Bytes.toString(destServerName));
+    	prefferedServer = new ServerName(Bytes.toString(destServerName));
     }
-    
-    // Now we can do the move
+    ServerName dest = balancer.randomAssignment(p.getFirst(), this.serverManager.getOnlineServersList(),
+    		prefferedServer);
     RegionPlan rp = new RegionPlan(p.getFirst(), p.getSecond(), dest);
-    
     try {
       if (this.cpHost != null) {
         if (this.cpHost.preMove(p.getFirst(), p.getSecond(), dest)) {
@@ -1222,7 +1217,7 @@ Server {
    * @return Pair indicating the number of regions updated Pair.getFirst is the
    *         regions that are yet to be updated Pair.getSecond is the total number
    *         of regions of the table
-   * @throws IOException 
+   * @throws IOException
    */
   public Pair<Integer, Integer> getAlterStatus(byte[] tableName)
   throws IOException {
@@ -1570,7 +1565,7 @@ Server {
   public AssignmentManager getAssignmentManager() {
     return this.assignmentManager;
   }
-  
+
   public MemoryBoundedLogMessageBuffer getRegionServerFatalLogBuffer() {
     return rsFatals;
   }
@@ -1634,13 +1629,13 @@ Server {
   public boolean isAborted() {
     return this.abort;
   }
-  
+
   void checkInitialized() throws PleaseHoldException {
     if (!this.initialized) {
       throw new PleaseHoldException("Master is initializing");
     }
   }
-  
+
   /**
    * Report whether this master is currently the active master or not.
    * If not active master, we are parked on ZK waiting to become active.
@@ -1698,8 +1693,8 @@ Server {
       cpHost.postAssign(pair.getFirst());
     }
   }
-  
-  
+
+
 
   public void assignRegion(HRegionInfo hri) {
     assignmentManager.assign(hri, true);
@@ -1711,7 +1706,15 @@ Server {
     checkInitialized();
     Pair<HRegionInfo, ServerName> pair =
       MetaReader.getRegion(this.catalogTracker, regionName);
-    if (pair == null) throw new UnknownRegionException(Bytes.toString(regionName));
+    if (Bytes.equals(HRegionInfo.ROOT_REGIONINFO.getRegionName(),regionName)) {
+      try {
+        pair = new Pair<HRegionInfo, ServerName>(HRegionInfo.ROOT_REGIONINFO, this.catalogTracker.getRootLocation());
+      } catch (InterruptedException e) {
+        throw new IOException(e);
+      }
+    }
+    if (pair == null) throw new UnknownRegionException(
+        Bytes.toString(HRegionInfo.ROOT_REGIONINFO.getRegionName())+"<-->"+Bytes.toString(regionName));
     HRegionInfo hri = pair.getFirst();
     if (cpHost != null) {
       if (cpHost.preUnassign(hri, force)) {
@@ -1730,7 +1733,7 @@ Server {
   }
 
   /**
-   * Get HTD array for given tables 
+   * Get HTD array for given tables
    * @param tableNames
    * @return HTableDescriptor[]
    */
diff --git a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java
index 7d2dd74..2fb9827 100644
--- a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java
+++ b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java
@@ -24,6 +24,7 @@ import org.apache.hadoop.hbase.ClusterStatus;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.ServerName;
 
+import java.io.IOException;
 import java.util.List;
 import java.util.Map;
 
@@ -91,8 +92,10 @@ public interface LoadBalancer extends Configurable {
 
   /**
    * Get a random region server from the list
+   * @param region
    * @param servers
    * @return Servername
    */
-  public ServerName randomAssignment(List<ServerName> servers);
+  public ServerName randomAssignment(HRegionInfo region, List<ServerName> servers, ServerName prefferedServer);
+
 }
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java b/src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java
index cd3989a..3ccc53f 100644
--- a/src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestAssignmentManager.java
@@ -158,7 +158,7 @@ public class TestAssignmentManager {
 
   /**
    * Test a balance going on at same time as a master failover
-   * 
+   *
    * @throws IOException
    * @throws KeeperException
    * @throws InterruptedException
@@ -403,7 +403,7 @@ public class TestAssignmentManager {
 
   /**
    * To test closed region handler to remove rit and delete corresponding znode if region in pending
-   * close or closing while processing shutdown of a region server.(HBASE-5927). 
+   * close or closing while processing shutdown of a region server.(HBASE-5927).
    * @throws KeeperException
    * @throws IOException
    */
@@ -413,7 +413,7 @@ public class TestAssignmentManager {
     testCaseWithPartiallyDisabledState(TableState.DISABLING);
     testCaseWithPartiallyDisabledState(TableState.DISABLED);
   }
-  
+
   /**
    * To test if the split region is removed from RIT if the region was in SPLITTING state
    * but the RS has actually completed the splitting in META but went down. See HBASE-6070
@@ -447,7 +447,7 @@ public class TestAssignmentManager {
     am.regionsInTransition.put(REGIONINFO.getEncodedName(), new RegionState(REGIONINFO,
         State.SPLITTING, System.currentTimeMillis(), SERVERNAME_A));
     am.getZKTable().setEnabledTable(REGIONINFO.getTableNameAsString());
-    
+
     RegionTransitionData data = new RegionTransitionData(EventType.RS_ZK_REGION_SPLITTING,
         REGIONINFO.getRegionName(), SERVERNAME_A);
     String node = ZKAssign.getNodeName(this.watcher, REGIONINFO.getEncodedName());
@@ -455,11 +455,11 @@ public class TestAssignmentManager {
     ZKUtil.createAndWatch(this.watcher, node, data.getBytes());
 
     try {
-      
+
       processServerShutdownHandler(ct, am, regionSplitDone);
       // check znode deleted or not.
       // In both cases the znode should be deleted.
-      
+
       if(regionSplitDone){
         assertTrue("Region state of region in SPLITTING should be removed from rit.",
             am.regionsInTransition.isEmpty());
@@ -502,7 +502,7 @@ public class TestAssignmentManager {
     } else {
       am.getZKTable().setDisabledTable(REGIONINFO.getTableNameAsString());
     }
-    
+
     RegionTransitionData data = new RegionTransitionData(EventType.M_ZK_REGION_CLOSING,
         REGIONINFO.getRegionName(), SERVERNAME_A);
     String node = ZKAssign.getNodeName(this.watcher, REGIONINFO.getEncodedName());
@@ -577,7 +577,7 @@ public class TestAssignmentManager {
    * @param hri Region to serialize into HRegionInfo
    * @return A mocked up Result that fakes a Get on a row in the
    * <code>.META.</code> table.
-   * @throws IOException 
+   * @throws IOException
    */
   private Result getMetaTableRowResult(final HRegionInfo hri,
       final ServerName sn)
@@ -596,13 +596,13 @@ public class TestAssignmentManager {
       Bytes.toBytes(sn.getStartcode())));
     return new Result(kvs);
   }
-  
+
   /**
    * @param sn ServerName to use making startcode and server in meta
    * @param hri Region to serialize into HRegionInfo
    * @return A mocked up Result that fakes a Get on a row in the
    * <code>.META.</code> table.
-   * @throws IOException 
+   * @throws IOException
    */
   private Result getMetaTableRowResultAsSplitRegion(final HRegionInfo hri, final ServerName sn)
       throws IOException {
@@ -664,12 +664,12 @@ public class TestAssignmentManager {
       am.shutdown();
     }
   }
-  
+
   /**
    * Tests the processDeadServersAndRegionsInTransition should not fail with NPE
    * when it failed to get the children. Let's abort the system in this
    * situation
-   * @throws ServiceException 
+   * @throws ServiceException
    */
   @Test(timeout = 5000)
   public void testProcessDeadServersAndRegionsInTransitionShouldNotFailWithNPE()
@@ -709,8 +709,8 @@ public class TestAssignmentManager {
    * @param region region to be created as offline
    * @param serverName server event originates from
    * @return Version of znode created.
-   * @throws KeeperException 
-   * @throws IOException 
+   * @throws KeeperException
+   * @throws IOException
    */
   // Copied from SplitTransaction rather than open the method over there in
   // the regionserver package.
@@ -790,9 +790,9 @@ public class TestAssignmentManager {
         server, manager, ct, balancer, executor);
     return am;
   }
-  
+
   /**
-   * TestCase verifies that the regionPlan is updated whenever a region fails to open 
+   * TestCase verifies that the regionPlan is updated whenever a region fails to open
    * and the master tries to process RS_ZK_FAILED_OPEN state.(HBASE-5546).
    */
   @Test
@@ -827,7 +827,7 @@ public class TestAssignmentManager {
     while (!gate.get()) {
       Thread.sleep(10);
     }
-    // new region plan may take some time to get updated after random assignment is called and 
+    // new region plan may take some time to get updated after random assignment is called and
     // gate is set to true.
     RegionPlan newRegionPlan = am.regionPlans.get(REGIONINFO.getEncodedName());
     while (newRegionPlan == null) {
@@ -840,11 +840,11 @@ public class TestAssignmentManager {
     assertTrue("Destnation servers should be different.", !(regionPlan.getDestination().equals(
         newRegionPlan.getDestination())));
   }
-  
+
   /**
    * Test verifies whether assignment is skipped for regions of tables in DISABLING state during
    * clean cluster startup. See HBASE-6281.
-   * 
+   *
    * @throws KeeperException
    * @throws IOException
    * @throws Exception
@@ -877,7 +877,7 @@ public class TestAssignmentManager {
           gate.get());
       // need to change table state from disabling to disabled.
       assertTrue("Table should be disabled.",
-          am.getZKTable().isDisabledTable(REGIONINFO.getTableNameAsString()));      
+          am.getZKTable().isDisabledTable(REGIONINFO.getTableNameAsString()));
     } finally {
       am.getZKTable().setEnabledTable(REGIONINFO.getTableNameAsString());
       am.shutdown();
@@ -896,12 +896,12 @@ public class TestAssignmentManager {
     }
 
     @Override
-    public ServerName randomAssignment(List<ServerName> servers) {
-      ServerName randomServerName = super.randomAssignment(servers);
+    public ServerName randomAssignment(HRegionInfo region, List<ServerName> servers, ServerName prefferedServer) {
+      ServerName randomServerName = super.randomAssignment(region, servers, prefferedServer);
       this.gate.set(true);
       return randomServerName;
     }
-    
+
     @Override
     public Map<ServerName, List<HRegionInfo>> retainAssignment(
         Map<HRegionInfo, ServerName> regions, List<ServerName> servers) {
@@ -949,19 +949,19 @@ public class TestAssignmentManager {
       while (this.gate.get()) Threads.sleep(1);
       super.processRegionsInTransition(data, regionInfo, deadServers, expectedVersion);
     }
-    
+
     @Override
     public void assign(HRegionInfo region, boolean setOfflineInZK, boolean forceNewPlan,
         boolean hijack) {
       assignInvoked = true;
       super.assign(region, setOfflineInZK, forceNewPlan, hijack);
     }
-    
+
     @Override
     public ServerName getRegionServerOfRegion(HRegionInfo hri) {
       return SERVERNAME_A;
     }
-    
+
     /** reset the watcher */
     void setWatcher(ZooKeeperWatcher watcher) {
       this.watcher = watcher;
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestGroupBasedLoadBalancer.java b/src/test/java/org/apache/hadoop/hbase/master/TestGroupBasedLoadBalancer.java
new file mode 100644
index 0000000..b6d14e6
--- /dev/null
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestGroupBasedLoadBalancer.java
@@ -0,0 +1,574 @@
+/**
+ * Copyright 2011 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.TreeMap;
+import java.util.TreeSet;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MediumTests;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.TableDescriptors;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+import org.mockito.Mockito;
+
+import com.google.common.collect.ArrayListMultimap;
+import com.google.common.collect.Lists;
+
+@Category(MediumTests.class)
+public class TestGroupBasedLoadBalancer {
+
+    private static final Log LOG = LogFactory.getLog(TestGroupBasedLoadBalancer.class);
+    private static LoadBalancer loadBalancer;
+    private static Random rand;
+
+    static String[]  groups = new String[] { GroupInfo.DEFAULT_GROUP, "dg2", "dg3",
+            "dg4" };
+    static String[] tables = new String[] { "dt1", "dt2", "dt3", "dt4" };
+    static List<ServerName> servers;
+    static Map<String, GroupInfo> groupMap;
+    static List<HTableDescriptor> tableDescs;
+    int[] regionAssignment = new int[] { 2, 5, 7, 10, 4, 3, 1 };
+    static int regionId = 0;
+
+    @BeforeClass
+    public static void beforeAllTests() throws Exception {
+        rand = new Random();
+        servers = generatedServers(7);
+        groupMap = constructGroupInfo(servers, groups);
+        tableDescs = constructTableDesc();
+        Configuration conf = HBaseConfiguration.create();
+        conf.set("hbase.regions.slop", "0");
+        loadBalancer = new GroupBasedLoadBalancer(getMockedGroupInfoManager());
+        loadBalancer.setMasterServices(getMockedMaster());
+        loadBalancer.setConf(conf);
+    }
+
+    /**
+     * Test the load balancing algorithm.
+     *
+     * Invariant is that all servers of the group should be hosting either floor(average) or
+     * ceiling(average)
+     *
+     * @throws Exception
+     */
+    @Test
+    public void testBalanceCluster() throws Exception {
+        Map<ServerName, List<HRegionInfo>> servers = mockClusterServers();
+        ArrayListMultimap<String, ServerAndLoad> list = convertToGroupBasedMap(servers);
+        LOG.info("Mock Cluster :  " + printStats(list));
+        List<RegionPlan> plans = loadBalancer.balanceCluster(servers);
+        ArrayListMultimap<String, ServerAndLoad> balancedCluster = reconcile(
+                                                    list, plans);
+        LOG.info("Mock Balance : " + printStats(balancedCluster));
+        assertClusterAsBalanced(balancedCluster);
+    }
+
+    /**
+     * Invariant is that all servers of a group have load between floor(avg) and
+     * ceiling(avg) number of regions.
+     */
+    private void assertClusterAsBalanced(
+            ArrayListMultimap<String, ServerAndLoad> groupLoadMap) {
+        for (String gName : groupLoadMap.keySet()) {
+            List<ServerAndLoad> groupLoad = groupLoadMap.get(gName);
+            int numServers = groupLoad.size();
+            int numRegions = 0;
+            int maxRegions = 0;
+            int minRegions = Integer.MAX_VALUE;
+            for (ServerAndLoad server : groupLoad) {
+                int nr = server.getLoad();
+                if (nr > maxRegions) {
+                    maxRegions = nr;
+                }
+                if (nr < minRegions) {
+                    minRegions = nr;
+                }
+                numRegions += nr;
+            }
+            if (maxRegions - minRegions < 2) {
+                // less than 2 between max and min, can't balance
+                return;
+            }
+            int min = numRegions / numServers;
+            int max = numRegions % numServers == 0 ? min : min + 1;
+
+            for (ServerAndLoad server : groupLoad) {
+                assertTrue(server.getLoad() <= max);
+                assertTrue(server.getLoad() >= min);
+            }
+        }
+    }
+
+    /**
+     * Tests immediate assignment.
+     *
+     * Invariant is that all regions have an assignment.
+     *
+     * @throws Exception
+     */
+    @Test
+    public void testImmediateAssignment() throws Exception {
+        List<HRegionInfo> regions = randomRegions(20);
+        Map<HRegionInfo, ServerName> assignments = loadBalancer
+                .immediateAssignment(regions, servers);
+        assertImmediateAssignment(regions, servers, assignments);
+    }
+
+    /**
+     * All regions have an assignment.
+     *
+     * @param regions
+     * @param servers
+     * @param assignments
+     * @throws IOException
+     * @throws FileNotFoundException
+     */
+    private void assertImmediateAssignment(List<HRegionInfo> regions,
+            List<ServerName> servers, Map<HRegionInfo, ServerName> assignments)
+            throws FileNotFoundException, IOException {
+        for (HRegionInfo region : regions) {
+            assertTrue(assignments.containsKey(region));
+            ServerName server = assignments.get(region);
+            String tableName = region.getTableNameAsString();
+            String groupName = getMockedGroupInfoManager()
+                    .getGroupPropertyOfTable(
+                            getMockedMaster().getTableDescriptors().get(
+                                    tableName));
+            assertTrue(StringUtils.isNotEmpty(groupName));
+            GroupInfo gInfo = getMockedGroupInfoManager().getGroup(groupName);
+            assertTrue("Region is not correctly assigned to group servers.",
+                    gInfo.containsServer(server.getHostAndPort()));
+        }
+    }
+
+    /**
+     * Tests the bulk assignment used during cluster startup.
+     *
+     * Round-robin. Should yield a balanced cluster so same invariant as the
+     * load balancer holds, all servers holding either floor(avg) or
+     * ceiling(avg).
+     *
+     * @throws Exception
+     */
+    @Test
+    public void testBulkAssignment() throws Exception {
+        List<HRegionInfo> regions = randomRegions(25);
+        Map<ServerName, List<HRegionInfo>> assignments = loadBalancer
+                .roundRobinAssignment(regions, servers);
+        assertTrue(assignments.keySet().size() == servers.size());
+        for (ServerName sn : assignments.keySet()) {
+            List<HRegionInfo> regionAssigned = assignments.get(sn);
+            for (HRegionInfo region : regionAssigned) {
+                String tableName = region.getTableNameAsString();
+                String groupName = getMockedGroupInfoManager()
+                        .getGroupPropertyOfTable(
+                                getMockedMaster().getTableDescriptors().get(
+                                        tableName));
+                assertTrue(StringUtils.isNotEmpty(groupName));
+                GroupInfo gInfo = getMockedGroupInfoManager().getGroup(
+                        groupName);
+                assertTrue(
+                        "Region is not correctly assigned to group servers.",
+                        gInfo.containsServer(sn.getHostAndPort()));
+            }
+        }
+        ArrayListMultimap<String, ServerAndLoad> loadMap = convertToGroupBasedMap(assignments);
+        assertClusterAsBalanced(loadMap);
+    }
+
+    /**
+     * Test the cluster startup bulk assignment which attempts to retain
+     * assignment info.
+     *
+     * @throws Exception
+     */
+    @Test
+    public void testRetainAssignment() throws Exception {
+        // Test simple case where all same servers are there
+        Map<ServerName, List<HRegionInfo>> currentAssignments = mockClusterServers();
+        Map<HRegionInfo, ServerName> inputForTest = new HashMap<HRegionInfo, ServerName>();
+        for (ServerName sn : currentAssignments.keySet()) {
+            for (HRegionInfo region : currentAssignments.get(sn)) {
+                inputForTest.put(region, sn);
+            }
+        }
+        Map<ServerName, List<HRegionInfo>> newAssignment = loadBalancer
+                .retainAssignment(inputForTest, servers);
+        assertRetainedAssignment(inputForTest, servers, newAssignment);
+    }
+
+    /**
+     * Asserts a valid retained assignment plan.
+     * <p>
+     * Must meet the following conditions:
+     * <ul>
+     * <li>Every input region has an assignment, and to an online server
+     * <li>If a region had an existing assignment to a server with the same
+     * address a a currently online server, it will be assigned to it
+     * </ul>
+     *
+     * @param existing
+     * @param groupBasedLoad
+     * @param assignment
+     * @throws IOException
+     * @throws FileNotFoundException
+     */
+    private void assertRetainedAssignment(
+            Map<HRegionInfo, ServerName> existing, List<ServerName> servers,
+            Map<ServerName, List<HRegionInfo>> assignment)
+            throws FileNotFoundException, IOException {
+        // Verify condition 1, every region assigned, and to online server
+        Set<ServerName> onlineServerSet = new TreeSet<ServerName>(servers);
+        Set<HRegionInfo> assignedRegions = new TreeSet<HRegionInfo>();
+        for (Map.Entry<ServerName, List<HRegionInfo>> a : assignment.entrySet()) {
+            assertTrue(
+                    "Region assigned to server that was not listed as online",
+                    onlineServerSet.contains(a.getKey()));
+            for (HRegionInfo r : a.getValue())
+                assignedRegions.add(r);
+        }
+        assertEquals(existing.size(), assignedRegions.size());
+
+        // Verify condition 2, every region must be assigned to correct server.
+        Set<String> onlineHostNames = new TreeSet<String>();
+        for (ServerName s : servers) {
+            onlineHostNames.add(s.getHostname());
+        }
+
+        for (Map.Entry<ServerName, List<HRegionInfo>> a : assignment.entrySet()) {
+            ServerName currentServer = a.getKey();
+            for (HRegionInfo r : a.getValue()) {
+                ServerName oldAssignedServer = existing.get(r);
+                String tableName = r.getTableNameAsString();
+                String groupName = getMockedGroupInfoManager()
+                        .getGroupPropertyOfTable(
+                                getMockedMaster().getTableDescriptors().get(
+                                        tableName));
+                assertTrue(StringUtils.isNotEmpty(groupName));
+                GroupInfo gInfo = getMockedGroupInfoManager().getGroup(
+                        groupName);
+                assertTrue(
+                        "Region is not correctly assigned to group servers.",
+                        gInfo.containsServer(currentServer.getHostAndPort()));
+                if (oldAssignedServer != null
+                        && onlineHostNames.contains(oldAssignedServer
+                                .getHostname())) {
+                    // this region was previously assigned somewhere, and that
+                    // host is still around, then the host must have been is a
+                    // different group.
+                    if (oldAssignedServer.getHostAndPort().equals(
+                            currentServer.getHostAndPort()) == false) {
+                        assertFalse(gInfo.containsServer(oldAssignedServer
+                                .getHostAndPort()));
+                    }
+                }
+            }
+        }
+    }
+
+    private String printStats(
+            ArrayListMultimap<String, ServerAndLoad> groupBasedLoad) {
+        StringBuffer sb = new StringBuffer();
+        sb.append("\n");
+        for (String groupName : groupBasedLoad.keySet()) {
+            sb.append("Stats for group: " + groupName);
+            sb.append("\n");
+            sb.append(groupMap.get(groupName).getServers());
+            sb.append("\n");
+            List<ServerAndLoad> groupLoad = groupBasedLoad.get(groupName);
+            int numServers = groupLoad.size();
+            int totalRegions = 0;
+            sb.append("Per Server Load: \n");
+            for (ServerAndLoad sLoad : groupLoad) {
+                sb.append("Server :" + sLoad.getServerName() + " Load : "
+                        + sLoad.getLoad() + "\n");
+                totalRegions += sLoad.getLoad();
+            }
+            sb.append(" Group Statistics : \n");
+            float average = (float) totalRegions / numServers;
+            int max = (int) Math.ceil(average);
+            int min = (int) Math.floor(average);
+            sb.append("[srvr=" + numServers + " rgns=" + totalRegions + " avg="
+                    + average + " max=" + max + " min=" + min + "]");
+            sb.append("\n");
+            sb.append("===============================");
+            sb.append("\n");
+        }
+        return sb.toString();
+    }
+
+    private ArrayListMultimap<String, ServerAndLoad> convertToGroupBasedMap(
+            final Map<ServerName, List<HRegionInfo>> serversMap) throws IOException {
+        ArrayListMultimap<String, ServerAndLoad> loadMap = ArrayListMultimap
+                .create();
+        for (GroupInfo gInfo : getMockedGroupInfoManager().listGroups()) {
+            Set<String> groupServers = gInfo.getServers();
+            for (String hostAndPort : groupServers) {
+                ServerName actual = ServerName.findServerWithSameHostnamePort(
+                        servers, ServerName.parseServerName(hostAndPort));
+                List<HRegionInfo> regions = serversMap.get(actual);
+                assertTrue("No load for " + actual, regions != null);
+                loadMap.put(gInfo.getName(),
+                        new ServerAndLoad(actual, regions.size()));
+            }
+        }
+        return loadMap;
+    }
+
+  private ArrayListMultimap<String, ServerAndLoad> reconcile(
+      ArrayListMultimap<String, ServerAndLoad> previousLoad,
+      List<RegionPlan> plans) {
+    ArrayListMultimap<String, ServerAndLoad> result = ArrayListMultimap
+        .create();
+    result.putAll(previousLoad);
+    if (plans != null) {
+      for (RegionPlan plan : plans) {
+        ServerName source = plan.getSource();
+        updateLoad(result, source, -1);
+        ServerName destination = plan.getDestination();
+        updateLoad(result, destination, +1);
+      }
+    }
+    return result;
+  }
+
+  private void updateLoad(
+      ArrayListMultimap<String, ServerAndLoad> previousLoad,
+      final ServerName sn, final int diff) {
+    for (String groupName : previousLoad.keySet()) {
+      ServerAndLoad newSAL = null;
+      ServerAndLoad oldSAL = null;
+      for (ServerAndLoad sal : previousLoad.get(groupName)) {
+        if (ServerName.isSameHostnameAndPort(sn, sal.getServerName())) {
+          oldSAL = sal;
+          newSAL = new ServerAndLoad(sn, sal.getLoad() + diff);
+          break;
+        }
+      }
+      if (newSAL != null) {
+        previousLoad.remove(groupName, oldSAL);
+        previousLoad.put(groupName, newSAL);
+        break;
+      }
+    }
+  }
+
+    private Map<ServerName, List<HRegionInfo>> mockClusterServers() throws IOException {
+        assertTrue(servers.size() == regionAssignment.length);
+        Map<ServerName, List<HRegionInfo>> assignment = new TreeMap<ServerName, List<HRegionInfo>>();
+        for (int i = 0; i < servers.size(); i++) {
+            int numRegions = regionAssignment[i];
+            List<HRegionInfo> regions = assignedRegions(numRegions, servers.get(i));
+            assignment.put(servers.get(i), regions);
+        }
+        return assignment;
+    }
+
+    /**
+     * Generated a list of regions evenly distributed between the tables.
+     *
+     * @param numRegions The number of regions to be generated.
+     * @return List of HRegionInfo.
+     */
+    private List<HRegionInfo> randomRegions(int numRegions) {
+        List<HRegionInfo> regions = new ArrayList<HRegionInfo>(numRegions);
+        byte[] start = new byte[16];
+        byte[] end = new byte[16];
+        rand.nextBytes(start);
+        rand.nextBytes(end);
+        int regionIdx = rand.nextInt(tables.length);
+        for (int i = 0; i < numRegions; i++) {
+            Bytes.putInt(start, 0, numRegions << 1);
+            Bytes.putInt(end, 0, (numRegions << 1) + 1);
+            int tableIndex = (i + regionIdx) % tables.length;
+            HRegionInfo hri = new HRegionInfo(
+                    Bytes.toBytes(tables[tableIndex]), start, end, false,
+                    regionId++);
+            regions.add(hri);
+        }
+        return regions;
+    }
+
+    /**
+     * Generated assigned regions to a given server using group information.
+     *
+     * @param numRegions the num regions to generate
+     * @param sn the servername
+     * @return the list
+     * @throws IOException Signals that an I/O exception has occurred.
+     */
+    private List<HRegionInfo> assignedRegions(int numRegions, ServerName sn) throws IOException {
+      List<HRegionInfo> regions = new ArrayList<HRegionInfo>(numRegions);
+      byte[] start = new byte[16];
+      byte[] end = new byte[16];
+      for (int i = 0; i < numRegions; i++) {
+          Bytes.putInt(start, 0, numRegions << 1);
+          Bytes.putInt(end, 0, (numRegions << 1) + 1);
+          String tableName = getTableName(sn);
+          HRegionInfo hri = new HRegionInfo(
+                  Bytes.toBytes(tableName), start, end, false,
+                  regionId++);
+          regions.add(hri);
+      }
+      return regions;
+  }
+
+    private static List<ServerName> generatedServers(int numServers) {
+        List<ServerName> servers = new ArrayList<ServerName>(numServers);
+        for (int i = 0; i < numServers; i++) {
+            String host = "server" + rand.nextInt(100000);
+            int port = rand.nextInt(60000);
+            servers.add(new ServerName(host, port, -1));
+        }
+        return servers;
+    }
+
+    /**
+     * Construct group info, with each group have atleast one server.
+     *
+     * @param servers the servers
+     * @param groups the groups
+     * @return the map
+     */
+    private static Map<String, GroupInfo> constructGroupInfo(
+            List<ServerName> servers, String[] groups) {
+        assertTrue(servers != null);
+        assertTrue(servers.size() >= groups.length);
+        int index = 0;
+        Map<String, GroupInfo> groupMap = new HashMap<String, GroupInfo>();
+        for (String grpName : groups) {
+            TreeSet<String> hostAndPort = new TreeSet<String>();
+            hostAndPort.add(servers.get(index).getHostAndPort());
+            groupMap.put(grpName, new GroupInfo(grpName, hostAndPort));
+            index++;
+        }
+        while (index < servers.size()) {
+            int grpIndex = rand.nextInt(groups.length);
+            groupMap.get(groups[grpIndex]).addServer(
+                    servers.get(index).getHostAndPort());
+            index++;
+        }
+        return groupMap;
+    }
+
+    /**
+     * Construct table descriptors evenly distributed between the groups.
+     *
+     * @return the list
+     */
+    private static List<HTableDescriptor> constructTableDesc() {
+        List<HTableDescriptor> tds = Lists.newArrayList();
+        int index = rand.nextInt(groups.length);
+        for (int i = 0; i < tables.length; i++) {
+            HTableDescriptor htd = new HTableDescriptor(tables[i]);
+            int grpIndex = (i + index) % groups.length ;
+            String groupName = groups[grpIndex];
+            htd.setValue(GroupInfo.GROUP_KEY, Bytes.toBytes(groupName));
+            tds.add(htd);
+        }
+        return tds;
+    }
+
+    private static MasterServices getMockedMaster() throws IOException {
+        TableDescriptors tds = Mockito.mock(TableDescriptors.class);
+        Mockito.when(tds.get(tables[0])).thenReturn(tableDescs.get(0));
+        Mockito.when(tds.get(tables[1])).thenReturn(tableDescs.get(1));
+        Mockito.when(tds.get(tables[2])).thenReturn(tableDescs.get(2));
+        Mockito.when(tds.get(tables[3])).thenReturn(tableDescs.get(3));
+        MasterServices services = Mockito.mock(HMaster.class);
+        Mockito.when(services.getTableDescriptors()).thenReturn(tds);
+        AssignmentManager am = Mockito.mock(AssignmentManager.class);
+        Mockito.when(services.getAssignmentManager()).thenReturn(am);
+        return services;
+    }
+
+    private static GroupInfoManager getMockedGroupInfoManager() throws IOException {
+        GroupInfoManager gm = Mockito.mock(GroupInfoManager.class);
+        Mockito.when(gm.getGroup(groups[0])).thenReturn(
+                groupMap.get(groups[0]));
+        Mockito.when(gm.getGroup(groups[1])).thenReturn(
+                groupMap.get(groups[1]));
+        Mockito.when(gm.getGroup(groups[2])).thenReturn(
+                groupMap.get(groups[2]));
+        Mockito.when(gm.getGroup(groups[3])).thenReturn(
+                groupMap.get(groups[3]));
+        Mockito.when(gm.listGroups()).thenReturn(
+                Lists.newLinkedList(groupMap.values()));
+        Mockito.when(gm.getGroupPropertyOfTable(tableDescs.get(0)))
+                .thenReturn(
+                        Bytes.toString(tableDescs.get(0).getValue(
+                                GroupInfo.GROUP_KEY)));
+        Mockito.when(gm.getGroupPropertyOfTable(tableDescs.get(1)))
+                .thenReturn(
+                        Bytes.toString(tableDescs.get(1).getValue(
+                                GroupInfo.GROUP_KEY)));
+        Mockito.when(gm.getGroupPropertyOfTable(tableDescs.get(2)))
+                .thenReturn(
+                        Bytes.toString(tableDescs.get(2).getValue(
+                                GroupInfo.GROUP_KEY)));
+        Mockito.when(gm.getGroupPropertyOfTable(tableDescs.get(3)))
+                .thenReturn(
+                        Bytes.toString(tableDescs.get(3).getValue(
+                                GroupInfo.GROUP_KEY)));
+
+        return gm;
+    }
+
+    private String getTableName(ServerName sn) throws IOException{
+      String tableName = null;
+      GroupInfoManager gm = getMockedGroupInfoManager();
+      GroupInfo groupOfServer = null;
+      for(GroupInfo gInfo : gm.listGroups()){
+        if(gInfo.containsServer(sn.getHostAndPort())){
+          groupOfServer = gInfo;
+          break;
+        }
+      }
+
+      for(HTableDescriptor desc : tableDescs){
+       if(gm.getGroupPropertyOfTable(desc).endsWith(groupOfServer.getName())){
+         tableName = desc.getNameAsString();
+       }
+      }
+      return tableName;
+    }
+}
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestGroups.java b/src/test/java/org/apache/hadoop/hbase/master/TestGroups.java
new file mode 100644
index 0000000..b197808
--- /dev/null
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestGroups.java
@@ -0,0 +1,246 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertSame;
+import static org.junit.Assert.assertTrue;
+
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.TreeSet;
+
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MediumTests;
+import org.apache.hadoop.hbase.MiniHBaseCluster;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.TableDescriptors;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.ipc.HRegionInterface;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+
+@Category(MediumTests.class)
+public class TestGroups {
+	private static HBaseTestingUtility TEST_UTIL;
+	private static HMaster master;
+	private static Random rand;
+  private static HBaseAdmin admin;
+	private static String groupPrefix = "Group-";
+	private static String tablePrefix = "TABLE-";
+	private static String familyPrefix = "FAMILY-";
+
+	@BeforeClass
+	public static void setUp() throws Exception {
+		TEST_UTIL = new HBaseTestingUtility();
+		TEST_UTIL.getConfiguration().set(
+				HConstants.HBASE_MASTER_LOADBALANCER_CLASS,
+				GroupBasedLoadBalancer.class.getName());
+    TEST_UTIL.getConfiguration().set("hbase.coprocessor.master.classes",
+        GroupMasterObserver.class.getName()+","+
+        GroupAdminEndpoint.class.getName());
+		TEST_UTIL.startMiniCluster(4);
+		MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
+		master = cluster.getMaster();
+		rand = new Random();
+    admin = TEST_UTIL.getHBaseAdmin();
+	}
+
+	@AfterClass
+	public static void tearDown() throws Exception {
+		TEST_UTIL.shutdownMiniCluster();
+	}
+
+  @After
+  public void afterMethod() throws Exception {
+		GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+    for(GroupInfo group: groupAdmin.listGroups()) {
+      if(!group.getName().equals(GroupInfo.DEFAULT_GROUP)) {
+        removeGroup(groupAdmin, group.getName());
+      }
+    }
+    for(HTableDescriptor table: TEST_UTIL.getHBaseAdmin().listTables()) {
+      if(!table.isMetaRegion() && !table.isRootRegion()) {
+        TEST_UTIL.deleteTable(table.getName());
+      }
+    }
+  }
+
+	@Test
+	public void testBasicStartUp() throws IOException {
+		GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+		GroupInfo defaultInfo = groupAdmin.getGroup(GroupInfo.DEFAULT_GROUP);
+		assertTrue(defaultInfo.getServers().size() == 4);
+		// Assignment of root and meta regions.
+		assertTrue(groupAdmin.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP)
+        .size() == 2);
+	}
+
+	@Test
+	public void testSimpleRegionServerMove() throws IOException,
+			InterruptedException {
+		GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+		GroupInfo appInfo = addGroup(groupAdmin, groupPrefix + rand.nextInt(), 1);
+		GroupInfo adminInfo = addGroup(groupAdmin, groupPrefix + rand.nextInt(), 1);
+    GroupInfo dInfo = groupAdmin.getGroup(GroupInfo.DEFAULT_GROUP);
+		// Force the group info manager to read group information from disk.
+		assertTrue(groupAdmin.listGroups().size() == 3);
+		assertTrue(adminInfo.getServers().size() == 1);
+		assertTrue(appInfo.getServers().size() == 1);
+		assertTrue(dInfo.getServers().size() == 2);
+		groupAdmin.moveServers(appInfo.getServers(),
+        GroupInfo.DEFAULT_GROUP);
+		groupAdmin.removeGroup(appInfo.getName());
+		groupAdmin.moveServers(adminInfo.getServers(),
+        GroupInfo.DEFAULT_GROUP);
+		groupAdmin.removeGroup(adminInfo.getName());
+		assertTrue(groupAdmin.listGroups().size() == 1);
+	}
+
+	@Test
+	public void testTableMove() throws IOException, InterruptedException {
+		String tableName = tablePrefix + rand.nextInt();
+		byte[] TABLENAME = Bytes.toBytes(tableName);
+		byte[] FAMILYNAME = Bytes.toBytes(familyPrefix + rand.nextInt());
+		GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+		GroupInfo newGroup = addGroup(groupAdmin, groupPrefix + rand.nextInt(), 2);
+    int currMetaCount = TEST_UTIL.getMetaTableRows().size();
+		HTable ht = TEST_UTIL.createTable(TABLENAME, FAMILYNAME);
+		assertTrue(TEST_UTIL.createMultiRegions(master.getConfiguration(), ht,
+				FAMILYNAME, 4) == 4);
+		TEST_UTIL.waitUntilAllRegionsAssigned(currMetaCount+4);
+		assertTrue(master.getAssignmentManager().getZKTable()
+				.isEnabledTable(Bytes.toString(TABLENAME)));
+		List<HRegionInfo> regionList = TEST_UTIL.getHBaseAdmin()
+				.getTableRegions(TABLENAME);
+		assertTrue(regionList.size() > 0);
+		GroupInfo tableGrp = groupAdmin.getGroupInfoOfTable(Bytes.toBytes(tableName));
+		assertTrue(tableGrp.getName().equals(GroupInfo.DEFAULT_GROUP));
+
+    //change table's group
+    admin.disableTable(TABLENAME);
+    HTableDescriptor desc = admin.getTableDescriptor(TABLENAME);
+    groupAdmin.setGroupPropertyOfTable(newGroup.getName(), desc);
+    admin.modifyTable(TABLENAME, desc);
+    admin.enableTable(TABLENAME);
+
+    //verify group change
+    desc = admin.getTableDescriptor(TABLENAME);
+		assertEquals(newGroup.getName(),
+        GroupInfo.getGroupString(desc));
+
+		Map<String, Map<ServerName, List<HRegionInfo>>> tableRegionAssignMap = master
+				.getAssignmentManager().getAssignmentsByTable();
+		assertTrue(tableRegionAssignMap.keySet().size() == 1);
+		Map<ServerName, List<HRegionInfo>> serverMap = tableRegionAssignMap
+				.get(tableName);
+		for (ServerName rs : serverMap.keySet()) {
+			if (serverMap.get(rs).size() > 0) {
+				assertTrue(newGroup.containsServer(rs.getHostAndPort()));
+			}
+		}
+    removeGroup(groupAdmin, newGroup.getName());
+		TEST_UTIL.deleteTable(TABLENAME);
+		tableRegionAssignMap = master.getAssignmentManager()
+				.getAssignmentsByTable();
+		assertEquals(tableRegionAssignMap.size(), 0);
+	}
+
+	@Test
+	public void testRegionMove() throws IOException, InterruptedException {
+		GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+		GroupInfo newGroup = addGroup(groupAdmin, groupPrefix + rand.nextInt(), 1);
+		String tableNameOne = tablePrefix + rand.nextInt();
+		byte[] tableOneBytes = Bytes.toBytes(tableNameOne);
+		byte[] familyOneBytes = Bytes.toBytes(familyPrefix + rand.nextInt());
+    int currMetaCount = TEST_UTIL.getMetaTableRows().size();
+		HTable ht = TEST_UTIL.createTable(tableOneBytes, familyOneBytes);
+		// All the regions created below will be assigned to the default group.
+		assertTrue(TEST_UTIL.createMultiRegions(master.getConfiguration(), ht,
+				familyOneBytes, 5) == 5);
+		TEST_UTIL.waitUntilAllRegionsAssigned(currMetaCount+5);
+		List<HRegionInfo> regions = groupAdmin
+				.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP);
+		assertTrue(regions.size() + ">=" + 5, regions.size() >= 5);
+		HRegionInfo region = regions.get(regions.size()-1);
+		// Lets move this region to newGroupName group.
+		ServerName tobeAssigned =
+        ServerName.parseServerName(newGroup.getServers().iterator().next());
+		master.move(region.getEncodedNameAsBytes(),
+        Bytes.toBytes(tobeAssigned.toString()));
+
+		while (master.getAssignmentManager().getRegionsInTransition().size() > 0) {
+			Thread.sleep(10);
+		}
+    //verify that region was never assigned to the server
+		List<HRegionInfo> updatedRegions = groupAdmin
+				.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP);
+		assertTrue(regions.size() == updatedRegions.size());
+    HRegionInterface rs = admin.getConnection().getHRegionConnection(tobeAssigned.getHostname(),tobeAssigned.getPort());
+		assertFalse(rs.getOnlineRegions().contains(region));
+	}
+
+	static GroupInfo addGroup(GroupAdminClient gAdmin, String groupName,
+			int serverCount) throws IOException, InterruptedException {
+		GroupInfo defaultInfo = gAdmin
+				.getGroup(GroupInfo.DEFAULT_GROUP);
+		assertTrue(defaultInfo != null);
+		assertTrue(defaultInfo.getServers().size() >= serverCount);
+		gAdmin.addGroup(groupName);
+
+    Set<String> set = new HashSet<String>();
+    for(String server: defaultInfo.getServers()) {
+      if(set.size() == serverCount) {
+        break;
+      }
+      set.add(server);
+    }
+    gAdmin.moveServers(set, groupName);
+    GroupInfo result = gAdmin.getGroup(groupName);
+		assertTrue(result.getServers().size() >= serverCount);
+    return result;
+	}
+
+  static void removeGroup(GroupAdminClient groupAdmin, String groupName) throws IOException {
+    for(String table: groupAdmin.listTablesOfGroup(groupName)) {
+      byte[] bTable = Bytes.toBytes(table);
+      admin.disableTable(bTable);
+      HTableDescriptor desc = admin.getTableDescriptor(bTable);
+      desc.remove(GroupInfo.GROUP_KEY);
+      admin.modifyTable(bTable, desc);
+      admin.enableTable(bTable);
+    }
+    groupAdmin.removeGroup(groupName);
+  }
+
+}
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestGroupsWithDeadServers.java b/src/test/java/org/apache/hadoop/hbase/master/TestGroupsWithDeadServers.java
new file mode 100644
index 0000000..f510cb8
--- /dev/null
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestGroupsWithDeadServers.java
@@ -0,0 +1,215 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import static org.junit.Assert.assertTrue;
+
+import java.io.IOException;
+import java.util.List;
+import java.util.Random;
+import java.util.Set;
+import java.util.TreeSet;
+
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.LargeTests;
+import org.apache.hadoop.hbase.MiniHBaseCluster;
+import org.apache.hadoop.hbase.ServerName;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.ResultScanner;
+import org.apache.hadoop.hbase.client.RetriesExhaustedException;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.JVMClusterUtil;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+
+@Category(LargeTests.class)
+public class TestGroupsWithDeadServers {
+	private static HBaseTestingUtility TEST_UTIL;
+	private static HMaster master;
+	private static Random rand;
+  private static HBaseAdmin admin;
+
+	@BeforeClass
+	public static void setUp() throws Exception {
+		TEST_UTIL = new HBaseTestingUtility();
+		TEST_UTIL.getConfiguration().set(
+				HConstants.HBASE_MASTER_LOADBALANCER_CLASS,
+				GroupBasedLoadBalancer.class.getName());
+    TEST_UTIL.getConfiguration().set("hbase.coprocessor.master.classes",
+        GroupMasterObserver.class.getName()+","+
+        GroupAdminEndpoint.class.getName());
+		TEST_UTIL.getConfiguration().setInt(
+				"hbase.master.assignment.timeoutmonitor.period", 2000);
+		TEST_UTIL.getConfiguration().setInt(
+				"hbase.master.assignment.timeoutmonitor.timeout", 5000);
+		TEST_UTIL.startMiniCluster(4);
+		MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
+		master = cluster.getMaster();
+		rand = new Random();
+    admin = TEST_UTIL.getHBaseAdmin();
+	}
+
+	@AfterClass
+	public static void tearDown() throws Exception {
+		TEST_UTIL.shutdownMiniCluster();
+	}
+
+	@Test
+	public void testGroupWithOnlineServers() throws IOException, InterruptedException{
+    GroupAdminClient groupAdmin = new GroupAdminClient(master.getConfiguration());
+		String newRSGroup = "group-" + rand.nextInt();
+		String tableNameTwo = "TABLE-" + rand.nextInt();
+		byte[] tableTwoBytes = Bytes.toBytes(tableNameTwo);
+		String familyName = "family" + rand.nextInt();
+		byte[] familyTwoBytes = Bytes.toBytes(familyName);
+    int baseNumRegions = TEST_UTIL.getMetaTableRows().size();
+		int NUM_REGIONS = 4;
+
+		GroupInfo defaultInfo = groupAdmin.getGroup(GroupInfo.DEFAULT_GROUP);
+		assertTrue(defaultInfo.getServers().size() == 4);
+		TestGroups.addGroup(groupAdmin, newRSGroup, 2);
+		defaultInfo = groupAdmin.getGroup(GroupInfo.DEFAULT_GROUP);
+		assertTrue(defaultInfo.getServers().size() == 2);
+		assertTrue(groupAdmin.getGroup(newRSGroup).getServers().size() == 2);
+		HTable ht = TEST_UTIL.createTable(tableTwoBytes, familyTwoBytes);
+		// All the regions created below will be assigned to the default group.
+		assertTrue(TEST_UTIL.createMultiRegions(master.getConfiguration(), ht,
+				familyTwoBytes, NUM_REGIONS) == NUM_REGIONS);
+		TEST_UTIL.waitUntilAllRegionsAssigned(baseNumRegions+NUM_REGIONS);
+		List<HRegionInfo> regions = groupAdmin.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP);
+		assertTrue(regions.size() >= NUM_REGIONS);
+    //move table to new group
+    admin.disableTable(tableNameTwo);
+    HTableDescriptor desc = admin.getTableDescriptor(tableTwoBytes);
+    groupAdmin.setGroupPropertyOfTable(newRSGroup, desc);
+    admin.modifyTable(tableTwoBytes, desc);
+    admin.enableTable(tableTwoBytes);
+
+		TEST_UTIL.waitUntilAllRegionsAssigned(baseNumRegions+NUM_REGIONS);
+		//Move the ROOT and META regions to default group.
+		ServerName serverForRoot =
+        ServerName.findServerWithSameHostnamePort(master.getServerManager().getOnlineServersList(),
+            ServerName.parseServerName(defaultInfo.getServers().iterator().next()));
+		master.move(HRegionInfo.ROOT_REGIONINFO.getEncodedNameAsBytes(), Bytes.toBytes(serverForRoot.toString()));
+		master.move(HRegionInfo.FIRST_META_REGIONINFO.getEncodedNameAsBytes(), Bytes.toBytes(serverForRoot.toString()));
+		while (master.getAssignmentManager().isRegionsInTransition()){
+			Thread.sleep(10);
+		}
+		List<HRegionInfo> newGrpRegions = groupAdmin.listOnlineRegionsOfGroup(newRSGroup);
+		assertTrue(newGrpRegions.size() == NUM_REGIONS);
+		MiniHBaseCluster hbaseCluster = TEST_UTIL.getHBaseCluster();
+		// Now we kill all the region servers in the new group.
+		Set<String> serverNames = groupAdmin.getGroup(newRSGroup).getServers();
+		for (String sName : serverNames) {
+			int serverNumber = getServerNumber(
+					hbaseCluster.getRegionServerThreads(), sName);
+			assert (serverNumber != -1);
+			hbaseCluster.stopRegionServer(serverNumber, false);
+		}
+		//wait till all the regions come transition state.
+		while (master.getAssignmentManager().getRegionsInTransition().size() < NUM_REGIONS){
+			Thread.sleep(5);
+		}
+		newGrpRegions = groupAdmin.listOnlineRegionsOfGroup(newRSGroup);
+		assertTrue(newGrpRegions.size() == 0);
+		regions = groupAdmin.listOnlineRegionsOfGroup(GroupInfo.DEFAULT_GROUP);
+		assertTrue(regions.size() == 2);
+		scanTableForNegativeResults(ht);
+		startServersAndMove(groupAdmin, 1, newRSGroup);
+		while(master.getAssignmentManager().isRegionsInTransition()){
+			Thread.sleep(5);
+		}
+		scanTableForPositiveResults(ht);
+		newGrpRegions = groupAdmin.listOnlineRegionsOfGroup(newRSGroup);
+		assertTrue(newGrpRegions.size() == NUM_REGIONS);
+		TEST_UTIL.deleteTable(tableTwoBytes);
+    groupAdmin.removeGroup(newRSGroup);
+	}
+
+	private int getServerNumber(List<JVMClusterUtil.RegionServerThread> servers, String sName){
+		int i = 0;
+		for(JVMClusterUtil.RegionServerThread rs : servers){
+			if(sName.equals(rs.getRegionServer().getServerName().getHostAndPort())){
+				return i;
+			}
+			i++;
+		}
+		return -1;
+	}
+
+	private void scanTableForNegativeResults(HTable ht){
+		ResultScanner s = null;
+		boolean isExceptionCaught = false;
+		try {
+			Scan scan = new Scan();
+			s = ht.getScanner(scan);
+		} catch (Exception exp) {
+			assertTrue(exp instanceof RetriesExhaustedException);
+			isExceptionCaught = true;
+		} finally {
+			if (s != null) {
+				s.close();
+			}
+			assertTrue(isExceptionCaught);
+		}
+	}
+
+	private void scanTableForPositiveResults(HTable ht) throws IOException{
+		ResultScanner s = null;
+		try {
+			Scan scan = new Scan();
+			s = ht.getScanner(scan);
+		} finally {
+			if (s != null) {
+				s.close();
+			}
+		}
+	}
+
+	private void startServersAndMove(GroupAdminClient groupAdmin, int numServers,
+			String groupName) throws IOException, InterruptedException {
+		MiniHBaseCluster hbaseCluster = TEST_UTIL.getHBaseCluster();
+		ServerName newServer;
+		for (int i = 0; i < numServers; i++) {
+			newServer = hbaseCluster.startRegionServer().getRegionServer()
+					.getServerName();
+			// Make sure that the server manager reports the new online servers.
+			while (ServerName.findServerWithSameHostnamePort(master
+					.getServerManager().getOnlineServersList(), newServer) == null) {
+				Thread.sleep(5);
+			}
+			assertTrue(groupAdmin.getGroup(GroupInfo.DEFAULT_GROUP)
+          .containsServer(newServer.getHostAndPort()));
+      Set<String> set = new TreeSet<String>();
+      set.add(newServer.getHostAndPort());
+			groupAdmin.moveServers(set, groupName);
+			assertTrue(groupAdmin.getGroup(groupName).containsServer(
+          newServer.getHostAndPort()));
+		}
+	}
+
+}
