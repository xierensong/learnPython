Index: src/main/java/org/apache/hadoop/hbase/HConstants.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/HConstants.java
+++ src/main/java/org/apache/hadoop/hbase/HConstants.java
@@ -32,7 +32,7 @@
   public enum OperationStatusCode {
     NOT_RUN,
     SUCCESS,
-    BAD_FAMILY,
+    SANITY_CHECK_FAILURE,
     FAILURE;
   }
 
Index: src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
+++ src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
@@ -248,6 +248,7 @@
 
   final WriteState writestate = new WriteState();
 
+  final long timestampTooNew;
   final long memstoreFlushSize;
   private volatile long lastFlushTime;
   private List<Pair<Long,Long>> recentFlushes
@@ -400,6 +401,7 @@
     this.conf = null;
     this.flushListener = null;
     this.fs = null;
+    this.timestampTooNew = HConstants.LATEST_TIMESTAMP;
     this.memstoreFlushSize = 0L;
     this.log = null;
     this.regiondir = null;
@@ -451,6 +453,17 @@
       // Write out region name as string and its encoded name.
       LOG.debug("Creating region " + this);
     }
+
+    /*
+     * timestamp.slop provides a server-side constraint on the timestamp. This
+     * assumes that you base your TS around currentTimeMillis(). In this case,
+     * throw an error to the user if the user-specified TS is newer than now +
+     * slop. LATEST_TIMESTAMP == don't use this functionality
+     */
+    this.timestampTooNew = conf.getLong(
+        "hbase.hregion.keyvalue.timestamp.slop.millisecs",
+        HConstants.LATEST_TIMESTAMP);
+
     long flushSize = regionInfo.getTableDesc().getMemStoreFlushSize();
     if (flushSize == HTableDescriptor.DEFAULT_MEMSTORE_FLUSH_SIZE) {
       flushSize = conf.getLong("hbase.hregion.memstore.flush.size",
@@ -1839,9 +1852,10 @@
         // Check the families in the put. If bad, skip this one.
         try {
           checkFamilies(put.getFamilyMap().keySet());
-        } catch (NoSuchColumnFamilyException nscf) {
-          LOG.warn("No such column family in batch put", nscf);
-          batchOp.retCodes[lastIndexExclusive] = OperationStatusCode.BAD_FAMILY;
+          checkTimestamps(put, now);
+        } catch (DoNotRetryIOException dnrioe) {
+          LOG.warn("Sanity check error in batch put", dnrioe);
+          batchOp.retCodes[lastIndexExclusive] = OperationStatusCode.SANITY_CHECK_FAILURE;
           lastIndexExclusive++;
           continue;
         }
@@ -2136,6 +2150,7 @@
     this.updatesLock.readLock().lock();
     try {
       checkFamilies(familyMap.keySet());
+      checkTimestamps(familyMap, now);
       updateKVTimestamps(familyMap.values(), byteNow);
       // write/sync to WAL should happen before we touch memstore.
       //
@@ -2215,6 +2230,26 @@
       checkFamily(family);
     }
   }
+  private void checkTimestamps(Put p, long now) throws DoNotRetryIOException {
+    checkTimestamps(p.getFamilyMap(), now);
+  }
+
+  private void checkTimestamps(final Map<byte[], List<KeyValue>> familyMap,
+      long now) throws DoNotRetryIOException {
+    if (timestampTooNew == HConstants.LATEST_TIMESTAMP) {
+      return;
+    }
+    long maxTs = now + timestampTooNew;
+    for (List<KeyValue> kvs : familyMap.values()) {
+      for (KeyValue kv : kvs) {
+        // see if the user-side TS is out of range. latest = server-side
+        if (!kv.isLatestTimestamp() && kv.getTimestamp() > maxTs) {
+          throw new DoNotRetryIOException("Timestamp for KV out of range "
+              + kv + " (too.new=" + timestampTooNew + ")");
+        }
+      }
+    }
+  }
 
   /**
    * Append the given map of family->edits to a WALEdit data structure.
Index: src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java
===================================================================
--- src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java
+++ src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java
@@ -22,6 +22,7 @@
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.DoNotRetryIOException;
 import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hbase.HBaseTestCase;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
@@ -377,7 +378,7 @@
     codes = this.region.put(puts);
     assertEquals(10, codes.length);
     for (int i = 0; i < 10; i++) {
-      assertEquals((i == 5) ? OperationStatusCode.BAD_FAMILY :
+      assertEquals((i == 5) ? OperationStatusCode.SANITY_CHECK_FAILURE :
         OperationStatusCode.SUCCESS, codes[i]);
     }
     assertEquals(1, HLog.getSyncTime().count);
@@ -415,7 +416,7 @@
     assertEquals(1, HLog.getSyncTime().count);
     codes = retFromThread.get();
     for (int i = 0; i < 10; i++) {
-      assertEquals((i == 5) ? OperationStatusCode.BAD_FAMILY :
+      assertEquals((i == 5) ? OperationStatusCode.SANITY_CHECK_FAILURE :
         OperationStatusCode.SUCCESS, codes[i]);
     }
 
@@ -432,7 +433,7 @@
     codes = region.put(putsAndLocks.toArray(new Pair[0]));
     LOG.info("...performed put");
     for (int i = 0; i < 10; i++) {
-      assertEquals((i == 5) ? OperationStatusCode.BAD_FAMILY :
+      assertEquals((i == 5) ? OperationStatusCode.SANITY_CHECK_FAILURE :
         OperationStatusCode.SUCCESS, codes[i]);
     }
     // Make sure we didn't do an extra batch
@@ -892,6 +893,35 @@
 
   }
 
+  /**
+   * Tests that there is server-side filtering for invalid timestamp upper
+   * bound. Note that the timestamp lower bound is automatically handled for us
+   * by the TTL field.
+   */
+  public void testPutWithTsSlop() throws IOException {
+    byte[] tableName = Bytes.toBytes("testtable");
+    byte[] fam = Bytes.toBytes("info");
+    byte[][] families = { fam };
+    String method = this.getName();
+    HBaseConfiguration conf = new HBaseConfiguration();
+
+    // add data with a timestamp that is too recent for range. Ensure assert
+    conf.setInt("hbase.hregion.keyvalue.timestamp.slop.millisecs", 1000);
+    initHRegion(tableName, method, conf, families);
+    try {
+      // no TS specified == use latest. should not error
+      region.put(new Put(row).add(fam, Bytes.toBytes("qual"), Bytes
+          .toBytes("value")), false);
+      // TS out of range. should error
+      region.put(new Put(row).add(fam, Bytes.toBytes("qual"),
+                 System.currentTimeMillis() + 2000,
+                 Bytes.toBytes("value")), false);
+      fail("Expected IOE for TS out of configured timerange");
+    } catch (DoNotRetryIOException ioe) {
+      LOG.debug("Received expected exception", ioe);
+    }
+  }
+
   public void testScanner_DeleteOneFamilyNotAnother() throws IOException {
     byte [] tableName = Bytes.toBytes("test_table");
     byte [] fam1 = Bytes.toBytes("columnA");
