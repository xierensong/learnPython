From 55b7fc663e84558444eff9864b119d7ae9cdb88c Mon Sep 17 00:00:00 2001
From: Sahil Aggarwal <sahil.aggarwal@flipkart.com>
Date: Fri, 10 Nov 2017 10:16:52 +0530
Subject: [PATCH] HBASE-19164: Remove UUID.randomUUID in tests.

---
 .../apache/hadoop/hbase/HBaseCommonTestingUtility.java    |  7 ++++++-
 .../TestReplicationSyncUpToolWithBulkLoadedData.java      |  3 +--
 .../apache/hadoop/hbase/RandomStringGeneratorImpl.java    |  3 ++-
 .../hadoop/hbase/test/IntegrationTestReplication.java     |  4 ++--
 .../mapreduce/TestImportTSVWithOperationAttributes.java   |  5 ++---
 .../hadoop/hbase/mapreduce/TestImportTSVWithTTLs.java     |  2 +-
 .../mapreduce/TestImportTSVWithVisibilityLabels.java      | 15 +++++++--------
 .../org/apache/hadoop/hbase/mapreduce/TestImportTsv.java  |  3 +--
 .../java/org/apache/hadoop/hbase/HBaseTestingUtility.java |  5 ++---
 .../apache/hadoop/hbase/TestHBaseOnOtherDfsCluster.java   |  4 +---
 .../org/apache/hadoop/hbase/TestNodeHealthCheckChore.java |  3 +--
 .../apache/hadoop/hbase/client/TestFromClientSide.java    |  8 ++++----
 .../apache/hadoop/hbase/client/TestSnapshotWithAcl.java   |  8 ++++----
 .../replication/TestReplicationAdminWithClusters.java     |  2 +-
 .../apache/hadoop/hbase/io/hfile/TestHFileEncryption.java |  3 +--
 .../apache/hadoop/hbase/master/TestSplitLogManager.java   |  5 ++---
 .../hbase/master/snapshot/TestSnapshotFileCache.java      |  3 +--
 .../java/org/apache/hadoop/hbase/mob/TestMobFileName.java |  5 ++++-
 .../mob/compactions/TestPartitionedMobCompactor.java      |  9 ++++-----
 .../apache/hadoop/hbase/regionserver/TestClusterId.java   |  4 +---
 .../org/apache/hadoop/hbase/regionserver/TestHRegion.java |  4 ++--
 .../hbase/regionserver/TestHRegionReplayEvents.java       |  2 +-
 .../hadoop/hbase/regionserver/wal/AbstractTestFSWAL.java  |  2 +-
 .../hadoop/hbase/replication/TestReplicationEndpoint.java |  2 +-
 .../hbase/security/access/TestAccessControlFilter.java    |  7 +++----
 .../hbase/security/access/TestScanEarlyTermination.java   | 10 +++++-----
 .../org/apache/hadoop/hbase/util/BaseTestHBaseFsck.java   |  3 +--
 .../java/org/apache/hadoop/hbase/util/TestFSUtils.java    | 10 +++++-----
 .../java/org/apache/hadoop/hbase/util/TestFSVisitor.java  |  3 +--
 .../hadoop/hbase/util/TestRegionSplitCalculator.java      |  4 +++-
 30 files changed, 71 insertions(+), 77 deletions(-)

diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/HBaseCommonTestingUtility.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/HBaseCommonTestingUtility.java
index d153637..e0669ef 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/HBaseCommonTestingUtility.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/HBaseCommonTestingUtility.java
@@ -23,6 +23,7 @@ import java.io.IOException;
 import java.util.Arrays;
 import java.util.List;
 import java.util.UUID;
+import java.util.concurrent.ThreadLocalRandom;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.commons.logging.Log;
@@ -143,7 +144,11 @@ public class HBaseCommonTestingUtility {
    * @see #getBaseTestDir()
    */
   public Path getRandomDir() {
-    return new Path(getBaseTestDir(), UUID.randomUUID().toString());
+    return new Path(getBaseTestDir(), getRandomUUID().toString());
+  }
+
+  public UUID getRandomUUID() {
+    return  new UUID(ThreadLocalRandom.current().nextLong(), ThreadLocalRandom.current().nextLong());
   }
 
   protected void createSubDir(String propertyName, Path parent, String subDirName) {
diff --git a/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSyncUpToolWithBulkLoadedData.java b/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSyncUpToolWithBulkLoadedData.java
index 0b33d20..d29aad2 100644
--- a/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSyncUpToolWithBulkLoadedData.java
+++ b/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSyncUpToolWithBulkLoadedData.java
@@ -19,7 +19,6 @@ import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
-import java.util.UUID;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -73,7 +72,7 @@ public class TestReplicationSyncUpToolWithBulkLoadedData extends TestReplication
     Iterator<String> randomHFileRangeListIterator = null;
     Set<String> randomHFileRanges = new HashSet<>(16);
     for (int i = 0; i < 16; i++) {
-      randomHFileRanges.add(UUID.randomUUID().toString());
+      randomHFileRanges.add(utility1.getRandomUUID().toString());
     }
     List<String> randomHFileRangeList = new ArrayList<>(randomHFileRanges);
     Collections.sort(randomHFileRangeList);
diff --git a/hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/RandomStringGeneratorImpl.java b/hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/RandomStringGeneratorImpl.java
index 8e3b71d..80f0cca 100644
--- a/hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/RandomStringGeneratorImpl.java
+++ b/hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/RandomStringGeneratorImpl.java
@@ -20,13 +20,14 @@ package org.apache.hadoop.hbase;
 
 
 import java.util.UUID;
+import java.util.concurrent.ThreadLocalRandom;
 
 public class RandomStringGeneratorImpl implements RandomStringGenerator {
 
   private final String s;
 
   public RandomStringGeneratorImpl() {
-    s = UUID.randomUUID().toString();
+    s = new UUID(ThreadLocalRandom.current().nextLong(), ThreadLocalRandom.current().nextLong()).toString();
   }
 
   @Override
diff --git a/hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestReplication.java b/hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestReplication.java
index 34af01b..c3e45df 100644
--- a/hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestReplication.java
+++ b/hbase-it/src/test/java/org/apache/hadoop/hbase/test/IntegrationTestReplication.java
@@ -261,7 +261,7 @@ public class IntegrationTestReplication extends IntegrationTestBigLinkedList {
      */
     protected void runGenerator() throws Exception {
       Path outputPath = new Path(outputDir);
-      UUID uuid = UUID.randomUUID(); //create a random UUID.
+      UUID uuid = util.getRandomUUID(); //create a random UUID.
       Path generatorOutput = new Path(outputPath, uuid.toString());
 
       Generator generator = new Generator();
@@ -285,7 +285,7 @@ public class IntegrationTestReplication extends IntegrationTestBigLinkedList {
      */
     protected void runVerify(long expectedNumNodes) throws Exception {
       Path outputPath = new Path(outputDir);
-      UUID uuid = UUID.randomUUID(); //create a random UUID.
+      UUID uuid = util.getRandomUUID(); //create a random UUID.
       Path iterationOutput = new Path(outputPath, uuid.toString());
 
       Verify verify = new Verify();
diff --git a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java
index a47bef1..1da0bb0 100644
--- a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java
+++ b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java
@@ -25,7 +25,6 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 import java.util.Optional;
-import java.util.UUID;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -118,7 +117,7 @@ public class TestImportTSVWithOperationAttributes implements Configurable {
 
   @Test
   public void testMROnTable() throws Exception {
-    final TableName tableName = TableName.valueOf(name.getMethodName() + UUID.randomUUID());
+    final TableName tableName = TableName.valueOf(name.getMethodName() + util.getRandomUUID());
 
     // Prepare the arguments required for the test.
     String[] args = new String[] {
@@ -134,7 +133,7 @@ public class TestImportTSVWithOperationAttributes implements Configurable {
 
   @Test
   public void testMROnTableWithInvalidOperationAttr() throws Exception {
-    final TableName tableName = TableName.valueOf(name.getMethodName() + UUID.randomUUID());
+    final TableName tableName = TableName.valueOf(name.getMethodName() + util.getRandomUUID());
 
     // Prepare the arguments required for the test.
     String[] args = new String[] {
diff --git a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithTTLs.java b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithTTLs.java
index f121f20..10a87b4 100644
--- a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithTTLs.java
+++ b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithTTLs.java
@@ -106,7 +106,7 @@ public class TestImportTSVWithTTLs implements Configurable {
 
   @Test
   public void testMROnTable() throws Exception {
-    final TableName tableName = TableName.valueOf(name.getMethodName() + UUID.randomUUID());
+    final TableName tableName = TableName.valueOf(name.getMethodName() + util.getRandomUUID());
 
     // Prepare the arguments required for the test.
     String[] args = new String[] {
diff --git a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java
index 4692847..4a6f610 100644
--- a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java
+++ b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java
@@ -27,7 +27,6 @@ import java.util.Arrays;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
-import java.util.UUID;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -157,7 +156,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
 
   @Test
   public void testMROnTable() throws Exception {
-    final TableName tableName = TableName.valueOf(name.getMethodName() + UUID.randomUUID());
+    final TableName tableName = TableName.valueOf(name.getMethodName() + util.getRandomUUID());
 
     // Prepare the arguments required for the test.
     String[] args = new String[] {
@@ -173,7 +172,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
 
   @Test
   public void testMROnTableWithDeletes() throws Exception {
-    final TableName tableName = TableName.valueOf(name.getMethodName() + UUID.randomUUID());
+    final TableName tableName = TableName.valueOf(name.getMethodName() + util.getRandomUUID());
 
     // Prepare the arguments required for the test.
     String[] args = new String[] {
@@ -225,7 +224,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
 
   @Test
   public void testMROnTableWithBulkload() throws Exception {
-    final TableName tableName = TableName.valueOf(name.getMethodName() + UUID.randomUUID());
+    final TableName tableName = TableName.valueOf(name.getMethodName() + util.getRandomUUID());
     Path hfiles = new Path(util.getDataTestDirOnTestFS(tableName.getNameAsString()), "hfiles");
     // Prepare the arguments required for the test.
     String[] args = new String[] {
@@ -241,7 +240,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
 
   @Test
   public void testBulkOutputWithTsvImporterTextMapper() throws Exception {
-    final TableName table = TableName.valueOf(name.getMethodName() + UUID.randomUUID());
+    final TableName table = TableName.valueOf(name.getMethodName() + util.getRandomUUID());
     String FAMILY = "FAM";
     Path bulkOutputPath = new Path(util.getDataTestDirOnTestFS(table.getNameAsString()),"hfiles");
     // Prepare the arguments required for the test.
@@ -262,7 +261,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
 
   @Test
   public void testMRWithOutputFormat() throws Exception {
-    final TableName tableName = TableName.valueOf(name.getMethodName() + UUID.randomUUID());
+    final TableName tableName = TableName.valueOf(name.getMethodName() + util.getRandomUUID());
     Path hfiles = new Path(util.getDataTestDirOnTestFS(tableName.getNameAsString()), "hfiles");
     // Prepare the arguments required for the test.
     String[] args = new String[] {
@@ -279,7 +278,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
 
   @Test
   public void testBulkOutputWithInvalidLabels() throws Exception {
-    final TableName tableName = TableName.valueOf(name.getMethodName() + UUID.randomUUID());
+    final TableName tableName = TableName.valueOf(name.getMethodName() + util.getRandomUUID());
     Path hfiles = new Path(util.getDataTestDirOnTestFS(tableName.getNameAsString()), "hfiles");
     // Prepare the arguments required for the test.
     String[] args =
@@ -297,7 +296,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
 
   @Test
   public void testBulkOutputWithTsvImporterTextMapperWithInvalidLabels() throws Exception {
-    final TableName tableName = TableName.valueOf(name.getMethodName() + UUID.randomUUID());
+    final TableName tableName = TableName.valueOf(name.getMethodName() + util.getRandomUUID());
     Path hfiles = new Path(util.getDataTestDirOnTestFS(tableName.getNameAsString()), "hfiles");
     // Prepare the arguments required for the test.
     String[] args =
diff --git a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java
index 6ad7694..c97afd7 100644
--- a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java
+++ b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java
@@ -29,7 +29,6 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.UUID;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -113,7 +112,7 @@ public class TestImportTsv implements Configurable {
 
   @Before
   public void setup() throws Exception {
-    tn = TableName.valueOf("test-" + UUID.randomUUID());
+    tn = TableName.valueOf("test-" + util.getRandomUUID());
     args = new HashMap<>();
     // Prepare the arguments required for the test.
     args.put(ImportTsv.COLUMNS_CONF_KEY, "HBASE_ROW_KEY,FAM:A,FAM:B");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
index dce04bd..33a785f 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
@@ -46,7 +46,6 @@ import java.util.Properties;
 import java.util.Random;
 import java.util.Set;
 import java.util.TreeSet;
-import java.util.UUID;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.stream.Collectors;
@@ -514,7 +513,7 @@ public class HBaseTestingUtility extends HBaseCommonTestingUtility {
 
     // Using randomUUID ensures that multiple clusters can be launched by
     //  a same test, if it stops & starts them
-    Path testDir = getDataTestDir("dfscluster_" + UUID.randomUUID().toString());
+    Path testDir = getDataTestDir("dfscluster_" + getRandomUUID().toString());
     clusterTestDir = new File(testDir.toString()).getAbsoluteFile();
     // Have it cleaned up on exit
     boolean b = deleteOnExit();
@@ -571,7 +570,7 @@ public class HBaseTestingUtility extends HBaseCommonTestingUtility {
     //the working directory, and create a unique sub dir there
     FileSystem fs = getTestFileSystem();
     Path newDataTestDir;
-    String randomStr = UUID.randomUUID().toString();
+    String randomStr = getRandomUUID().toString();
     if (fs.getUri().getScheme().equals(FileSystem.getLocal(conf).getUri().getScheme())) {
       newDataTestDir = new Path(getDataTestDir(), randomStr);
       File dataTestDir = new File(newDataTestDir.toString());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHBaseOnOtherDfsCluster.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHBaseOnOtherDfsCluster.java
index 55a1b5b..578e2b1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHBaseOnOtherDfsCluster.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHBaseOnOtherDfsCluster.java
@@ -29,8 +29,6 @@ import org.junit.Test;
 import org.junit.experimental.categories.Category;
 import org.junit.rules.TestName;
 
-import java.util.UUID;
-
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
@@ -63,7 +61,7 @@ public class TestHBaseOnOtherDfsCluster {
     targetFs = FileSystem.get(util2.getConfiguration());
     assertFsSameUri(fs, targetFs);
 
-    Path randomFile = new Path("/"+UUID.randomUUID());
+    Path randomFile = new Path("/"+ util1.getRandomUUID());
     assertTrue(targetFs.createNewFile(randomFile));
     assertTrue(fs.exists(randomFile));
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestNodeHealthCheckChore.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestNodeHealthCheckChore.java
index 9360b1f..50755e5 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestNodeHealthCheckChore.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestNodeHealthCheckChore.java
@@ -25,7 +25,6 @@ import java.io.File;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.PrintWriter;
-import java.util.UUID;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -140,7 +139,7 @@ public class TestNodeHealthCheckChore {
         throw new IOException("Failed mkdirs " + tempDir);
       }
     }
-    String scriptName = "HealthScript" + UUID.randomUUID().toString()
+    String scriptName = "HealthScript" + UTIL.getRandomUUID().toString()
         + (Shell.WINDOWS ? ".cmd" : ".sh");
     healthScriptFile = new File(tempDir.getAbsolutePath(), scriptName);
     conf.set(HConstants.HEALTH_SCRIPT_LOC, healthScriptFile.getAbsolutePath());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
index c8eea98..ec95e07 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
@@ -356,9 +356,9 @@ public class TestFromClientSide {
     Table ht = TEST_UTIL.createTable(tableName, FAMILIES);
     String value = "this is the value";
     String value2 = "this is some other value";
-    String keyPrefix1 = UUID.randomUUID().toString();
-    String keyPrefix2 = UUID.randomUUID().toString();
-    String keyPrefix3 = UUID.randomUUID().toString();
+    String keyPrefix1 = TEST_UTIL.getRandomUUID().toString();
+    String keyPrefix2 = TEST_UTIL.getRandomUUID().toString();
+    String keyPrefix3 = TEST_UTIL.getRandomUUID().toString();
     putRows(ht, 3, value, keyPrefix1);
     putRows(ht, 3, value, keyPrefix2);
     putRows(ht, 3, value, keyPrefix3);
@@ -448,7 +448,7 @@ public class TestFromClientSide {
   private void putRows(Table ht, int numRows, String value, String key)
       throws IOException {
     for (int i = 0; i < numRows; i++) {
-      String row = key + "_" + UUID.randomUUID().toString();
+      String row = key + "_" + TEST_UTIL.getRandomUUID().toString();
       System.out.println(String.format("Saving row: %s, with value %s", row,
           value));
       Put put = new Put(Bytes.toBytes(row));
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotWithAcl.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotWithAcl.java
index df2a6e8..b09e7ba 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotWithAcl.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotWithAcl.java
@@ -48,7 +48,7 @@ import java.util.UUID;
 @Category({ MediumTests.class, ClientTests.class })
 public class TestSnapshotWithAcl extends SecureTestUtil {
 
-  public TableName TEST_TABLE = TableName.valueOf(UUID.randomUUID().toString());
+  public TableName TEST_TABLE = TableName.valueOf(TEST_UTIL.getRandomUUID().toString());
 
   private static final int ROW_COUNT = 30000;
 
@@ -193,11 +193,11 @@ public class TestSnapshotWithAcl extends SecureTestUtil {
     loadData();
     verifyRows(TEST_TABLE);
 
-    String snapshotName1 = UUID.randomUUID().toString();
+    String snapshotName1 = TEST_UTIL.getRandomUUID().toString();
     admin.snapshot(snapshotName1, TEST_TABLE);
 
     // clone snapshot with restoreAcl true.
-    TableName tableName1 = TableName.valueOf(UUID.randomUUID().toString());
+    TableName tableName1 = TableName.valueOf(TEST_UTIL.getRandomUUID().toString());
     admin.cloneSnapshot(snapshotName1, tableName1, true);
     verifyRows(tableName1);
     verifyAllowed(new AccessReadAction(tableName1), USER_OWNER, USER_RO, USER_RW);
@@ -206,7 +206,7 @@ public class TestSnapshotWithAcl extends SecureTestUtil {
     verifyDenied(new AccessWriteAction(tableName1), USER_RO, USER_NONE);
 
     // clone snapshot with restoreAcl false.
-    TableName tableName2 = TableName.valueOf(UUID.randomUUID().toString());
+    TableName tableName2 = TableName.valueOf(TEST_UTIL.getRandomUUID().toString());
     admin.cloneSnapshot(snapshotName1, tableName2, false);
     verifyRows(tableName2);
     verifyAllowed(new AccessReadAction(tableName2), USER_OWNER);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/replication/TestReplicationAdminWithClusters.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/replication/TestReplicationAdminWithClusters.java
index 2610313..75a2630 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/replication/TestReplicationAdminWithClusters.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/replication/TestReplicationAdminWithClusters.java
@@ -272,7 +272,7 @@ public class TestReplicationAdminWithClusters extends TestReplicationBase {
 
     @Override
     public UUID getPeerUUID() {
-      return UUID.randomUUID();
+      return utility1.getRandomUUID();
     }
 
     @Override
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileEncryption.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileEncryption.java
index 2dd0073..95814e2 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileEncryption.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileEncryption.java
@@ -28,7 +28,6 @@ import java.io.DataOutputStream;
 import java.io.IOException;
 import java.security.SecureRandom;
 import java.util.List;
-import java.util.UUID;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -215,7 +214,7 @@ public class TestHFileEncryption {
           .build();
         // write a new test HFile
         LOG.info("Writing with " + fileContext);
-        Path path = new Path(TEST_UTIL.getDataTestDir(), UUID.randomUUID().toString() + ".hfile");
+        Path path = new Path(TEST_UTIL.getDataTestDir(), TEST_UTIL.getRandomUUID().toString() + ".hfile");
         FSDataOutputStream out = fs.create(path);
         HFile.Writer writer = HFile.getWriterFactory(conf, cacheConf)
           .withOutputStream(out)
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestSplitLogManager.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestSplitLogManager.java
index 3dcd849..a84552d 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestSplitLogManager.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestSplitLogManager.java
@@ -38,7 +38,6 @@ import static org.junit.Assert.assertTrue;
 import java.io.IOException;
 import java.util.List;
 import java.util.Map;
-import java.util.UUID;
 import java.util.concurrent.atomic.LongAdder;
 
 import org.apache.commons.logging.Log;
@@ -130,7 +129,7 @@ public class TestSplitLogManager {
     conf = TEST_UTIL.getConfiguration();
     // Use a different ZK wrapper instance for each tests.
     zkw =
-        new ZooKeeperWatcher(conf, "split-log-manager-tests" + UUID.randomUUID().toString(), null);
+        new ZooKeeperWatcher(conf, "split-log-manager-tests" + TEST_UTIL.getRandomUUID().toString(), null);
     master = new DummyMasterServices(zkw, conf);
 
     ZKUtil.deleteChildrenRecursively(zkw, zkw.znodePaths.baseZNode);
@@ -533,7 +532,7 @@ public class TestSplitLogManager {
     Path logDirPath = new Path(new Path(dir, HConstants.HREGION_LOGDIR_NAME), serverName);
     fs.mkdirs(logDirPath);
     // create an empty log file
-    String logFile = new Path(logDirPath, UUID.randomUUID().toString()).toString();
+    String logFile = new Path(logDirPath, TEST_UTIL.getRandomUUID().toString()).toString();
     fs.create(new Path(logDirPath, logFile)).close();
 
     // spin up a thread mocking split done.
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java
index 15e3c9a..2a34c19 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java
@@ -29,7 +29,6 @@ import java.util.Arrays;
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.List;
-import java.util.UUID;
 import java.util.concurrent.atomic.AtomicInteger;
 
 import org.apache.commons.logging.Log;
@@ -173,7 +172,7 @@ public class TestSnapshotFileCache {
 
 
     // add a random file to make sure we refresh
-    FileStatus randomFile = mockStoreFile(UUID.randomUUID().toString());
+    FileStatus randomFile = mockStoreFile(UTIL.getRandomUUID().toString());
     allStoreFiles.add(randomFile);
     deletableFiles = cache.getUnreferencedFiles(allStoreFiles, null);
     assertEquals(randomFile, Iterables.getOnlyElement(deletableFiles));
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobFileName.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobFileName.java
index 8478e20..010f415 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobFileName.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobFileName.java
@@ -24,6 +24,7 @@ import java.util.UUID;
 
 import junit.framework.TestCase;
 
+import org.apache.hadoop.hbase.HBaseTestingUtility;
 import org.apache.hadoop.hbase.testclassification.SmallTests;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.MD5Hash;
@@ -33,6 +34,8 @@ import org.junit.experimental.categories.Category;
 @Category(SmallTests.class)
 public class TestMobFileName extends TestCase {
 
+  private static final HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
+
   private String uuid;
   private Date date;
   private String dateStr;
@@ -40,7 +43,7 @@ public class TestMobFileName extends TestCase {
 
   public void setUp() {
     Random random = new Random();
-    uuid = UUID.randomUUID().toString().replaceAll("-", "");
+    uuid = TEST_UTIL.getRandomUUID().toString().replaceAll("-", "");
     date = new Date();
     dateStr = MobUtils.formatDate(date);
     startKey = Bytes.toBytes(random.nextInt());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/compactions/TestPartitionedMobCompactor.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/compactions/TestPartitionedMobCompactor.java
index bf899ea..88f79eb 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/compactions/TestPartitionedMobCompactor.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/compactions/TestPartitionedMobCompactor.java
@@ -32,7 +32,6 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Random;
-import java.util.UUID;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.RejectedExecutionException;
 import java.util.concurrent.RejectedExecutionHandler;
@@ -131,8 +130,8 @@ public class TestPartitionedMobCompactor {
     Path testDir = FSUtils.getRootDir(conf);
     Path mobTestDir = new Path(testDir, MobConstants.MOB_DIR_NAME);
     basePath = new Path(new Path(mobTestDir, tableName), family);
-    mobSuffix = UUID.randomUUID().toString().replaceAll("-", "");
-    delSuffix = UUID.randomUUID().toString().replaceAll("-", "") + "_del";
+    mobSuffix = TEST_UTIL.getRandomUUID().toString().replaceAll("-", "");
+    delSuffix = TEST_UTIL.getRandomUUID().toString().replaceAll("-", "") + "_del";
     allFiles.clear();
     mobFiles.clear();
     delFiles.clear();
@@ -827,8 +826,8 @@ public class TestPartitionedMobCompactor {
       if (sameStartKey) {
         // When creating multiple files under one partition, suffix needs to be different.
         startRow = Bytes.toBytes(startKey);
-        mobSuffix = UUID.randomUUID().toString().replaceAll("-", "");
-        delSuffix = UUID.randomUUID().toString().replaceAll("-", "") + "_del";
+        mobSuffix = TEST_UTIL.getRandomUUID().toString().replaceAll("-", "");
+        delSuffix = TEST_UTIL.getRandomUUID().toString().replaceAll("-", "") + "_del";
       } else {
         startRow = Bytes.toBytes(startKey + i);
       }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestClusterId.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestClusterId.java
index 46fd702..a5806c7 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestClusterId.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestClusterId.java
@@ -21,8 +21,6 @@ package org.apache.hadoop.hbase.regionserver;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 
-import java.util.UUID;
-
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FSDataOutputStream;
 import org.apache.hadoop.fs.FileSystem;
@@ -100,7 +98,7 @@ public class TestClusterId {
     FSDataOutputStream s = null;
     try {
       s = fs.create(filePath);
-      s.writeUTF(UUID.randomUUID().toString());
+      s.writeUTF(TEST_UTIL.getRandomUUID().toString());
     } finally {
       if (s != null) {
         s.close();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java
index 2e3edf1..03681bd 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java
@@ -1487,7 +1487,7 @@ public class TestHRegion {
 
   private void putRows(HRegion r, int numRows, String value, String key) throws IOException {
     for (int i = 0; i < numRows; i++) {
-      String row = key + "_" + i/* UUID.randomUUID().toString() */;
+      String row = key + "_" + i;
       System.out.println(String.format("Saving row: %s, with value %s", row, value));
       Put put = new Put(Bytes.toBytes(row));
       put.setDurability(Durability.SKIP_WAL);
@@ -4629,7 +4629,7 @@ public class TestHRegion {
     // XXX: The spied AsyncFSWAL can not work properly because of a Mockito defect that can not
     // deal with classes which have a field of an inner class. See discussions in HBASE-15536.
     walConf.set(WALFactory.WAL_PROVIDER, "filesystem");
-    final WALFactory wals = new WALFactory(walConf, null, UUID.randomUUID().toString());
+    final WALFactory wals = new WALFactory(walConf, null, TEST_UTIL.getRandomUUID().toString());
     final WAL wal = spy(wals.getWAL(tableName.getName(), tableName.getNamespace()));
     this.region = initHRegion(tableName, HConstants.EMPTY_START_ROW,
         HConstants.EMPTY_END_ROW, false, tableDurability, wal,
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java
index bab5b26..22d1197 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegionReplayEvents.java
@@ -1641,7 +1641,7 @@ public class TestHRegionReplayEvents {
       byte[] valueBytes) throws IOException {
     HFile.WriterFactory hFileFactory = HFile.getWriterFactoryNoCache(TEST_UTIL.getConfiguration());
     // TODO We need a way to do this without creating files
-    Path testFile = new Path(testPath, UUID.randomUUID().toString());
+    Path testFile = new Path(testPath, TEST_UTIL.getRandomUUID().toString());
     FSDataOutputStream out = TEST_UTIL.getTestFileSystem().create(testFile);
     try {
       hFileFactory.withOutputStream(out);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/AbstractTestFSWAL.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/AbstractTestFSWAL.java
index b736fae..3d5d372 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/AbstractTestFSWAL.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/AbstractTestFSWAL.java
@@ -410,7 +410,7 @@ public abstract class AbstractTestFSWAL {
       }
       // Add any old cluster id.
       List<UUID> clusterIds = new ArrayList<>(1);
-      clusterIds.add(UUID.randomUUID());
+      clusterIds.add(TEST_UTIL.getRandomUUID());
       // Now make appends run slow.
       goslow.set(true);
       for (int i = 0; i < countPerFamily; i++) {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationEndpoint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationEndpoint.java
index 6396228..76106c2 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationEndpoint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationEndpoint.java
@@ -376,7 +376,7 @@ public class TestReplicationEndpoint extends TestReplicationBase {
   }
 
   public static class ReplicationEndpointForTest extends BaseReplicationEndpoint {
-    static UUID uuid = UUID.randomUUID();
+    static UUID uuid = utility1.getRandomUUID();
     static AtomicInteger contructedCount = new AtomicInteger();
     static AtomicInteger startedCount = new AtomicInteger();
     static AtomicInteger stoppedCount = new AtomicInteger();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessControlFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessControlFilter.java
index 06389ab..76a9423 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessControlFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessControlFilter.java
@@ -25,7 +25,6 @@ import static org.junit.Assert.assertTrue;
 import java.security.PrivilegedExceptionAction;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.UUID;
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
@@ -126,7 +125,7 @@ public class TestAccessControlFilter extends SecureTestUtil {
       public Object run() throws Exception {
         Configuration conf = new Configuration(TEST_UTIL.getConfiguration());
         // force a new RS connection
-        conf.set("testkey", UUID.randomUUID().toString());
+        conf.set("testkey", TEST_UTIL.getRandomUUID().toString());
         Connection connection = ConnectionFactory.createConnection(conf);
         Table t = connection.getTable(TABLE);
         try {
@@ -154,7 +153,7 @@ public class TestAccessControlFilter extends SecureTestUtil {
       public Object run() throws Exception {
         Configuration conf = new Configuration(TEST_UTIL.getConfiguration());
         // force a new RS connection
-        conf.set("testkey", UUID.randomUUID().toString());
+        conf.set("testkey", TEST_UTIL.getRandomUUID().toString());
         Connection connection = ConnectionFactory.createConnection(conf);
         Table t = connection.getTable(TABLE);
         try {
@@ -181,7 +180,7 @@ public class TestAccessControlFilter extends SecureTestUtil {
       public Object run() throws Exception {
         Configuration conf = new Configuration(TEST_UTIL.getConfiguration());
         // force a new RS connection
-        conf.set("testkey", UUID.randomUUID().toString());
+        conf.set("testkey", TEST_UTIL.getRandomUUID().toString());
         Connection connection = ConnectionFactory.createConnection(conf);
         Table t = connection.getTable(TABLE);
         try {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestScanEarlyTermination.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestScanEarlyTermination.java
index f60209f..efd1a47 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestScanEarlyTermination.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestScanEarlyTermination.java
@@ -157,7 +157,7 @@ public class TestScanEarlyTermination extends SecureTestUtil {
       @Override
       public Object run() throws Exception {
         // force a new RS connection
-        conf.set("testkey", UUID.randomUUID().toString());
+        conf.set("testkey", TEST_UTIL.getRandomUUID().toString());
         Connection connection = ConnectionFactory.createConnection(conf);
         Table t = connection.getTable(TEST_TABLE.getTableName());
         try {
@@ -184,7 +184,7 @@ public class TestScanEarlyTermination extends SecureTestUtil {
       @Override
       public Object run() throws Exception {
         // force a new RS connection
-        conf.set("testkey", UUID.randomUUID().toString());
+        conf.set("testkey", TEST_UTIL.getRandomUUID().toString());
         Connection connection = ConnectionFactory.createConnection(conf);
         Table t = connection.getTable(TEST_TABLE.getTableName());
         try {
@@ -210,7 +210,7 @@ public class TestScanEarlyTermination extends SecureTestUtil {
       @Override
       public Object run() throws Exception {
         // force a new RS connection
-        conf.set("testkey", UUID.randomUUID().toString());
+        conf.set("testkey", TEST_UTIL.getRandomUUID().toString());
         Connection connection = ConnectionFactory.createConnection(conf);
         Table t = connection.getTable(TEST_TABLE.getTableName());
         try {
@@ -234,7 +234,7 @@ public class TestScanEarlyTermination extends SecureTestUtil {
       @Override
       public Object run() throws Exception {
         // force a new RS connection
-        conf.set("testkey", UUID.randomUUID().toString());
+        conf.set("testkey", TEST_UTIL.getRandomUUID().toString());
         Connection connection = ConnectionFactory.createConnection(conf);
         Table t = connection.getTable(TEST_TABLE.getTableName());
         try {
@@ -262,7 +262,7 @@ public class TestScanEarlyTermination extends SecureTestUtil {
       @Override
       public Object run() throws Exception {
         // force a new RS connection
-        conf.set("testkey", UUID.randomUUID().toString());
+        conf.set("testkey", TEST_UTIL.getRandomUUID().toString());
         Connection connection = ConnectionFactory.createConnection(conf);
         Table t = connection.getTable(TEST_TABLE.getTableName());
         try {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/util/BaseTestHBaseFsck.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/util/BaseTestHBaseFsck.java
index d9bef11..0d94c71 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/util/BaseTestHBaseFsck.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/util/BaseTestHBaseFsck.java
@@ -29,7 +29,6 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Optional;
-import java.util.UUID;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.ScheduledThreadPoolExecutor;
@@ -435,7 +434,7 @@ public class BaseTestHBaseFsck {
     MobFileName mobFileName = MobFileName.create(oldFileName);
     String startKey = mobFileName.getStartKey();
     String date = mobFileName.getDate();
-    return MobFileName.create(startKey, date, UUID.randomUUID().toString().replaceAll("-", ""))
+    return MobFileName.create(startKey, date, TEST_UTIL.getRandomUUID().toString().replaceAll("-", ""))
       .getFileName();
   }
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSUtils.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSUtils.java
index 055c28d..60818cb 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSUtils.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSUtils.java
@@ -243,7 +243,7 @@ public class TestFSUtils {
     assertEquals(new FsPermission("700"), filePerm);
 
     // then that the correct file is created
-    Path p = new Path("target" + File.separator + UUID.randomUUID().toString());
+    Path p = new Path("target" + File.separator + htu.getRandomUUID().toString());
     try {
       FSDataOutputStream out = FSUtils.create(conf, fs, p, filePerm, null);
       out.close();
@@ -262,7 +262,7 @@ public class TestFSUtils {
     conf.setBoolean(HConstants.ENABLE_DATA_FILE_UMASK, true);
     FsPermission perms = FSUtils.getFilePermissions(fs, conf, HConstants.DATA_FILE_UMASK_KEY);
     // then that the correct file is created
-    String file = UUID.randomUUID().toString();
+    String file = htu.getRandomUUID().toString();
     Path p = new Path(htu.getDataTestDir(), "temptarget" + File.separator + file);
     Path p1 = new Path(htu.getDataTestDir(), "temppath" + File.separator + file);
     try {
@@ -293,7 +293,7 @@ public class TestFSUtils {
     FileSystem fs = FileSystem.get(conf);
     Path testDir = htu.getDataTestDirOnTestFS("testArchiveFile");
 
-    String file = UUID.randomUUID().toString();
+    String file = htu.getRandomUUID().toString();
     Path p = new Path(testDir, file);
 
     FSDataOutputStream out = fs.create(p);
@@ -307,7 +307,7 @@ public class TestFSUtils {
     mockEnv.setValue(expect);
     EnvironmentEdgeManager.injectEdge(mockEnv);
     try {
-      String dstFile = UUID.randomUUID().toString();
+      String dstFile = htu.getRandomUUID().toString();
       Path dst = new Path(testDir , dstFile);
 
       assertTrue(FSUtils.renameAndSetModifyTime(fs, p, dst));
@@ -353,7 +353,7 @@ public class TestFSUtils {
       FSUtils.setStoragePolicy(fs, conf, testDir, HConstants.WAL_STORAGE_POLICY,
           HConstants.DEFAULT_WAL_STORAGE_POLICY);
 
-      String file = UUID.randomUUID().toString();
+      String file = htu.getRandomUUID().toString();
       Path p = new Path(testDir, file);
       WriteDataToHDFS(fs, p, 4096);
       // will assert existance before deleting.
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSVisitor.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSVisitor.java
index e455b0a..22adf79 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSVisitor.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestFSVisitor.java
@@ -21,7 +21,6 @@ package org.apache.hadoop.hbase.util;
 import static org.junit.Assert.assertEquals;
 
 import java.io.IOException;
-import java.util.UUID;
 import java.util.Set;
 import java.util.HashSet;
 
@@ -112,7 +111,7 @@ public class TestFSVisitor {
         Path familyDir = new Path(regionDir, familyName);
         fs.mkdirs(familyDir);
         for (int h = 0; h < 5; ++h) {
-         String hfileName = UUID.randomUUID().toString().replaceAll("-", "");
+         String hfileName = TEST_UTIL.getRandomUUID().toString().replaceAll("-", "");
          tableHFiles.add(hfileName);
          fs.createNewFile(new Path(familyDir, hfileName));
         }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestRegionSplitCalculator.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestRegionSplitCalculator.java
index 02578ff..420e0b0 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestRegionSplitCalculator.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/util/TestRegionSplitCalculator.java
@@ -30,6 +30,7 @@ import java.util.UUID;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
 import org.apache.hadoop.hbase.testclassification.MiscTests;
 import org.apache.hadoop.hbase.testclassification.SmallTests;
 import org.junit.Test;
@@ -42,6 +43,7 @@ import org.junit.experimental.categories.Category;
 @Category({MiscTests.class, SmallTests.class})
 public class TestRegionSplitCalculator {
   private static final Log LOG = LogFactory.getLog(TestRegionSplitCalculator.class);
+  private static final HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
 
   /**
    * This is range uses a user specified start and end keys. It also has an
@@ -55,7 +57,7 @@ public class TestRegionSplitCalculator {
     SimpleRange(byte[] start, byte[] end) {
       this.start = start;
       this.end = end;
-      this.tiebreaker = UUID.randomUUID();
+      this.tiebreaker = TEST_UTIL.getRandomUUID();
     }
 
     @Override
-- 
2.7.4
