Index: src/test/org/apache/hadoop/hbase/TestHColumnDescriptor.java
===================================================================
--- src/test/org/apache/hadoop/hbase/TestHColumnDescriptor.java	(revision 0)
+++ src/test/org/apache/hadoop/hbase/TestHColumnDescriptor.java	(revision 0)
@@ -0,0 +1,151 @@
+package org.apache.hadoop.hbase;
+
+import static org.junit.Assert.*;
+
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.Map;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.io.hfile.Compression;
+import org.apache.hadoop.hbase.io.hfile.Compression.Algorithm;
+import org.codehaus.jackson.JsonParseException;
+import org.codehaus.jackson.map.JsonMappingException;
+import org.codehaus.jackson.map.ObjectMapper;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+public class TestHColumnDescriptor {
+  private final Log LOG = LogFactory.getLog(this.getClass().getName());
+  private HColumnDescriptor hcd;
+
+  @Before
+  public void setUp() throws Exception {
+    this.hcd = new HColumnDescriptor("a");
+  }
+
+  @Test public void testSerialization()
+  throws JsonParseException, JsonMappingException, IOException {
+    String serialized = this.hcd.toString();
+    LOG.info("before=" + serialized);
+    ObjectMapper mapper = new ObjectMapper();
+    Reader reader = new StringReader(serialized);
+    HColumnDescriptor deserhcd =
+      mapper.readValue(reader, HColumnDescriptor.class);
+    LOG.info("after=" + deserhcd.toString());
+    assertEquals(this.hcd.hashCode(), deserhcd.hashCode());
+    // Do a more complicated one
+    this.hcd.setBlocksize(123);
+    this.hcd.setCompressionType(Algorithm.LZO);
+    this.hcd.setInMemory(true);
+    this.hcd.put("arbitrary", "some value");
+    serialized = this.hcd.toString();
+    LOG.info("before2=" + serialized);
+    reader = new StringReader(serialized);
+    deserhcd = mapper.readValue(reader, HColumnDescriptor.class);
+    LOG.info("after2=" + deserhcd.toString());
+    assertEquals(this.hcd.hashCode(), deserhcd.hashCode());
+  }
+
+  @Test
+  public void testHashCode() {
+    HColumnDescriptor hcd2 = new HColumnDescriptor("a");
+    assertEquals(this.hcd.hashCode(), hcd2.hashCode());
+    hcd2.setTimeToLive(23);
+    assertNotSame(this.hcd.hashCode(), hcd2.hashCode());
+    HColumnDescriptor hcd3 = new HColumnDescriptor("b");
+    assertNotSame(this.hcd.hashCode(), hcd3.hashCode());
+    HColumnDescriptor hcd4 = new HColumnDescriptor(this.hcd);
+    assertEquals(this.hcd.hashCode(), hcd4.hashCode());
+  }
+
+  @Test
+  public void testIsLegalFamilyName() {
+    HColumnDescriptor.isLegalFamilyName("a");
+  }
+
+  @Test (expected=IllegalArgumentException.class)
+  public void testIllegalFamilyName1() {
+    HColumnDescriptor.isLegalFamilyName("a:");
+  }
+
+  @Test (expected=IllegalArgumentException.class)
+  public void testIllegalFamilyName2() {
+    HColumnDescriptor.isLegalFamilyName(".META.");
+  }
+
+  @Test
+  public void testGetCompression() {
+    assertEquals(Compression.Algorithm.NONE, this.hcd.getCompression());
+    this.hcd.setCompressionType(Compression.Algorithm.LZO);
+    assertEquals(Compression.Algorithm.LZO, this.hcd.getCompression());
+  }
+
+  @Test
+  public void testGetMaxVersions() {
+    assertEquals(HColumnDescriptor.DEFAULT_VERSIONS, this.hcd.getMaxVersions());
+    int max = 5;
+    this.hcd.setMaxVersions(max);
+    assertEquals(max, this.hcd.getMaxVersions());
+  }
+
+  @Test
+  public void testGetBlocksize() {
+    assertEquals(HColumnDescriptor.DEFAULT_BLOCKSIZE, this.hcd.getBlocksize());
+    int max = 12;
+    this.hcd.setBlocksize(max);
+    assertEquals(max, this.hcd.getBlocksize());
+  }
+
+  @Test
+  public void testIsInMemory() {
+    assertEquals(HColumnDescriptor.DEFAULT_IN_MEMORY, this.hcd.isInMemory());
+    boolean b = true;
+    this.hcd.setInMemory(b);
+    assertEquals(b, this.hcd.isInMemory());
+  }
+
+  @Test
+  public void testGetTimeToLive() {
+    assertEquals(HColumnDescriptor.DEFAULT_TTL, this.hcd.getTimeToLive());
+    int max = 12;
+    this.hcd.setTimeToLive(max);
+    assertEquals(max, this.hcd.getTimeToLive());
+  }
+
+  @Test
+  public void testIsBlockCacheEnabled() {
+    assertEquals(HColumnDescriptor.DEFAULT_BLOCKCACHE,
+      this.hcd.isBlockCacheEnabled());
+    boolean b = true;
+    this.hcd.isBlockCacheEnabled();
+    assertEquals(b, this.hcd.isBlockCacheEnabled());
+  }
+
+  @Test
+  public void testToString() {
+    this.hcd.setBlockCacheEnabled(true);
+    this.hcd.setBlocksize(123);
+    this.hcd.setCompressionType(Algorithm.GZ);
+    this.hcd.setInMemory(true);
+    this.hcd.setMaxVersions(47);
+    this.hcd.setTimeToLive(21);
+    System.out.println(this.hcd.toString());
+  }
+
+  @Test
+  public void testEqualsObject() {
+    HColumnDescriptor hcd2 = new HColumnDescriptor("a");
+    assertEquals(this.hcd, hcd2);
+  }
+
+  @Test
+  public void testNotEqualsObject() {
+    HColumnDescriptor hcd2 = new HColumnDescriptor("b");
+    assertNotSame(this.hcd, hcd2);
+  }
+}
Index: src/java/org/apache/hadoop/hbase/HColumnDescriptor.java
===================================================================
--- src/java/org/apache/hadoop/hbase/HColumnDescriptor.java	(revision 831514)
+++ src/java/org/apache/hadoop/hbase/HColumnDescriptor.java	(working copy)
@@ -19,64 +19,43 @@
  */
 package org.apache.hadoop.hbase;
 
-import java.io.DataInput;
-import java.io.DataOutput;
 import java.io.IOException;
-import java.util.Collections;
-import java.util.HashMap;
+import java.io.StringWriter;
+import java.util.Collection;
 import java.util.Map;
+import java.util.Set;
+import java.util.TreeMap;
 
-import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
 import org.apache.hadoop.hbase.io.hfile.Compression;
 import org.apache.hadoop.hbase.io.hfile.HFile;
 import org.apache.hadoop.hbase.util.Bytes;
-import org.apache.hadoop.io.Text;
-import org.apache.hadoop.io.WritableComparable;
+import org.codehaus.jackson.JsonGenerationException;
+import org.codehaus.jackson.map.JsonMappingException;
+import org.codehaus.jackson.map.ObjectMapper;
 
+
 /**
  * An HColumnDescriptor contains information about a column family such as the
  * number of versions, compression settings, etc.
  * 
- * It is used as input when creating a table or adding a column. Once set, the
- * parameters that specify a column cannot be changed without deleting the
- * column and recreating it. If there is data stored in the column, it will be
- * deleted when the column is deleted.
+ * Not thread-safe.
  */
-public class HColumnDescriptor implements WritableComparable<HColumnDescriptor> {
-  // For future backward compatibility
-
+public class HColumnDescriptor implements Map<String, Object> {
   // Version 3 was when column names become byte arrays and when we picked up
   // Time-to-live feature.  Version 4 was when we moved to byte arrays, HBASE-82.
   // Version 5 was when bloom filter descriptors were removed.
   // Version 6 adds metadata as a map where keys and values are byte[].
   // Version 7 -- add new compression and hfile blocksize to HColumnDescriptor (HBASE-1217)
-  private static final byte COLUMN_DESCRIPTOR_VERSION = (byte)7;
+  // Version 8 moves off Writable to Map
+  private static final byte COLUMN_DESCRIPTOR_VERSION = (byte)8;
 
-  /** 
-   * The type of compression.
-   * @see org.apache.hadoop.io.SequenceFile.Writer
-   * @deprecated Compression now means which compression library
-   * rather than 'what' to compress.
-   */
-  @Deprecated
-  public static enum CompressionType {
-    /** Do not compress records. */
-    NONE, 
-    /** Compress values only, each separately. */
-    RECORD,
-    /** Compress sequences of records together in blocks. */
-    BLOCK
-  }
-
   public static final String COMPRESSION = "COMPRESSION";
   public static final String BLOCKCACHE = "BLOCKCACHE";
   public static final String BLOCKSIZE = "BLOCKSIZE";
   public static final String LENGTH = "LENGTH";
   public static final String TTL = "TTL";
-  public static final String BLOOMFILTER = "BLOOMFILTER";
   public static final String FOREVER = "FOREVER";
-  public static final String MAPFILE_INDEX_INTERVAL =
-      "MAPFILE_INDEX_INTERVAL";
+  public static final String NAME = "NAME";
 
   /**
    * Default compression type.
@@ -89,12 +68,6 @@
    */
   public static final int DEFAULT_VERSIONS = 3;
 
-  /*
-   * Cache here the HCD value.
-   * Question: its OK to cache since when we're reenable, we create a new HCD?
-   */
-  private volatile Integer blocksize = null;
-
   /**
    * Default setting for whether to serve from memory or not.
    */
@@ -112,32 +85,33 @@
   public static final int DEFAULT_BLOCKSIZE = HFile.DEFAULT_BLOCKSIZE;
 
   /**
-   * Default setting for whether or not to use bloomfilters.
-   */
-  public static final boolean DEFAULT_BLOOMFILTER = false;
-  
-  /**
    * Default time to live of cell contents.
    */
   public static final int DEFAULT_TTL = HConstants.FOREVER;
 
-  // Column family name
-  private byte [] name;
+  // Keep differences only rather than all attributes.
+  // Make it sorted so items come out same every time.
+  private final Map<String, Object> properties =  new TreeMap<String, Object>();
 
-  // Column metadata
-  protected Map<ImmutableBytesWritable,ImmutableBytesWritable> values =
-    new HashMap<ImmutableBytesWritable,ImmutableBytesWritable>();
+  /*
+   * Cache here the HCD value.
+   * Question: its OK to cache since when we're reenable, we create a new HCD?
+   */
+  private volatile int blocksize = -1;
 
   /*
    * Cache the max versions rather than calculate it every time.
    */
-  private int cachedMaxVersions = -1;
+  private volatile int cachedMaxVersions = -1;
 
+  private final ObjectMapper mapper = new ObjectMapper();
+
   /**
    * Default constructor. Must be present for Writable.
+   * @deprecated Used when this class implemented Writable
    */
   public HColumnDescriptor() {
-    this.name = null;
+    super();
   }
 
   /**
@@ -146,11 +120,12 @@
    * 
    * @param familyName Column family name. Must be 'printable' -- digit or
    * letter -- and may not contain a <code>:<code>
+   * @deprecated Use {@link #HColumnDescriptor(String)}
    */
-  public HColumnDescriptor(final String familyName) {
-    this(Bytes.toBytes(familyName));
+  public HColumnDescriptor(final byte [] familyName) {
+    this(Bytes.toString(familyName));
   }
-  
+
   /**
    * Construct a column descriptor specifying only the family name 
    * The other attributes are defaulted.
@@ -158,26 +133,17 @@
    * @param familyName Column family name. Must be 'printable' -- digit or
    * letter -- and may not contain a <code>:<code>
    */
-  public HColumnDescriptor(final byte [] familyName) {
-    this (familyName == null || familyName.length <= 0?
-      HConstants.EMPTY_BYTE_ARRAY: familyName, DEFAULT_VERSIONS,
-      DEFAULT_COMPRESSION, DEFAULT_IN_MEMORY, DEFAULT_BLOCKCACHE,
-      DEFAULT_TTL, false);
+  public HColumnDescriptor(final String familyName) {
+    this.properties.put(NAME, familyName);
   }
 
   /**
    * Constructor.
-   * Makes a deep copy of the supplied descriptor. 
-   * Can make a modifiable descriptor from an UnmodifyableHColumnDescriptor.
-   * @param desc The descriptor.
+   * Makes a deep copy of the supplied descriptor.
+   * @param hcd What to copy.
    */
-  public HColumnDescriptor(HColumnDescriptor desc) {
-    super();
-    this.name = desc.name.clone();
-    for (Map.Entry<ImmutableBytesWritable, ImmutableBytesWritable> e:
-        desc.values.entrySet()) {
-      this.values.put(e.getKey(), e.getValue());
-    }
+  public HColumnDescriptor(final HColumnDescriptor hcd) {
+    this.properties.putAll(hcd);
   }
 
   /**
@@ -197,15 +163,39 @@
    * other than 'word' characters: i.e. <code>[a-zA-Z_0-9]</code> or contains
    * a <code>:</code>
    * @throws IllegalArgumentException if the number of versions is &lt;= 0
+   * @deprecated Use {@link #HColumnDescriptor(byte[], int, String, boolean, boolean, int)}
    */
   public HColumnDescriptor(final byte [] familyName, final int maxVersions,
       final String compression, final boolean inMemory,
       final boolean blockCacheEnabled,
+      final int timeToLive) {
+  }
+
+  /**
+   * Constructor
+   * @param familyName Column family name. Must be 'printable' -- digit or
+   * letter -- and may not contain a <code>:<code>
+   * @param maxVersions Maximum number of versions to keep
+   * @param compression Compression type
+   * @param inMemory If true, column data should be kept in an HRegionServer's
+   * cache
+   * @param blockCacheEnabled If true, MapFile blocks should be cached
+   * @param timeToLive Time-to-live of cell contents, in seconds
+   * (use HConstants.FOREVER for unlimited TTL)
+   * 
+   * @throws IllegalArgumentException if passed a family name that is made of 
+   * other than 'word' characters: i.e. <code>[a-zA-Z_0-9]</code> or contains
+   * a <code>:</code>
+   * @throws IllegalArgumentException if the number of versions is &lt;= 0
+   */
+  public HColumnDescriptor(final String familyName, final int maxVersions,
+      final String compression, final boolean inMemory,
+      final boolean blockCacheEnabled,
       final int timeToLive, final boolean bloomFilter) {
     this(familyName, maxVersions, compression, inMemory, blockCacheEnabled,
-      DEFAULT_BLOCKSIZE, timeToLive, bloomFilter);
+      DEFAULT_BLOCKSIZE, timeToLive);
   }
-  
+
   /**
    * Constructor
    * @param familyName Column family name. Must be 'printable' -- digit or
@@ -224,14 +214,40 @@
    * other than 'word' characters: i.e. <code>[a-zA-Z_0-9]</code> or contains
    * a <code>:</code>
    * @throws IllegalArgumentException if the number of versions is &lt;= 0
+   * @deprecated Use {@link #HColumnDescriptor(String, int, String, boolean, boolean, int, int)}
    */
   public HColumnDescriptor(final byte [] familyName, final int maxVersions,
       final String compression, final boolean inMemory,
       final boolean blockCacheEnabled, final int blocksize,
       final int timeToLive, final boolean bloomFilter) {
-    isLegalFamilyName(familyName);
-    this.name = familyName;
+    this(Bytes.toString(familyName), maxVersions, compression, inMemory,
+      blockCacheEnabled, blocksize, timeToLive);
+  }
 
+  /**
+   * Constructor
+   * @param familyName Column family name. Must be 'printable' -- digit or
+   * letter -- and may not contain a <code>:<code>
+   * @param maxVersions Maximum number of versions to keep
+   * @param compression Compression type
+   * @param inMemory If true, column data should be kept in an HRegionServer's
+   * cache
+   * @param blockCacheEnabled If true, MapFile blocks should be cached
+   * @param blocksize
+   * @param timeToLive Time-to-live of cell contents, in seconds
+   * (use HConstants.FOREVER for unlimited TTL)
+   * 
+   * @throws IllegalArgumentException if passed a family name that is made of 
+   * other than 'word' characters: i.e. <code>[a-zA-Z_0-9]</code> or contains
+   * a <code>:</code>
+   * @throws IllegalArgumentException if the number of versions is &lt;= 0
+   */
+  public HColumnDescriptor(final String familyName, final int maxVersions,
+      final String compression, final boolean inMemory,
+      final boolean blockCacheEnabled, final int blocksize,
+      final int timeToLive) {
+    isLegalFamilyName(familyName);
+    this.properties.put(NAME, familyName);
     if (maxVersions <= 0) {
       // TODO: Allow maxVersion of 0 to be the way you say "Keep all versions".
       // Until there is support, consider 0 or < 0 -- a configuration error.
@@ -243,7 +259,6 @@
     setTimeToLive(timeToLive);
     setCompressionType(Compression.Algorithm.
       valueOf(compression.toUpperCase()));
-    setBloomfilter(bloomFilter);
     setBlocksize(blocksize);
   }
 
@@ -254,104 +269,67 @@
    * name: i.e. 'printable' and ends in a ':' (Null passes are allowed because
    * <code>b</code> can be null when deserializing).  Cannot start with a '.'
    * either.
+   * @deprecated Use {@link #isLegalFamilyName(String)}
    */
   public static byte [] isLegalFamilyName(final byte [] b) {
+    String s = isLegalFamilyName(Bytes.toString(b));
+    return s == null? null: Bytes.toBytes(s);
+  }
+
+  /**
+   * @param b Family name.
+   * @return <code>b</code>
+   * @throws IllegalArgumentException If not null and not a legitimate family
+   * name: i.e. 'printable' and ends in a ':' (Null passes are allowed because
+   * <code>b</code> can be null when deserializing).  Cannot start with a '.'
+   * either.
+   */
+  public static String isLegalFamilyName(final String b) {
     if (b == null) {
       return b;
     }
-    if (b[0] == '.') {
+    if (b.charAt(0) == '.') {
       throw new IllegalArgumentException("Family names cannot start with a " +
-        "period: " + Bytes.toString(b));
+        "period: " + b);
     }
-    for (int i = 0; i < b.length; i++) {
-      if (Character.isISOControl(b[i]) || b[i] == ':') {
-        throw new IllegalArgumentException("Illegal character <" + b[i] +
-          ">. Family names cannot contain control characters or colons: " +
-          Bytes.toString(b));
+    for (int i = 0; i < b.length(); i++) {
+      char c = b.charAt(i);
+      if (Character.isISOControl(c) || c == ':') {
+        throw new IllegalArgumentException("Illegal character <" + c +
+          ">. Family names cannot contain control characters or colons: " + b);
       }
     }
     return b;
   }
 
   /**
-   * @return Name of this column family
+   * @return Name of this column family as a byte array.
+   * @deprecated Use {@link #getNameAsString()}; Later we'll rename getNameAsString
+   * as getName.
    */
   public byte [] getName() {
-    return name;
+    String name = (String)this.properties.get(NAME);
+    return name == null? null: Bytes.toBytes(name);
   }
-  
+
   /**
    * @return Name of this column family
    */
   public String getNameAsString() {
-    return Bytes.toString(this.name);
+    return (String)this.properties.get(NAME);
   }
 
-  /**
-   * @param key The key.
-   * @return The value.
-   */
-  public byte[] getValue(byte[] key) {
-    ImmutableBytesWritable ibw = values.get(new ImmutableBytesWritable(key));
-    if (ibw == null)
-      return null;
-    return ibw.get();
-  }
-
-  /**
-   * @param key The key.
-   * @return The value as a string.
-   */
-  public String getValue(String key) {
-    byte[] value = getValue(Bytes.toBytes(key));
-    if (value == null)
-      return null;
-    return Bytes.toString(value);
-  }
-
-  /**
-   * @return All values.
-   */
-  public Map<ImmutableBytesWritable,ImmutableBytesWritable> getValues() {
-    return Collections.unmodifiableMap(values);
-  }
-
-  /**
-   * @param key The key.
-   * @param value The value.
-   */
-  public void setValue(byte[] key, byte[] value) {
-    values.put(new ImmutableBytesWritable(key),
-      new ImmutableBytesWritable(value));
-  }
-
-  /**
-   * @param key Key whose key and value we're to remove from HCD parameters.
-   */
-  public void remove(final byte [] key) {
-    values.remove(new ImmutableBytesWritable(key));
-  }
-
-  /**
-   * @param key The key.
-   * @param value The value.
-   */
-  public void setValue(String key, String value) {
-    setValue(Bytes.toBytes(key), Bytes.toBytes(value));
-  }
-
   /** @return compression type being used for the column family */
   public Compression.Algorithm getCompression() {
-    String n = getValue(COMPRESSION);
-    return Compression.Algorithm.valueOf(n.toUpperCase());
+    Object v = this.properties.get(COMPRESSION);
+    return v == null? Compression.Algorithm.NONE:
+      Compression.Algorithm.valueOf(((String)v).toUpperCase());
   }
   
   /** @return maximum number of versions */
-  public synchronized int getMaxVersions() {
+  public int getMaxVersions() {
     if (this.cachedMaxVersions == -1) {
-      String value = getValue(HConstants.VERSIONS);
-      this.cachedMaxVersions = (value != null)?
-        Integer.valueOf(value).intValue(): DEFAULT_VERSIONS;
+      this.cachedMaxVersions = getInt(HConstants.VERSIONS, DEFAULT_VERSIONS);
     }
     return this.cachedMaxVersions;
   }
@@ -360,27 +338,26 @@
    * @param maxVersions maximum number of versions
    */
   public void setMaxVersions(int maxVersions) {
-    setValue(HConstants.VERSIONS, Integer.toString(maxVersions));
+    this.properties.put(HConstants.VERSIONS, maxVersions);
+    this.cachedMaxVersions = -1;
   }
 
   /**
    * @return Blocksize.
    */
-  public synchronized int getBlocksize() {
-    if (this.blocksize == null) {
-      String value = getValue(BLOCKSIZE);
-      this.blocksize = (value != null)?
-        Integer.decode(value): Integer.valueOf(DEFAULT_BLOCKSIZE);
+  public int getBlocksize() {
+    if (this.blocksize == -1) {
+      this.blocksize = getInt(BLOCKSIZE, DEFAULT_BLOCKSIZE);
     }
-    return this.blocksize.intValue();
+    return this.blocksize;
   }
 
   /**
    * @param s
    */
   public void setBlocksize(int s) {
-    setValue(BLOCKSIZE, Integer.toString(s));
-    this.blocksize = null;
+    this.properties.put(BLOCKSIZE, s);
+    this.blocksize = -1;
   }
 
   /**
@@ -404,17 +381,14 @@
       case GZ: compressionType = "GZ"; break;
       default: compressionType = "NONE"; break;
     }
-    setValue(COMPRESSION, compressionType);
+    this.properties.put(COMPRESSION, compressionType);
   }
 
   /**
    * @return True if we are to keep all in use HRegionServer cache.
    */
   public boolean isInMemory() {
-    String value = getValue(HConstants.IN_MEMORY);
-    if (value != null)
-      return Boolean.valueOf(value).booleanValue();
-    return DEFAULT_IN_MEMORY;
+    return getBoolean(HConstants.IN_MEMORY, DEFAULT_IN_MEMORY);
   }
   
   /**
@@ -422,93 +396,59 @@
    * cache
    */
   public void setInMemory(boolean inMemory) {
-    setValue(HConstants.IN_MEMORY, Boolean.toString(inMemory));
+    this.properties.put(HConstants.IN_MEMORY,
+      inMemory? Boolean.TRUE: Boolean.FALSE);
   }
 
   /**
    * @return Time-to-live of cell contents, in seconds.
    */
   public int getTimeToLive() {
-    String value = getValue(TTL);
-    return (value != null)? Integer.valueOf(value).intValue(): DEFAULT_TTL;
+    return getInt(TTL, DEFAULT_TTL);
   }
 
   /**
    * @param timeToLive Time-to-live of cell contents, in seconds.
    */
   public void setTimeToLive(int timeToLive) {
-    setValue(TTL, Integer.toString(timeToLive));
+    this.properties.put(TTL, timeToLive);
   }
 
   /**
    * @return True if MapFile blocks should be cached.
    */
   public boolean isBlockCacheEnabled() {
-    String value = getValue(BLOCKCACHE);
-    if (value != null)
-      return Boolean.valueOf(value).booleanValue();
-    return DEFAULT_BLOCKCACHE;
+    return getBoolean(BLOCKCACHE, DEFAULT_BLOCKCACHE);
   }
 
   /**
    * @param blockCacheEnabled True if MapFile blocks should be cached.
    */
   public void setBlockCacheEnabled(boolean blockCacheEnabled) {
-    setValue(BLOCKCACHE, Boolean.toString(blockCacheEnabled));
+    this.properties.put(BLOCKCACHE, blockCacheEnabled);
   }
 
   /**
-   * @return true if a bloom filter is enabled
-   */
-  public boolean isBloomfilter() {
-    String value = getValue(BLOOMFILTER);
-    if (value != null)
-      return Boolean.valueOf(value).booleanValue();
-    return DEFAULT_BLOOMFILTER;
-  }
-
-  /**
-   * @param onOff Enable/Disable bloom filter
-   */
-  public void setBloomfilter(final boolean onOff) {
-    setValue(BLOOMFILTER, Boolean.toString(onOff));
-  }
-
-  /**
-   * @param interval The number of entries that are added to the store MapFile before
-   * an index entry is added.
-   */
-  public void setMapFileIndexInterval(int interval) {
-    setValue(MAPFILE_INDEX_INTERVAL, Integer.toString(interval));
-  }
-
-  /**
    * @see java.lang.Object#toString()
    */
   @Override
   public String toString() {
-    StringBuffer s = new StringBuffer();
-    s.append('{');
-    s.append(HConstants.NAME);
-    s.append(" => '");
-    s.append(Bytes.toString(name));
-    s.append("'");
-    for (Map.Entry<ImmutableBytesWritable, ImmutableBytesWritable> e:
-        values.entrySet()) {
-      String key = Bytes.toString(e.getKey().get());
-      String value = Bytes.toString(e.getValue().get());
-      if (key != null && key.toUpperCase().equals(BLOOMFILTER)) {
-        // Don't emit bloomfilter.  Its not working.
-        continue;
-      }
-      s.append(", ");
-      s.append(key);
-      s.append(" => '");
-      s.append(value);
-      s.append("'");
+    StringWriter sw = new StringWriter();
+    try {
+      this.mapper.writeValue(sw, this);
+    } catch (JsonGenerationException e) {
+      e.printStackTrace();
+    } catch (JsonMappingException e) {
+      e.printStackTrace();
+    } catch (IOException e) {
+      e.printStackTrace();
     }
-    s.append('}');
-    return s.toString();
+    try {
+      sw.close();
+    } catch (IOException e) {
+      e.printStackTrace();
+    }
+    return sw.toString();
   }
 
   /**
@@ -533,86 +473,18 @@
    */
   @Override
   public int hashCode() {
-    int result = Bytes.hashCode(this.name);
+    int result = this.properties.hashCode();
     result ^= Byte.valueOf(COLUMN_DESCRIPTOR_VERSION).hashCode();
-    result ^= values.hashCode();
     return result;
   }
-  
-  // Writable
 
-  public void readFields(DataInput in) throws IOException {
-    int version = in.readByte();
-    if (version < 6) {
-      if (version <= 2) {
-        Text t = new Text();
-        t.readFields(in);
-        this.name = t.getBytes();
-//        if(KeyValue.getFamilyDelimiterIndex(this.name, 0, this.name.length)
-//            > 0) {
-//          this.name = stripColon(this.name);
-//        }
-      } else {
-        this.name = Bytes.readByteArray(in);
-      }
-      this.values.clear();
-      setMaxVersions(in.readInt());
-      int ordinal = in.readInt();
-      setCompressionType(Compression.Algorithm.values()[ordinal]);
-      setInMemory(in.readBoolean());
-      setBloomfilter(in.readBoolean());
-      if (isBloomfilter() && version < 5) {
-        // If a bloomFilter is enabled and the column descriptor is less than
-        // version 5, we need to skip over it to read the rest of the column
-        // descriptor. There are no BloomFilterDescriptors written to disk for
-        // column descriptors with a version number >= 5
-        throw new UnsupportedClassVersionError(this.getClass().getName() +
-            " does not support backward compatibility with versions older " +
-            "than version 5");
-      }
-      if (version > 1) {
-        setBlockCacheEnabled(in.readBoolean());
-      }
-      if (version > 2) {
-       setTimeToLive(in.readInt());
-      }
-    } else {
-      // version 7+
-      this.name = Bytes.readByteArray(in);
-      this.values.clear();
-      int numValues = in.readInt();
-      for (int i = 0; i < numValues; i++) {
-        ImmutableBytesWritable key = new ImmutableBytesWritable();
-        ImmutableBytesWritable value = new ImmutableBytesWritable();
-        key.readFields(in);
-        value.readFields(in);
-        values.put(key, value);
-      }
-      if (version == 6) {
-        // Convert old values.
-        setValue(COMPRESSION, Compression.Algorithm.NONE.getName());
-      }
-    }
-  }
-
-  public void write(DataOutput out) throws IOException {
-    out.writeByte(COLUMN_DESCRIPTOR_VERSION);
-    Bytes.writeByteArray(out, this.name);
-    out.writeInt(values.size());
-    for (Map.Entry<ImmutableBytesWritable, ImmutableBytesWritable> e:
-        values.entrySet()) {
-      e.getKey().write(out);
-      e.getValue().write(out);
-    }
-  }
-
-  // Comparable
-
   public int compareTo(HColumnDescriptor o) {
-    int result = Bytes.compareTo(this.name, o.getName());
+    String myname = getNameAsString();
+    String hername = o.getNameAsString();
+    int result = myname.compareTo(hername);
     if (result == 0) {
-      // punt on comparison for ordering, just calculate difference
-      result = this.values.hashCode() - o.values.hashCode();
+      // Punt on comparison for ordering, just calculate difference
+      result = this.properties.hashCode() - o.properties.hashCode();
       if (result < 0)
         result = -1;
       else if (result > 0)
@@ -620,4 +492,74 @@
     }
     return result;
   }
-}
+
+  @Override
+  public void clear() {
+    this.properties.clear();
+  }
+
+  @Override
+  public boolean containsKey(Object key) {
+    return this.properties.containsKey(key);
+  }
+
+  @Override
+  public boolean containsValue(Object value) {
+    return this.properties.containsValue(value);
+  }
+
+  @Override
+  public Set<java.util.Map.Entry<String, Object>> entrySet() {
+    return this.properties.entrySet();
+  }
+
+  @Override
+  public Object get(Object key) {
+    return this.properties.get(key);
+  }
+
+  @Override
+  public boolean isEmpty() {
+    return this.properties.isEmpty();
+  }
+
+  @Override
+  public Set<String> keySet() {
+    return this.properties.keySet();
+  }
+
+  @Override
+  public Object put(String key, Object value) {
+    return this.properties.put(key, value);
+  }
+
+  @Override
+  public void putAll(Map<? extends String, ? extends Object> m) {
+    this.properties.putAll(m);
+  }
+
+  @Override
+  public Object remove(Object key) {
+    return this.properties.remove(key);
+  }
+
+  @Override
+  public int size() {
+    return this.properties.size();
+  }
+
+  @Override
+  public Collection<Object> values() {
+    return this.properties.values();
+  }
+
+  private int getInt(final String key, final int defaultValue) {
+    Integer v = (Integer)this.properties.get(key);
+    return v == null? defaultValue: v.intValue();
+  }
+
+  private boolean getBoolean(final String key, final boolean defaultValue) {
+    Boolean v = (Boolean)this.properties.get(key);
+    return v == null? defaultValue: v.booleanValue();
+  }
+}
\ No newline at end of file
Index: src/java/org/apache/hadoop/hbase/HConstants.java
===================================================================
--- src/java/org/apache/hadoop/hbase/HConstants.java	(revision 831514)
+++ src/java/org/apache/hadoop/hbase/HConstants.java	(working copy)
@@ -165,10 +165,12 @@
   //
   
   /** The root table's name.*/
-  static final byte [] ROOT_TABLE_NAME = Bytes.toBytes("-ROOT-");
+  static final String ROOT_TABLE_NAME_STR = "-ROOT-";
+  static final byte [] ROOT_TABLE_NAME = Bytes.toBytes(ROOT_TABLE_NAME_STR);
 
   /** The META table's name. */
-  static final byte [] META_TABLE_NAME = Bytes.toBytes(".META.");  
+  static final String META_TABLE_NAME_STR = ".META.";
+  static final byte [] META_TABLE_NAME = Bytes.toBytes(META_TABLE_NAME_STR);  
 
   /** delimiter used between portions of a region name */
   public static final int META_ROW_DELIMITER = ',';
Index: src/java/org/apache/hadoop/hbase/HTableDescriptor.java
===================================================================
--- src/java/org/apache/hadoop/hbase/HTableDescriptor.java	(revision 831514)
+++ src/java/org/apache/hadoop/hbase/HTableDescriptor.java	(working copy)
@@ -37,91 +37,84 @@
 import org.apache.hadoop.io.WritableComparable;
 
 /**
- * HTableDescriptor contains the name of an HTable, and its
- * column families.
+ * HTableDescriptor contains the name of an HTable, its attributes, and its
+ * column families. Not thread-safe.
  */
-public class HTableDescriptor implements WritableComparable<HTableDescriptor> {
-
+public class HTableDescriptor implements Map<String, Object> {
   // Changes prior to version 3 were not recorded here.
   // Version 3 adds metadata as a map where keys and values are byte[].
   // Version 4 adds indexes
   // Version 5 removed transactional pollution -- e.g. indexes
-  public static final byte TABLE_DESCRIPTOR_VERSION = 5;
+  // Version 6 move from Writable to JSON serialization.
+  public static final byte TABLE_DESCRIPTOR_VERSION = 6;
 
-  private byte [] name = HConstants.EMPTY_BYTE_ARRAY;
-  private String nameAsString = "";
-
   // Table metadata
-  protected Map<ImmutableBytesWritable, ImmutableBytesWritable> values =
-    new HashMap<ImmutableBytesWritable, ImmutableBytesWritable>();
+  private Map<String, Object> properties = new TreeMap<String, Object>();
 
   public static final String FAMILIES = "FAMILIES";
-  public static final ImmutableBytesWritable FAMILIES_KEY =
-    new ImmutableBytesWritable(Bytes.toBytes(FAMILIES));
   public static final String MAX_FILESIZE = "MAX_FILESIZE";
-  public static final ImmutableBytesWritable MAX_FILESIZE_KEY =
-    new ImmutableBytesWritable(Bytes.toBytes(MAX_FILESIZE));
   public static final String READONLY = "READONLY";
-  public static final ImmutableBytesWritable READONLY_KEY =
-    new ImmutableBytesWritable(Bytes.toBytes(READONLY));
   public static final String MEMSTORE_FLUSHSIZE = "MEMSTORE_FLUSHSIZE";
-  public static final ImmutableBytesWritable MEMSTORE_FLUSHSIZE_KEY =
-    new ImmutableBytesWritable(Bytes.toBytes(MEMSTORE_FLUSHSIZE));
   public static final String IS_ROOT = "IS_ROOT";
-  public static final ImmutableBytesWritable IS_ROOT_KEY =
-    new ImmutableBytesWritable(Bytes.toBytes(IS_ROOT));
   public static final String IS_META = "IS_META";
-
-  public static final ImmutableBytesWritable IS_META_KEY =
-    new ImmutableBytesWritable(Bytes.toBytes(IS_META));
-
   public static final String DEFERRED_LOG_FLUSH = "DEFERRED_LOG_FLUSH";
-  public static final ImmutableBytesWritable DEFERRED_LOG_FLUSH_KEY =
-    new ImmutableBytesWritable(Bytes.toBytes(DEFERRED_LOG_FLUSH));
 
-
-  // The below are ugly but better than creating them each time till we
-  // replace booleans being saved as Strings with plain booleans.  Need a
-  // migration script to do this.  TODO.
-  private static final ImmutableBytesWritable FALSE =
-    new ImmutableBytesWritable(Bytes.toBytes(Boolean.FALSE.toString()));
-  private static final ImmutableBytesWritable TRUE =
-    new ImmutableBytesWritable(Bytes.toBytes(Boolean.TRUE.toString()));
-
   public static final boolean DEFAULT_READONLY = false;
-
   public static final int DEFAULT_MEMSTORE_FLUSH_SIZE = 1024*1024*64;
-  
   public static final int DEFAULT_MAX_FILESIZE = 1024*1024*256;
+  public static final boolean DEFAULT_DEFERRED_LOG_FLUSH = false;
 
-  public static final boolean DEFAULT_DEFERRED_LOG_FLUSH = false;
-    
   private volatile Boolean meta = null;
   private volatile Boolean root = null;
 
-  // Key is hash of the family name.
-  public final Map<byte [], HColumnDescriptor> families =
-    new TreeMap<byte [], HColumnDescriptor>(Bytes.BYTES_RAWCOMPARATOR);
-   
   /**
    * Private constructor used internally creating table descriptors for 
    * catalog tables: e.g. .META. and -ROOT-.
+   * @param name
+   * @param families
+   * @deprecated Use {@link #HTableDescriptor(byte[], HColumnDescriptor[])
    */
   protected HTableDescriptor(final byte [] name, HColumnDescriptor[] families) {
-    this.name = name.clone();
-    this.nameAsString = Bytes.toString(this.name);
+    this(Bytes.toString(name), families);
+  }
+
+  /**
+   * Private constructor used internally creating table descriptors for 
+   * catalog tables: e.g. .META. and -ROOT-.
+   * @param name
+   * @param families
+   */
+  protected HTableDescriptor(final String name, HColumnDescriptor[] families) {
     setMetaFlags(name);
-    for(HColumnDescriptor descriptor : families) {
-      this.families.put(descriptor.getName(), descriptor);
+    Map<String, HColumnDescriptor> m = new TreeMap<String, HColumnDescriptor>();
+    this.properties.put(FAMILIES, m);
+    for (HColumnDescriptor f: families) {
+      f.put(f.getNameAsString(), f);
     }
   }
 
   /**
    * Private constructor used internally creating table descriptors for 
    * catalog tables: e.g. .META. and -ROOT-.
+   * @param name
+   * @param families
+   * @param values
+   * @deprecated Use {@link #HTableDescriptor(byte[], HColumnDescriptor[], Map)}
    */
   protected HTableDescriptor(final byte [] name, HColumnDescriptor[] families,
       Map<ImmutableBytesWritable,ImmutableBytesWritable> values) {
+    this(Bytes.toString(name), families, values);
+  }
+
+  /**
+   * Private constructor used internally creating table descriptors for 
+   * catalog tables: e.g. .META. and -ROOT-.
+   * @param name
+   * @param families
+   * @param values
+   */
+  protected HTableDescriptor(final String name, HColumnDescriptor[] families,
+      Map<ImmutableBytesWritable,ImmutableBytesWritable> values) {
     this.name = name.clone();
     this.nameAsString = Bytes.toString(this.name);
     setMetaFlags(name);
@@ -197,16 +190,15 @@
    * Called by constructors.
    * @param name
    */
-  private void setMetaFlags(final byte [] name) {
-    setRootRegion(Bytes.equals(name, HConstants.ROOT_TABLE_NAME));
-    setMetaRegion(isRootRegion() ||
-      Bytes.equals(name, HConstants.META_TABLE_NAME));
+  private void setMetaFlags(final String name) {
+    setRootRegion(name.equals(HConstants.ROOT_TABLE_NAME_STR));
+    setMetaRegion(isRootRegion() || name.equals(HConstants.META_TABLE_NAME_STR));
   }
 
   /** @return true if this is the root region */
   public boolean isRootRegion() {
     if (this.root == null) {
-      this.root = isSomething(IS_ROOT_KEY, false)? Boolean.TRUE: Boolean.FALSE;
+      this.root = isSomething(IS_ROOT, false)? Boolean.TRUE: Boolean.FALSE;
     }
     return this.root.booleanValue();
   }
@@ -214,7 +206,7 @@
   /** @param isRoot true if this is the root region */
   protected void setRootRegion(boolean isRoot) {
     // TODO: Make the value a boolean rather than String of boolean.
-    values.put(IS_ROOT_KEY, isRoot? TRUE: FALSE);
+    this.properties.put(IS_ROOT, isRoot? Boolean.TRUE: Boolean.FALSE);
   }
 
   /** @return true if this is a meta region (part of the root or meta tables) */
@@ -230,9 +222,8 @@
     return (value != null)? Boolean.valueOf(Bytes.toString(value)): Boolean.FALSE;
   }
 
-  private boolean isSomething(final ImmutableBytesWritable key,
-      final boolean valueIfNull) {
-    byte [] value = getValue(key);
+  private boolean isSomething(final String key, final boolean valueIfNull) {
+    Object value = this.properties.get(key);
     if (value != null) {
       // TODO: Make value be a boolean rather than String of boolean.
       return Boolean.valueOf(Bytes.toString(value)).booleanValue();
@@ -670,4 +661,53 @@
             HConstants.ALL_VERSIONS, Compression.Algorithm.NONE.getName(),
             false, false,  8 * 1024,
             HConstants.WEEK_IN_SECONDS, false)});
-}
+
+
+  public void clear() {
+    properties.clear();
+  }
+
+  public boolean containsKey(Object key) {
+    return properties.containsKey(key);
+  }
+
+  public boolean containsValue(Object value) {
+    return properties.containsValue(value);
+  }
+
+  public Set<java.util.Map.Entry<String, Object>> entrySet() {
+    return properties.entrySet();
+  }
+
+  public Object get(Object key) {
+    return properties.get(key);
+  }
+
+  public boolean isEmpty() {
+    return properties.isEmpty();
+  }
+
+  public Set<String> keySet() {
+    return properties.keySet();
+  }
+
+  public Object put(String key, Object value) {
+    return properties.put(key, value);
+  }
+
+  public void putAll(Map<? extends String, ? extends Object> m) {
+    properties.putAll(m);
+  }
+
+  public Object remove(Object key) {
+    return properties.remove(key);
+  }
+
+  public int size() {
+    return properties.size();
+  }
+
+  public Collection<Object> values() {
+    return properties.values();
+  }
+}
\ No newline at end of file
Index: src/java/org/apache/hadoop/hbase/client/UnmodifyableHColumnDescriptor.java
===================================================================
--- src/java/org/apache/hadoop/hbase/client/UnmodifyableHColumnDescriptor.java	(revision 831514)
+++ src/java/org/apache/hadoop/hbase/client/UnmodifyableHColumnDescriptor.java	(working copy)
@@ -1,81 +0,0 @@
-package org.apache.hadoop.hbase.client;
-
-import org.apache.hadoop.hbase.HColumnDescriptor;
-import org.apache.hadoop.hbase.io.hfile.Compression;
-
-/**
- * Immutable HColumnDescriptor
- */
-public class UnmodifyableHColumnDescriptor extends HColumnDescriptor {
-
-  /**
-   * @param desc
-   */
-  public UnmodifyableHColumnDescriptor (final HColumnDescriptor desc) {
-    super(desc);
-  }
-
-  /**
-   * @see org.apache.hadoop.hbase.HColumnDescriptor#setValue(byte[], byte[])
-   */
-  @Override
-  public void setValue(byte[] key, byte[] value) {
-    throw new UnsupportedOperationException("HColumnDescriptor is read-only");
-  }
-
-  /**
-   * @see org.apache.hadoop.hbase.HColumnDescriptor#setValue(java.lang.String, java.lang.String)
-   */
-  @Override
-  public void setValue(String key, String value) {
-    throw new UnsupportedOperationException("HColumnDescriptor is read-only");
-  }
-
-  /**
-   * @see org.apache.hadoop.hbase.HColumnDescriptor#setMaxVersions(int)
-   */
-  @Override
-  public void setMaxVersions(int maxVersions) {
-    throw new UnsupportedOperationException("HColumnDescriptor is read-only");
-  }
-
-  /**
-   * @see org.apache.hadoop.hbase.HColumnDescriptor#setInMemory(boolean)
-   */
-  @Override
-  public void setInMemory(boolean inMemory) {
-    throw new UnsupportedOperationException("HColumnDescriptor is read-only");
-  }
-
-  /**
-   * @see org.apache.hadoop.hbase.HColumnDescriptor#setBlockCacheEnabled(boolean)
-   */
-  @Override
-  public void setBlockCacheEnabled(boolean blockCacheEnabled) {
-    throw new UnsupportedOperationException("HColumnDescriptor is read-only");
-  }
-
-  /**
-   * @see org.apache.hadoop.hbase.HColumnDescriptor#setTimeToLive(int)
-   */
-  @Override
-  public void setTimeToLive(int timeToLive) {
-    throw new UnsupportedOperationException("HColumnDescriptor is read-only");
-  }
-
-  /**
-   * @see org.apache.hadoop.hbase.HColumnDescriptor#setCompressionType(org.apache.hadoop.hbase.io.hfile.Compression.Algorithm)
-   */
-  @Override
-  public void setCompressionType(Compression.Algorithm type) {
-    throw new UnsupportedOperationException("HColumnDescriptor is read-only");
-  }
-
-  /**
-   * @see org.apache.hadoop.hbase.HColumnDescriptor#setMapFileIndexInterval(int)
-   */
-  @Override
-  public void setMapFileIndexInterval(int interval) {
-    throw new UnsupportedOperationException("HTableDescriptor is read-only");
-  }
-}
\ No newline at end of file
