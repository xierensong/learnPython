diff --git a/src/main/java/org/apache/hadoop/hbase/HConstants.java b/src/main/java/org/apache/hadoop/hbase/HConstants.java
index f565fa1..32619a0 100644
--- a/src/main/java/org/apache/hadoop/hbase/HConstants.java
+++ b/src/main/java/org/apache/hadoop/hbase/HConstants.java
@@ -209,6 +209,12 @@ public final class HConstants {
   /** The regioninfo column qualifier */
   public static final byte [] REGIONINFO_QUALIFIER = Bytes.toBytes("regioninfo");
 
+  /** begin ACL stuff */
+  public static final String ACL_FAMILY_STR = "acl";
+  public static final byte [] ACL_FAMILY = Bytes.toBytes(ACL_FAMILY_STR);
+  public static final byte [] REGIONACL_OWNER = Bytes.toBytes("owner");
+  /** end ACL stuff */
+
   /** The server column qualifier */
   public static final byte [] SERVER_QUALIFIER = Bytes.toBytes("server");
 
@@ -298,6 +304,9 @@ public final class HConstants {
   public static final String VERSIONS = "VERSIONS";
   public static final String IN_MEMORY = "IN_MEMORY";
 
+  // for access control implementation.
+  public static final String OWNER = "OWNER";
+
   /**
    * This is a retry backoff multiplier table similar to the BSD TCP syn
    * backoff table, a bit more aggressive than simple exponential backoff.
diff --git a/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java b/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java
index 2855c52..6191264 100644
--- a/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java
+++ b/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java
@@ -32,6 +32,7 @@ import org.apache.hadoop.hbase.util.JenkinsHash;
 import org.apache.hadoop.hbase.util.MD5Hash;
 import org.apache.hadoop.io.VersionedWritable;
 import org.apache.hadoop.io.WritableComparable;
+import org.apache.hadoop.security.UserGroupInformation;
 
 /**
  * HRegion information.
@@ -174,6 +175,22 @@ public class HRegionInfo extends VersionedWritable implements WritableComparable
                                        regionId, false);
     this.regionNameStr = Bytes.toStringBinary(this.regionName);
     setHashCode();
+
+    if (tableDesc == HTableDescriptor.ROOT_TABLEDESC) {
+      try {
+        tableDesc.setOwnerString(UserGroupInformation.getCurrentUser().getUserName());
+      } catch (IOException ioe) {
+        LOG.debug("UGI.getCurrentUser() failed", ioe);
+      }
+    }
+
+    if (tableDesc == HTableDescriptor.META_TABLEDESC) {
+      try {
+        tableDesc.setOwnerString(UserGroupInformation.getCurrentUser().getUserName());
+      } catch (IOException ioe) {
+        LOG.debug("UGI.getCurrentUser() failed", ioe);
+      }
+    }
   }
 
   /** Default constructor - creates empty object */
diff --git a/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java b/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
index 6310788..f398fe3 100644
--- a/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
+++ b/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
@@ -30,11 +30,14 @@ import java.util.Map;
 import java.util.Set;
 import java.util.TreeMap;
 
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
 import org.apache.hadoop.hbase.io.hfile.Compression;
 import org.apache.hadoop.hbase.regionserver.StoreFile;
 import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.security.UserGroupInformation;
 import org.apache.hadoop.io.WritableComparable;
 
 /**
@@ -42,13 +45,14 @@ import org.apache.hadoop.io.WritableComparable;
  * column families.
  */
 public class HTableDescriptor implements WritableComparable<HTableDescriptor> {
-
   // Changes prior to version 3 were not recorded here.
   // Version 3 adds metadata as a map where keys and values are byte[].
   // Version 4 adds indexes
   // Version 5 removed transactional pollution -- e.g. indexes
   public static final byte TABLE_DESCRIPTOR_VERSION = 5;
 
+  private static final Log LOG = LogFactory.getLog(HTableDescriptor.class);
+
   private byte [] name = HConstants.EMPTY_BYTE_ARRAY;
   private String nameAsString = "";
 
@@ -59,20 +63,28 @@ public class HTableDescriptor implements WritableComparable<HTableDescriptor> {
   public static final String FAMILIES = "FAMILIES";
   public static final ImmutableBytesWritable FAMILIES_KEY =
     new ImmutableBytesWritable(Bytes.toBytes(FAMILIES));
+
   public static final String MAX_FILESIZE = "MAX_FILESIZE";
   public static final ImmutableBytesWritable MAX_FILESIZE_KEY =
     new ImmutableBytesWritable(Bytes.toBytes(MAX_FILESIZE));
+
+  public static final String OWNER = "OWNER";
+  public static final ImmutableBytesWritable OWNER_KEY =
+    new ImmutableBytesWritable(Bytes.toBytes(OWNER));
+
   public static final String READONLY = "READONLY";
   public static final ImmutableBytesWritable READONLY_KEY =
     new ImmutableBytesWritable(Bytes.toBytes(READONLY));
+
   public static final String MEMSTORE_FLUSHSIZE = "MEMSTORE_FLUSHSIZE";
   public static final ImmutableBytesWritable MEMSTORE_FLUSHSIZE_KEY =
     new ImmutableBytesWritable(Bytes.toBytes(MEMSTORE_FLUSHSIZE));
+
   public static final String IS_ROOT = "IS_ROOT";
   public static final ImmutableBytesWritable IS_ROOT_KEY =
     new ImmutableBytesWritable(Bytes.toBytes(IS_ROOT));
-  public static final String IS_META = "IS_META";
 
+  public static final String IS_META = "IS_META";
   public static final ImmutableBytesWritable IS_META_KEY =
     new ImmutableBytesWritable(Bytes.toBytes(IS_META));
 
@@ -144,6 +156,12 @@ public class HTableDescriptor implements WritableComparable<HTableDescriptor> {
    */
   public HTableDescriptor() {
     super();
+    try {
+      setOwner(UserGroupInformation.getCurrentUser());
+    }
+    catch (IOException e) {
+      LOG.error("UGI.getCurrentUser failed", e);
+    }
   }
 
   /**
@@ -666,7 +686,7 @@ public class HTableDescriptor implements WritableComparable<HTableDescriptor> {
   public static final HTableDescriptor ROOT_TABLEDESC = new HTableDescriptor(
       HConstants.ROOT_TABLE_NAME,
       new HColumnDescriptor[] { new HColumnDescriptor(HConstants.CATALOG_FAMILY,
-          10,  // Ten is arbitrary number.  Keep versions to help debuggging.
+          10,  // Ten is arbitrary number.  Keep versions to help debugging.
           Compression.Algorithm.NONE.getName(), true, true, 8 * 1024,
           HConstants.FOREVER, StoreFile.BloomType.NONE.toString(),  
           HConstants.REPLICATION_SCOPE_LOCAL) });
@@ -675,8 +695,33 @@ public class HTableDescriptor implements WritableComparable<HTableDescriptor> {
   public static final HTableDescriptor META_TABLEDESC = new HTableDescriptor(
       HConstants.META_TABLE_NAME, new HColumnDescriptor[] {
           new HColumnDescriptor(HConstants.CATALOG_FAMILY,
-            10, // Ten is arbitrary number.  Keep versions to help debuggging.
+            10, // Ten is arbitrary number.  Keep versions to help debugging.
+            Compression.Algorithm.NONE.getName(), true, true, 8 * 1024,
+            HConstants.FOREVER, StoreFile.BloomType.NONE.toString(),
+            HConstants.REPLICATION_SCOPE_LOCAL),
+          new HColumnDescriptor(HConstants.ACL_FAMILY,
+            10, // Ten is arbitrary number.  Keep versions to help debugging.
             Compression.Algorithm.NONE.getName(), true, true, 8 * 1024,
             HConstants.FOREVER, StoreFile.BloomType.NONE.toString(),
             HConstants.REPLICATION_SCOPE_LOCAL)});
+
+
+  public void setOwner(UserGroupInformation owner) {
+    setOwnerString(owner.getUserName());
+  }
+
+  // used by admin.rb:alter(table_name,*args) to update owner.
+  public void setOwnerString(String owner_string) {
+    setValue(OWNER_KEY,Bytes.toBytes(owner_string));
+  }
+
+  public String getOwnerString() {
+    if (getValue(OWNER_KEY) != null) {
+      return Bytes.toString(getValue(OWNER_KEY));
+    }
+    // Note that every table should have an owner (i.e. should have
+    // OWNER_KEY set). .META. and -ROOT- should return system user as owner,
+    // not null (see MasterFileSystem.java:bootstrap()).
+    return (String)null;
+  }
 }
diff --git a/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java b/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java
index 17c7d9e..69b1eb7 100644
--- a/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java
+++ b/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java
@@ -27,12 +27,14 @@ import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.HServerInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.ipc.HRegionInterface;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.Writables;
+import org.apache.hadoop.security.UserGroupInformation;
 
 /**
  * Writes region and assignment information to <code>.META.</code>.
@@ -49,9 +51,14 @@ public class MetaEditor {
    * @throws IOException if problem connecting or updating meta
    */
   public static void addRegionToMeta(CatalogTracker catalogTracker,
-      HRegionInfo regionInfo)
+      HRegionInfo regionInfo, UserGroupInformation owner)
   throws IOException {
     Put put = new Put(regionInfo.getRegionName());
+    if (owner != null) {
+      put.add(HConstants.ACL_FAMILY, HConstants.REGIONACL_OWNER,
+	      Bytes.toBytes(owner.getUserName()));
+      regionInfo.getTableDesc().setOwnerString(owner.getUserName());
+    }
     put.add(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER,
         Writables.getBytes(regionInfo));
     catalogTracker.waitForMetaServerConnectionDefault().put(
@@ -227,8 +234,18 @@ public class MetaEditor {
 
   private static Put addRegionInfo(final Put p, final HRegionInfo hri)
   throws IOException {
+
+    // Implement: alter <table>, {OWNER => '<username>'}.
+    // check for OWNER in hri.tableDesc: if found, set acl:owner to this username. 
+    HTableDescriptor desc = hri.getTableDesc();
+    String owner_name = desc.getValue("OWNER");
+    if (owner_name != null) {
+      hri.getTableDesc().setOwnerString(owner_name);
+      p.add(HConstants.ACL_FAMILY,HConstants.REGIONACL_OWNER,Bytes.toBytes(owner_name));
+    }
     p.add(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER,
-        Writables.getBytes(hri));
+	  Writables.getBytes(hri));
+
     return p;
   }
 
diff --git a/src/main/java/org/apache/hadoop/hbase/ipc/HBaseServer.java b/src/main/java/org/apache/hadoop/hbase/ipc/HBaseServer.java
index 40473e3..2dec6b5 100644
--- a/src/main/java/org/apache/hadoop/hbase/ipc/HBaseServer.java
+++ b/src/main/java/org/apache/hadoop/hbase/ipc/HBaseServer.java
@@ -58,6 +58,7 @@ import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.LinkedBlockingQueue;
+import java.security.PrivilegedExceptionAction;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -1060,7 +1061,7 @@ public abstract class HBaseServer implements RpcServer {
       ByteArrayOutputStream buf = new ByteArrayOutputStream(buffersize);
       while (running) {
         try {
-          Call call = myCallQueue.take(); // pop the queue; maybe blocked here
+          final Call call = myCallQueue.take(); // pop the queue; maybe blocked here
 
           if (LOG.isDebugEnabled())
             LOG.debug(getName() + ": has #" + call.id + " from " +
@@ -1073,7 +1074,32 @@ public abstract class HBaseServer implements RpcServer {
           CurCall.set(call);
           // TODO: simple auth -- store user in context
           try {
-            value = call(call.connection.protocol, call.param, call.timestamp);             // make the call
+            if (call.connection.ticket == null) {
+              // No user associated with this call's connection:
+              // call.connection.ticket should have been set in Connection::processHeader().
+              if (LOG.isDebugEnabled()) {
+                LOG.debug(getName() + ": has no principal information associated with call #" + call.id + " from " +
+                          call.connection + " : proceeding using server user: '" + UserGroupInformation.getCurrentUser().getUserName() + "' instead.");
+              }
+
+              value = call(call.connection.protocol, call.param, call.timestamp);
+            }
+            else {
+              Object obj = (Writable)call.connection.ticket.doAs(new PrivilegedExceptionAction<Object>() {
+                  public Object run() throws IOException, InterruptedException {
+                    return call(call.connection.protocol, call.param,
+                                call.timestamp);
+                  }
+                });
+              
+              if (obj instanceof Writable) {
+                value = (Writable)obj;
+              }
+              else {
+                // doAs() return value could not be converted to Writable: 
+                // probably should throw an exception here in that case.
+              }
+            }
           } catch (Throwable e) {
             LOG.debug(getName()+", call "+call+": error: " + e, e);
             errorClass = e.getClass().getName();
diff --git a/src/main/java/org/apache/hadoop/hbase/master/HMaster.java b/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
index d2e8fbc..72f7d58 100644
--- a/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
+++ b/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
@@ -73,6 +73,7 @@ import org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler;
 import org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler;
 import org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler;
 import org.apache.hadoop.hbase.regionserver.HRegion;
+import org.apache.hadoop.hbase.security.AccessDeniedException;
 import org.apache.hadoop.hbase.security.HBasePolicyProvider;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.InfoServer;
@@ -89,7 +90,9 @@ import org.apache.hadoop.io.Text;
 import org.apache.hadoop.ipc.RemoteException;
 import org.apache.hadoop.net.DNS;
 import org.apache.hadoop.security.SecurityUtil;
+import org.apache.hadoop.security.UserGroupInformation;
 import org.apache.zookeeper.KeeperException;
+import org.apache.zookeeper.WatchedEvent;
 import org.apache.zookeeper.Watcher;
 
 /**
@@ -164,6 +167,8 @@ implements HMasterInterface, HMasterRegionInterface, MasterServices, Server {
 
   private Thread catalogJanitorChore;
 
+  private String superuser = null;
+
   /**
    * Initializes the HMaster. The steps are as follows:
    *
@@ -200,6 +205,11 @@ implements HMasterInterface, HMasterRegionInterface, MasterServices, Server {
     HBasePolicyProvider.init(conf);
     // TODO: do we need a secret manager for digest auth?  If so need to set it in RpcServer here
 
+    this.superuser = conf.get("hbase.superuser","");
+    if (this.superuser.equals("")) {
+      this.superuser = UserGroupInformation.getCurrentUser().getUserName();
+    }
+
     // set the thread name now we have an address
     setName(MASTER + "-" + this.address);
 
@@ -681,11 +691,12 @@ implements HMasterInterface, HMasterRegionInterface, MasterServices, Server {
       LOG.warn("Interrupted waiting for meta availability", e);
       throw new IOException(e);
     }
-    createTable(newRegions, sync);
+
+    UserGroupInformation owner = UserGroupInformation.getCurrentUser();
+    createTable(newRegions, sync, owner);
   }
 
-  private synchronized void createTable(final HRegionInfo [] newRegions,
-      boolean sync)
+  private synchronized void createTable(final HRegionInfo [] newRegions, boolean sync, UserGroupInformation owner)
   throws IOException {
     String tableName = newRegions[0].getTableDesc().getNameAsString();
     if(MetaReader.tableExists(catalogTracker, tableName)) {
@@ -694,10 +705,10 @@ implements HMasterInterface, HMasterRegionInterface, MasterServices, Server {
     for(HRegionInfo newRegion : newRegions) {
       // 1. Create HRegion
       HRegion region = HRegion.createHRegion(newRegion,
           fileSystemManager.getRootDir(), conf);
 
       // 2. Insert into META
-      MetaEditor.addRegionToMeta(catalogTracker, region.getRegionInfo());
+      MetaEditor.addRegionToMeta(catalogTracker, region.getRegionInfo(), owner);
 
       // 3. Close the new region to flush to disk.  Close log file too.
       region.close();
@@ -813,6 +824,9 @@ implements HMasterInterface, HMasterRegionInterface, MasterServices, Server {
     if (!getAssignmentManager().isTableDisabled(Bytes.toString(tableName))) {
       throw new TableNotDisabledException(tableName);
     }
+    if (!(UserGroupInformation.getCurrentUser().getUserName().equals(superuser))) {
+      throw new AccessDeniedException("You cannot modify table '"+Bytes.toString(tableName)+"' because you are not superuser");
+    }
   }
 
   /**
diff --git a/src/main/java/org/apache/hadoop/hbase/security/AccessDeniedException.java b/src/main/java/org/apache/hadoop/hbase/security/AccessDeniedException.java
new file mode 100644
index 0000000..903abcc
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/security/AccessDeniedException.java
@@ -0,0 +1,51 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.security;
+
+import org.apache.hadoop.hbase.DoNotRetryIOException;
+
+/**
+ * Exception thrown by access-related methods.
+ */
+public class AccessDeniedException extends DoNotRetryIOException {
+  private static final long serialVersionUID = 1913879564363001780L;
+
+  /** Default Constructor */
+  public AccessDeniedException() {
+    super();
+  }
+
+  /**
+   * Constructor with a Class object and exception message.
+   * @param clazz
+   * @param s
+   */
+  public AccessDeniedException(Class<?> clazz, String s) {
+    super( "AccessDenied [" + clazz.getName() + "]: " + s);
+  }
+
+  /**
+   * Constructs the exception and supplies a string as the message
+   * @param s message
+   */
+  public AccessDeniedException(String s) {
+    super(s);
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/security/rbac/AccessControlLists.java b/src/main/java/org/apache/hadoop/hbase/security/rbac/AccessControlLists.java
new file mode 100644
index 0000000..8b551be
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/security/rbac/AccessControlLists.java
@@ -0,0 +1,360 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.security.rbac;
+
+import com.google.common.collect.ArrayListMultimap;
+import com.google.common.collect.ListMultimap;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.catalog.CatalogTracker;
+import org.apache.hadoop.hbase.client.Put;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.ResultScanner;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.filter.CompareFilter;
+import org.apache.hadoop.hbase.filter.RegexStringComparator;
+import org.apache.hadoop.hbase.filter.RowFilter;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.ipc.HRegionInterface;
+import org.apache.hadoop.hbase.regionserver.HRegion;
+import org.apache.hadoop.hbase.regionserver.InternalScanner;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Pair;
+import org.apache.hadoop.hbase.util.Writables;
+import org.apache.hadoop.io.Text;
+
+import java.io.ByteArrayOutputStream;
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.TreeMap;
+
+public class AccessControlLists {
+  /** delimiter to separate user and column family in .META. acl: column keys */
+  public static final char ACL_KEY_DELIMITER = ',';
+  /** prefix character to denote group names */
+  public static final String GROUP_PREFIX = "@";
+  /** column qualifier for table owner */
+  public static final byte[] OWNER_QUALIFIER = Bytes.toBytes("owner");
+
+  private static Log LOG = LogFactory.getLog(AccessControlLists.class);
+
+  public static void addTablePermission(CatalogTracker tracker,
+      HRegionInfo firstRegion, String username, TablePermission perm)
+    throws IOException {
+
+    Put p = new Put(firstRegion.getRegionName());
+    byte[] key = null;
+    if (perm.getFamily() != null && perm.getFamily().length > 0) {
+      key = Bytes.toBytes(username + ACL_KEY_DELIMITER +
+          Bytes.toString(perm.getFamily()));
+    } else {
+      key = Bytes.toBytes(username);
+    }
+
+    TablePermission.Action[] actions = perm.getActions();
+    if ((actions == null) || (actions.length == 0)) {
+      LOG.warn("No actions associated with user '"+username+"'");
+      return;
+    }
+
+    byte[] value = new byte[actions.length];
+    for (int i=0; i<actions.length; i++) {
+      value[i] = actions[i].code();
+    }
+    p.add(HConstants.ACL_FAMILY, key, value);
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Writing permission for table "+
+          Bytes.toString(firstRegion.getTableDesc().getName())+" "+
+          Bytes.toString(key)+": "+Bytes.toStringBinary(value)
+      );
+    }
+
+    tracker.waitForMetaServerConnectionDefault().put(
+        CatalogTracker.META_REGION, p);
+  }
+
+  public static Map<byte[],ListMultimap<String,TablePermission>> loadAll(
+      HRegion metaRegion)
+    throws IOException {
+
+    if (!metaRegion.getRegionInfo().isMetaRegion()) {
+      throw new IOException("Can only load permissions from .META.");
+    }
+
+    Map<byte[],ListMultimap<String,TablePermission>> allPerms =
+        new TreeMap<byte[],ListMultimap<String,TablePermission>>(Bytes.BYTES_COMPARATOR);
+    
+    // do a full scan of .META., filtering on only first table region rows
+
+    Scan scan = new Scan();
+    scan.addFamily(HConstants.ACL_FAMILY);
+    scan.addColumn(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER);
+    scan.setFilter(new RowFilter(CompareFilter.CompareOp.EQUAL,
+        new RegexStringComparator("^[\\w\\-\\.]+,,")));
+
+    InternalScanner iScanner = null;
+    try {
+      iScanner = metaRegion.getScanner(scan);
+
+      while (true) {
+        List<KeyValue> row = new ArrayList<KeyValue>();
+
+        boolean hasNext = iScanner.next(row);
+        ListMultimap<String,TablePermission> perms = ArrayListMultimap.create();
+        byte[] table = null;
+        for (KeyValue kv : row) {
+          if (table == null) {
+            String rowkey = Bytes.toStringBinary(kv.getRow());
+            table = Bytes.toBytes( rowkey.substring(0, rowkey.indexOf(',')) );
+          }
+          Pair<String,TablePermission> permissionsOfUserOnTable =
+              parsePermissionRecord(table,kv);
+          if (permissionsOfUserOnTable != null) {
+            String username = permissionsOfUserOnTable.getFirst();
+            TablePermission permissions = permissionsOfUserOnTable.getSecond();
+            perms.put(username, permissions);
+          }
+        }
+        allPerms.put(table, perms);
+        if (!hasNext) {
+          break;
+        }
+      }
+    } finally {
+      if (iScanner != null) {
+        iScanner.close();
+      }
+    }
+
+    return allPerms;
+  }
+
+  /**
+   * Load all permissions from the region server holding .META., primarily
+   * intended for testing purposes.
+   *
+   * @param tracker
+   * @return
+   * @throws IOException
+   */
+  public static Map<byte[],ListMultimap<String,TablePermission>> loadAll(
+      CatalogTracker tracker) throws IOException {
+    Map<byte[],ListMultimap<String,TablePermission>> allPerms =
+        new TreeMap<byte[],ListMultimap<String,TablePermission>>(Bytes.BYTES_COMPARATOR);
+
+    // do a full scan of .META., filtering on only first table region rows
+
+    Scan scan = new Scan();
+    scan.addFamily(HConstants.ACL_FAMILY);
+    scan.addColumn(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER);
+    scan.setFilter(new RowFilter(CompareFilter.CompareOp.EQUAL,
+        new RegexStringComparator("^[\\w\\-\\.]+,,")));
+    HRegionInterface connection = tracker.waitForMetaServerConnectionDefault();
+    long scannerId =
+        connection.openScanner(
+            HRegionInfo.FIRST_META_REGIONINFO.getRegionName(), scan);
+
+    try {
+      Result row = null;
+      while((row = connection.next(scannerId)) != null) {
+        HRegionInfo regionInfo = Writables.getHRegionInfo(
+            row.getValue(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER));
+        ListMultimap<String,TablePermission> resultPerms =
+            parsePermissions(regionInfo.getTableDesc().getName(), row);
+        allPerms.put(regionInfo.getTableDesc().getName(), resultPerms);
+      }
+    } finally {
+      connection.close(scannerId);
+    }
+
+    return allPerms;
+  }
+
+  /**
+   * Reads user permission assignments stored in the <code>acl:</code> column
+   * family of the first table row in <code>.META.</code>.
+   *
+   * <p>
+   * KeyValues for permissions assignments are stored in one of the formats:
+   * <pre>
+   * Key            Desc
+   * --------       --------
+   * user           table level permissions for a user [R=read, W=write]
+   * @group         table level permissions for a group
+   * user,family    column family level permissions for a user
+   * @group,family  column family level permissions for a group
+   * </pre>
+   * All values are encoded as byte arrays containing the codes from the
+   * {@link org.apache.hadoop.hbase.security.rbac.TablePermission.Action} enum.
+   * </p>
+   */
+  public static ListMultimap<String,TablePermission> getTablePermissions(
+      CatalogTracker tracker, byte[] tableName)
+  throws IOException {
+    // TODO: -ROOT- and .META. not handled with .META. acl: storage, what to do here?
+    if (Bytes.equals(tableName, HConstants.ROOT_TABLE_NAME) ||
+        Bytes.equals(tableName, HConstants.META_TABLE_NAME)) {
+      return ArrayListMultimap.create(0,0);
+    }
+
+    // for normal user tables, we just read from the first .META. row for the table
+    HRegionInterface metaServer = tracker.waitForMetaServerConnectionDefault();
+
+    byte[] firstRow = Bytes.toBytes(Bytes.toString(tableName)+",,");
+    Scan scan = new Scan(firstRow);
+    scan.setCaching(1);
+    scan.addFamily(HConstants.ACL_FAMILY);
+    long scannerId =
+        metaServer.openScanner(
+            HRegionInfo.FIRST_META_REGIONINFO.getRegionName(), scan);
+
+    ListMultimap<String,TablePermission> perms = null;
+    try {
+      Result acls = metaServer.next(scannerId);
+      perms = parsePermissions(tableName, acls);
+    } finally {
+      metaServer.close(scannerId);
+    }
+
+    return perms;
+  }
+
+  private static ListMultimap<String,TablePermission> parsePermissions(
+      byte[] table, Result result) {
+    ListMultimap<String,TablePermission> perms = ArrayListMultimap.create();
+    if (result != null && result.size() > 0) {
+      byte[] lastKey = null;
+      for (KeyValue kv : result.sorted()) {
+
+        Pair<String,TablePermission> permissionsOfUserOnTable = parsePermissionRecord(table,kv);
+
+        if (permissionsOfUserOnTable != null) {
+          String username = permissionsOfUserOnTable.getFirst();
+          TablePermission permissions = permissionsOfUserOnTable.getSecond();
+          perms.put(username, permissions);
+        }
+      }
+    }
+    return perms;
+  }
+
+  private static Pair<String,TablePermission> parsePermissionRecord(
+                                                                    byte[] table, KeyValue kv) {
+    // return X given a set of permissions encoded in the permissionRecord kv.
+    byte[] family = kv.getFamily();
+
+    if (!Bytes.equals(family, HConstants.ACL_FAMILY)) {
+      return null;
+    }
+
+    byte[] key = kv.getQualifier();
+    if (Bytes.equals(key, OWNER_QUALIFIER)) {
+      return null;
+    }
+
+    byte[] value = kv.getValue();
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Read acl: kv ["+
+                Bytes.toStringBinary(key)+": "+
+                Bytes.toStringBinary(value)+"]");
+    }
+
+    // check for a column family appended to the key
+    String username = Bytes.toString(key);
+    int idx = username.lastIndexOf(ACL_KEY_DELIMITER);
+    byte[] permFamily = null;
+    if (idx > 0 && idx < username.length()-1) {
+      permFamily = Bytes.toBytes(username.substring(idx+1));
+      username = username.substring(0, idx);
+    }
+
+    return new Pair<String,TablePermission>(username,new TablePermission(table,permFamily,value));
+  }
+
+  /**
+   * Writes a set of permissions as {@link org.apache.hadoop.io.Writable} instances
+   * to the given output stream.
+   * @param out
+   * @param perms
+   * @param conf
+   * @throws IOException
+   */
+  public static void writePermissions(DataOutput out,
+      ListMultimap<String,TablePermission> perms, Configuration conf)
+  throws IOException {
+    Set<String> keys = perms.keySet();
+    out.writeInt(keys.size());
+    for (String key : keys) {
+      Text.writeString(out, key);
+      HbaseObjectWritable.writeObject(out, perms.get(key), List.class, conf);
+    }
+  }
+
+  /**
+   * Writes a set of permissions as {@link org.apache.hadoop.io.Writable} instances
+   * and returns the resulting byte array.
+   */
+  public static byte[] writePermissionsAsBytes(
+      ListMultimap<String,TablePermission> perms, Configuration conf) {
+    try {
+      ByteArrayOutputStream bos = new ByteArrayOutputStream();
+      writePermissions(new DataOutputStream(bos), perms, conf);
+      return bos.toByteArray();
+    } catch (IOException ioe) {
+      // shouldn't happen here
+      LOG.error("Error serializing permissions", ioe);
+    }
+    return null;
+  }
+
+  /**
+   * Reads a set of permissions as {@link org.apache.hadoop.io.Writable} instances
+   * from the input stream.
+   * 
+   * @param in
+   * @param conf
+   * @return
+   * @throws IOException
+   */
+  public static ListMultimap<String,TablePermission> readPermissions(
+      DataInput in, Configuration conf) throws IOException {
+    ListMultimap<String,TablePermission> perms = ArrayListMultimap.create();
+    int length = in.readInt();
+    for (int i=0; i<length; i++) {
+      String user = Text.readString(in);
+      List<TablePermission> userPerms =
+          (List)HbaseObjectWritable.readObject(in, conf);
+      perms.putAll(user, userPerms);
+    }
+
+    return perms;
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/security/rbac/AccessController.java b/src/main/java/org/apache/hadoop/hbase/security/rbac/AccessController.java
new file mode 100644
index 0000000..68bd0b3
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/security/rbac/AccessController.java
@@ -0,0 +1,321 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.security.rbac;
+
+import com.google.common.collect.ListMultimap;
+import com.google.common.collect.Lists;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.KeyValue;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.catalog.CatalogTracker;
+import org.apache.hadoop.hbase.client.Get;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;
+import org.apache.hadoop.hbase.coprocessor.CoprocessorEnvironment;
+import org.apache.hadoop.hbase.coprocessor.CoprocessorException;
+import org.apache.hadoop.hbase.regionserver.HRegion;
+import org.apache.hadoop.hbase.security.AccessDeniedException;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.security.UserGroupInformation;
+import java.io.IOException;
+import java.util.*;
+
+public class AccessController extends BaseRegionObserver {
+  public static final Log LOG = LogFactory.getLog(AccessController.class);
+
+  TableAuthManager authManager = null;
+  boolean isMetaRegion = false;
+
+  void openMetaRegion(CoprocessorEnvironment e) throws IOException {
+    final HRegion region = e.getRegion();
+
+    Map<byte[],ListMultimap<String,TablePermission>> tables =
+        AccessControlLists.loadAll(region);
+    // For each table, write out the table's permissions to the respective
+    // znode for that table.
+    for (Map.Entry<byte[],ListMultimap<String,TablePermission>> t:
+      tables.entrySet()) {
+      byte[] table = t.getKey();
+      String tableName = Bytes.toString(table);
+      ListMultimap<String,TablePermission> perms = t.getValue();
+      byte[] serialized = AccessControlLists.writePermissionsAsBytes(perms,
+          e.getRegion().getConf());
+      this.authManager.getZKPermissionWatcher().writeToZookeeper(tableName,
+        serialized);
+    }
+  }
+
+  void updateACL(CoprocessorEnvironment e,
+      final Map<byte[], List<KeyValue>> familyMap) {
+    Set<String> tableSet = new HashSet<String>();
+    for (Map.Entry<byte[], List<KeyValue>> f : familyMap.entrySet()) {
+      List<KeyValue> kvs = f.getValue();
+      for (KeyValue kv: kvs) {
+        if (Bytes.compareTo(kv.getBuffer(), kv.getFamilyOffset(),
+            kv.getFamilyLength(), HConstants.ACL_FAMILY, 0,
+            HConstants.ACL_FAMILY.length) == 0) {
+          String row = Bytes.toString(kv.getRow());
+          String tableName = row.substring(0, row.indexOf(","));
+          tableSet.add(tableName);
+        }
+      }
+    }
+    CatalogTracker ct = e.getRegionServerServices().getCatalogTracker();
+    for (String tableName: tableSet) {
+      try {
+        ListMultimap<String,TablePermission> perms =
+          AccessControlLists.getTablePermissions(ct, Bytes.toBytes(tableName));
+        byte[] serialized = AccessControlLists.writePermissionsAsBytes(
+            perms, e.getRegion().getConf());
+        this.authManager.getZKPermissionWatcher().writeToZookeeper(tableName,
+          serialized);
+      } catch (IOException ex) {
+        LOG.error("Failed updating permissions mirror for '" + tableName +
+          "'", ex);
+      }
+    }
+  }
+
+  void updateACL(CoprocessorEnvironment e, final KeyValue kv) {
+    if (Bytes.compareTo(kv.getBuffer(), kv.getFamilyOffset(),
+        kv.getFamilyLength(), HConstants.ACL_FAMILY, 0,
+        HConstants.ACL_FAMILY.length) == 0) {
+      String row = Bytes.toString(kv.getRow());
+      String tableName = row.substring(0, row.indexOf(","));
+      CatalogTracker ct = e.getRegionServerServices().getCatalogTracker();
+      try {
+        ListMultimap<String,TablePermission> perms =
+          AccessControlLists.getTablePermissions(ct, Bytes.toBytes(tableName));
+        byte[] serialized = AccessControlLists.writePermissionsAsBytes(perms,
+            e.getRegion().getConf());
+        this.authManager.getZKPermissionWatcher().writeToZookeeper(tableName,
+          serialized); 
+      } catch (IOException ex) {
+        LOG.error("Failed updating permissions mirror for '" + tableName +
+          "'", ex);
+      }
+    }
+  }
+
+  boolean permissionGranted(TablePermission.Action permRequest,
+      CoprocessorEnvironment e, Collection<byte[]> families) {
+    HRegionInfo hri = e.getRegion().getRegionInfo();
+    HTableDescriptor htd = hri.getTableDesc();
+
+    // 1. All users need read access to .META. and -ROOT- tables; also, this is a very
+    // common call to permissionGranted(), so deal with it quickly.
+    if (isMetaRegion && (permRequest == TablePermission.Action.READ)) {
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("All users are allowed to " + permRequest.toString() +
+          " the table '" + htd.getNameAsString() + "'");
+      }
+      return true;
+    }
+
+    // 2. Get owner of this table: owners can do anything, (including the 
+    // specific permRequest requested).
+    // Note that .META. and -ROOT- set on creation to be owned by the system
+    // user: (see MasterFileSystem.java:bootstrap()), so that only system user
+    // may write to them.  Of course, other users may be later granted write
+    // access to these tables if desired.
+    UserGroupInformation user = null;
+    String owner = htd.getOwnerString();
+
+    if (owner == null) {
+      LOG.debug("Owner of '" + htd.getNameAsString() + " is (incorrectly) null.");
+    }
+
+    try {
+      user = UserGroupInformation.getCurrentUser();
+      if (owner.equals(user.getUserName())) {
+        // owner of table can do anything to the table.
+        if (LOG.isDebugEnabled()) {
+          LOG.debug("User '" + user.getUserName() + "' is owner: allowed to " +
+            permRequest.toString() + " the table '" + htd.getNameAsString() +
+            "'");
+        }
+        return true;
+      } else if (LOG.isDebugEnabled()) {
+        LOG.debug("User '" + user.getUserName() +
+          "' is not owner of the table '" + htd.getNameAsString() +
+          "' (owner is : '" + owner + "')");
+      }
+    } catch (IOException ioe) {
+      //... problem getting user info: throw AccessDeniedException() probably?
+      LOG.info("UGI.getCurrentUser() failed", ioe);
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("User '" + user.getUserName() + "' is not allowed to " +
+          permRequest.toString() + " the table '" + htd.getNameAsString() + "'");
+      }
+      return false;
+    }
+
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Owner-based authorization did not succeed, " +
+        "continuing with user-based authorization check");
+    }
+    boolean result = false;
+
+    // 3. get permissions for this user for table with desc tableDesc.
+    if (families != null && families.size() > 0) {
+      // all families must pass
+      result = true;
+      for (byte[] family : families) {
+        result = result &&
+            authManager.authorize(user, htd.getName(), family, permRequest);
+        if (!result) {
+          break;  //failed
+        }
+      }
+    } else {
+      // just check for the table-level
+      result = authManager.authorize(user, htd.getName(), null, permRequest);
+    }
+
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("User '" + user.getUserName() + "' is " +
+        (result ? "" : "not ") + "allowed to " +
+        permRequest.toString() + " the table '" + htd.getNameAsString() +
+        "'");
+    }
+
+    return result;
+  }
+
+  public void requirePermission(TablePermission.Action perm,
+        CoprocessorEnvironment env, Collection<byte[]> families)
+      throws IOException {
+    if (!permissionGranted(perm, env,families)) {
+      throw new AccessDeniedException("Insufficient permissions (table=" +
+        env.getRegion().getTableDesc().getNameAsString()+", action=" +
+        perm.toString());
+    }
+  }
+
+  @Override
+  public void postOpen(CoprocessorEnvironment e) {
+    HRegionInfo hri = e.getRegion().getRegionInfo();
+
+    if (hri.isRootRegion()) {
+      isMetaRegion = true;
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("Opening -ROOT-, no op");
+      }
+      return;
+    }
+
+    this.authManager = TableAuthManager.get(
+      e.getRegionServerServices().getZooKeeperWatcher(),
+      e.getRegion().getConf());
+
+    HTableDescriptor htd = hri.getTableDesc();
+
+    if (htd.isMetaRegion()) {
+      isMetaRegion = true;
+      try {
+        openMetaRegion(e);
+      } catch (IOException ex) {
+        LOG.error("Failed to initialize permissions mirror", ex);
+      }
+    }
+  }
+
+  private Collection<byte[]> getFamilies(List<KeyValue> kvs) {
+    TreeSet<byte[]> distinct = new TreeSet<byte[]>(Bytes.BYTES_COMPARATOR);
+    for (KeyValue kv : kvs) {
+      distinct.add(kv.getFamily());
+    }
+    return distinct;
+  }
+
+  @Override
+  public Result preGetClosestRowBefore(CoprocessorEnvironment e, byte[] row,
+      byte[] family, Result result) throws IOException {
+    requirePermission(TablePermission.Action.READ, e,
+        (family != null ? Lists.newArrayList(family) : null));
+    return result;
+  }
+
+  @Override
+  public List<KeyValue> preGet(CoprocessorEnvironment e, Get get,
+      final List<KeyValue> results) throws IOException {
+    requirePermission(TablePermission.Action.READ, e, get.familySet());
+    return results;
+  }
+
+  @Override
+  public void preExists(CoprocessorEnvironment e, Get get)
+      throws IOException {
+    requirePermission(TablePermission.Action.READ, e, get.familySet());
+  }
+
+  @Override
+  public Map<byte[], List<KeyValue>> prePut(CoprocessorEnvironment e,
+      Map<byte[], List<KeyValue>> familyMap) throws IOException {
+    requirePermission(TablePermission.Action.WRITE, e, familyMap.keySet());
+    return familyMap;
+  }
+
+  @Override
+  public Map<byte[], List<KeyValue>> postPut(final CoprocessorEnvironment e,
+      final Map<byte[], List<KeyValue>> familyMap) {
+    if (isMetaRegion) {
+      updateACL(e, familyMap);
+    }
+    return familyMap;
+  }
+
+  @Override
+  public Map<byte[], List<KeyValue>> preDelete(CoprocessorEnvironment e,
+      Map<byte[], List<KeyValue>> familyMap) throws IOException {
+    requirePermission(TablePermission.Action.WRITE, e, familyMap.keySet());
+    return familyMap;
+  }
+
+  @Override
+  public Map<byte[], List<KeyValue>> postDelete(CoprocessorEnvironment e,
+      Map<byte[], List<KeyValue>> familyMap) throws CoprocessorException {
+    if (isMetaRegion) {
+      updateACL(e, familyMap);
+    }
+    return familyMap;
+  }
+
+  @Override
+  public void preScannerOpen(CoprocessorEnvironment e, Scan scan)
+      throws IOException {
+    requirePermission(TablePermission.Action.READ, e,
+        Arrays.asList(scan.getFamilies()));
+  }
+
+  @Override
+  public List<KeyValue> preScannerNext(CoprocessorEnvironment e,
+      long scannerId, List<KeyValue> results) throws IOException {
+    requirePermission(TablePermission.Action.READ, e, getFamilies(results));
+    return results;
+  }
+
+  @Override
+  public void preScannerClose(CoprocessorEnvironment e, long scannerId)
+      throws IOException {
+    requirePermission(TablePermission.Action.READ, e, null);
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/security/rbac/TableAuthManager.java b/src/main/java/org/apache/hadoop/hbase/security/rbac/TableAuthManager.java
new file mode 100644
index 0000000..44d8cad
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/security/rbac/TableAuthManager.java
@@ -0,0 +1,255 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.security.rbac;
+
+import com.google.common.collect.ArrayListMultimap;
+import com.google.common.collect.ListMultimap;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
+import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.zookeeper.KeeperException;
+
+import java.io.*;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.ConcurrentSkipListMap;
+
+/**
+ * Performs authorization checks for a given user's assigned permissions
+ */
+public class TableAuthManager {
+  private static Log LOG = LogFactory.getLog(TableAuthManager.class);
+
+  private static TableAuthManager instance;
+
+  private ConcurrentSkipListMap<byte[], ListMultimap<String,TablePermission>> TABLE_USER_CACHE =
+      new ConcurrentSkipListMap<byte[], ListMultimap<String,TablePermission>>(Bytes.BYTES_COMPARATOR);
+
+  private ConcurrentSkipListMap<byte[], ListMultimap<String,TablePermission>> TABLE_GROUP_CACHE =
+      new ConcurrentSkipListMap<byte[], ListMultimap<String,TablePermission>>(Bytes.BYTES_COMPARATOR);
+
+  private Configuration conf;
+  private ZKPermissionWatcher zkperms;
+
+  private TableAuthManager(ZooKeeperWatcher watcher, Configuration conf) {
+    this.conf = conf;
+    this.zkperms = new ZKPermissionWatcher(watcher, this, conf);
+    try {
+      this.zkperms.start();
+    } catch (KeeperException ke) {
+      LOG.error("ZooKeeper initialization failed", ke);
+    }
+  }
+
+  public ZKPermissionWatcher getZKPermissionWatcher() {
+    return this.zkperms;
+  }
+
+  public void refreshCacheFromWritable(byte[] table, byte[] data) throws IOException {
+    DataInput in = new DataInputStream( new ByteArrayInputStream(data) );
+    ListMultimap<String,TablePermission> perms = AccessControlLists.readPermissions(in, conf);
+    cache(table, perms);
+  }
+
+  /**
+   * Updates the internal permissions cache for a single table, splitting
+   * the permissions listed into separate caches for users and groups to optimize
+   * group lookups.
+   * 
+   * @param table
+   * @param tablePerms
+   */
+  private void cache(byte[] table,
+      ListMultimap<String,TablePermission> tablePerms) {
+    // split user from group assignments so we don't have to prepend the group
+    // prefix every time we query for groups
+    ListMultimap<String,TablePermission> userPerms = ArrayListMultimap.create();
+    ListMultimap<String,TablePermission> groupPerms = ArrayListMultimap.create();
+
+    if (tablePerms != null) {
+      for (Map.Entry<String,TablePermission> entry : tablePerms.entries()) {
+        if (entry.getKey().startsWith(AccessControlLists.GROUP_PREFIX)) {
+          groupPerms.put(
+              entry.getKey().substring(AccessControlLists.GROUP_PREFIX.length()),
+              entry.getValue());
+        } else {
+          userPerms.put(entry.getKey(), entry.getValue());
+        }
+      }
+      TABLE_GROUP_CACHE.put(table, groupPerms);
+      TABLE_USER_CACHE.put(table, userPerms);
+    }
+  }
+
+  private List<TablePermission> getUserPermissions(String username, byte[] table) {
+    ListMultimap<String, TablePermission> tablePerms = TABLE_USER_CACHE.get(table);
+    if (tablePerms != null) {
+      return tablePerms.get(username);
+    }
+
+    return null;
+  }
+
+  private List<TablePermission> getGroupPermissions(String groupName, byte[] table) {
+    ListMultimap<String, TablePermission> tablePerms = TABLE_GROUP_CACHE.get(table);
+    if (tablePerms != null) {
+      return tablePerms.get(groupName);
+    }
+
+    return null;
+  }
+
+  public boolean authorize(List<TablePermission> perms, byte[] table, byte[] family,
+      TablePermission.Action action) {
+    if (perms != null) {
+      for (TablePermission p : perms) {
+        if (p.implies(table, family, action)) {
+          return true;
+        }
+      }
+    } else if (LOG.isDebugEnabled()) {
+      LOG.debug("No permissions found for table="+Bytes.toStringBinary(table));
+    }
+
+    return false;
+  }
+
+  /**
+   * Checks authorization to a given table and column family for a user, based on the
+   * stored user permissions.
+   *
+   * @param username
+   * @param table
+   * @param family
+   * @param action
+   * @return
+   */
+  public boolean authorizeUser(String username, byte[] table, byte[] family,
+      TablePermission.Action action) {
+    return authorize(getUserPermissions(username, table), table, family, action);
+  }
+
+  /**
+   * Checks authorization to a given table and column family for a group, based
+   * on the stored permissions. 
+   * @param groupName
+   * @param table
+   * @param family
+   * @param action
+   * @return
+   */
+  public boolean authorizeGroup(String groupName, byte[] table, byte[] family,
+      TablePermission.Action action) {
+    return authorize(getGroupPermissions(groupName, table), table, family, action);
+  }
+
+  public boolean authorize(UserGroupInformation user, byte[] table, byte[] family,
+      TablePermission.Action action) {
+    if (authorizeUser(user.getUserName(), table, family, action)) {
+      return true;
+    }
+
+    String[] groups = user.getGroupNames();
+    if (groups != null) {
+      for (String group : groups) {
+        if (authorizeGroup(group, table, family, action)) {
+          return true;
+        }
+      }
+    }
+    return false;
+  }
+
+  public void remove(byte[] table) {
+    TABLE_USER_CACHE.remove(table);
+    TABLE_GROUP_CACHE.remove(table);
+  }
+
+  /**
+   * Overwrites the existing permission set for a given user for a table, and
+   * triggers an update for zookeeper synchronization.
+   * @param username
+   * @param table
+   * @param perms
+   */
+  public void setUserPermissions(String username, byte[] table,
+      List<TablePermission> perms) {
+    ListMultimap<String,TablePermission> tablePerms = TABLE_USER_CACHE.get(table);
+    if (tablePerms == null) {
+      tablePerms = ArrayListMultimap.create();
+      TABLE_USER_CACHE.put(table, tablePerms);
+    }
+    tablePerms.replaceValues(username, perms);
+    writeToZooKeeper(table, tablePerms, TABLE_GROUP_CACHE.get(table));
+  }
+
+  /**
+   * Overwrites the existing permission set for a group and triggers an update
+   * for zookeeper synchronization.
+   * @param group
+   * @param table
+   * @param perms
+   */
+  public void setGroupPermissions(String group, byte[] table,
+      List<TablePermission> perms) {
+    ListMultimap<String,TablePermission> tablePerms = TABLE_GROUP_CACHE.get(table);
+    if (tablePerms == null) {
+      tablePerms = ArrayListMultimap.create();
+      TABLE_GROUP_CACHE.put(table, tablePerms);
+    }
+    tablePerms.replaceValues(group, perms);
+    writeToZooKeeper(table, TABLE_USER_CACHE.get(table), tablePerms);
+  }
+
+  public void writeToZooKeeper(byte[] table,
+      ListMultimap<String,TablePermission> userPerms,
+      ListMultimap<String,TablePermission> groupPerms) {
+    ListMultimap<String,TablePermission> tmp = ArrayListMultimap.create();
+    if (userPerms != null) {
+      tmp.putAll(userPerms);
+    }
+    if (groupPerms != null) {
+      for (String group : groupPerms.keySet()) {
+        tmp.putAll(AccessControlLists.GROUP_PREFIX + group,
+            groupPerms.get(group));
+      }
+    }
+    byte[] serialized = AccessControlLists.writePermissionsAsBytes(tmp, conf);
+    zkperms.writeToZookeeper(Bytes.toString(table), serialized);
+  }
+
+  static Map<ZooKeeperWatcher,TableAuthManager> managerMap = 
+    new HashMap<ZooKeeperWatcher,TableAuthManager>();
+
+  public synchronized static TableAuthManager get(
+      ZooKeeperWatcher watcher, Configuration conf) {
+    instance = managerMap.get(watcher);
+    if (instance == null) {
+      instance = new TableAuthManager(watcher, conf);
+      managerMap.put(watcher, instance);
+    }
+    return instance;
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/security/rbac/TablePermission.java b/src/main/java/org/apache/hadoop/hbase/security/rbac/TablePermission.java
new file mode 100644
index 0000000..886101d
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/security/rbac/TablePermission.java
@@ -0,0 +1,254 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.security.rbac;
+
+import com.google.common.collect.Maps;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.io.VersionedWritable;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.Map;
+
+/**
+ * Represents an authorization for access for the given actions, optionally
+ * restricted to the given column family, over the given table.  If the family
+ * property is <code>null</code>, it implies full table access.
+ */
+public class TablePermission extends VersionedWritable {
+  private static Log LOG = LogFactory.getLog(TablePermission.class);
+  private static final byte VERSION = 0;
+  public enum Action {
+    READ('R'), WRITE('W');
+
+    private byte code;
+    Action(char code) {
+      this.code = (byte)code;
+    }
+
+    public byte code() { return code; }
+  }
+
+  private static Map<Byte,Action> ACTION_BY_CODE = Maps.newHashMap();
+  static {
+    for (Action a : Action.values()) {
+      ACTION_BY_CODE.put(a.code(), a);
+    }
+  }
+
+  private byte[] table;
+  private byte[] family;
+  private Action[] actions;
+
+  /** Nullary constructor for Writable, do not use */
+  public TablePermission() {
+    super();
+  }
+
+  /**
+   * Constructor
+   * @param table the table
+   * @param family the family, can be null if a global permission on the table
+   * @param assigned the list of allowed actions
+   */
+  public TablePermission(byte[] table, byte[] family, Action... assigned) {
+    super();
+    this.table = table;
+    this.family = family;
+    if (assigned != null && assigned.length > 0) {
+      actions = Arrays.copyOf(assigned, assigned.length);
+    }
+  }
+
+  /**
+   * Constructor
+   * @param table the table
+   * @param family the family, can be null if a global permission on the table
+   * @param actionCodes the list of allowed action codes
+   */
+  public TablePermission(byte[] table, byte[] family, byte[] actionCodes) {
+    super();
+    this.table = table;
+    this.family = family;
+
+    if (actionCodes != null) {
+      this.actions = new Action[actionCodes.length];
+      for (int i=0; i<actionCodes.length; i++) {
+        byte b = actionCodes[i];
+        Action a = ACTION_BY_CODE.get(b);
+        if (a == null) {
+          LOG.error("Ignoring unknown action code '"+
+              Bytes.toStringBinary(new byte[]{b})+"'");
+          continue;
+        }
+        this.actions[i] = a;
+      }
+    }
+  }
+
+  public byte[] getTable() {
+    return table;
+  }
+
+  public byte[] getFamily() {
+    return family;
+  }
+
+  public Action[] getActions() {
+    return actions;
+  }
+
+  /**
+   * Checks that a given table operation is authorized by this permission
+   * instance.
+   *
+   * @param table
+   * @param family
+   * @param action
+   * @return
+   */
+  public boolean implies(byte[] table, byte[] family, Action action) {
+    if (!Bytes.equals(this.table, table)) {
+      return false;
+    }
+
+    if (this.family != null &&
+        (family == null ||
+         !Bytes.equals(this.family, family))) {
+      return false;
+    }
+
+    if (this.actions != null) {
+      for (Action a : this.actions) {
+        if (a == action) {
+          return true;
+        }
+      }
+    }
+
+    return false;
+  }
+
+  public boolean equals(Object obj) {
+    if (!(obj instanceof TablePermission)) {
+      return false;
+    }
+    TablePermission other = (TablePermission)obj;
+
+    if (!(Bytes.equals(table, other.getTable()) &&
+        ((family == null && other.getFamily() == null) ||
+         Bytes.equals(family, other.getFamily())
+       ))) {
+      return false;
+    }
+
+    // check actions
+    if (actions == null && other.getActions() == null) {
+      return true;
+    } else if (actions != null && other.getActions() != null) {
+      Action[] otherActions = other.getActions();
+      if (actions.length != otherActions.length) {
+        return false;
+      }
+
+      outer:
+      for (Action a : actions) {
+        for (Action oa : otherActions) {
+          if (a == oa) continue outer;
+        }
+        return false;
+      }
+      return true;
+    }
+
+    return false;
+  }
+
+  public String toString() {
+    StringBuilder str = new StringBuilder("[Permission: ")
+        .append("table=").append(Bytes.toString(table))
+        .append(", family=").append(Bytes.toString(family))
+        .append(", actions=");
+    if (actions != null) {
+      for (int i=0; i<actions.length; i++) {
+        if (i > 0)
+          str.append(",");
+        if (actions[i] != null)
+          str.append(actions[i].toString());
+        else
+          str.append("NULL");
+      }
+    }
+    str.append("]");
+
+    return str.toString();
+  }
+
+  /** @return the object version number */
+  public byte getVersion() {
+    return VERSION;
+  }
+
+  @Override
+  public void readFields(DataInput in) throws IOException {
+    super.readFields(in);
+    table = Bytes.readByteArray(in);
+    if (in.readBoolean()) {
+      family = Bytes.readByteArray(in);
+    }
+    int length = (int)in.readByte();
+    if (length > 0) {
+      actions = new Action[length];
+      for (int i = 0; i < length; i++) {
+        byte b = in.readByte();
+        Action a = ACTION_BY_CODE.get(b);
+        if (a == null) {
+          LOG.error("Ignoring unknown action code '"+
+              Bytes.toStringBinary(new byte[]{b})+"'");
+          continue;
+        }
+        this.actions[i] = a;
+      }
+    } else {
+      actions = new Action[0];
+    }
+  }
+
+  @Override
+  public void write(DataOutput out) throws IOException {
+    super.write(out);
+    Bytes.writeByteArray(out, table);
+    out.writeBoolean(family != null);
+    if (family != null) {
+      Bytes.writeByteArray(out, family);
+    }
+    out.writeByte(actions != null ? actions.length : 0);
+    if (actions != null) {
+      for (Action a: actions) {
+        out.writeByte(a.code());
+      }
+    }
+  }
+}
diff --git a/src/main/java/org/apache/hadoop/hbase/security/rbac/ZKPermissionWatcher.java b/src/main/java/org/apache/hadoop/hbase/security/rbac/ZKPermissionWatcher.java
new file mode 100644
index 0000000..1a2496c
--- /dev/null
+++ b/src/main/java/org/apache/hadoop/hbase/security/rbac/ZKPermissionWatcher.java
@@ -0,0 +1,142 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.security.rbac;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.zookeeper.ZKUtil;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperListener;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
+import org.apache.zookeeper.KeeperException;
+
+import java.io.IOException;
+import java.util.List;
+
+public class ZKPermissionWatcher extends ZooKeeperListener {
+  private static Log LOG = LogFactory.getLog(ZKPermissionWatcher.class);
+  // parent node for permissions lists
+  static final String ACL_NODE = "acl";
+  TableAuthManager authManager;
+  String aclZNode;
+
+  public ZKPermissionWatcher(ZooKeeperWatcher watcher,
+      TableAuthManager authManager, Configuration conf) {
+    super(watcher);
+    this.authManager = authManager;
+    String aclZnodeParent = conf.get("zookeeper.znode.acl.parent", ACL_NODE);
+    this.aclZNode = ZKUtil.joinZNode(watcher.baseZNode, aclZnodeParent);
+  }
+
+  public void start() throws KeeperException {
+    watcher.registerListener(this);
+    if (ZKUtil.watchAndCheckExists(watcher, aclZNode)) {
+      ZKUtil.watchAndGetNewChildren(watcher, aclZNode);
+    }
+  }
+
+  @Override
+  public void nodeCreated(String path) {
+    if (path.equals(aclZNode)) {
+      try {
+        List<ZKUtil.NodeAndData> nodes =
+            ZKUtil.watchAndGetNewChildren(watcher, aclZNode);
+        refreshNodes(nodes);
+      } catch (KeeperException ke) {
+        LOG.error("Error reading data from zookeeper", ke);
+      }
+    }
+  }
+
+  @Override
+  public void nodeDeleted(String path) {
+    if (aclZNode.equals(ZKUtil.getParent(path))) {
+      String table = ZKUtil.getNodeName(path);
+      authManager.remove(Bytes.toBytes(table));
+    }
+  }
+
+  @Override
+  public void nodeDataChanged(String path) {
+    if (aclZNode.equals(ZKUtil.getParent(path))) {
+      // update cache on an existing table node
+      String table = ZKUtil.getNodeName(path);
+      try {
+        byte[] data = ZKUtil.getDataAndWatch(watcher, path);
+        authManager.refreshCacheFromWritable(Bytes.toBytes(table), data);
+      } catch (KeeperException ke) {
+        LOG.error("Error reading data from zookeeper", ke);
+      } catch (IOException ioe) {
+        LOG.error("Error reading permissions writables", ioe);
+      }
+    }
+  }
+
+  @Override
+  public void nodeChildrenChanged(String path) {
+    if (path.equals(aclZNode)) {
+      // table permissions changed
+      try {
+        List<ZKUtil.NodeAndData> nodes =
+            ZKUtil.watchAndGetNewChildren(watcher, aclZNode);
+        refreshNodes(nodes);
+      } catch (KeeperException ke) {
+        LOG.error("Error reading data from zookeeper", ke);
+      }
+    }
+  }
+
+  private void refreshNodes(List<ZKUtil.NodeAndData> nodes) {
+    for (ZKUtil.NodeAndData n : nodes) {
+      String path = n.getNode();
+      String table = ZKUtil.getNodeName(path);
+      try {
+        authManager.refreshCacheFromWritable(Bytes.toBytes(table),
+          n.getData());
+      } catch (IOException ioe) {
+        LOG.error("Failed parsing permissions for table '" + table +
+            "' from zk", ioe);
+      }
+    }
+  }
+
+  /***
+   * Write a table's access controls to the permissions mirror in zookeeper
+   * @param tableName
+   * @param permsData
+   */
+  public void writeToZookeeper(String tableName, 
+      byte[] permsData) {
+    try {
+      String zkNode =
+        ZKUtil.joinZNode(ZKUtil.joinZNode(watcher.baseZNode, ACL_NODE),
+          tableName);
+      ZKUtil.createWithParents(watcher, zkNode);
+      ZKUtil.updateExistingNodeData(watcher, zkNode,
+        permsData, -1);
+    }
+    catch (KeeperException e) {
+      LOG.error("Failed updating permissions for table '" + tableName +
+          "'", e);
+    }
+  }
+}
diff --git a/src/main/resources/hbase-default.xml b/src/main/resources/hbase-default.xml
index 7a1baa2..e823ed0 100644
--- a/src/main/resources/hbase-default.xml
+++ b/src/main/resources/hbase-default.xml
@@ -496,7 +496,11 @@
       authorization decisions on client requests.
     </description>
   </property>
-
+  <property>
+    <name>hbase.superuser</name>
+    <value></value>
+    <description>The user who is solely authorized to alter tables, including table ownership.</description>
+  </property>
   <property>
     <name>hbase.rpc.engine</name>
     <value>org.apache.hadoop.hbase.ipc.SecureRpcEngine</value>
@@ -549,6 +553,12 @@
       this means the root location is stored at /hbase/root-region-server.
     </description>
   </property>
+
+  <property>
+    <name>zookeeper.znode.acl.parent</name>
+    <value>acl</value>
+    <description>Root ZNode for access control lists.</description>
+  </property>
   
   <property>
     <name>hbase.coprocessor.default.classes</name>
diff --git a/src/main/ruby/hbase/admin.rb b/src/main/ruby/hbase/admin.rb
index 83765a0..8806e14 100644
--- a/src/main/ruby/hbase/admin.rb
+++ b/src/main/ruby/hbase/admin.rb
@@ -40,6 +40,7 @@ module Hbase
       zk = @zk_wrapper.getZooKeeper()
       @zk_main = ZooKeeperMain.new(zk)
       @formatter = formatter
+      @meta = HTable.new(HConstants::META_TABLE_NAME)
     end
 
     #----------------------------------------------------------------------------------------------
@@ -121,7 +122,8 @@ module Hbase
       # Fail if no column families defined
       raise(ArgumentError, "Table must have at least one column family") if args.empty?
 
-      # Start defining the table
+      # Start defining the table. Note that the owner will be set using UserGroupInformation.getCurrentUser()
+      # in the HTableDescriptor constructor.
       htd = HTableDescriptor.new(table_name)
 
       # All args are columns, add them to the table definition
@@ -192,6 +194,39 @@ module Hbase
     end
 
     #----------------------------------------------------------------------------------------------
+    # Add an rbac:info column with the value _rights_
+    # for the .META. row for the first region in the table _table_name_.
+    def grant(user,rights,table_name)
+      region_name = get_first_region(table_name)
+      put = Put.new(Bytes.toBytes(region_name))
+      put.add(HConstants::ACL_FAMILY,Bytes.toBytes(user),Bytes.toBytes(rights));
+      meta = HTable.new(HConstants::META_TABLE_NAME)
+      meta.put(put)
+    end
+
+    def get_first_region(table_name)
+      #return the name of the first region for the given table name.
+      #for example, given "foo", this will return something like:
+      # "foo,,1285018739013.639eb6f8570828eb2fcab130b7914c25."
+      region = nil
+      scan = Scan.new
+      scan.setStartRow(Bytes.toBytes(table_name+",,"))
+      scan.setCaching(1);
+      scanner = @meta.getScanner(scan)
+      iter = scanner.iterator
+      row = iter.next
+      row_string = row.to_s
+      kv = row.list[0]
+
+      #kv.to_s looks like e.g. : "foo,,1285018739013.639eb6f8570828eb2fcab130b7914c25."
+      parts = kv.to_s.split(/,/)
+      region = parts[0]+",,"+parts[2].split(/\//)[0]
+
+      scanner.close
+      return region
+    end
+
+    #----------------------------------------------------------------------------------------------
     # Change table structure or table options
     def alter(table_name, *args)
       # Table name should be a string
@@ -219,6 +254,16 @@ module Hbase
 
         # No method parameter, try to use the args as a column definition
         unless method = arg.delete(METHOD)
+          # Note that we handle owner here, and also below (see (2)) as part of the "METHOD => 'table_att'" table attributes.
+          # In other words, if OWNER is specified, then METHOD is set to table_att.
+          # (1) Here, we handle the following (as specified in http://boa02:8000/hbase/wiki/RBACDesign):
+          #   alter 'tablename', {OWNER => 'username'} (that is, METHOD => 'table_att' is not specified).
+          if arg[OWNER]
+            htd.setOwnerString(arg[OWNER])
+            @admin.modifyTable(table_name.to_java_bytes, htd)
+            return
+          end
+
           descriptor = hcd(arg)
           if arg[COMPRESSION_COMPACT]
             descriptor.setValue(COMPRESSION_COMPACT, arg[COMPRESSION_COMPACT])
@@ -229,7 +274,15 @@ module Hbase
           if htd.hasFamily(column_name.to_java_bytes)
             @admin.modifyColumn(table_name, column_name, descriptor)
           else
-            @admin.addColumn(table_name, descriptor)
+            descriptor = hcd(arg)
+            column_name = descriptor.getNameAsString
+
+            # If column already exists, then try to alter it. Create otherwise.
+            if htd.hasFamily(column_name.to_java_bytes)
+              @admin.modifyColumn(table_name, column_name, descriptor)
+            else
+              @admin.addColumn(table_name, descriptor)
+            end
           end
           next
         end
@@ -247,6 +300,8 @@ module Hbase
           htd.setReadOnly(JBoolean.valueOf(arg[READONLY])) if arg[READONLY]
           htd.setMemStoreFlushSize(JLong.valueOf(arg[MEMSTORE_FLUSHSIZE])) if arg[MEMSTORE_FLUSHSIZE]
           htd.setDeferredLogFlush(JBoolean.valueOf(arg[DEFERRED_LOG_FLUSH])) if arg[DEFERRED_LOG_FLUSH]
+          # (2) Here, we handle the alternate syntax of ownership setting, where method => 'table_att' is specified.
+          htd.setOwnerString(arg[OWNER]) if arg[OWNER]
           @admin.modifyTable(table_name.to_java_bytes, htd)
           next
         end
diff --git a/src/main/ruby/shell.rb b/src/main/ruby/shell.rb
index 5654840..bf00464 100644
--- a/src/main/ruby/shell.rb
+++ b/src/main/ruby/shell.rb
@@ -216,6 +216,7 @@ Shell.load_command_group(
     drop
     enable
     exists
+    grant
     list
   ]
 )
diff --git a/src/main/ruby/shell/commands/grant.rb b/src/main/ruby/shell/commands/grant.rb
new file mode 100644
index 0000000..9fd040f
--- /dev/null
+++ b/src/main/ruby/shell/commands/grant.rb
@@ -0,0 +1,40 @@
+#
+# Copyright 2010 The Apache Software Foundation
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+module Shell
+  module Commands
+    class Grant < Command
+      def help
+        return <<-EOF
+          Grant users specific rights to tables.
+          Syntax : grant <user> <rights> <table>
+           For example:
+          hbase> grant 'bobsmith', 'RW', 't1'
+        EOF
+      end
+
+      def command(user,rights,table_name)
+        format_simple_command do
+          admin.grant(user,rights,table_name)
+        end
+      end
+    end
+  end
+end
diff --git a/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java b/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
index 9307448..978c828 100644
--- a/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
+++ b/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
@@ -70,8 +70,6 @@ import org.apache.hadoop.mapred.MiniMRCluster;
 import org.apache.hadoop.security.UserGroupInformation;
 import org.apache.zookeeper.ZooKeeper;
 
-import com.google.common.base.Preconditions;
-
 /**
  * Facility for testing HBase. Replacement for
  * old HBaseTestCase and HBaseCluserTestCase functionality.
@@ -496,6 +494,16 @@ public class HBaseTestingUtility {
   }
 
   /**
+   * Drop an existing table
+   * @param tableName existing table
+   */
+  public void deleteTable(byte[] tableName) throws IOException {
+    HBaseAdmin admin = new HBaseAdmin(getConfiguration());
+    admin.disableTable(tableName);
+    admin.deleteTable(tableName);
+  }
+
+  /**
    * Provide an existing table name to truncate
    * @param tableName existing table
    * @return HTable to that new table
diff --git a/src/test/java/org/apache/hadoop/hbase/security/rbac/TestTablePermissions.java b/src/test/java/org/apache/hadoop/hbase/security/rbac/TestTablePermissions.java
new file mode 100644
index 0000000..31f701e
--- /dev/null
+++ b/src/test/java/org/apache/hadoop/hbase/security/rbac/TestTablePermissions.java
@@ -0,0 +1,251 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.security.rbac;
+
+import com.google.common.collect.ArrayListMultimap;
+import com.google.common.collect.ListMultimap;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.Abortable;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.catalog.CatalogTracker;
+import org.apache.hadoop.hbase.catalog.MetaReader;
+import org.apache.hadoop.hbase.client.HConnection;
+import org.apache.hadoop.hbase.client.HConnectionManager;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import java.io.*;
+import java.util.Arrays;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+import static org.junit.Assert.*;
+
+/**
+ * Test the reading and writing of rbac permission in {@link org.apache.hadoop.hbase.catalog.MetaReader} and {@link org.apache.hadoop.hbase.catalog.MetaEditor}.
+ */
+public class TestTablePermissions {
+  private static final Log LOG = LogFactory.getLog(TestTablePermissions.class);
+  private static final HBaseTestingUtility UTIL = new HBaseTestingUtility();
+  private static ZooKeeperWatcher ZKW;
+  private static CatalogTracker CT;
+  private final static Abortable ABORTABLE = new Abortable() {
+    private final AtomicBoolean abort = new AtomicBoolean(false);
+
+    @Override
+    public void abort(String why, Throwable e) {
+      LOG.info(why, e);
+      abort.set(true);
+    }
+  };
+
+  private static byte[] TEST_TABLE = Bytes.toBytes("perms_test");
+  private static byte[] TEST_TABLE2 = Bytes.toBytes("perms_test2");
+  private static byte[] TEST_FAMILY = Bytes.toBytes("f1");
+
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    UTIL.startMiniCluster();
+    ZKW = new ZooKeeperWatcher(UTIL.getConfiguration(),
+      "TestMetaReaderEditor", ABORTABLE);
+    HConnection connection =
+      HConnectionManager.getConnection(UTIL.getConfiguration());
+    CT = new CatalogTracker(ZKW, connection, ABORTABLE);
+    CT.start();
+
+    UTIL.createTable(TEST_TABLE, TEST_FAMILY);
+    UTIL.createTable(TEST_TABLE2, TEST_FAMILY);
+  }
+
+  @AfterClass
+  public static void afterClass() throws IOException {
+    UTIL.shutdownMiniCluster();
+  }
+
+  @Test
+  public void testBasicWrite() throws Exception {
+    List<HRegionInfo> regions = MetaReader.getTableRegions(CT, TEST_TABLE);
+    assertTrue(regions.size() > 0);
+    // perms only stored against the first region
+    HRegionInfo firstRegion = regions.get(0);
+
+    // add some permissions
+    AccessControlLists.addTablePermission(CT, firstRegion,
+        "george", new TablePermission(TEST_TABLE, null,
+            TablePermission.Action.READ, TablePermission.Action.WRITE));
+    AccessControlLists.addTablePermission(CT, firstRegion,
+        "hubert", new TablePermission(TEST_TABLE, null,
+            TablePermission.Action.READ));
+
+    // retrieve the same
+    ListMultimap<String,TablePermission> perms =
+        AccessControlLists.getTablePermissions(CT, TEST_TABLE);
+    List<TablePermission> userPerms = perms.get("george");
+    assertNotNull("Should have read permissions for george", userPerms);
+    assertEquals("Should have 1 permission for george", 1, userPerms.size());
+    TablePermission permission = userPerms.get(0);
+    assertTrue("Permission should be for " + TEST_TABLE,
+        Bytes.equals(TEST_TABLE, permission.getTable()));
+    assertNull("Column family should be empty", permission.getFamily());
+
+    // check actions
+    assertNotNull(permission.getActions());
+    assertEquals(2, permission.getActions().length);
+    List<TablePermission.Action> actions = Arrays.asList(permission.getActions());
+    assertTrue(actions.contains(TablePermission.Action.READ));
+    assertTrue(actions.contains(TablePermission.Action.WRITE));
+
+    userPerms = perms.get("hubert");
+    assertNotNull("Should have read permissions for hubert", userPerms);
+    assertEquals("Should have 1 permission for hubert", 1, userPerms.size());
+    permission = userPerms.get(0);
+    assertTrue("Permission should be for " + TEST_TABLE,
+        Bytes.equals(TEST_TABLE, permission.getTable()));
+    assertNull("Column family should be empty", permission.getFamily());
+
+    // check actions
+    assertNotNull(permission.getActions());
+    assertEquals(1, permission.getActions().length);
+    actions = Arrays.asList(permission.getActions());
+    assertTrue(actions.contains(TablePermission.Action.READ));
+    assertFalse(actions.contains(TablePermission.Action.WRITE));
+
+    // table 2 permissions
+    List<HRegionInfo> table2regions = MetaReader.getTableRegions(CT, TEST_TABLE2);
+    assertTrue(regions.size() > 0);
+    // perms only stored against the first region
+    HRegionInfo first = table2regions.get(0);
+    AccessControlLists.addTablePermission(CT, first, "hubert",
+        new TablePermission(TEST_TABLE2, null,
+            TablePermission.Action.READ, TablePermission.Action.WRITE));
+
+    // check full load
+    Map<byte[],ListMultimap<String,TablePermission>> allPerms =
+        AccessControlLists.loadAll(CT);
+    assertEquals("Full permission map should have entries for both test tables",
+        2, allPerms.size());
+
+    userPerms = allPerms.get(TEST_TABLE).get("hubert");
+    assertNotNull(userPerms);
+    assertEquals(1, userPerms.size());
+    permission = userPerms.get(0);
+    assertTrue(Bytes.equals(TEST_TABLE, permission.getTable()));
+    assertEquals(1, permission.getActions().length);
+    assertEquals(TablePermission.Action.READ, permission.getActions()[0]);
+
+    userPerms = allPerms.get(TEST_TABLE2).get("hubert");
+    assertNotNull(userPerms);
+    assertEquals(1, userPerms.size());
+    permission = userPerms.get(0);
+    assertTrue(Bytes.equals(TEST_TABLE2, permission.getTable()));
+    assertEquals(2, permission.getActions().length);
+    actions = Arrays.asList(permission.getActions());
+    assertTrue(actions.contains(TablePermission.Action.READ));
+    assertTrue(actions.contains(TablePermission.Action.WRITE));
+  }
+
+  @Test
+  public void testSerialization() throws Exception {
+    Configuration conf = UTIL.getConfiguration();
+    ListMultimap<String,TablePermission> permissions = ArrayListMultimap.create();
+    permissions.put("george", new TablePermission(TEST_TABLE, null,
+        TablePermission.Action.READ));
+    permissions.put("george", new TablePermission(TEST_TABLE, TEST_FAMILY,
+        TablePermission.Action.WRITE));
+    permissions.put("george", new TablePermission(TEST_TABLE2, null,
+        TablePermission.Action.READ));
+    permissions.put("hubert", new TablePermission(TEST_TABLE2, null,
+        TablePermission.Action.READ, TablePermission.Action.WRITE));
+
+    ByteArrayOutputStream bos = new ByteArrayOutputStream();
+    AccessControlLists.writePermissions(new DataOutputStream(bos),
+        permissions, conf);
+
+    ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray());
+    ListMultimap<String,TablePermission> copy =
+        AccessControlLists.readPermissions(new DataInputStream(bis), conf);
+
+    checkMultimapEqual(permissions, copy);
+  }
+
+  public void checkMultimapEqual(ListMultimap<String,TablePermission> first,
+      ListMultimap<String,TablePermission> second) {
+    assertEquals(first.size(), second.size());
+    for (String key : first.keySet()) {
+      List<TablePermission> firstPerms = first.get(key);
+      List<TablePermission> secondPerms = second.get(key);
+      assertNotNull(secondPerms);
+      assertEquals(firstPerms.size(), secondPerms.size());
+      LOG.info("First permissions: "+firstPerms.toString());
+      LOG.info("Second permissions: "+secondPerms.toString());
+      for (TablePermission p : firstPerms) {
+        assertTrue("Permission "+p.toString()+" not found", secondPerms.contains(p));
+      }
+    }
+  }
+
+  @Test
+  public void testEquals() throws Exception {
+    TablePermission p1 = new TablePermission(TEST_TABLE, null, TablePermission.Action.READ);
+    TablePermission p2 = new TablePermission(TEST_TABLE, null, TablePermission.Action.READ);
+    assertTrue(p1.equals(p2));
+    assertTrue(p2.equals(p1));
+
+    p1 = new TablePermission(TEST_TABLE, null, TablePermission.Action.READ, TablePermission.Action.WRITE);
+    p2 = new TablePermission(TEST_TABLE, null, TablePermission.Action.WRITE, TablePermission.Action.READ);
+    assertTrue(p1.equals(p2));
+    assertTrue(p2.equals(p1));
+
+    p1 = new TablePermission(TEST_TABLE, TEST_FAMILY, TablePermission.Action.READ, TablePermission.Action.WRITE);
+    p2 = new TablePermission(TEST_TABLE, TEST_FAMILY, TablePermission.Action.WRITE, TablePermission.Action.READ);
+    assertTrue(p1.equals(p2));
+    assertTrue(p2.equals(p1));
+
+    p1 = new TablePermission(TEST_TABLE, null, TablePermission.Action.READ);
+    p2 = new TablePermission(TEST_TABLE, TEST_FAMILY, TablePermission.Action.READ);
+    assertFalse(p1.equals(p2));
+    assertFalse(p2.equals(p1));
+
+    p1 = new TablePermission(TEST_TABLE, null, TablePermission.Action.READ);
+    p2 = new TablePermission(TEST_TABLE, null, TablePermission.Action.WRITE);
+    assertFalse(p1.equals(p2));
+    assertFalse(p2.equals(p1));
+    p2 = new TablePermission(TEST_TABLE, null, TablePermission.Action.READ, TablePermission.Action.WRITE);
+    assertFalse(p1.equals(p2));
+    assertFalse(p2.equals(p1));
+
+    p1 = new TablePermission(TEST_TABLE, null, TablePermission.Action.READ);
+    p2 = new TablePermission(TEST_TABLE2, null, TablePermission.Action.READ);
+    assertFalse(p1.equals(p2));
+    assertFalse(p2.equals(p1));
+
+    p2 = new TablePermission(TEST_TABLE, null);
+    assertFalse(p1.equals(p2));
+    assertFalse(p2.equals(p1));
+  }
+}
diff --git a/src/test/java/org/apache/hadoop/hbase/security/rbac/TestZKPermissionsWatcher.java b/src/test/java/org/apache/hadoop/hbase/security/rbac/TestZKPermissionsWatcher.java
new file mode 100644
index 0000000..8539959
--- /dev/null
+++ b/src/test/java/org/apache/hadoop/hbase/security/rbac/TestZKPermissionsWatcher.java
@@ -0,0 +1,139 @@
+/*
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.security.rbac;
+
+import static org.junit.Assert.*;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.Abortable;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.zookeeper.ZKUtil;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import java.io.*;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+/**
+ * Test the reading and writing of rbac permission in {@link org.apache.hadoop.hbase.catalog.MetaReader} and {@link org.apache.hadoop.hbase.catalog.MetaEditor}.
+ */
+public class TestZKPermissionsWatcher {
+  private static final Log LOG = LogFactory.getLog(TestZKPermissionsWatcher.class);
+  private static final HBaseTestingUtility UTIL = new HBaseTestingUtility();
+  private static TableAuthManager AUTH_A;
+  private static TableAuthManager AUTH_B;
+  private final static Abortable ABORTABLE = new Abortable() {
+    private final AtomicBoolean abort = new AtomicBoolean(false);
+
+    @Override
+    public void abort(String why, Throwable e) {
+      LOG.info(why, e);
+      abort.set(true);
+    }
+  };
+
+  private static byte[] TEST_TABLE = Bytes.toBytes("perms_test");
+
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    // start minicluster
+    UTIL.startMiniCluster();
+    Configuration conf = UTIL.getConfiguration();
+    AUTH_A = TableAuthManager.get(new ZooKeeperWatcher(conf, 
+      "TestZKPermissionsWatcher_1", ABORTABLE), conf);
+    AUTH_B = TableAuthManager.get(new ZooKeeperWatcher(conf,
+      "TestZKPermissionsWatcher_2", ABORTABLE), conf);
+  }
+
+  @AfterClass
+  public static void afterClass() throws IOException {
+    UTIL.shutdownMiniCluster();
+  }
+
+  @Test
+  public void testPermissionsWatcher() throws Exception {
+    assertFalse(AUTH_A.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.READ));
+    assertFalse(AUTH_A.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.WRITE));
+    assertFalse(AUTH_A.authorizeUser("hubert", TEST_TABLE, null,
+      TablePermission.Action.READ));
+    assertFalse(AUTH_A.authorizeUser("hubert", TEST_TABLE, null,
+      TablePermission.Action.WRITE));
+
+    assertFalse(AUTH_B.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.READ));
+    assertFalse(AUTH_B.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.WRITE));
+    assertFalse(AUTH_B.authorizeUser("hubert", TEST_TABLE, null,
+      TablePermission.Action.READ));
+    assertFalse(AUTH_B.authorizeUser("hubert", TEST_TABLE, null,
+      TablePermission.Action.WRITE));
+
+    // update ACL: george RW
+    List<TablePermission> acl = new ArrayList<TablePermission>();
+    acl.add(new TablePermission(TEST_TABLE, null, TablePermission.Action.READ,
+      TablePermission.Action.WRITE));
+    AUTH_A.setUserPermissions("george", TEST_TABLE, acl);
+    Thread.sleep(10);
+
+    // check it
+    assertTrue(AUTH_A.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.READ));
+    assertTrue(AUTH_A.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.WRITE));
+    assertTrue(AUTH_B.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.READ));
+    assertTrue(AUTH_B.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.WRITE));
+
+    // update ACL: hubert R
+    acl = new ArrayList<TablePermission>();
+    acl.add(new TablePermission(TEST_TABLE, null, TablePermission.Action.READ));
+    AUTH_B.setUserPermissions("hubert", TEST_TABLE, acl);
+    Thread.sleep(10);
+
+    // check it
+    assertTrue(AUTH_A.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.READ));
+    assertTrue(AUTH_A.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.WRITE));
+    assertTrue(AUTH_B.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.READ));
+    assertTrue(AUTH_B.authorizeUser("george", TEST_TABLE, null,
+      TablePermission.Action.WRITE));
+    assertTrue(AUTH_A.authorizeUser("hubert", TEST_TABLE, null,
+      TablePermission.Action.READ));
+    assertFalse(AUTH_A.authorizeUser("hubert", TEST_TABLE, null,
+      TablePermission.Action.WRITE));
+    assertTrue(AUTH_B.authorizeUser("hubert", TEST_TABLE, null,
+      TablePermission.Action.READ));
+    assertFalse(AUTH_B.authorizeUser("hubert", TEST_TABLE, null,
+      TablePermission.Action.WRITE));
+  }
+}
