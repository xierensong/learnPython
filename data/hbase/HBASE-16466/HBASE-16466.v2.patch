From 66f7076eca15671af310b9c102bee50e1d5bfe6d Mon Sep 17 00:00:00 2001
From: Sukumar Maddineni <sukunaidu@gmail.com>
Date: Thu, 27 Apr 2017 16:14:31 -0700
Subject: [PATCH 1/2] #HBASE-16466 - Snapshot support(Source side and peer
 side) in VerifyReplication tool

---
 .../hadoop/hbase/mapreduce/TableMapReduceUtil.java |  41 +++++
 .../hbase/mapreduce/TableSnapshotInputFormat.java  |   5 +
 .../mapreduce/replication/VerifyReplication.java   | 199 +++++++++++++++++----
 .../replication/TestReplicationSmallTests.java     | 133 +++++++++++++-
 4 files changed, 334 insertions(+), 44 deletions(-)

diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java
index e6a69ac..b131c81 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java
@@ -43,10 +43,13 @@ import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.MetaTableAccessor;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
+import org.apache.hadoop.hbase.client.ClusterConnection;
 import org.apache.hadoop.hbase.client.Connection;
 import org.apache.hadoop.hbase.client.ConnectionFactory;
+import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.client.Table;
 import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
 import org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos;
@@ -796,6 +799,44 @@ public class TableMapReduceUtil {
       org.apache.htrace.Trace.class,
       com.codahale.metrics.MetricRegistry.class);
   }
+  
+  
+  /**
+   * Util to add a table related coprocessors classes to M/R job classpath
+   * @param conf
+   * @param tableName
+   * @throws IOException
+   */
+  public static void addTableCoprocessorJarsToClasspath(Configuration conf,
+      TableName tableName) throws IOException
+  {
+    ClusterConnection connection = null;
+    Table table = null;
+    try {
+      connection = (ClusterConnection) ConnectionFactory.createConnection(conf);
+      table = connection.getTable(tableName);
+      List<String> coprocessorClasses = table.getTableDescriptor()
+          .getCoprocessors();
+      if (coprocessorClasses != null && coprocessorClasses.size() > 0) {
+        Class[] classes = new Class[coprocessorClasses.size()];
+        int i = 0;
+        for (String coprocessor : coprocessorClasses) {
+          LOG.debug("Adding coprocessor "+coprocessor+" to classpath");
+          classes[i++] = Class.forName(coprocessor);
+        }
+        addDependencyJarsForClasses(conf, classes);
+      }
+    } catch (ClassNotFoundException e) {
+      throw new IOException(e);
+    }
+    finally
+    {
+      if (table != null)
+        table.close();
+      if(connection!=null)
+        connection.close();
+    }
+  }
 
   /**
    * Returns a classpath string built from the content of the "tmpjars" value in {@code conf}.
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
index 15d403f..aa8c584 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
@@ -120,6 +120,11 @@ public class TableSnapshotInputFormat extends InputFormat<ImmutableBytesWritable
     public void readFields(DataInput in) throws IOException {
       delegate.readFields(in);
     }
+    
+    public HRegionInfo getRegionInfo()
+    {
+      return delegate.getRegionInfo();
+    }
   }
 
   @VisibleForTesting
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java
index 3f8317b..511c46b 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java
@@ -25,6 +25,8 @@ import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.conf.Configured;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.Abortable;
 import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hbase.TableName;
@@ -36,6 +38,7 @@ import org.apache.hadoop.hbase.client.Result;
 import org.apache.hadoop.hbase.client.ResultScanner;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.client.Table;
+import org.apache.hadoop.hbase.client.TableSnapshotScanner;
 import org.apache.hadoop.hbase.filter.Filter;
 import org.apache.hadoop.hbase.filter.FilterList;
 import org.apache.hadoop.hbase.filter.PrefixFilter;
@@ -43,6 +46,7 @@ import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
 import org.apache.hadoop.hbase.mapreduce.TableInputFormat;
 import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;
 import org.apache.hadoop.hbase.mapreduce.TableMapper;
+import org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat;
 import org.apache.hadoop.hbase.mapreduce.TableSplit;
 import org.apache.hadoop.hbase.replication.ReplicationException;
 import org.apache.hadoop.hbase.replication.ReplicationFactory;
@@ -50,14 +54,19 @@ import org.apache.hadoop.hbase.replication.ReplicationPeerConfig;
 import org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl;
 import org.apache.hadoop.hbase.replication.ReplicationPeers;
 import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.hbase.util.Threads;
 import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
+import org.apache.hadoop.mapreduce.InputSplit;
 import org.apache.hadoop.mapreduce.Job;
+import org.apache.hadoop.mapreduce.MRJobConfig;
 import org.apache.hadoop.mapreduce.lib.output.NullOutputFormat;
 import org.apache.hadoop.util.Tool;
 import org.apache.hadoop.util.ToolRunner;
 
+import com.google.common.annotations.VisibleForTesting;
+
 /**
  * This map-only job compares the data from a local table with a remote one.
  * Every cell is compared and must have exactly the same keys (even timestamp)
@@ -75,18 +84,25 @@ public class VerifyReplication extends Configured implements Tool {
 
   public final static String NAME = "verifyrep";
   private final static String PEER_CONFIG_PREFIX = NAME + ".peer.";
-  static long startTime = 0;
-  static long endTime = Long.MAX_VALUE;
-  static int batch = -1;
-  static int versions = -1;
-  static String tableName = null;
-  static String families = null;
-  static String delimiter = "";
-  static String peerId = null;
-  static String rowPrefixes = null;
-  static int sleepMsBeforeReCompare = 0;
-  static boolean verbose = false;
-  static boolean includeDeletedCells = false;
+  long startTime = 0;
+  long endTime = Long.MAX_VALUE;
+  int batch = -1;
+  int versions = -1;
+  String tableName = null;
+  String families = null;
+  String delimiter = "";
+  String peerId = null;
+  String rowPrefixes = null;
+  int sleepMsBeforeReCompare = 0;
+  boolean verbose = false;
+  boolean includeDeletedCells = false;
+  String sourceSnapshotName = null;
+  String sourceSnapshotTmpDir = null;
+  String peerSnapshotName = null;
+  String peerSnapshotTmpDir = null;
+  String peerFSAddress = null;
+  String peerHBaseRootAddress = null;
+
 
   private final static String JOB_NAME_CONF_KEY = "mapreduce.job.name";
 
@@ -159,7 +175,7 @@ public class VerifyReplication extends Configured implements Tool {
         sourceConnection = ConnectionFactory.createConnection(conf);
         sourceTable = sourceConnection.getTable(tableName);
 
-        final TableSplit tableSplit = (TableSplit)(context.getInputSplit());
+        final InputSplit tableSplit = context.getInputSplit();
 
         String zkClusterKey = conf.get(NAME + ".peerQuorumAddress");
         Configuration peerConf = HBaseConfiguration.createClusterConf(conf,
@@ -168,8 +184,32 @@ public class VerifyReplication extends Configured implements Tool {
         replicatedConnection = ConnectionFactory.createConnection(peerConf);
         replicatedTable = replicatedConnection.getTable(tableName);
         scan.setStartRow(value.getRow());
-        scan.setStopRow(tableSplit.getEndRow());
-        replicatedScanner = replicatedTable.getScanner(scan);
+        
+        byte[] endRow = null;
+        if(tableSplit instanceof TableSnapshotInputFormat.TableSnapshotRegionSplit)
+          endRow = ((TableSnapshotInputFormat.TableSnapshotRegionSplit)tableSplit).getRegionInfo().getEndKey();
+        else
+          endRow = ((TableSplit)tableSplit).getEndRow();
+        
+        String peerSnapshotName = conf.get(NAME + ".peerSnapshotName", null);
+        if(peerSnapshotName!=null)
+        {
+          String peerSnapshotTmpDir = conf.get(NAME + ".peerSnapshotTmpDir", null);
+          String peerFSAddress = conf.get(NAME + ".peerFSAddress", null);
+          String peerHBaseRootAddress = conf.get(NAME + ".peerHBaseRootAddress", null);
+          FileSystem.setDefaultUri(peerConf, peerFSAddress);
+          FSUtils.setRootDir(peerConf, new Path(peerHBaseRootAddress));
+          LOG.info("Using peer snapshot-"+peerSnapshotName +" with temp dir:"+peerSnapshotTmpDir +" peer root uri:"+FSUtils.getRootDir(peerConf)
+            + "     peerFSAddress:"+peerFSAddress);
+          scan.setStopRow(endRow);
+          
+          replicatedScanner = new TableSnapshotScanner(peerConf, new Path(peerFSAddress,peerSnapshotTmpDir), peerSnapshotName, scan);
+        }
+        else
+        {
+          scan.setStopRow(endRow);
+          replicatedScanner = replicatedTable.getScanner(scan);
+        }
         currentCompareRowInPeerTable = replicatedScanner.next();
       }
       while (true) {
@@ -282,7 +322,7 @@ public class VerifyReplication extends Configured implements Tool {
   }
 
   private static Pair<ReplicationPeerConfig, Configuration> getPeerQuorumConfig(
-      final Configuration conf) throws IOException {
+      final Configuration conf, String peerId) throws IOException {
     ZooKeeperWatcher localZKW = null;
     ReplicationPeerZKImpl peer = null;
     try {
@@ -322,7 +362,7 @@ public class VerifyReplication extends Configured implements Tool {
    * @return The newly created job.
    * @throws java.io.IOException When setting up the job fails.
    */
-  public static Job createSubmittableJob(Configuration conf, String[] args)
+  public Job createSubmittableJob(Configuration conf, String[] args)
   throws IOException {
     if (!doCommandLine(args)) {
       return null;
@@ -343,7 +383,7 @@ public class VerifyReplication extends Configured implements Tool {
       conf.set(NAME+".rowPrefixes", rowPrefixes);
     }
 
-    Pair<ReplicationPeerConfig, Configuration> peerConfigPair = getPeerQuorumConfig(conf);
+    Pair<ReplicationPeerConfig, Configuration> peerConfigPair = getPeerQuorumConfig(conf, peerId);
     ReplicationPeerConfig peerConfig = peerConfigPair.getFirst();
     String peerQuorumAddress = peerConfig.getClusterKey();
     LOG.info("Peer Quorum Address: " + peerQuorumAddress + ", Peer Configuration: " +
@@ -354,6 +394,19 @@ public class VerifyReplication extends Configured implements Tool {
 
     conf.setInt(NAME + ".versions", versions);
     LOG.info("Number of version: " + versions);
+    
+    //Set Snapshot specific parameters  
+    if(peerSnapshotName!=null)
+    {
+      conf.set(NAME+".peerSnapshotName", peerSnapshotName);
+      conf.set(NAME+".peerSnapshotTmpDir", peerSnapshotTmpDir);
+      conf.set(NAME+".peerFSAddress", peerFSAddress);
+      conf.set(NAME+".peerHBaseRootAddress", peerHBaseRootAddress);
+      
+      //This is to create HDFS delegation token for peer cluster in case of secured
+      conf.setStrings(MRJobConfig.JOB_NAMENODES, peerFSAddress);
+    }
+    
 
     Job job = Job.getInstance(conf, conf.get(JOB_NAME_CONF_KEY, NAME + "_" + tableName));
     job.setJarByClass(VerifyReplication.class);
@@ -378,8 +431,20 @@ public class VerifyReplication extends Configured implements Tool {
 
     setRowPrefixFilter(scan, rowPrefixes);
 
-    TableMapReduceUtil.initTableMapperJob(tableName, scan,
-        Verifier.class, null, null, job);
+    if(sourceSnapshotName!=null)
+    {
+      Path snapshotTempPath = new Path(sourceSnapshotTmpDir);
+      LOG.info("Using source snapshot-"+sourceSnapshotName +" with temp dir:"+sourceSnapshotTmpDir);
+      //deleteDirectories(conf, snapshotTempPath);
+      TableMapReduceUtil.addTableCoprocessorJarsToClasspath(job.getConfiguration(), TableName.valueOf(tableName));
+      TableMapReduceUtil.initTableSnapshotMapperJob(sourceSnapshotName,
+            scan, Verifier.class, null, null, job, true, snapshotTempPath);
+    }
+    else
+    {
+      TableMapReduceUtil.initTableMapperJob(tableName, scan,
+              Verifier.class, null, null, job);
+    }
 
     Configuration peerClusterConf = peerConfigPair.getSecond();
     // Obtain the auth token from peer cluster
@@ -413,15 +478,12 @@ public class VerifyReplication extends Configured implements Tool {
     scan.setStopRow(stopRow);
   }
 
-  private static boolean doCommandLine(final String[] args) {
+  @VisibleForTesting
+  public boolean doCommandLine(final String[] args) {
     if (args.length < 2) {
       printUsage(null);
       return false;
     }
-    //in case we've been run before, restore all parameters to their initial states
-    //Otherwise, if our previous run included a parameter not in args this time,
-    //we might hold on to the old value.
-    restoreDefaults();
     try {
       for (int i = 0; i < args.length; i++) {
         String cmd = args[i];
@@ -487,10 +549,47 @@ public class VerifyReplication extends Configured implements Tool {
         if (cmd.startsWith(verboseKey)) {
           verbose = true;
           continue;
-        }        
+        }
+        
+        final String sourceSnapshotNameArgKey = "--sourceSnapshotName=";
+        if (cmd.startsWith(sourceSnapshotNameArgKey)) {
+          sourceSnapshotName = cmd.substring(sourceSnapshotNameArgKey.length());
+          continue;
+        }
+        
+        final String sourceSnapshotTmpDirArgKey = "--sourceSnapshotTmpDir=";
+        if (cmd.startsWith(sourceSnapshotTmpDirArgKey)) {
+          sourceSnapshotTmpDir = cmd.substring(sourceSnapshotTmpDirArgKey.length());
+          continue;
+        }
+        
+        final String peerSnapshotNameArgKey = "--peerSnapshotName=";
+        if (cmd.startsWith(peerSnapshotNameArgKey)) {
+          peerSnapshotName = cmd.substring(peerSnapshotNameArgKey.length());
+          continue;
+        }
+        
+        final String peerSnapshotTmpDirArgKey = "--peerSnapshotTmpDir=";
+        if (cmd.startsWith(peerSnapshotTmpDirArgKey)) {
+          peerSnapshotTmpDir = cmd.substring(peerSnapshotTmpDirArgKey.length());
+          continue;
+        }
+        
+        final String peerFSAddressArgKey = "--peerFSAddress=";
+        if (cmd.startsWith(peerFSAddressArgKey)) {
+          peerFSAddress = cmd.substring(peerFSAddressArgKey.length());
+          continue;
+        }
+        
+        final String peerHBaseRootAddressArgKey = "--peerHBaseRootAddress=";
+        if (cmd.startsWith(peerHBaseRootAddressArgKey)) {
+          peerHBaseRootAddress = cmd.substring(peerHBaseRootAddressArgKey.length());
+          continue;
+        }
 
         if (cmd.startsWith("--")) {
           printUsage("Invalid argument '" + cmd + "'");
+          return false;
         }
 
         if (i == args.length-2) {
@@ -501,6 +600,33 @@ public class VerifyReplication extends Configured implements Tool {
           tableName = cmd;
         }
       }
+      
+      
+      if ((sourceSnapshotName != null && sourceSnapshotTmpDir == null)
+          || (sourceSnapshotName == null && sourceSnapshotTmpDir != null)) {
+        printUsage(
+          "Source snapshot name and snapshot temp location should be provided to use snapshots in source cluster");
+        return false;
+      }
+
+      if (peerSnapshotName != null || peerSnapshotTmpDir != null || peerFSAddress != null
+          || peerHBaseRootAddress != null) {
+        if (peerSnapshotName == null || peerSnapshotTmpDir == null || peerFSAddress == null
+            || peerHBaseRootAddress == null) {
+          printUsage(
+            "Peer snapshot name, peer snapshot temp location, Peer HBase root address and  peer FSAddress should be provided to use snapshots in peer cluster");
+          return false;
+        }
+      }
+      
+      //This is to avoid making recompare calls to source/peer tables when snapshots is used
+      if((sourceSnapshotName!=null || peerSnapshotName!=null) && sleepMsBeforeReCompare>0)
+      {
+        printUsage(
+            "Using sleepMsBeforeReCompare along with snapshots is not allowed as snapshots are immutable");
+          return false;
+      }
+
     } catch (Exception e) {
       e.printStackTrace();
       printUsage("Can't start because " + e.getMessage());
@@ -509,18 +635,6 @@ public class VerifyReplication extends Configured implements Tool {
     return true;
   }
 
-  private static void restoreDefaults() {
-    startTime = 0;
-    endTime = Long.MAX_VALUE;
-    batch = -1;
-    versions = -1;
-    tableName = null;
-    families = null;
-    peerId = null;
-    rowPrefixes = null;
-    includeDeletedCells = false;
-  }
-
   /*
    * @param errorMsg Error message.  Can be null.
    */
@@ -530,7 +644,8 @@ public class VerifyReplication extends Configured implements Tool {
     }
     System.err.println("Usage: verifyrep [--starttime=X]" +
         " [--endtime=Y] [--families=A] [--row-prefixes=B] [--delimiter=] [--recomparesleep=] " +
-        "[--batch=] [--verbose] <peerid> <tablename>");
+        "[--batch=] [--verbose] [--sourceSnapshotName=P] [--sourceSnapshotTmpDir=Q] [--peerSnapshotName=R] "
+            + "[--peerSnapshotTmpDir=S] [--peerFSAddress=T] [--peerHBaseRootAddress=U]  <peerid> <tablename>");
     System.err.println();
     System.err.println("Options:");
     System.err.println(" starttime    beginning of the time range");
@@ -546,6 +661,12 @@ public class VerifyReplication extends Configured implements Tool {
     System.err.println(" recomparesleep   milliseconds to sleep before recompare row, " +
         "default value is 0 which disables the recompare.");
     System.err.println(" verbose      logs row keys of good rows");
+    System.err.println(" sourceSnapshotName  Source Snapshot Name");
+    System.err.println(" sourceSnapshotTmpDir Tmp location to restore source table snapshot");
+    System.err.println(" peerSnapshotName  Peer Snapshot Name");
+    System.err.println(" peerSnapshotTmpDir Tmp location to restore peer table snapshot");
+    System.err.println(" peerFSAddress      Peer cluster Hadoop FS address");
+    System.err.println(" peerHBaseRootAddress  Peer cluster HBase root location");
     System.err.println();
     System.err.println("Args:");
     System.err.println(" peerid       Id of the peer used for verification, must match the one given for replication");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
index 1c5a994..21418db 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
@@ -18,10 +18,7 @@
 
 package org.apache.hadoop.hbase.replication;
 
-import static org.junit.Assert.assertArrayEquals;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
+import static org.junit.Assert.*;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -33,6 +30,8 @@ import java.util.TreeMap;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.Cell;
 import org.apache.hadoop.hbase.CellUtil;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
@@ -59,10 +58,12 @@ import org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl;
 import org.apache.hadoop.hbase.regionserver.wal.WALEdit;
 import org.apache.hadoop.hbase.replication.regionserver.Replication;
 import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos;
+import org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils;
 import org.apache.hadoop.hbase.testclassification.LargeTests;
 import org.apache.hadoop.hbase.testclassification.ReplicationTests;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
+import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.JVMClusterUtil;
 import org.apache.hadoop.hbase.wal.WAL;
 import org.apache.hadoop.hbase.wal.WALKey;
@@ -73,6 +74,8 @@ import org.junit.Test;
 import org.junit.experimental.categories.Category;
 import org.junit.rules.TestName;
 
+import com.google.common.collect.Lists;
+
 @Category({ReplicationTests.class, LargeTests.class})
 public class TestReplicationSmallTests extends TestReplicationBase {
 
@@ -593,7 +596,7 @@ public class TestReplicationSmallTests extends TestReplicationBase {
 
   private void runVerifyReplication(String[] args, int expectedGoodRows, int expectedBadRows)
       throws IOException, InterruptedException, ClassNotFoundException {
-    Job job = VerifyReplication.createSubmittableJob(new Configuration(CONF_WITH_LOCALFS), args);
+    Job job = new VerifyReplication().createSubmittableJob(new Configuration(conf1), args);
     if (job == null) {
       fail("Job wasn't created, see the log");
     }
@@ -863,5 +866,125 @@ public class TestReplicationSmallTests extends TestReplicationBase {
         tableName.getNameAsString()};
     runVerifyReplication(args, NB_ROWS_IN_BATCH *2, 0);
   }
+  
+  @Test(timeout = 300000)
+  public void testVerifyReplicationSnapshotArguments()
+  {
+    String[] args = new String[] { "--sourceSnapshotName=snapshot1", 
+        "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--sourceSnapshotTmpDir=tmp", 
+        "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--sourceSnapshotName=snapshot1", 
+        "--sourceSnapshotTmpDir=tmp",
+        "2", tableName.getNameAsString() };
+    assertTrue(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--peerSnapshotName=snapshot1", 
+        "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--peerSnapshotTmpDir=/tmp/", 
+        "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--peerSnapshotName=snapshot1", 
+        "--peerSnapshotTmpDir=/tmp/", "--peerFSAddress=tempfs","--peerHBaseRootAddress=hdfs://tempfs:50070/hbase/",
+        "2", tableName.getNameAsString() };
+    assertTrue(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--sourceSnapshotName=snapshot1", 
+        "--sourceSnapshotTmpDir=/tmp/", "--peerSnapshotName=snapshot2", "--peerSnapshotTmpDir=/tmp/",
+        "--peerFSAddress=tempfs","--peerHBaseRootAddress=hdfs://tempfs:50070/hbase/",
+        "2", tableName.getNameAsString() };
+    
+    assertTrue(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+  }
+  
+  @Test(timeout = 300000)
+  public void testVerifyReplicationWithSnapshotSupport() throws Exception {
+    // Populate the tables, at the same time it guarantees that the tables are
+    // identical since it does the check
+    testSmallBatch();
+    
+    //Take source and target tables snapshot
+    Path rootDir = FSUtils.getRootDir(conf1);
+    FileSystem fs = rootDir.getFileSystem(conf1);
+    String sourceSnapshotName = "sourceSnapshot-"+System.currentTimeMillis();
+    SnapshotTestingUtils.createSnapshotAndValidate(utility1.getHBaseAdmin(), tableName,
+      new String(famName), sourceSnapshotName, rootDir, fs, true);
+
+    //Take target snapshot
+    Path peerRootDir = FSUtils.getRootDir(conf2);
+    FileSystem peerFs = peerRootDir.getFileSystem(conf2);
+    String peerSnapshotName = "peerSnapshot-"+System.currentTimeMillis();
+    SnapshotTestingUtils.createSnapshotAndValidate(utility2.getHBaseAdmin(), tableName,
+      new String(famName), peerSnapshotName, peerRootDir, peerFs, true);
+    
+    String peerFSAddress = peerFs.getUri().toString();
+    String temPath1 = utility1.getRandomDir().toString();
+    String temPath2 = "/tmp2";
+
+    String[] args = new String[] { "--sourceSnapshotName="+sourceSnapshotName, 
+        "--sourceSnapshotTmpDir="+temPath1, "--peerSnapshotName="+peerSnapshotName, "--peerSnapshotTmpDir="+temPath2,
+        "--peerFSAddress="+peerFSAddress, "--peerHBaseRootAddress="+FSUtils.getRootDir(conf2),
+        "2", tableName.getNameAsString() };
+    
+    Job job = new VerifyReplication().createSubmittableJob(conf1, args);
+    if (job == null) {
+      fail("Job wasn't created, see the log");
+    }
+    if (!job.waitForCompletion(true)) {
+      fail("Job failed, see the log");
+    }
+    assertEquals(NB_ROWS_IN_BATCH, job.getCounters().
+        findCounter(VerifyReplication.Verifier.Counters.GOODROWS).getValue());
+    assertEquals(0, job.getCounters().
+        findCounter(VerifyReplication.Verifier.Counters.BADROWS).getValue());
+
+    Scan scan = new Scan();
+    ResultScanner rs = htable2.getScanner(scan);
+    Put put = null;
+    for (Result result : rs) {
+      put = new Put(result.getRow());
+      Cell firstVal = result.rawCells()[0];
+      put.addColumn(CellUtil.cloneFamily(firstVal), CellUtil.cloneQualifier(firstVal),
+        Bytes.toBytes("diff data"));
+      htable2.put(put);
+    }
+    Delete delete = new Delete(put.getRow());
+    htable2.delete(delete);
+    
+    sourceSnapshotName = "sourceSnapshot-"+System.currentTimeMillis();
+    SnapshotTestingUtils.createSnapshotAndValidate(utility1.getHBaseAdmin(), tableName,
+      new String(famName), sourceSnapshotName, rootDir, fs, true);
+    
+    peerSnapshotName = "peerSnapshot-"+System.currentTimeMillis();
+    SnapshotTestingUtils.createSnapshotAndValidate(utility2.getHBaseAdmin(), tableName,
+      new String(famName), peerSnapshotName, peerRootDir, peerFs, true);
+    
+    args = new String[] { "--sourceSnapshotName="+sourceSnapshotName, 
+        "--sourceSnapshotTmpDir="+temPath1, "--peerSnapshotName="+peerSnapshotName, "--peerSnapshotTmpDir="+temPath2,
+        "--peerFSAddress="+peerFSAddress, "--peerHBaseRootAddress="+FSUtils.getRootDir(conf2),
+        "2", tableName.getNameAsString() };
+    
+    job = new VerifyReplication().createSubmittableJob(conf1, args);
+    if (job == null) {
+      fail("Job wasn't created, see the log");
+    }
+    if (!job.waitForCompletion(true)) {
+      fail("Job failed, see the log");
+    }
+    assertEquals(0, job.getCounters().
+        findCounter(VerifyReplication.Verifier.Counters.GOODROWS).getValue());
+    assertEquals(NB_ROWS_IN_BATCH, job.getCounters().
+        findCounter(VerifyReplication.Verifier.Counters.BADROWS).getValue());
+  
+    
+  }
+
 
 }
-- 
2.0.1


From 052059fd310a054be5914787918bcda97eee64db Mon Sep 17 00:00:00 2001
From: Sukumar Maddineni <sukunaidu@gmail.com>
Date: Thu, 27 Apr 2017 18:22:40 -0700
Subject: [PATCH 2/2] #HBASE-16466 Snapshot support in VerifyRep - review
 comments related to format and unused imports

---
 .../hadoop/hbase/mapreduce/TableMapReduceUtil.java |  21 ++--
 .../hbase/mapreduce/TableSnapshotInputFormat.java  |   3 +-
 .../mapreduce/replication/VerifyReplication.java   |  57 +++++-----
 .../replication/TestReplicationSmallTests.java     | 123 ++++++++++-----------
 4 files changed, 98 insertions(+), 106 deletions(-)

diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java
index b131c81..fa29c43 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java
@@ -46,7 +46,6 @@ import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.client.ClusterConnection;
 import org.apache.hadoop.hbase.client.Connection;
 import org.apache.hadoop.hbase.client.ConnectionFactory;
-import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.client.Table;
@@ -807,34 +806,28 @@ public class TableMapReduceUtil {
    * @param tableName
    * @throws IOException
    */
-  public static void addTableCoprocessorJarsToClasspath(Configuration conf,
-      TableName tableName) throws IOException
-  {
+  public static void addTableCoprocessorJarsToClasspath(Configuration conf, TableName tableName)
+      throws IOException {
     ClusterConnection connection = null;
     Table table = null;
     try {
       connection = (ClusterConnection) ConnectionFactory.createConnection(conf);
       table = connection.getTable(tableName);
-      List<String> coprocessorClasses = table.getTableDescriptor()
-          .getCoprocessors();
+      List<String> coprocessorClasses = table.getTableDescriptor().getCoprocessors();
       if (coprocessorClasses != null && coprocessorClasses.size() > 0) {
         Class[] classes = new Class[coprocessorClasses.size()];
         int i = 0;
         for (String coprocessor : coprocessorClasses) {
-          LOG.debug("Adding coprocessor "+coprocessor+" to classpath");
+          LOG.debug("Adding coprocessor " + coprocessor + " to classpath");
           classes[i++] = Class.forName(coprocessor);
         }
         addDependencyJarsForClasses(conf, classes);
       }
     } catch (ClassNotFoundException e) {
       throw new IOException(e);
-    }
-    finally
-    {
-      if (table != null)
-        table.close();
-      if(connection!=null)
-        connection.close();
+    } finally {
+      if (table != null) table.close();
+      if (connection != null) connection.close();
     }
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
index aa8c584..8c06345 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
@@ -121,8 +121,7 @@ public class TableSnapshotInputFormat extends InputFormat<ImmutableBytesWritable
       delegate.readFields(in);
     }
     
-    public HRegionInfo getRegionInfo()
-    {
+    public HRegionInfo getRegionInfo() {
       return delegate.getRegionInfo();
     }
   }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java
index 511c46b..b651e8f 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java
@@ -96,11 +96,17 @@ public class VerifyReplication extends Configured implements Tool {
   int sleepMsBeforeReCompare = 0;
   boolean verbose = false;
   boolean includeDeletedCells = false;
+  //Source table snapshot name
   String sourceSnapshotName = null;
+  //Temp location in source cluster to restore source snapshot
   String sourceSnapshotTmpDir = null;
+  //Peer table snapshot name
   String peerSnapshotName = null;
+  //Temp location in peer cluster to restore peer snapshot
   String peerSnapshotTmpDir = null;
+  //Peer cluster Hadoop FS address
   String peerFSAddress = null;
+  //Peer cluster HBase root dir location
   String peerHBaseRootAddress = null;
 
 
@@ -186,28 +192,29 @@ public class VerifyReplication extends Configured implements Tool {
         scan.setStartRow(value.getRow());
         
         byte[] endRow = null;
-        if(tableSplit instanceof TableSnapshotInputFormat.TableSnapshotRegionSplit)
-          endRow = ((TableSnapshotInputFormat.TableSnapshotRegionSplit)tableSplit).getRegionInfo().getEndKey();
-        else
-          endRow = ((TableSplit)tableSplit).getEndRow();
-        
+        if (tableSplit instanceof TableSnapshotInputFormat.TableSnapshotRegionSplit) {
+          endRow = ((TableSnapshotInputFormat.TableSnapshotRegionSplit) tableSplit).getRegionInfo()
+              .getEndKey();
+        } else {
+          endRow = ((TableSplit) tableSplit).getEndRow();
+        }
+
+        scan.setStopRow(endRow);
+
         String peerSnapshotName = conf.get(NAME + ".peerSnapshotName", null);
-        if(peerSnapshotName!=null)
-        {
+        if (peerSnapshotName != null) {
           String peerSnapshotTmpDir = conf.get(NAME + ".peerSnapshotTmpDir", null);
           String peerFSAddress = conf.get(NAME + ".peerFSAddress", null);
           String peerHBaseRootAddress = conf.get(NAME + ".peerHBaseRootAddress", null);
           FileSystem.setDefaultUri(peerConf, peerFSAddress);
           FSUtils.setRootDir(peerConf, new Path(peerHBaseRootAddress));
-          LOG.info("Using peer snapshot-"+peerSnapshotName +" with temp dir:"+peerSnapshotTmpDir +" peer root uri:"+FSUtils.getRootDir(peerConf)
-            + "     peerFSAddress:"+peerFSAddress);
-          scan.setStopRow(endRow);
-          
-          replicatedScanner = new TableSnapshotScanner(peerConf, new Path(peerFSAddress,peerSnapshotTmpDir), peerSnapshotName, scan);
-        }
-        else
-        {
-          scan.setStopRow(endRow);
+          LOG.info("Using peer snapshot:" + peerSnapshotName + " with temp dir:"
+              + peerSnapshotTmpDir + " peer root uri:" + FSUtils.getRootDir(peerConf)
+              + " peerFSAddress:" + peerFSAddress);
+
+          replicatedScanner = new TableSnapshotScanner(peerConf,
+              new Path(peerFSAddress, peerSnapshotTmpDir), peerSnapshotName, scan);
+        } else {
           replicatedScanner = replicatedTable.getScanner(scan);
         }
         currentCompareRowInPeerTable = replicatedScanner.next();
@@ -604,8 +611,8 @@ public class VerifyReplication extends Configured implements Tool {
       
       if ((sourceSnapshotName != null && sourceSnapshotTmpDir == null)
           || (sourceSnapshotName == null && sourceSnapshotTmpDir != null)) {
-        printUsage(
-          "Source snapshot name and snapshot temp location should be provided to use snapshots in source cluster");
+        printUsage("Source snapshot name and snapshot temp location should be provided"
+            + " to use snapshots in source cluster");
         return false;
       }
 
@@ -614,17 +621,17 @@ public class VerifyReplication extends Configured implements Tool {
         if (peerSnapshotName == null || peerSnapshotTmpDir == null || peerFSAddress == null
             || peerHBaseRootAddress == null) {
           printUsage(
-            "Peer snapshot name, peer snapshot temp location, Peer HBase root address and  peer FSAddress should be provided to use snapshots in peer cluster");
+            "Peer snapshot name, peer snapshot temp location, Peer HBase root address and  "
+                + "peer FSAddress should be provided to use snapshots in peer cluster");
           return false;
         }
       }
-      
-      //This is to avoid making recompare calls to source/peer tables when snapshots is used
-      if((sourceSnapshotName!=null || peerSnapshotName!=null) && sleepMsBeforeReCompare>0)
-      {
+
+      // This is to avoid making recompare calls to source/peer tables when snapshots are used
+      if ((sourceSnapshotName != null || peerSnapshotName != null) && sleepMsBeforeReCompare > 0) {
         printUsage(
-            "Using sleepMsBeforeReCompare along with snapshots is not allowed as snapshots are immutable");
-          return false;
+          "Using sleepMsBeforeReCompare along with snapshots is not allowed as snapshots are immutable");
+        return false;
       }
 
     } catch (Exception e) {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
index 21418db..adcd54e 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
@@ -868,40 +868,34 @@ public class TestReplicationSmallTests extends TestReplicationBase {
   }
   
   @Test(timeout = 300000)
-  public void testVerifyReplicationSnapshotArguments()
-  {
-    String[] args = new String[] { "--sourceSnapshotName=snapshot1", 
-        "2", tableName.getNameAsString() };
-    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
-    
-    args = new String[] { "--sourceSnapshotTmpDir=tmp", 
-        "2", tableName.getNameAsString() };
-    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
-    
-    args = new String[] { "--sourceSnapshotName=snapshot1", 
-        "--sourceSnapshotTmpDir=tmp",
-        "2", tableName.getNameAsString() };
-    assertTrue(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
-    
-    args = new String[] { "--peerSnapshotName=snapshot1", 
-        "2", tableName.getNameAsString() };
-    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
-    
-    args = new String[] { "--peerSnapshotTmpDir=/tmp/", 
-        "2", tableName.getNameAsString() };
-    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
-    
-    args = new String[] { "--peerSnapshotName=snapshot1", 
-        "--peerSnapshotTmpDir=/tmp/", "--peerFSAddress=tempfs","--peerHBaseRootAddress=hdfs://tempfs:50070/hbase/",
-        "2", tableName.getNameAsString() };
-    assertTrue(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
-    
-    args = new String[] { "--sourceSnapshotName=snapshot1", 
-        "--sourceSnapshotTmpDir=/tmp/", "--peerSnapshotName=snapshot2", "--peerSnapshotTmpDir=/tmp/",
-        "--peerFSAddress=tempfs","--peerHBaseRootAddress=hdfs://tempfs:50070/hbase/",
-        "2", tableName.getNameAsString() };
-    
-    assertTrue(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+  public void testVerifyReplicationSnapshotArguments() {
+    String[] args =
+        new String[] { "--sourceSnapshotName=snapshot1", "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(), new VerifyReplication().doCommandLine(args));
+
+    args = new String[] { "--sourceSnapshotTmpDir=tmp", "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(), new VerifyReplication().doCommandLine(args));
+
+    args = new String[] { "--sourceSnapshotName=snapshot1", "--sourceSnapshotTmpDir=tmp", "2",
+        tableName.getNameAsString() };
+    assertTrue(Lists.newArrayList(args).toString(), new VerifyReplication().doCommandLine(args));
+
+    args = new String[] { "--peerSnapshotName=snapshot1", "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(), new VerifyReplication().doCommandLine(args));
+
+    args = new String[] { "--peerSnapshotTmpDir=/tmp/", "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(), new VerifyReplication().doCommandLine(args));
+
+    args = new String[] { "--peerSnapshotName=snapshot1", "--peerSnapshotTmpDir=/tmp/",
+        "--peerFSAddress=tempfs", "--peerHBaseRootAddress=hdfs://tempfs:50070/hbase/", "2",
+        tableName.getNameAsString() };
+    assertTrue(Lists.newArrayList(args).toString(), new VerifyReplication().doCommandLine(args));
+
+    args = new String[] { "--sourceSnapshotName=snapshot1", "--sourceSnapshotTmpDir=/tmp/",
+        "--peerSnapshotName=snapshot2", "--peerSnapshotTmpDir=/tmp/", "--peerFSAddress=tempfs",
+        "--peerHBaseRootAddress=hdfs://tempfs:50070/hbase/", "2", tableName.getNameAsString() };
+
+    assertTrue(Lists.newArrayList(args).toString(), new VerifyReplication().doCommandLine(args));
   }
   
   @Test(timeout = 300000)
@@ -909,30 +903,30 @@ public class TestReplicationSmallTests extends TestReplicationBase {
     // Populate the tables, at the same time it guarantees that the tables are
     // identical since it does the check
     testSmallBatch();
-    
-    //Take source and target tables snapshot
+
+    // Take source and target tables snapshot
     Path rootDir = FSUtils.getRootDir(conf1);
     FileSystem fs = rootDir.getFileSystem(conf1);
-    String sourceSnapshotName = "sourceSnapshot-"+System.currentTimeMillis();
+    String sourceSnapshotName = "sourceSnapshot-" + System.currentTimeMillis();
     SnapshotTestingUtils.createSnapshotAndValidate(utility1.getHBaseAdmin(), tableName,
       new String(famName), sourceSnapshotName, rootDir, fs, true);
 
-    //Take target snapshot
+    // Take target snapshot
     Path peerRootDir = FSUtils.getRootDir(conf2);
     FileSystem peerFs = peerRootDir.getFileSystem(conf2);
-    String peerSnapshotName = "peerSnapshot-"+System.currentTimeMillis();
+    String peerSnapshotName = "peerSnapshot-" + System.currentTimeMillis();
     SnapshotTestingUtils.createSnapshotAndValidate(utility2.getHBaseAdmin(), tableName,
       new String(famName), peerSnapshotName, peerRootDir, peerFs, true);
-    
+
     String peerFSAddress = peerFs.getUri().toString();
     String temPath1 = utility1.getRandomDir().toString();
     String temPath2 = "/tmp2";
 
-    String[] args = new String[] { "--sourceSnapshotName="+sourceSnapshotName, 
-        "--sourceSnapshotTmpDir="+temPath1, "--peerSnapshotName="+peerSnapshotName, "--peerSnapshotTmpDir="+temPath2,
-        "--peerFSAddress="+peerFSAddress, "--peerHBaseRootAddress="+FSUtils.getRootDir(conf2),
-        "2", tableName.getNameAsString() };
-    
+    String[] args = new String[] { "--sourceSnapshotName=" + sourceSnapshotName,
+        "--sourceSnapshotTmpDir=" + temPath1, "--peerSnapshotName=" + peerSnapshotName,
+        "--peerSnapshotTmpDir=" + temPath2, "--peerFSAddress=" + peerFSAddress,
+        "--peerHBaseRootAddress=" + FSUtils.getRootDir(conf2), "2", tableName.getNameAsString() };
+
     Job job = new VerifyReplication().createSubmittableJob(conf1, args);
     if (job == null) {
       fail("Job wasn't created, see the log");
@@ -940,10 +934,10 @@ public class TestReplicationSmallTests extends TestReplicationBase {
     if (!job.waitForCompletion(true)) {
       fail("Job failed, see the log");
     }
-    assertEquals(NB_ROWS_IN_BATCH, job.getCounters().
-        findCounter(VerifyReplication.Verifier.Counters.GOODROWS).getValue());
-    assertEquals(0, job.getCounters().
-        findCounter(VerifyReplication.Verifier.Counters.BADROWS).getValue());
+    assertEquals(NB_ROWS_IN_BATCH,
+      job.getCounters().findCounter(VerifyReplication.Verifier.Counters.GOODROWS).getValue());
+    assertEquals(0,
+      job.getCounters().findCounter(VerifyReplication.Verifier.Counters.BADROWS).getValue());
 
     Scan scan = new Scan();
     ResultScanner rs = htable2.getScanner(scan);
@@ -957,20 +951,20 @@ public class TestReplicationSmallTests extends TestReplicationBase {
     }
     Delete delete = new Delete(put.getRow());
     htable2.delete(delete);
-    
-    sourceSnapshotName = "sourceSnapshot-"+System.currentTimeMillis();
+
+    sourceSnapshotName = "sourceSnapshot-" + System.currentTimeMillis();
     SnapshotTestingUtils.createSnapshotAndValidate(utility1.getHBaseAdmin(), tableName,
       new String(famName), sourceSnapshotName, rootDir, fs, true);
-    
-    peerSnapshotName = "peerSnapshot-"+System.currentTimeMillis();
+
+    peerSnapshotName = "peerSnapshot-" + System.currentTimeMillis();
     SnapshotTestingUtils.createSnapshotAndValidate(utility2.getHBaseAdmin(), tableName,
       new String(famName), peerSnapshotName, peerRootDir, peerFs, true);
-    
-    args = new String[] { "--sourceSnapshotName="+sourceSnapshotName, 
-        "--sourceSnapshotTmpDir="+temPath1, "--peerSnapshotName="+peerSnapshotName, "--peerSnapshotTmpDir="+temPath2,
-        "--peerFSAddress="+peerFSAddress, "--peerHBaseRootAddress="+FSUtils.getRootDir(conf2),
-        "2", tableName.getNameAsString() };
-    
+
+    args = new String[] { "--sourceSnapshotName=" + sourceSnapshotName,
+        "--sourceSnapshotTmpDir=" + temPath1, "--peerSnapshotName=" + peerSnapshotName,
+        "--peerSnapshotTmpDir=" + temPath2, "--peerFSAddress=" + peerFSAddress,
+        "--peerHBaseRootAddress=" + FSUtils.getRootDir(conf2), "2", tableName.getNameAsString() };
+
     job = new VerifyReplication().createSubmittableJob(conf1, args);
     if (job == null) {
       fail("Job wasn't created, see the log");
@@ -978,12 +972,11 @@ public class TestReplicationSmallTests extends TestReplicationBase {
     if (!job.waitForCompletion(true)) {
       fail("Job failed, see the log");
     }
-    assertEquals(0, job.getCounters().
-        findCounter(VerifyReplication.Verifier.Counters.GOODROWS).getValue());
-    assertEquals(NB_ROWS_IN_BATCH, job.getCounters().
-        findCounter(VerifyReplication.Verifier.Counters.BADROWS).getValue());
-  
-    
+    assertEquals(0,
+      job.getCounters().findCounter(VerifyReplication.Verifier.Counters.GOODROWS).getValue());
+    assertEquals(NB_ROWS_IN_BATCH,
+      job.getCounters().findCounter(VerifyReplication.Verifier.Counters.BADROWS).getValue());
+
   }
 
 
-- 
2.0.1

