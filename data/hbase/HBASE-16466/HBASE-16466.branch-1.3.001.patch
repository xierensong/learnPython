From a4cd79589951f989c1fa288f23326a155dfb6e4f Mon Sep 17 00:00:00 2001
From: Sukumar Maddineni <sukunaidu@gmail.com>
Date: Wed, 26 Apr 2017 20:35:36 -0700
Subject: [PATCH] #HBASE-16466 - Snapshot support in VerifyReplication tool

---
 .../hadoop/hbase/mapreduce/TableMapReduceUtil.java |  35 +++++
 .../hbase/mapreduce/TableSnapshotInputFormat.java  |   5 +
 .../mapreduce/replication/VerifyReplication.java   | 165 +++++++++++++++++++--
 .../replication/TestReplicationSmallTests.java     | 145 +++++++++++++++++-
 4 files changed, 326 insertions(+), 24 deletions(-)

diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java
index 9ba1f07..827d79c 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java
@@ -40,6 +40,7 @@ import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.classification.InterfaceStability;
 import org.apache.hadoop.hbase.client.Connection;
 import org.apache.hadoop.hbase.client.ConnectionFactory;
+import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
@@ -904,6 +905,40 @@ public class TableMapReduceUtil {
 
     conf.set("tmpjars", StringUtils.arrayToString(jars.toArray(new String[jars.size()])));
   }
+  
+  
+  /**
+   * Util to add a table related coprocessors classes to M/R job classpath
+   * @param conf
+   * @param tableName
+   * @throws IOException
+   */
+  public static void addTableCoprocessorJarsToClasspath(Configuration conf,
+      TableName tableName) throws IOException
+  {
+    HTable table = null;
+    try {
+      table = new HTable(conf, tableName);
+      List<String> coprocessorClasses = table.getTableDescriptor()
+          .getCoprocessors();
+      if (coprocessorClasses != null && coprocessorClasses.size() > 0) {
+        Class[] classes = new Class[coprocessorClasses.size()];
+        int i = 0;
+        for (String coprocessor : coprocessorClasses) {
+          LOG.debug("Adding coprocessor "+coprocessor+" to classpath");
+          classes[i++] = Class.forName(coprocessor);
+        }
+        addDependencyJarsForClasses(conf, classes);
+      }
+    } catch (ClassNotFoundException e) {
+      throw new IOException(e);
+    }
+    finally
+    {
+      if (table != null)
+        table.close();
+    }
+  }
 
   /**
    * Finds the Jar for a class or creates it if it doesn't exist. If the class is in
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
index c40396f..c14c0b4 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java
@@ -122,6 +122,11 @@ public class TableSnapshotInputFormat extends InputFormat<ImmutableBytesWritable
     public void readFields(DataInput in) throws IOException {
       delegate.readFields(in);
     }
+    
+    public HRegionInfo getRegionInfo()
+    {
+      return delegate.getRegionInfo();
+    }
   }
 
   @VisibleForTesting
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java
index a40de4e..77fbf3c 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java
@@ -24,6 +24,8 @@ import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.conf.Configured;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.*;
 import org.apache.hadoop.hbase.client.HConnectable;
 import org.apache.hadoop.hbase.client.HConnection;
@@ -34,10 +36,12 @@ import org.apache.hadoop.hbase.client.Result;
 import org.apache.hadoop.hbase.client.ResultScanner;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.client.Table;
+import org.apache.hadoop.hbase.client.TableSnapshotScanner;
 import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
 import org.apache.hadoop.hbase.mapreduce.TableInputFormat;
 import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;
 import org.apache.hadoop.hbase.mapreduce.TableMapper;
+import org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormat;
 import org.apache.hadoop.hbase.mapreduce.TableSplit;
 import org.apache.hadoop.hbase.replication.ReplicationException;
 import org.apache.hadoop.hbase.replication.ReplicationFactory;
@@ -45,13 +49,18 @@ import org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl;
 import org.apache.hadoop.hbase.replication.ReplicationPeerConfig;
 import org.apache.hadoop.hbase.replication.ReplicationPeers;
 import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
+import org.apache.hadoop.mapreduce.InputSplit;
 import org.apache.hadoop.mapreduce.Job;
+import org.apache.hadoop.mapreduce.MRJobConfig;
 import org.apache.hadoop.mapreduce.lib.output.NullOutputFormat;
 import org.apache.hadoop.util.Tool;
 import org.apache.hadoop.util.ToolRunner;
 
+import com.google.common.annotations.VisibleForTesting;
+
 /**
  * This map-only job compares the data from a local table with a remote one.
  * Every cell is compared and must have exactly the same keys (even timestamp)
@@ -70,11 +79,18 @@ public class VerifyReplication extends Configured implements Tool {
   public final static String NAME = "verifyrep";
   private final static String PEER_CONFIG_PREFIX = NAME + ".peer.";
   static long startTime = 0;
-  static long endTime = Long.MAX_VALUE;
-  static int versions = -1;
-  static String tableName = null;
-  static String families = null;
-  static String peerId = null;
+  long endTime = Long.MAX_VALUE;
+  int versions = -1;
+  String tableName = null;
+  String families = null;
+  String peerId = null;
+  String sourceSnapshotName = null;
+  String sourceSnapshotTmpDir = null;
+  String peerSnapshotName = null;
+  String peerSnapshotTmpDir = null;
+  String peerFSAddress = null;
+  String peerHBaseRootAddress = null;
+ 
 
   /**
    * Map-only comparator for 2 tables
@@ -121,7 +137,7 @@ public class VerifyReplication extends Configured implements Tool {
           scan.setMaxVersions(versions);
         }
 
-        final TableSplit tableSplit = (TableSplit)(context.getInputSplit());
+        final InputSplit tableSplit = context.getInputSplit();
         HConnectionManager.execute(new HConnectable<Void>(conf) {
           @Override
           public Void connect(HConnection conn) throws IOException {
@@ -131,9 +147,33 @@ public class VerifyReplication extends Configured implements Tool {
 
             TableName tableName = TableName.valueOf(conf.get(NAME + ".tableName"));
             replicatedTable = new HTable(peerConf, tableName);
-            scan.setStartRow(value.getRow());
-            scan.setStopRow(tableSplit.getEndRow());
-            replicatedScanner = replicatedTable.getScanner(scan);
+            byte[] endRow = null;
+            if(tableSplit instanceof TableSnapshotInputFormat.TableSnapshotRegionSplit)
+              endRow = ((TableSnapshotInputFormat.TableSnapshotRegionSplit)tableSplit).getRegionInfo().getEndKey();
+            else
+              endRow = ((TableSplit)tableSplit).getEndRow();
+            
+            String peerSnapshotName = conf.get(NAME + ".peerSnapshotName", null);
+            if(peerSnapshotName!=null)
+            {
+              String peerSnapshotTmpDir = conf.get(NAME + ".peerSnapshotTmpDir", null);
+              String peerFSAddress = conf.get(NAME + ".peerFSAddress", null);
+              String peerHBaseRootAddress = conf.get(NAME + ".peerHBaseRootAddress", null);
+              
+              FileSystem.setDefaultUri(peerConf, peerFSAddress);
+              FSUtils.setRootDir(peerConf, new Path(peerHBaseRootAddress));
+              
+              LOG.info("Using peer snapshot-"+peerSnapshotName +" with temp dir:"+peerSnapshotTmpDir +" peer root uri:"+FSUtils.getRootDir(peerConf)
+                + "     peerFSAddress:"+peerFSAddress);
+              scan.setStopRow(endRow);
+              
+              replicatedScanner = new TableSnapshotScanner(peerConf, new Path(peerFSAddress,peerSnapshotTmpDir), peerSnapshotName, scan);
+            }
+            else
+            {
+              scan.setStopRow(endRow);
+              replicatedScanner = replicatedTable.getScanner(scan);
+            }
             return null;
           }
         });
@@ -203,7 +243,7 @@ public class VerifyReplication extends Configured implements Tool {
     }
   }
 
-  private static Pair<ReplicationPeerConfig, Configuration> getPeerQuorumConfig(
+  private Pair<ReplicationPeerConfig, Configuration> getPeerQuorumConfig(
       final Configuration conf) throws IOException {
     ZooKeeperWatcher localZKW = null;
     ReplicationPeerZKImpl peer = null;
@@ -244,7 +284,7 @@ public class VerifyReplication extends Configured implements Tool {
    * @return The newly created job.
    * @throws java.io.IOException When setting up the job fails.
    */
-  public static Job createSubmittableJob(Configuration conf, String[] args)
+  public Job createSubmittableJob(Configuration conf, String[] args)
   throws IOException {
     if (!doCommandLine(args)) {
       return null;
@@ -272,6 +312,18 @@ public class VerifyReplication extends Configured implements Tool {
 
     conf.setInt(NAME + ".versions", versions);
     LOG.info("Number of version: " + versions);
+    
+    //Set Snapshot specific parameters  
+    if(peerSnapshotName!=null)
+    {
+      conf.set(NAME+".peerSnapshotName", peerSnapshotName);
+      conf.set(NAME+".peerSnapshotTmpDir", peerSnapshotTmpDir);
+      conf.set(NAME+".peerFSAddress", peerFSAddress);
+      conf.set(NAME+".peerHBaseRootAddress", peerHBaseRootAddress);
+      
+      //This is to create HDFS delegation token for peer cluster in case of secured
+      conf.setStrings(MRJobConfig.JOB_NAMENODES, peerFSAddress);
+    }
 
     Job job = new Job(conf, NAME + "_" + tableName);
     job.setJarByClass(VerifyReplication.class);
@@ -288,9 +340,22 @@ public class VerifyReplication extends Configured implements Tool {
         scan.addFamily(Bytes.toBytes(fam));
       }
     }
-    TableMapReduceUtil.initTableMapperJob(tableName, scan,
-        Verifier.class, null, null, job);
-
+    
+    if(sourceSnapshotName!=null)
+    {
+      Path snapshotTempPath = new Path(sourceSnapshotTmpDir);
+      LOG.info("Using source snapshot-"+sourceSnapshotName +" with temp dir:"+sourceSnapshotTmpDir);
+      //deleteDirectories(conf, snapshotTempPath);
+      TableMapReduceUtil.addTableCoprocessorJarsToClasspath(job.getConfiguration(), TableName.valueOf(tableName));
+      TableMapReduceUtil.initTableSnapshotMapperJob(sourceSnapshotName,
+            scan, Verifier.class, null, null, job, true, snapshotTempPath);
+    }
+    else
+    {
+      TableMapReduceUtil.initTableMapperJob(tableName, scan,
+              Verifier.class, null, null, job);
+    }
+    
     Configuration peerClusterConf = peerConfigPair.getSecond();
     // Obtain the auth token from peer cluster
     TableMapReduceUtil.initCredentialsForCluster(job, peerClusterConf);
@@ -300,7 +365,8 @@ public class VerifyReplication extends Configured implements Tool {
     return job;
   }
 
-  private static boolean doCommandLine(final String[] args) {
+  @VisibleForTesting
+  public boolean doCommandLine(final String[] args) {
     if (args.length < 2) {
       printUsage(null);
       return false;
@@ -336,6 +402,48 @@ public class VerifyReplication extends Configured implements Tool {
           families = cmd.substring(familiesArgKey.length());
           continue;
         }
+        
+        final String sourceSnapshotNameArgKey = "--sourceSnapshotName=";
+        if (cmd.startsWith(sourceSnapshotNameArgKey)) {
+          sourceSnapshotName = cmd.substring(sourceSnapshotNameArgKey.length());
+          continue;
+        }
+        
+        final String sourceSnapshotTmpDirArgKey = "--sourceSnapshotTmpDir=";
+        if (cmd.startsWith(sourceSnapshotTmpDirArgKey)) {
+          sourceSnapshotTmpDir = cmd.substring(sourceSnapshotTmpDirArgKey.length());
+          continue;
+        }
+        
+        final String peerSnapshotNameArgKey = "--peerSnapshotName=";
+        if (cmd.startsWith(peerSnapshotNameArgKey)) {
+          peerSnapshotName = cmd.substring(peerSnapshotNameArgKey.length());
+          continue;
+        }
+        
+        final String peerSnapshotTmpDirArgKey = "--peerSnapshotTmpDir=";
+        if (cmd.startsWith(peerSnapshotTmpDirArgKey)) {
+          peerSnapshotTmpDir = cmd.substring(peerSnapshotTmpDirArgKey.length());
+          continue;
+        }
+        
+        final String peerFSAddressArgKey = "--peerFSAddress=";
+        if (cmd.startsWith(peerFSAddressArgKey)) {
+          peerFSAddress = cmd.substring(peerFSAddressArgKey.length());
+          continue;
+        }
+        
+        final String peerHBaseRootAddressArgKey = "--peerHBaseRootAddress=";
+        if (cmd.startsWith(peerHBaseRootAddressArgKey)) {
+          peerHBaseRootAddress = cmd.substring(peerHBaseRootAddressArgKey.length());
+          continue;
+        }
+        
+        if (cmd.startsWith("--")) {
+            printUsage("Invalid argument '" + cmd + "'");
+            return false;
+        }
+
 
         if (i == args.length-2) {
           peerId = cmd;
@@ -345,6 +453,23 @@ public class VerifyReplication extends Configured implements Tool {
           tableName = cmd;
         }
       }
+      
+      if ((sourceSnapshotName != null && sourceSnapshotTmpDir == null)
+          || (sourceSnapshotName == null && sourceSnapshotTmpDir != null)) {
+        printUsage(
+          "Source snapshot name and snapshot temp location should be provided to use snapshots in source cluster");
+        return false;
+      }
+
+      if (peerSnapshotName != null || peerSnapshotTmpDir != null || peerFSAddress != null
+          || peerHBaseRootAddress != null) {
+        if (peerSnapshotName == null || peerSnapshotTmpDir == null || peerFSAddress == null
+            || peerHBaseRootAddress == null) {
+          printUsage(
+            "Peer snapshot name, peer snapshot temp location, Peer HBase root address and  peer FSAddress should be provided to use snapshot in peer cluster");
+          return false;
+        }
+      }
     } catch (Exception e) {
       e.printStackTrace();
       printUsage("Can't start because " + e.getMessage());
@@ -361,7 +486,8 @@ public class VerifyReplication extends Configured implements Tool {
       System.err.println("ERROR: " + errorMsg);
     }
     System.err.println("Usage: verifyrep [--starttime=X]" +
-        " [--stoptime=Y] [--families=A] <peerid> <tablename>");
+        " [--stoptime=Y] [--families=A] [--sourceSnapshotName=P] [--sourceSnapshotTmpDir=Q] [--peerSnapshotName=R] "
+            + "[--peerSnapshotTmpDir=S] [--peerFSAddress=T] [--peerHBaseRootAddress=U] <peerid> <tablename>");
     System.err.println();
     System.err.println("Options:");
     System.err.println(" starttime    beginning of the time range");
@@ -369,6 +495,13 @@ public class VerifyReplication extends Configured implements Tool {
     System.err.println(" endtime      end of the time range");
     System.err.println(" versions     number of cell versions to verify");
     System.err.println(" families     comma-separated list of families to copy");
+    
+    System.err.println(" sourceSnapshotName  Source Snapshot Name");
+    System.err.println(" sourceSnapshotTmpDir Tmp location to restore source table snapshot");
+    System.err.println(" peerSnapshotName  Peer Snapshot Name");
+    System.err.println(" peerSnapshotTmpDir Tmp location to restore peer table snapshot");
+    System.err.println(" peerFSAddress      Peer cluster Hadoop FS address");
+    System.err.println(" peerHBaseRootAddress  Peer cluster HBase root location");
     System.err.println();
     System.err.println("Args:");
     System.err.println(" peerid       Id of the peer used for verification, must match the one given for replication");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
index 42a127f..10e158c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplicationSmallTests.java
@@ -18,18 +18,18 @@
 
 package org.apache.hadoop.hbase.replication;
 
-import static org.junit.Assert.assertArrayEquals;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
+import static org.junit.Assert.*;
 
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.List;
+import java.util.ServiceLoader;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.Cell;
 import org.apache.hadoop.hbase.CellUtil;
 import org.apache.hadoop.hbase.ClusterStatus;
@@ -56,14 +56,22 @@ import org.apache.hadoop.hbase.testclassification.LargeTests;
 import org.apache.hadoop.hbase.wal.WALKey;
 import org.apache.hadoop.hbase.regionserver.wal.WALEdit;
 import org.apache.hadoop.hbase.replication.regionserver.Replication;
+import org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
+import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.JVMClusterUtil;
+import org.apache.hadoop.mapreduce.Cluster;
 import org.apache.hadoop.mapreduce.Job;
+import org.apache.hadoop.mapreduce.JobSubmissionFiles;
+import org.apache.hadoop.mapreduce.filecache.DistributedCache;
+import org.apache.hadoop.mapreduce.protocol.ClientProtocolProvider;
+import org.apache.log4j.LogManager;
 import org.junit.Before;
 import org.junit.Test;
 import org.junit.experimental.categories.Category;
 
+import com.google.common.collect.Lists;
 import com.google.protobuf.ByteString;
 import com.sun.tools.javac.code.Attribute.Array;
 
@@ -458,7 +466,7 @@ public class TestReplicationSmallTests extends TestReplicationBase {
     testSmallBatch();
 
     String[] args = new String[] {"2", tableName.getNameAsString()};
-    Job job = VerifyReplication.createSubmittableJob(CONF_WITH_LOCALFS, args);
+    Job job = new VerifyReplication().createSubmittableJob(CONF_WITH_LOCALFS, args);
     if (job == null) {
       fail("Job wasn't created, see the log");
     }
@@ -482,7 +490,7 @@ public class TestReplicationSmallTests extends TestReplicationBase {
     }
     Delete delete = new Delete(put.getRow());
     htable2.delete(delete);
-    job = VerifyReplication.createSubmittableJob(CONF_WITH_LOCALFS, args);
+    job = new VerifyReplication().createSubmittableJob(CONF_WITH_LOCALFS, args);
     if (job == null) {
       fail("Job wasn't created, see the log");
     }
@@ -555,7 +563,7 @@ public class TestReplicationSmallTests extends TestReplicationBase {
     assertEquals(5, res1[0].getColumnCells(famName, qualifierName).size());
 
     String[] args = new String[] {"--versions=100", "2", tableName.getNameAsString()};
-    Job job = VerifyReplication.createSubmittableJob(CONF_WITH_LOCALFS, args);
+    Job job = new VerifyReplication().createSubmittableJob(CONF_WITH_LOCALFS, args);
     if (job == null) {
       fail("Job wasn't created, see the log");
     }
@@ -630,7 +638,7 @@ public class TestReplicationSmallTests extends TestReplicationBase {
       assertEquals(3, res1[0].getColumnCells(famName, qualifierName).size());
     
       String[] args = new String[] {"--versions=100", "2", tableName.getNameAsString()};
-      Job job = VerifyReplication.createSubmittableJob(CONF_WITH_LOCALFS, args);
+      Job job = new VerifyReplication().createSubmittableJob(CONF_WITH_LOCALFS, args);
       if (job == null) {
         fail("Job wasn't created, see the log");
       }
@@ -758,4 +766,125 @@ public class TestReplicationSmallTests extends TestReplicationBase {
       }
     }
   }
+  
+  
+  @Test(timeout = 300000)
+  public void testVerifyReplicationSnapshotArguments()
+  {
+    String[] args = new String[] { "--sourceSnapshotName=snapshot1", 
+        "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--sourceSnapshotTmpDir=tmp", 
+        "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--sourceSnapshotName=snapshot1", 
+        "--sourceSnapshotTmpDir=tmp",
+        "2", tableName.getNameAsString() };
+    assertTrue(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--peerSnapshotName=snapshot1", 
+        "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--peerSnapshotTmpDir=/tmp/", 
+        "2", tableName.getNameAsString() };
+    assertFalse(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--peerSnapshotName=snapshot1", 
+        "--peerSnapshotTmpDir=/tmp/", "--peerFSAddress=tempfs","--peerHBaseRootAddress=hdfs://tempfs:50070/hbase/",
+        "2", tableName.getNameAsString() };
+    assertTrue(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+    
+    args = new String[] { "--sourceSnapshotName=snapshot1", 
+        "--sourceSnapshotTmpDir=/tmp/", "--peerSnapshotName=snapshot2", "--peerSnapshotTmpDir=/tmp/",
+        "--peerFSAddress=tempfs","--peerHBaseRootAddress=hdfs://tempfs:50070/hbase/",
+        "2", tableName.getNameAsString() };
+    
+    assertTrue(Lists.newArrayList(args).toString(),new VerifyReplication().doCommandLine(args));
+  }
+  
+  @Test(timeout = 300000)
+  public void testVerifyReplicationWithSnapshotSupport() throws Exception {
+
+    // Populate the tables, at the same time it guarantees that the tables are
+    // identical since it does the check
+    testSmallBatch();
+    
+    //Take source and target tables snapshot
+    Path rootDir = FSUtils.getRootDir(conf1);
+    FileSystem fs = rootDir.getFileSystem(conf1);
+    String sourceSnapshotName = "sourceSnapshot-"+System.currentTimeMillis();
+    SnapshotTestingUtils.createSnapshotAndValidate(utility1.getHBaseAdmin(), tableName,
+      new String(famName), sourceSnapshotName, rootDir, fs, true);
+
+    //Take target snapshot
+    Path peerRootDir = FSUtils.getRootDir(conf2);
+    FileSystem peerFs = peerRootDir.getFileSystem(conf2);
+    String peerSnapshotName = "peerSnapshot-"+System.currentTimeMillis();
+    SnapshotTestingUtils.createSnapshotAndValidate(utility2.getHBaseAdmin(), tableName,
+      new String(famName), peerSnapshotName, peerRootDir, peerFs, true);
+    String peerFSAddress = peerFs.getUri().toString(); 
+    
+    String temPath1 = utility1.getRandomDir().toString();
+    String temPath2 = "/tmp2";
+
+    String[] args = new String[] { "--sourceSnapshotName="+sourceSnapshotName, 
+        "--sourceSnapshotTmpDir="+temPath1, "--peerSnapshotName="+peerSnapshotName, "--peerSnapshotTmpDir="+temPath2,
+        "--peerFSAddress="+peerFSAddress, "--peerHBaseRootAddress="+FSUtils.getRootDir(conf2),
+        "2", tableName.getNameAsString() };
+    
+    Job job = new VerifyReplication().createSubmittableJob(conf1, args);
+    if (job == null) {
+      fail("Job wasn't created, see the log");
+    }
+    if (!job.waitForCompletion(true)) {
+      fail("Job failed, see the log");
+    }
+    assertEquals(NB_ROWS_IN_BATCH, job.getCounters().
+        findCounter(VerifyReplication.Verifier.Counters.GOODROWS).getValue());
+    assertEquals(0, job.getCounters().
+        findCounter(VerifyReplication.Verifier.Counters.BADROWS).getValue());
+
+    Scan scan = new Scan();
+    ResultScanner rs = htable2.getScanner(scan);
+    Put put = null;
+    for (Result result : rs) {
+      put = new Put(result.getRow());
+      Cell firstVal = result.rawCells()[0];
+      put.add(CellUtil.cloneFamily(firstVal),
+          CellUtil.cloneQualifier(firstVal), Bytes.toBytes("diff data"));
+      htable2.put(put);
+    }
+    Delete delete = new Delete(put.getRow());
+    htable2.delete(delete);
+    
+    sourceSnapshotName = "sourceSnapshot-"+System.currentTimeMillis();
+    SnapshotTestingUtils.createSnapshotAndValidate(utility1.getHBaseAdmin(), tableName,
+      new String(famName), sourceSnapshotName, rootDir, fs, true);
+    
+    peerSnapshotName = "peerSnapshot-"+System.currentTimeMillis();
+    SnapshotTestingUtils.createSnapshotAndValidate(utility2.getHBaseAdmin(), tableName,
+      new String(famName), peerSnapshotName, peerRootDir, peerFs, true);
+    
+    args = new String[] { "--sourceSnapshotName="+sourceSnapshotName, 
+        "--sourceSnapshotTmpDir="+temPath1, "--peerSnapshotName="+peerSnapshotName, "--peerSnapshotTmpDir="+temPath2,
+        "--peerFSAddress="+peerFSAddress, "--peerHBaseRootAddress="+FSUtils.getRootDir(conf2),
+        "2", tableName.getNameAsString() };
+    
+    job = new VerifyReplication().createSubmittableJob(conf1, args);
+    if (job == null) {
+      fail("Job wasn't created, see the log");
+    }
+    if (!job.waitForCompletion(true)) {
+      fail("Job failed, see the log");
+    }
+    assertEquals(0, job.getCounters().
+        findCounter(VerifyReplication.Verifier.Counters.GOODROWS).getValue());
+    assertEquals(NB_ROWS_IN_BATCH, job.getCounters().
+        findCounter(VerifyReplication.Verifier.Counters.BADROWS).getValue());
+  
+    
+  }
 }
-- 
1.9.1

