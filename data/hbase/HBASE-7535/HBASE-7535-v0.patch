diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java
index e63b43f..98577e4 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java
@@ -73,6 +73,11 @@ public class HFileLink extends FileLink {
     Pattern.compile(String.format("^(%s)=(%s)-(%s)$", HTableDescriptor.VALID_USER_TABLE_REGEX,
       HRegionInfo.ENCODED_REGION_NAME_REGEX, StoreFile.HFILE_NAME_REGEX));
 
+  /** The link should be used for everything that can be found in /hbase/table/region/family/ */
+  private static final Pattern LINK_NAME_OPEN_PATTERN =
+    Pattern.compile(String.format("^(%s)=(%s)-(.+)$", HTableDescriptor.VALID_USER_TABLE_REGEX,
+      HRegionInfo.ENCODED_REGION_NAME_REGEX));
+
   private final Path archivePath;
   private final Path originPath;
 
@@ -182,7 +187,7 @@ public class HFileLink extends FileLink {
 
   /**
    * Convert a HFileLink path to a table relative path.
-   * e.g. the link: /hbase/test/0123/cf/abcd-4567-testtb
+   * e.g. the link: /hbase/test/0123/cf/testtb=4567-abcd
    *      becomes: /hbase/testtb/4567/cf/abcd
    *
    * @param path HFileLink path
@@ -190,8 +195,8 @@ public class HFileLink extends FileLink {
    * @throws IOException on unexpected error.
    */
   private static Path getRelativeTablePath(final Path path) {
-    // hfile-region-table
-    Matcher m = LINK_NAME_PATTERN.matcher(path.getName());
+    // table=region-hfile
+    Matcher m = LINK_NAME_OPEN_PATTERN.matcher(path.getName());
     if (!m.matches()) {
       throw new IllegalArgumentException(path.getName() + " is not a valid HFileLink name!");
     }
@@ -211,7 +216,7 @@ public class HFileLink extends FileLink {
    * @return the name of the referenced HFile
    */
   public static String getReferencedHFileName(final String fileName) {
-    Matcher m = LINK_NAME_PATTERN.matcher(fileName);
+    Matcher m = LINK_NAME_OPEN_PATTERN.matcher(fileName);
     if (!m.matches()) {
       throw new IllegalArgumentException(fileName + " is not a valid HFileLink name!");
     }
@@ -225,7 +230,7 @@ public class HFileLink extends FileLink {
    * @return the name of the referenced Region
    */
   public static String getReferencedRegionName(final String fileName) {
-    Matcher m = LINK_NAME_PATTERN.matcher(fileName);
+    Matcher m = LINK_NAME_OPEN_PATTERN.matcher(fileName);
     if (!m.matches()) {
       throw new IllegalArgumentException(fileName + " is not a valid HFileLink name!");
     }
@@ -239,7 +244,7 @@ public class HFileLink extends FileLink {
    * @return the name of the referenced Table
    */
   public static String getReferencedTableName(final String fileName) {
-    Matcher m = LINK_NAME_PATTERN.matcher(fileName);
+    Matcher m = LINK_NAME_OPEN_PATTERN.matcher(fileName);
     if (!m.matches()) {
       throw new IllegalArgumentException(fileName + " is not a valid HFileLink name!");
     }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java
index 34fca5c..f6312a4 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java
@@ -360,7 +360,7 @@ public class StoreFile {
       throw new IllegalArgumentException("Failed match of store file name " +
           p.toString());
     }
-    LOG.info("getReferredToFile(): p=" + p + " g1=" + m.group(1) + " g2=" + m.group(2));
+
     // Other region name is suffix on the passed Reference file name
     String otherRegion = m.group(2);
     // Tabledir is up two directories from where Reference was written.
@@ -946,7 +946,6 @@ public class StoreFile {
     // Write reference with same file id only with the other region name as
     // suffix and into the new region location (under same family).
     Path p = new Path(splitDir, f.getPath().getName() + "." + parentRegionName);
-    LOG.info("StoreFile.split(): splitDir=" + splitDir + " p=" + p);
     return r.write(fs, p);
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java
index 7ba5cb2..677586f 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java
@@ -362,10 +362,13 @@ public class RestoreSnapshotHelper {
   private void restoreStoreFile(final Path familyDir, final HRegionInfo regionInfo,
       final String hfileName) throws IOException {
     if (HFileLink.isHFileLink(hfileName)) {
+      LOG.info("restore file as link-link=" + hfileName + " in=" + familyDir);
       HFileLink.createFromHFileLink(conf, fs, familyDir, hfileName);
     } else if (StoreFile.isReference(hfileName)) {
+      LOG.info("restore file as reference=" + hfileName + " in=" + familyDir);
       restoreReferenceFile(familyDir, regionInfo, hfileName);
     } else {
+      LOG.info("restore file as link=" + hfileName + " in=" + familyDir);;
       HFileLink.create(conf, fs, familyDir, regionInfo, hfileName);
     }
   }
@@ -379,10 +382,28 @@ public class RestoreSnapshotHelper {
    */
   private void restoreReferenceFile(final Path familyDir, final HRegionInfo regionInfo,
       final String hfileName) throws IOException {
-    Path inPath = new Path(new Path(new Path(snapshotDesc.getTable(),
-        regionInfo.getEncodedName()), familyDir.getName()), hfileName);
-    Path outPath = new Path(familyDir, StoreFile.getReferredToFile(inPath).getName());
-    InputStream in = new HFileLink(conf, inPath).open(fs);
+    // Extract the referred information (hfile name and parent region)
+    String tableName = snapshotDesc.getTable();
+    Path refPath = StoreFile.getReferredToFile(new Path(new Path(new Path(tableName,
+        regionInfo.getEncodedName()), familyDir.getName()), hfileName));
+    String snapshotRegionName = refPath.getParent().getParent().getName();
+    String fileName = refPath.getName();
+
+    // The new reference should have the cloned region name as parent, if it is a clone.
+    String clonedRegionName = Bytes.toString(regionsMap.get(Bytes.toBytes(snapshotRegionName)));
+    if (clonedRegionName == null) clonedRegionName = snapshotRegionName;
+
+    // The output file should be a reference link table=snapshotRegion-fileName.clonedRegionName
+    String refLink = fileName;
+    if (!HFileLink.isHFileLink(fileName)) {
+      refLink = HFileLink.createHFileLinkName(tableName, snapshotRegionName, fileName);
+    }
+    Path outPath = new Path(familyDir, refLink + '.' + clonedRegionName);
+
+    // Create the new reference
+    Path linkPath = new Path(familyDir,
+      HFileLink.createHFileLinkName(tableName, regionInfo.getEncodedName(), hfileName));
+    InputStream in = new HFileLink(conf, linkPath).open(fs);
     OutputStream out = fs.create(outPath);
     IOUtils.copyBytes(in, out, conf);
   }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ModifyRegionUtils.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ModifyRegionUtils.java
index 28d2a22..74d30de 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ModifyRegionUtils.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/util/ModifyRegionUtils.java
@@ -108,6 +108,8 @@ public abstract class ModifyRegionUtils {
           HRegion region = HRegion.createHRegion(newRegion,
               rootDir, conf, hTableDescriptor, null,
               false, true);
+          HRegion.writeRegioninfoOnFilesystem(region.getRegionInfo(), region.getRegionDir(),
+            region.getFilesystem(), conf);
           try {
             // 2. Custom user code to interact with the created region
             if (task != null) {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreSnapshotHelper.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreSnapshotHelper.java
new file mode 100644
index 0000000..95e55c9
--- /dev/null
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestRestoreSnapshotHelper.java
@@ -0,0 +1,203 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.snapshot;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.FileUtil;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.HColumnDescriptor;
+import org.apache.hadoop.hbase.SmallTests;
+import org.apache.hadoop.hbase.catalog.CatalogTracker;
+import org.apache.hadoop.hbase.client.HConnection;
+import org.apache.hadoop.hbase.client.HConnectionTestingUtility;
+import org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher;
+import org.apache.hadoop.hbase.io.HFileLink;
+import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription;
+import org.apache.hadoop.hbase.regionserver.HRegion;
+import org.apache.hadoop.hbase.regionserver.StoreFile;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.FSTableDescriptors;
+import org.apache.hadoop.hbase.util.FSUtils;
+import org.apache.hadoop.hbase.util.MD5Hash;
+import org.junit.*;
+import org.junit.experimental.categories.Category;
+import org.mockito.Mockito;
+
+/**
+ * Test the restore/clone operation from a file-system point of view.
+ */
+@Category(SmallTests.class)
+public class TestRestoreSnapshotHelper {
+  final Log LOG = LogFactory.getLog(getClass());
+
+  private final static HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
+  private final static String TEST_FAMILY = "cf";
+  private final static String TEST_HFILE = "abc";
+
+  private Configuration conf;
+  private Path archiveDir;
+  private FileSystem fs;
+  private Path rootDir;
+
+  @Before
+  public void setup() throws Exception {
+    rootDir = TEST_UTIL.getDataTestDir("testRestore");
+    archiveDir = new Path(rootDir, HConstants.HFILE_ARCHIVE_DIRECTORY);
+    fs = TEST_UTIL.getTestFileSystem();
+    conf = TEST_UTIL.getConfiguration();
+    FSUtils.setRootDir(conf, rootDir);
+  }
+
+  @After
+  public void tearDown() throws Exception {
+    fs.delete(TEST_UTIL.getDataTestDir(), true);
+  }
+
+  @Test
+  public void testRestore() throws IOException {
+    HTableDescriptor htd = createTableDescriptor("table");
+
+    Path snapshotDir = new Path(rootDir, "snapshot");
+    createSnapshot(rootDir, snapshotDir, htd);
+
+    // Test clone a snapshot
+    HTableDescriptor htdClone = createTableDescriptor("table-clone");
+    testRestore(snapshotDir, htd.getNameAsString(), htdClone);
+    verifyRestore(rootDir, htd, htdClone);
+
+    // Test clone a clone ("link to link")
+    Path cloneDir = HTableDescriptor.getTableDir(rootDir, htdClone.getName());
+    HTableDescriptor htdClone2 = createTableDescriptor("table-clone2");
+    testRestore(cloneDir, htdClone.getNameAsString(), htdClone2);
+    verifyRestore(rootDir, htd, htdClone2);
+  }
+
+  private void verifyRestore(final Path rootDir, final HTableDescriptor sourceHtd,
+      final HTableDescriptor htdClone) throws IOException {
+    String[] files = getHFiles(HTableDescriptor.getTableDir(rootDir, htdClone.getName()));
+    assertEquals(2, files.length);
+    assertTrue(files[0] + " should be a HFileLink", HFileLink.isHFileLink(files[0]));
+    assertTrue(files[1] + " should be a Referene", StoreFile.isReference(files[1]));
+    assertEquals(sourceHtd.getNameAsString(), HFileLink.getReferencedTableName(files[0]));
+    assertEquals(TEST_HFILE, HFileLink.getReferencedHFileName(files[0]));
+    Path refPath = getReferredToFile(files[1]);
+    assertTrue(refPath.getName() + " should be a HFileLink", HFileLink.isHFileLink(refPath.getName()));
+    assertEquals(files[0], refPath.getName());
+  }
+
+  /**
+   * Execute the restore operation
+   * @param snapshotDir The snapshot directory to use as "restore source"
+   * @param sourceTableName The name of the snapshotted table
+   * @param htdClone The HTableDescriptor of the table to restore/clone.
+   */
+  public void testRestore(final Path snapshotDir, final String sourceTableName,
+      final HTableDescriptor htdClone) throws IOException {
+    LOG.debug("pre-restore table=" + htdClone.getNameAsString() + " snapshot=" + snapshotDir);
+    FSUtils.logFileSystemState(fs, rootDir, LOG);
+
+    FSTableDescriptors.createTableDescriptor(htdClone, conf);
+    RestoreSnapshotHelper helper = getRestoreHelper(rootDir, snapshotDir, sourceTableName, htdClone);
+    helper.restore();
+
+    LOG.debug("post-restore table=" + htdClone.getNameAsString() + " snapshot=" + snapshotDir);
+    FSUtils.logFileSystemState(fs, rootDir, LOG);
+  }
+
+  /**
+   * Initialize the restore helper, based on the snapshot and table information provided.
+   */
+  private RestoreSnapshotHelper getRestoreHelper(final Path rootDir, final Path snapshotDir,
+      final String sourceTableName, final HTableDescriptor htdClone) throws IOException {
+    CatalogTracker catalogTracker = Mockito.mock(CatalogTracker.class);
+    HTableDescriptor tableDescriptor = Mockito.mock(HTableDescriptor.class);
+    ForeignExceptionDispatcher monitor = Mockito.mock(ForeignExceptionDispatcher.class);
+
+    HConnection hconnection = HConnectionTestingUtility.getMockedConnection(conf);
+    Mockito.when(catalogTracker.getConnection()).thenReturn(hconnection);
+
+    SnapshotDescription sd = SnapshotDescription.newBuilder()
+      .setName("snapshot").setTable(sourceTableName).build();
+
+    return new RestoreSnapshotHelper(conf, fs, catalogTracker, sd, snapshotDir,
+      htdClone, HTableDescriptor.getTableDir(rootDir, htdClone.getName()), monitor);
+  }
+
+  private void createSnapshot(final Path rootDir, final Path snapshotDir, final HTableDescriptor htd)
+      throws IOException {
+    // First region, simple with one plain hfile.
+    HRegion r0 = HRegion.createHRegion(new HRegionInfo(htd.getName()), archiveDir,
+        conf, htd, null, true, true);
+    Path storeFile = new Path(new Path(r0.getRegionDir(), TEST_FAMILY), TEST_HFILE);
+    fs.createNewFile(storeFile);
+    r0.close();
+
+    // Second region, used to test the split case.
+    // This region contains a reference to the hfile in the first region.
+    HRegion r1 = HRegion.createHRegion(new HRegionInfo(htd.getName()), archiveDir,
+        conf, htd, null, true, true);
+    fs.createNewFile(new Path(new Path(r1.getRegionDir(), TEST_FAMILY),
+        storeFile.getName() + '.' + r0.getRegionInfo().getEncodedName()));
+    r1.close();
+
+    Path tableDir = HTableDescriptor.getTableDir(archiveDir, htd.getName());
+    FileUtil.copy(fs, tableDir, fs, snapshotDir, false, conf);
+  }
+
+  private HTableDescriptor createTableDescriptor(final String tableName) {
+    HTableDescriptor htd = new HTableDescriptor(tableName);
+    htd.addFamily(new HColumnDescriptor(TEST_FAMILY));
+    return htd;
+  }
+
+  private Path getReferredToFile(final String referenceName) {
+    Path basePath = new Path(new Path("table", "region"), "cf");
+    return StoreFile.getReferredToFile(new Path(basePath, referenceName));
+  }
+
+  private String[] getHFiles(final Path tableDir) throws IOException {
+    List<String> files = new ArrayList<String>();
+    for (Path regionDir: FSUtils.getRegionDirs(fs, tableDir)) {
+      for (Path familyDir: FSUtils.getFamilyDirs(fs, regionDir)) {
+        for (FileStatus file: FSUtils.listStatus(fs, familyDir)) {
+          files.add(file.getPath().getName());
+        }
+      }
+    }
+    Collections.sort(files);
+    return files.toArray(new String[files.size()]);
+  }
+}
\ No newline at end of file
