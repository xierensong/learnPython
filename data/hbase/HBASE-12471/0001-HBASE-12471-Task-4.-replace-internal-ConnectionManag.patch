From c7949ebd2396728e5fa5b3c8cf810a16af466df8 Mon Sep 17 00:00:00 2001
From: stack <stack@apache.org>
Date: Thu, 13 Nov 2014 18:29:29 -0800
Subject: [PATCH]     HBASE-12471 Task 4. replace internal
 ConnectionManager#{delete,get}Connection use with #close, #createConnection
 (0.98, 0.99)

    Use ConnectionFactory instead of ConnectionManager.
    There is some overlap between this patch and that
    of HBASE-12404.

    This fixes all under hbase-*/src/main/java.
    Does not do tests. Figure can do that in next round.
---
 .../apache/hadoop/hbase/client/AsyncProcess.java   | 22 +++----
 .../hadoop/hbase/client/ConnectionUtils.java       |  2 +-
 .../org/apache/hadoop/hbase/client/HBaseAdmin.java | 73 ++++++++--------------
 .../org/apache/hadoop/hbase/client/HTable.java     |  4 +-
 .../apache/hadoop/hbase/client/RegionLocator.java  |  2 +-
 .../hbase/client/replication/ReplicationAdmin.java |  8 +--
 .../hadoop/hbase/DistributedHBaseCluster.java      | 39 ++++++------
 .../hbase/master/RegionPlacementMaintainer.java    | 37 +++++------
 .../apache/hadoop/hbase/master/ServerManager.java  | 10 +--
 .../hadoop/hbase/regionserver/HRegionServer.java   |  3 +-
 .../hadoop/hbase/regionserver/SplitLogWorker.java  |  4 --
 .../hbase/regionserver/wal/HLogSplitter.java       |  5 +-
 .../java/org/apache/hadoop/hbase/HBaseCluster.java |  7 ++-
 .../org/apache/hadoop/hbase/MiniHBaseCluster.java  |  5 +-
 .../TestSplitTransactionOnCluster.java             |  6 +-
 15 files changed, 103 insertions(+), 124 deletions(-)

diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java
index 3806115..fe1906d 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java
@@ -161,7 +161,7 @@ class AsyncProcess {
   // TODO: many of the fields should be made private
   protected final long id;
 
-  protected final ClusterConnection hConnection;
+  protected final ClusterConnection connection;
   protected final RpcRetryingCallerFactory rpcCallerFactory;
   protected final RpcControllerFactory rpcFactory;
   protected final BatchErrors globalErrors;
@@ -244,7 +244,7 @@ class AsyncProcess {
       throw new IllegalArgumentException("HConnection cannot be null.");
     }
 
-    this.hConnection = hc;
+    this.connection = hc;
     this.pool = pool;
     this.globalErrors = useGlobalErrors ? new BatchErrors() : null;
 
@@ -338,7 +338,7 @@ class AsyncProcess {
         new HashMap<ServerName, MultiAction<Row>>();
     List<Action<Row>> retainedActions = new ArrayList<Action<Row>>(rows.size());
 
-    NonceGenerator ng = this.hConnection.getNonceGenerator();
+    NonceGenerator ng = this.connection.getNonceGenerator();
     long nonceGroup = ng.getNonceGroup(); // Currently, nonce group is per entire client.
 
     // Location errors that happen before we decide what requests to take.
@@ -361,7 +361,7 @@ class AsyncProcess {
         try {
           if (r == null) throw new IllegalArgumentException("#" + id + ", row cannot be null");
           // Make sure we get 0-s replica.
-          RegionLocations locs = hConnection.locateRegion(
+          RegionLocations locs = connection.locateRegion(
               tableName, r.getRow(), true, true, RegionReplicaUtil.DEFAULT_REPLICA_ID);
           if (locs == null || locs.isEmpty() || locs.getDefaultRegionLocation() == null) {
             throw new IOException("#" + id + ", no location found, aborting submit for"
@@ -533,7 +533,7 @@ class AsyncProcess {
 
     // The position will be used by the processBatch to match the object array returned.
     int posInList = -1;
-    NonceGenerator ng = this.hConnection.getNonceGenerator();
+    NonceGenerator ng = this.connection.getNonceGenerator();
     for (Row r : rows) {
       posInList++;
       if (r instanceof Put) {
@@ -908,7 +908,7 @@ class AsyncProcess {
           ", row cannot be null");
       RegionLocations loc = null;
       try {
-        loc = hConnection.locateRegion(
+        loc = connection.locateRegion(
             tableName, action.getAction().getRow(), useCache, true, action.getReplicaId());
       } catch (IOException ex) {
         manageLocationError(action, ex);
@@ -1023,7 +1023,7 @@ class AsyncProcess {
 
       if (tableName == null) {
         // tableName is null when we made a cross-table RPC call.
-        hConnection.clearCaches(server);
+        connection.clearCaches(server);
       }
       int failed = 0, stopped = 0;
       List<Action<Row>> toReplay = new ArrayList<Action<Row>>();
@@ -1034,7 +1034,7 @@ class AsyncProcess {
         // any of the regions in the MultiAction.
         // TODO: depending on type of exception we might not want to update cache at all?
         if (tableName != null) {
-          hConnection.updateCachedLocations(tableName, regionName, row, null, server);
+          connection.updateCachedLocations(tableName, regionName, row, null, server);
         }
         for (Action<Row> action : e.getValue()) {
           Retry retry = manageError(
@@ -1148,7 +1148,7 @@ class AsyncProcess {
             // Register corresponding failures once per server/once per region.
             if (!regionFailureRegistered) {
               regionFailureRegistered = true;
-              hConnection.updateCachedLocations(
+              connection.updateCachedLocations(
                   tableName, regionName, row.getRow(), result, server);
             }
             if (failureCount == 0) {
@@ -1197,7 +1197,7 @@ class AsyncProcess {
           errorsByServer.reportServerError(server);
           canRetry = errorsByServer.canRetryMore(numAttempt);
         }
-        hConnection.updateCachedLocations(
+        connection.updateCachedLocations(
             tableName, region, actions.get(0).getAction().getRow(), throwable, server);
         failureCount += actions.size();
 
@@ -1512,7 +1512,7 @@ class AsyncProcess {
   @VisibleForTesting
   protected MultiServerCallable<Row> createCallable(final ServerName server,
       TableName tableName, final MultiAction<Row> multi) {
-    return new MultiServerCallable<Row>(hConnection, tableName, server, this.rpcFactory, multi);
+    return new MultiServerCallable<Row>(connection, tableName, server, this.rpcFactory, multi);
   }
 
   /**
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java
index e26ae48..88a3c59 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java
@@ -111,7 +111,7 @@ public class ConnectionUtils {
    * @param client the client interface of the local server
    * @return an adapted/decorated HConnection
    */
-  public static HConnection createShortCircuitHConnection(final HConnection conn,
+  public static HConnection createShortCircuitHConnection(final Connection conn,
       final ServerName serverName, final AdminService.BlockingInterface admin,
       final ClientService.BlockingInterface client) {
     return new ConnectionAdapter(conn) {
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
index aec5ae8..5eb38c4 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
@@ -83,7 +83,6 @@ import org.apache.hadoop.hbase.protobuf.generated.AdminProtos.RollWALWriterReque
 import org.apache.hadoop.hbase.protobuf.generated.AdminProtos.RollWALWriterResponse;
 import org.apache.hadoop.hbase.protobuf.generated.AdminProtos.StopServerRequest;
 import org.apache.hadoop.hbase.protobuf.generated.AdminProtos.UpdateConfigurationRequest;
-import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ClientService;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ProcedureDescription;
@@ -175,8 +174,6 @@ public class HBaseAdmin implements Admin {
 
   private static final String ZK_IDENTIFIER_PREFIX =  "hbase-admin-on-";
 
-  // We use the implementation class rather then the interface because we
-  //  need the package protected functions to get the connection to master
   private ClusterConnection connection;
 
   private volatile Configuration conf;
@@ -206,7 +203,7 @@ public class HBaseAdmin implements Admin {
   throws MasterNotRunningException, ZooKeeperConnectionException, IOException {
     // Will not leak connections, as the new implementation of the constructor
     // does not throw exceptions anymore.
-    this(ConnectionManager.getConnectionInternal(new Configuration(c)));
+    this((ClusterConnection)ConnectionFactory.createConnection(new Configuration(c)));
     this.cleanupConnectionOnClose = true;
   }
 
@@ -1450,8 +1447,7 @@ public class HBaseAdmin implements Admin {
    * Get all the online regions on a region server.
    */
   @Override
-  public List<HRegionInfo> getOnlineRegions(
-      final ServerName sn) throws IOException {
+  public List<HRegionInfo> getOnlineRegions(final ServerName sn) throws IOException {
     AdminService.BlockingInterface admin = this.connection.getAdmin(sn);
     return ProtobufUtil.getOnlineRegions(admin);
   }
@@ -2340,12 +2336,6 @@ public class HBaseAdmin implements Admin {
     });
   }
 
-  private HRegionLocation getFirstMetaServerForTable(final TableName tableName)
-  throws IOException {
-    return connection.locateRegion(TableName.META_TABLE_NAME,
-      HRegionInfo.createRegionName(tableName, null, HConstants.NINES, false));
-  }
-
   /**
    * @return Configuration used by the instance.
    */
@@ -2502,52 +2492,40 @@ public class HBaseAdmin implements Admin {
 
   /**
    * Check to see if HBase is running. Throw an exception if not.
-   * We consider that HBase is running if ZooKeeper and Master are running.
-   *
    * @param conf system configuration
    * @throws MasterNotRunningException if the master is not running
    * @throws ZooKeeperConnectionException if unable to connect to zookeeper
    */
+  // Used by tests and by the Merge tool. Merge tool uses it to figure if HBase is up or not.
   public static void checkHBaseAvailable(Configuration conf)
-    throws MasterNotRunningException, ZooKeeperConnectionException, ServiceException, IOException {
+  throws MasterNotRunningException, ZooKeeperConnectionException, ServiceException, IOException {
     Configuration copyOfConf = HBaseConfiguration.create(conf);
-
     // We set it to make it fail as soon as possible if HBase is not available
     copyOfConf.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 1);
     copyOfConf.setInt("zookeeper.recovery.retry", 0);
-
-    ConnectionManager.HConnectionImplementation connection
-      = (ConnectionManager.HConnectionImplementation)
-      HConnectionManager.getConnection(copyOfConf);
-
-    try {
-      // Check ZK first.
-      // If the connection exists, we may have a connection to ZK that does
-      //  not work anymore
-      ZooKeeperKeepAliveConnection zkw = null;
-      try {
-        zkw = connection.getKeepAliveZooKeeperWatcher();
-        zkw.getRecoverableZooKeeper().getZooKeeper().exists(
-          zkw.baseZNode, false);
-
-      } catch (IOException e) {
-        throw new ZooKeeperConnectionException("Can't connect to ZooKeeper", e);
-      } catch (InterruptedException e) {
-        throw (InterruptedIOException)
+    try (ClusterConnection connection =
+        (ClusterConnection)ConnectionFactory.createConnection(copyOfConf)) {
+        // Check ZK first.
+        // If the connection exists, we may have a connection to ZK that does not work anymore
+        ZooKeeperKeepAliveConnection zkw = null;
+        try {
+          // This is NASTY. FIX!!!! Dependent on internal implementation! TODO
+          zkw = ((ConnectionManager.HConnectionImplementation)connection).
+            getKeepAliveZooKeeperWatcher();
+          zkw.getRecoverableZooKeeper().getZooKeeper().exists(zkw.baseZNode, false);
+        } catch (IOException e) {
+          throw new ZooKeeperConnectionException("Can't connect to ZooKeeper", e);
+        } catch (InterruptedException e) {
+          throw (InterruptedIOException)
             new InterruptedIOException("Can't connect to ZooKeeper").initCause(e);
-      } catch (KeeperException e) {
-        throw new ZooKeeperConnectionException("Can't connect to ZooKeeper", e);
-      } finally {
-        if (zkw != null) {
-          zkw.close();
+        } catch (KeeperException e) {
+          throw new ZooKeeperConnectionException("Can't connect to ZooKeeper", e);
+        } finally {
+          if (zkw != null) {
+            zkw.close();
+          }
         }
-      }
-
-      // Check Master
       connection.isMasterRunning();
-
-    } finally {
-      connection.close();
     }
   }
 
@@ -3754,8 +3732,9 @@ public class HBaseAdmin implements Admin {
 
   @Override
   public int getMasterInfoPort() throws IOException {
+    // TODO: Fix!  Reaching into internal implementation!!!!
     ConnectionManager.HConnectionImplementation connection =
-        (ConnectionManager.HConnectionImplementation) HConnectionManager.getConnection(conf);
+        (ConnectionManager.HConnectionImplementation)this.connection;
     ZooKeeperKeepAliveConnection zkw = connection.getKeepAliveZooKeeperWatcher();
     try {
       return MasterAddressTracker.getMasterInfoPort(zkw);
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java
index c3a94e3..04c2246 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java
@@ -182,7 +182,7 @@ public class HTable implements HTableInterface, RegionLocator {
       this.connection = null;
       return;
     }
-    this.connection = ConnectionManager.getConnectionInternal(conf);
+    this.connection = (ClusterConnection)ConnectionFactory.createConnection(conf);
     this.configuration = conf;
 
     this.pool = getDefaultExecutor(conf);
@@ -254,7 +254,7 @@ public class HTable implements HTableInterface, RegionLocator {
   @Deprecated
   public HTable(Configuration conf, final TableName tableName, final ExecutorService pool)
       throws IOException {
-    this.connection = ConnectionManager.getConnectionInternal(conf);
+    this.connection = (ClusterConnection)ConnectionFactory.createConnection(conf);
     this.configuration = conf;
     this.pool = pool;
     if (pool == null) {
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/RegionLocator.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/RegionLocator.java
index 8168fe1..39518a6 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/RegionLocator.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/RegionLocator.java
@@ -30,7 +30,7 @@ import org.apache.hadoop.hbase.util.Pair;
 
 /**
  * Used to view region location information for a single HBase table.
- * Obtain an instance from an {@link HConnection}.
+ * Obtain an instance from an {@link Connection}.
  *
  * @see ConnectionFactory
  * @see Connection
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java
index 3a33760..f6c65cf 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java
@@ -40,8 +40,8 @@ import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.classification.InterfaceStability;
-import org.apache.hadoop.hbase.client.HConnection;
-import org.apache.hadoop.hbase.client.HConnectionManager;
+import org.apache.hadoop.hbase.client.ClusterConnection;
+import org.apache.hadoop.hbase.client.ConnectionFactory;
 import org.apache.hadoop.hbase.replication.ReplicationException;
 import org.apache.hadoop.hbase.replication.ReplicationFactory;
 import org.apache.hadoop.hbase.replication.ReplicationPeerConfig;
@@ -90,7 +90,7 @@ public class ReplicationAdmin implements Closeable {
   public static final String REPLICATIONGLOBAL = Integer
       .toString(HConstants.REPLICATION_SCOPE_GLOBAL);
 
-  private final HConnection connection;
+  private final ClusterConnection connection;
   // TODO: replication should be managed by master. All the classes except ReplicationAdmin should
   // be moved to hbase-server. Resolve it in HBASE-11392.
   private final ReplicationQueuesClient replicationQueuesClient;
@@ -108,7 +108,7 @@ public class ReplicationAdmin implements Closeable {
       throw new RuntimeException("hbase.replication isn't true, please " +
           "enable it in order to use replication");
     }
-    this.connection = HConnectionManager.getConnection(conf);
+    this.connection = (ClusterConnection)ConnectionFactory.createConnection(conf);
     ZooKeeperWatcher zkw = createZooKeeperWatcher();
     try {
       this.replicationPeers = ReplicationFactory.getReplicationPeers(zkw, conf, this.connection);
diff --git a/hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java b/hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java
index d97862d..ac20535 100644
--- a/hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java
+++ b/hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java
@@ -25,9 +25,11 @@ import java.util.List;
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.ClusterManager.ServiceType;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
-import org.apache.hadoop.hbase.client.HConnection;
-import org.apache.hadoop.hbase.client.HConnectionManager;
+import org.apache.hadoop.hbase.client.Admin;
+import org.apache.hadoop.hbase.client.ClusterConnection;
+import org.apache.hadoop.hbase.client.Connection;
+import org.apache.hadoop.hbase.client.ConnectionFactory;
+import org.apache.hadoop.hbase.client.RegionLocator;
 import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.protobuf.generated.AdminProtos;
 import org.apache.hadoop.hbase.protobuf.generated.AdminProtos.ServerInfo;
@@ -44,8 +46,8 @@ import com.google.common.collect.Sets;
  */
 @InterfaceAudience.Private
 public class DistributedHBaseCluster extends HBaseCluster {
-
-  private HBaseAdmin admin;
+  private Admin admin;
+  private final Connection connection;
 
   private ClusterManager clusterManager;
 
@@ -53,7 +55,8 @@ public class DistributedHBaseCluster extends HBaseCluster {
       throws IOException {
     super(conf);
     this.clusterManager = clusterManager;
-    this.admin = new HBaseAdmin(conf);
+    this.connection = ConnectionFactory.createConnection(conf);
+    this.admin = this.connection.getAdmin();
     this.initialClusterStatus = getClusterStatus();
   }
 
@@ -89,13 +92,13 @@ public class DistributedHBaseCluster extends HBaseCluster {
   @Override
   public AdminProtos.AdminService.BlockingInterface getAdminProtocol(ServerName serverName)
   throws IOException {
-    return admin.getConnection().getAdmin(serverName);
+    return ((ClusterConnection)this.connection).getAdmin(serverName);
   }
 
   @Override
   public ClientProtos.ClientService.BlockingInterface getClientProtocol(ServerName serverName)
   throws IOException {
-    return admin.getConnection().getClient(serverName);
+    return ((ClusterConnection)this.connection).getClient(serverName);
   }
 
   @Override
@@ -138,8 +141,7 @@ public class DistributedHBaseCluster extends HBaseCluster {
   @Override
   public MasterService.BlockingInterface getMasterAdminService()
   throws IOException {
-    HConnection conn = HConnectionManager.getConnection(conf);
-    return conn.getMaster();
+    return ((ClusterConnection)this.connection).getMaster();
   }
 
   @Override
@@ -183,18 +185,19 @@ public class DistributedHBaseCluster extends HBaseCluster {
   }
 
   @Override
-  public ServerName getServerHoldingRegion(byte[] regionName) throws IOException {
-    HConnection connection = admin.getConnection();
-    HRegionLocation regionLoc = connection.locateRegion(regionName);
+  public ServerName getServerHoldingRegion(TableName tn, byte[] regionName) throws IOException {
+    HRegionLocation regionLoc = null;
+    try (RegionLocator locator = connection.getRegionLocator(tn)) {
+      regionLoc = locator.getRegionLocation(regionName);
+    }
     if (regionLoc == null) {
-      LOG.warn("Cannot find region server holding region " + Bytes.toString(regionName)
-          + " for table " + HRegionInfo.getTableName(regionName) + ", start key [" +
-          Bytes.toString(HRegionInfo.getStartKey(regionName)) + "]");
+      LOG.warn("Cannot find region server holding region " + Bytes.toString(regionName) +
+        ", start key [" + Bytes.toString(HRegionInfo.getStartKey(regionName)) + "]");
       return null;
     }
 
     AdminProtos.AdminService.BlockingInterface client =
-      connection.getAdmin(regionLoc.getServerName());
+        ((ClusterConnection)this.connection).getAdmin(regionLoc.getServerName());
     ServerInfo info = ProtobufUtil.getServerInfo(client);
     return ProtobufUtil.toServerName(info.getServerName());
   }
@@ -374,7 +377,7 @@ public class DistributedHBaseCluster extends HBaseCluster {
     } catch (IOException ioe) {
       LOG.warn("While closing the old connection", ioe);
     }
-    this.admin = new HBaseAdmin(conf);
+    this.admin = this.connection.getAdmin();
     LOG.info("Added new HBaseAdmin");
     return true;
   }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java
index 1d16bdf..10ad1f6 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java
@@ -48,9 +48,9 @@ import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.client.Admin;
-import org.apache.hadoop.hbase.client.HBaseAdmin;
-import org.apache.hadoop.hbase.client.HConnection;
-import org.apache.hadoop.hbase.client.HConnectionManager;
+import org.apache.hadoop.hbase.client.ClusterConnection;
+import org.apache.hadoop.hbase.client.Connection;
+import org.apache.hadoop.hbase.client.ConnectionFactory;
 import org.apache.hadoop.hbase.master.balancer.FavoredNodeAssignmentHelper;
 import org.apache.hadoop.hbase.master.balancer.FavoredNodesPlan;
 import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
@@ -67,9 +67,9 @@ import org.apache.log4j.Logger;
 /**
  * A tool that is used for manipulating and viewing favored nodes information
  * for regions. Run with -h to get a list of the options
- *
  */
 @InterfaceAudience.Private
+// TODO: Remove? Unused. Partially implemented only.
 public class RegionPlacementMaintainer {
   private static final Log LOG = LogFactory.getLog(RegionPlacementMaintainer.class
       .getName());
@@ -93,9 +93,9 @@ public class RegionPlacementMaintainer {
   private Configuration conf;
   private final boolean enforceLocality;
   private final boolean enforceMinAssignmentMove;
-  private HBaseAdmin admin;
   private RackManager rackManager;
   private Set<TableName> targetTableSet;
+  private final Connection connection;
 
   public RegionPlacementMaintainer(Configuration conf) {
     this(conf, true, true);
@@ -108,7 +108,13 @@ public class RegionPlacementMaintainer {
     this.enforceMinAssignmentMove = enforceMinAssignmentMove;
     this.targetTableSet = new HashSet<TableName>();
     this.rackManager = new RackManager(conf);
+    try {
+      this.connection = ConnectionFactory.createConnection(this.conf);
+    } catch (IOException e) {
+      throw new RuntimeException(e);
+    }
   }
+
   private static void printHelp(Options opt) {
     new HelpFormatter().printHelp(
         "RegionPlacement < -w | -u | -n | -v | -t | -h | -overwrite -r regionName -f favoredNodes " +
@@ -125,24 +131,13 @@ public class RegionPlacementMaintainer {
   }
 
   /**
-   * @return the cached HBaseAdmin
-   * @throws IOException
-   */
-  private HBaseAdmin getHBaseAdmin() throws IOException {
-    if (this.admin == null) {
-      this.admin = new HBaseAdmin(this.conf);
-    }
-    return this.admin;
-  }
-
-  /**
    * @return the new RegionAssignmentSnapshot
    * @throws IOException
    */
   public SnapshotOfRegionAssignmentFromMeta getRegionAssignmentSnapshot()
   throws IOException {
     SnapshotOfRegionAssignmentFromMeta currentAssignmentShapshot =
-      new SnapshotOfRegionAssignmentFromMeta(HConnectionManager.getConnection(conf));
+      new SnapshotOfRegionAssignmentFromMeta(ConnectionFactory.createConnection(conf));
     currentAssignmentShapshot.initialize();
     return currentAssignmentShapshot;
   }
@@ -210,7 +205,9 @@ public class RegionPlacementMaintainer {
 
       // Get the all the region servers
       List<ServerName> servers = new ArrayList<ServerName>();
-      servers.addAll(getHBaseAdmin().getClusterStatus().getServers());
+      try (Admin admin = this.connection.getAdmin()) {
+        servers.addAll(admin.getClusterStatus().getServers());
+      }
       
       LOG.info("Start to generate assignment plan for " + numRegions +
           " regions from table " + tableName + " with " +
@@ -660,7 +657,6 @@ public class RegionPlacementMaintainer {
     // Get the region to region server map
     Map<ServerName, List<HRegionInfo>> currentAssignment =
       this.getRegionAssignmentSnapshot().getRegionServerToRegionMap();
-    HConnection connection = this.getHBaseAdmin().getConnection();
 
     // track of the failed and succeeded updates
     int succeededNum = 0;
@@ -691,7 +687,8 @@ public class RegionPlacementMaintainer {
         }
         if (singleServerPlan != null) {
           // Update the current region server with its updated favored nodes
-          BlockingInterface currentRegionServer = connection.getAdmin(entry.getKey());
+          BlockingInterface currentRegionServer =
+            ((ClusterConnection)this.connection).getAdmin(entry.getKey());
           UpdateFavoredNodesRequest request =
               RequestConverter.buildUpdateFavoredNodesRequest(regionUpdateInfos);
           
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
index cca39f5..369362b 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
@@ -36,7 +36,6 @@ import java.util.concurrent.CopyOnWriteArrayList;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.ClockOutOfSyncException;
 import org.apache.hadoop.hbase.HRegionInfo;
@@ -46,8 +45,9 @@ import org.apache.hadoop.hbase.ServerLoad;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.YouAreDeadException;
 import org.apache.hadoop.hbase.ZooKeeperConnectionException;
-import org.apache.hadoop.hbase.client.HConnection;
-import org.apache.hadoop.hbase.client.HConnectionManager;
+import org.apache.hadoop.hbase.classification.InterfaceAudience;
+import org.apache.hadoop.hbase.client.ClusterConnection;
+import org.apache.hadoop.hbase.client.ConnectionFactory;
 import org.apache.hadoop.hbase.client.RetriesExhaustedException;
 import org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer;
 import org.apache.hadoop.hbase.master.handler.MetaServerShutdownHandler;
@@ -137,7 +137,7 @@ public class ServerManager {
 
   private final Server master;
   private final MasterServices services;
-  private final HConnection connection;
+  private final ClusterConnection connection;
 
   private final DeadServer deadservers = new DeadServer();
 
@@ -201,7 +201,7 @@ public class ServerManager {
     Configuration c = master.getConfiguration();
     maxSkew = c.getLong("hbase.master.maxclockskew", 30000);
     warningSkew = c.getLong("hbase.master.warningclockskew", 10000);
-    this.connection = connect ? HConnectionManager.getConnection(c) : null;
+    this.connection = connect ? (ClusterConnection)ConnectionFactory.createConnection(c) : null;
   }
 
   /**
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
index 45e5558..7952a87 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
@@ -73,6 +73,7 @@ import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.YouAreDeadException;
 import org.apache.hadoop.hbase.ZNodeClearer;
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
+import org.apache.hadoop.hbase.client.ConnectionFactory;
 import org.apache.hadoop.hbase.client.ConnectionUtils;
 import org.apache.hadoop.hbase.client.HConnection;
 import org.apache.hadoop.hbase.client.HConnectionManager;
@@ -609,7 +610,7 @@ public class HRegionServer extends HasThread implements
    */
   protected HConnection createShortCircuitConnection() throws IOException {
     return ConnectionUtils.createShortCircuitHConnection(
-      HConnectionManager.getConnection(conf), serverName, rpcServices, rpcServices);
+      ConnectionFactory.createConnection(conf), serverName, rpcServices, rpcServices);
   }
   
   /**
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java
index 94864ba..0052b00 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java
@@ -31,7 +31,6 @@ import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.NotServingRegionException;
 import org.apache.hadoop.hbase.Server;
-import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.RetriesExhaustedException;
 import org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager;
 import org.apache.hadoop.hbase.coordination.SplitLogWorkerCoordination;
@@ -132,9 +131,6 @@ public class SplitLogWorker implements Runnable {
     try {
       LOG.info("SplitLogWorker " + server.getServerName() + " starting");
       coordination.registerListener();
-      // pre-initialize a new connection for splitlogworker configuration
-      HConnectionManager.getConnection(conf);
-
       // wait for Coordination Engine is ready
       boolean res = false;
       while (!res && !coordination.isStop()) {
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java
index 1f81874..20eb783 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java
@@ -49,6 +49,7 @@ import java.util.concurrent.atomic.AtomicReference;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.Lists;
 import com.google.protobuf.ServiceException;
+
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
@@ -70,11 +71,11 @@ import org.apache.hadoop.hbase.TableNotFoundException;
 import org.apache.hadoop.hbase.Tag;
 import org.apache.hadoop.hbase.TagRewriteCell;
 import org.apache.hadoop.hbase.TagType;
+import org.apache.hadoop.hbase.client.ConnectionFactory;
 import org.apache.hadoop.hbase.client.ConnectionUtils;
 import org.apache.hadoop.hbase.client.Delete;
 import org.apache.hadoop.hbase.client.Durability;
 import org.apache.hadoop.hbase.client.HConnection;
-import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.client.Mutation;
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.coordination.BaseCoordinatedStateManager;
@@ -1892,7 +1893,7 @@ public class HLogSplitter {
         synchronized (this.tableNameToHConnectionMap) {
           hconn = this.tableNameToHConnectionMap.get(tableName);
           if (hconn == null) {
-            hconn = HConnectionManager.getConnection(conf);
+            hconn = (HConnection)ConnectionFactory.createConnection(conf);
             this.tableNameToHConnectionMap.put(tableName, hconn);
           }
         }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseCluster.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseCluster.java
index 76a9566..9e7a0c4 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseCluster.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseCluster.java
@@ -250,15 +250,18 @@ public abstract class HBaseCluster implements Closeable, Configurable {
    * Get the ServerName of region server serving the first hbase:meta region
    */
   public ServerName getServerHoldingMeta() throws IOException {
-    return getServerHoldingRegion(HRegionInfo.FIRST_META_REGIONINFO.getRegionName());
+    return getServerHoldingRegion(TableName.META_TABLE_NAME,
+      HRegionInfo.FIRST_META_REGIONINFO.getRegionName());
   }
 
   /**
    * Get the ServerName of region server serving the specified region
    * @param regionName Name of the region in bytes
+   * @param tn Table name that has the region.
    * @return ServerName that hosts the region or null
    */
-  public abstract ServerName getServerHoldingRegion(byte[] regionName) throws IOException;
+  public abstract ServerName getServerHoldingRegion(final TableName tn, byte[] regionName)
+  throws IOException;
 
   /**
    * @return whether we are interacting with a distributed cluster as opposed to an
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
index a3ec004..7672ac1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java
@@ -29,7 +29,6 @@ import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.classification.InterfaceStability;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.hbase.client.HConnectionManager;
 import org.apache.hadoop.hbase.master.HMaster;
 import org.apache.hadoop.hbase.protobuf.generated.AdminProtos.AdminService;
 import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ClientService;
@@ -517,7 +516,6 @@ public class MiniHBaseCluster extends HBaseCluster {
     if (this.hbaseCluster != null) {
       this.hbaseCluster.shutdown();
     }
-    HConnectionManager.deleteAllConnections(false);
   }
 
   @Override
@@ -657,7 +655,8 @@ public class MiniHBaseCluster extends HBaseCluster {
   }
 
   @Override
-  public ServerName getServerHoldingRegion(byte[] regionName) throws IOException {
+  public ServerName getServerHoldingRegion(final TableName tn, byte[] regionName)
+  throws IOException {
     // Assume there is only one master thread which is the active master.
     // If there are multiple master threads, the backup master threads
     // should hold some regions. Please refer to #countServedRegions
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransactionOnCluster.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransactionOnCluster.java
index 29073ed..678adc4 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransactionOnCluster.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestSplitTransactionOnCluster.java
@@ -107,8 +107,8 @@ import com.google.protobuf.RpcController;
 import com.google.protobuf.ServiceException;
 
 /**
- * Like {@link TestSplitTransaction} in that we're testing {@link SplitTransaction}
- * only the below tests are against a running cluster where {@link TestSplitTransaction}
+ * Like TestSplitTransaction in that we're testing {@link SplitTransaction}
+ * only the below tests are against a running cluster where TestSplitTransaction
  * is tests against a bare {@link HRegion}.
  */
 @Category({RegionServerTests.class, LargeTests.class})
@@ -904,7 +904,7 @@ public class TestSplitTransactionOnCluster {
       fail("Each table should have at least one region.");
     }
     ServerName serverName =
-        cluster.getServerHoldingRegion(firstTableRegions.get(0).getRegionName());
+        cluster.getServerHoldingRegion(firstTable, firstTableRegions.get(0).getRegionName());
     admin.move(secondTableRegions.get(0).getRegionInfo().getEncodedNameAsBytes(),
       Bytes.toBytes(serverName.getServerName()));
     Table table1 = null;
-- 
1.8.5.2 (Apple Git-48)

