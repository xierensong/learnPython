diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompositeImmutableSegment.java hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompositeImmutableSegment.java
index 0d2608f6c7..ef4c3cd4de 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompositeImmutableSegment.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompositeImmutableSegment.java
@@ -42,17 +42,11 @@ import org.apache.hadoop.hbase.shaded.com.google.common.annotations.VisibleForTe
 public class CompositeImmutableSegment extends ImmutableSegment {
 
   private final List<ImmutableSegment> segments;
-  // CompositeImmutableSegment is used for snapshots and snapshot should
-  // support getTimeRangeTracker() interface.
-  // Thus we hold a constant TRT build in the construction time from TRT of the given segments.
-  private final TimeRangeTracker timeRangeTracker;
-
   private long keySize = 0;
 
   public CompositeImmutableSegment(CellComparator comparator, List<ImmutableSegment> segments) {
     super(comparator);
     this.segments = segments;
-    this.timeRangeTracker = TimeRangeTracker.create(TimeRangeTracker.Type.SYNC);
     for (ImmutableSegment s : segments) {
       this.timeRangeTracker.includeTimestamp(s.getTimeRangeTracker().getMax());
       this.timeRangeTracker.includeTimestamp(s.getTimeRangeTracker().getMin());
@@ -127,11 +121,6 @@ public class CompositeImmutableSegment extends ImmutableSegment {
     throw new IllegalStateException("Not supported by CompositeImmutableScanner");
   }
 
-  @Override
-  public long getMinTimestamp(){
-    throw new IllegalStateException("Not supported by CompositeImmutableScanner");
-  }
-
   /**
    * Creates the scanner for the given read point
    * @return a scanner for the given read point
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ImmutableSegment.java hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ImmutableSegment.java
index aacd189e83..7b5e5beacb 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ImmutableSegment.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ImmutableSegment.java
@@ -35,15 +35,7 @@ import java.util.List;
 @InterfaceAudience.Private
 public abstract class ImmutableSegment extends Segment {
 
-  public static final long DEEP_OVERHEAD = Segment.DEEP_OVERHEAD
-      + ClassSize.align(ClassSize.REFERENCE // Referent to timeRange
-      + ClassSize.TIMERANGE);
-
-  /**
-   * This is an immutable segment so use the read-only TimeRange rather than the heavy-weight
-   * TimeRangeTracker with all its synchronization when doing time range stuff.
-   */
-  private final TimeRange timeRange;
+  public static final long DEEP_OVERHEAD = Segment.DEEP_OVERHEAD;
 
   // each sub-type of immutable segment knows whether it is flat or not
   protected abstract boolean canBeFlattened();
@@ -53,16 +45,14 @@ public abstract class ImmutableSegment extends Segment {
    * Empty C-tor to be used only for CompositeImmutableSegment
    */
   protected ImmutableSegment(CellComparator comparator) {
-    super(comparator);
-    this.timeRange = null;
+    super(comparator, TimeRangeTracker.create(TimeRangeTracker.Type.NON_SYNC));
   }
 
   /**------------------------------------------------------------------------
    * C-tor to be used to build the derived classes
    */
   protected ImmutableSegment(CellSet cs, CellComparator comparator, MemStoreLAB memStoreLAB) {
-    super(cs, comparator, memStoreLAB);
-    this.timeRange = this.timeRangeTracker == null ? null : this.timeRangeTracker.toTimeRange();
+    super(cs, comparator, memStoreLAB, TimeRangeTracker.create(TimeRangeTracker.Type.NON_SYNC));
   }
 
   /**------------------------------------------------------------------------
@@ -72,21 +62,10 @@ public abstract class ImmutableSegment extends Segment {
    */
   protected ImmutableSegment(Segment segment) {
     super(segment);
-    this.timeRange = this.timeRangeTracker == null ? null : this.timeRangeTracker.toTimeRange();
   }
 
 
   /////////////////////  PUBLIC METHODS  /////////////////////
-  @Override
-  public boolean shouldSeek(TimeRange tr, long oldestUnexpiredTS) {
-    return this.timeRange.includesTimeRange(tr) &&
-        this.timeRange.getMax() >= oldestUnexpiredTS;
-  }
-
-  @Override
-  public long getMinTimestamp() {
-    return this.timeRange.getMin();
-  }
 
   public int getNumOfSegments() {
     return 1;
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MutableSegment.java hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MutableSegment.java
index 856f40e006..4d6e3307b8 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MutableSegment.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MutableSegment.java
@@ -41,7 +41,7 @@ public class MutableSegment extends Segment {
   public final static long DEEP_OVERHEAD = Segment.DEEP_OVERHEAD + ClassSize.CONCURRENT_SKIPLISTMAP;
 
   protected MutableSegment(CellSet cellSet, CellComparator comparator, MemStoreLAB memStoreLAB) {
-    super(cellSet, comparator, memStoreLAB);
+    super(cellSet, comparator, memStoreLAB, TimeRangeTracker.create(TimeRangeTracker.Type.SYNC));
     incSize(0,DEEP_OVERHEAD); // update the mutable segment metadata
   }
 
@@ -112,17 +112,6 @@ public class MutableSegment extends Segment {
     return this.getCellSet().first();
   }
 
-  @Override
-  public boolean shouldSeek(TimeRange tr, long oldestUnexpiredTS) {
-    return (this.timeRangeTracker.includesTimeRange(tr)
-        && (this.timeRangeTracker.getMax() >= oldestUnexpiredTS));
-  }
-
-  @Override
-  public long getMinTimestamp() {
-    return this.timeRangeTracker.getMin();
-  }
-
   @Override protected long indexEntrySize() {
       return ClassSize.CONCURRENT_SKIPLISTMAP_ENTRY;
   }
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Segment.java hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Segment.java
index 23b386f3df..c12ecafd0c 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Segment.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Segment.java
@@ -54,7 +54,9 @@ public abstract class Segment {
       + Bytes.SIZEOF_LONG // minSequenceId
       + Bytes.SIZEOF_BOOLEAN); // tagsPresent
   public final static long DEEP_OVERHEAD = FIXED_OVERHEAD + ClassSize.ATOMIC_REFERENCE
-      + ClassSize.CELL_SET + 2 * ClassSize.ATOMIC_LONG + ClassSize.SYNC_TIMERANGE_TRACKER;
+      + ClassSize.CELL_SET + 2 * ClassSize.ATOMIC_LONG
+      // TODO: The TimeRangeTracker used by Segment may be a NON-SYNC impl.
+      + ClassSize.SYNC_TIMERANGE_TRACKER;
 
   private AtomicReference<CellSet> cellSet= new AtomicReference<>();
   private final CellComparator comparator;
@@ -69,15 +71,15 @@ public abstract class Segment {
 
   // Empty constructor to be used when Segment is used as interface,
   // and there is no need in true Segments state
-  protected Segment(CellComparator comparator) {
+  protected Segment(CellComparator comparator, TimeRangeTracker trt) {
     this.comparator = comparator;
     this.dataSize = new AtomicLong(0);
     this.heapSize = new AtomicLong(0);
-    this.timeRangeTracker = TimeRangeTracker.create(TimeRangeTracker.Type.SYNC);
+    this.timeRangeTracker = trt;
   }
 
   // This constructor is used to create empty Segments.
-  protected Segment(CellSet cellSet, CellComparator comparator, MemStoreLAB memStoreLAB) {
+  protected Segment(CellSet cellSet, CellComparator comparator, MemStoreLAB memStoreLAB, TimeRangeTracker trt) {
     this.cellSet.set(cellSet);
     this.comparator = comparator;
     this.minSequenceId = Long.MAX_VALUE;
@@ -85,7 +87,7 @@ public abstract class Segment {
     this.dataSize = new AtomicLong(0);
     this.heapSize = new AtomicLong(0);
     this.tagsPresent = false;
-    this.timeRangeTracker = TimeRangeTracker.create(TimeRangeTracker.Type.SYNC);
+    this.timeRangeTracker = trt;
   }
 
   protected Segment(Segment segment) {
@@ -177,9 +179,10 @@ public abstract class Segment {
     return KeyValueUtil.length(cell);
   }
 
-  public abstract boolean shouldSeek(TimeRange tr, long oldestUnexpiredTS);
-
-  public abstract long getMinTimestamp();
+  public boolean shouldSeek(TimeRange tr, long oldestUnexpiredTS) {
+    return (tr.isAllTime() || timeRangeTracker.includesTimeRange(tr))
+        && timeRangeTracker.getMax() >= oldestUnexpiredTS;
+  }
 
   public boolean isTagsPresent() {
     return tagsPresent;
@@ -354,7 +357,8 @@ public abstract class Segment {
     res += "cellsCount "+getCellsCount()+"; ";
     res += "cellsSize "+keySize()+"; ";
     res += "totalHeapSize "+heapSize()+"; ";
-    res += "Min ts "+getMinTimestamp()+"; ";
+    res += "Min ts " + timeRangeTracker.getMin() + "; ";
+    res += "Max ts " + timeRangeTracker.getMax() + "; ";
     return res;
   }
 }
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java
index 48e438cf1b..ff29f71a9b 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java
@@ -399,7 +399,6 @@ public class TestHeapSize  {
     expected += ClassSize.estimateBase(AtomicReference.class, false);
     expected += ClassSize.estimateBase(CellSet.class, false);
     expected += ClassSize.estimateBase(SyncTimeRangeTracker.class, false);
-    expected += ClassSize.estimateBase(TimeRange.class, false);
     if (expected != actual) {
       ClassSize.estimateBase(cl, true);
       ClassSize.estimateBase(AtomicLong.class, true);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactingToCellFlatMapMemStore.java hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactingToCellFlatMapMemStore.java
index 3fa5cd0ed9..f938e4ae33 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactingToCellFlatMapMemStore.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactingToCellFlatMapMemStore.java
@@ -351,6 +351,89 @@ public class TestCompactingToCellFlatMapMemStore extends TestCompactingMemStore
   }
 
   @Test
+  public void testTimeRangeAfterCompaction() throws IOException {
+    if (toCellChunkMap) {
+      // set memstore to flat into CellChunkMap
+      conf.set(CompactingMemStore.COMPACTING_MEMSTORE_INDEX_KEY,
+          String.valueOf(CompactingMemStore.IndexType.CHUNK_MAP));
+      ((CompactingMemStore)memstore).setIndexType();
+    }
+    testTimeRange(true);
+  }
+
+  @Test
+  public void testTimeRangeAfterMerge() throws IOException {
+    if (toCellChunkMap) {
+      // set memstore to flat into CellChunkMap
+      conf.set(CompactingMemStore.COMPACTING_MEMSTORE_INDEX_KEY,
+          String.valueOf(CompactingMemStore.IndexType.CHUNK_MAP));
+      ((CompactingMemStore)memstore).setIndexType();
+    }
+    MemoryCompactionPolicy compactionType = MemoryCompactionPolicy.BASIC;
+    memstore.getConfiguration().set(CompactingMemStore.COMPACTING_MEMSTORE_TYPE_KEY,
+        String.valueOf(compactionType));
+    ((CompactingMemStore)memstore).initiateType(compactionType);
+    testTimeRange(false);
+  }
+
+  private void testTimeRange(boolean isCompaction) throws IOException {
+    final long initTs = 100;
+    long currentTs = initTs;
+    byte[] row = Bytes.toBytes("row");
+    byte[] family = Bytes.toBytes("family");
+    byte[] qf1 = Bytes.toBytes("qf1");
+
+    // first segment in pipeline
+    this.memstore.add(new KeyValue(row, family, qf1, ++currentTs, (byte[])null), null);
+    long minTs = currentTs;
+    this.memstore.add(new KeyValue(row, family, qf1, ++currentTs, (byte[])null), null);
+
+    long numberOfCell = 2;
+    assertEquals(numberOfCell, memstore.getSegments().stream().mapToInt(Segment::getCellsCount).sum());
+    assertEquals(minTs, memstore.getSegments().stream().mapToLong(
+        m -> m.getTimeRangeTracker().getMin()).min().getAsLong());
+    assertEquals(currentTs, memstore.getSegments().stream().mapToLong(
+        m -> m.getTimeRangeTracker().getMax()).max().getAsLong());
+
+    ((CompactingMemStore) memstore).flushInMemory();
+
+    while (((CompactingMemStore) memstore).isMemStoreFlushingInMemory()) {
+      Threads.sleep(10);
+    }
+    if (isCompaction) {
+      // max version = 1, so one cell will be dropped.
+      numberOfCell = 1;
+      minTs = currentTs;
+    }
+    // second segment in pipeline
+    this.memstore.add(new KeyValue(row, family, qf1, ++currentTs, (byte[])null), null);
+    this.memstore.add(new KeyValue(row, family, qf1, ++currentTs, (byte[])null), null);
+    numberOfCell += 2;
+    assertEquals(numberOfCell, memstore.getSegments().stream().mapToInt(Segment::getCellsCount).sum());
+    assertEquals(minTs, memstore.getSegments().stream().mapToLong(
+        m -> m.getTimeRangeTracker().getMin()).min().getAsLong());
+    assertEquals(currentTs, memstore.getSegments().stream().mapToLong(
+        m -> m.getTimeRangeTracker().getMax()).max().getAsLong());
+
+    ((CompactingMemStore) memstore).flushInMemory(); // trigger the merge
+
+    while (((CompactingMemStore) memstore).isMemStoreFlushingInMemory()) {
+      Threads.sleep(10);
+    }
+    if (isCompaction) {
+      // max version = 1, so one cell will be dropped.
+      numberOfCell = 1;
+      minTs = currentTs;
+    }
+
+    assertEquals(numberOfCell, memstore.getSegments().stream().mapToInt(Segment::getCellsCount).sum());
+    assertEquals(minTs, memstore.getSegments().stream().mapToLong(
+        m -> m.getTimeRangeTracker().getMin()).min().getAsLong());
+    assertEquals(currentTs, memstore.getSegments().stream().mapToLong(
+        m -> m.getTimeRangeTracker().getMax()).max().getAsLong());
+  }
+
+  @Test
   public void testCountOfCellsAfterFlatteningByScan() throws IOException {
     String[] keys1 = { "A", "B", "C" }; // A, B, C
     addRowsByKeysWith50Cols(memstore, keys1);
