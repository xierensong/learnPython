Index: src/test/org/apache/hadoop/hbase/HBaseTestCase.java
===================================================================
--- src/test/org/apache/hadoop/hbase/HBaseTestCase.java	(revision 700743)
+++ src/test/org/apache/hadoop/hbase/HBaseTestCase.java	(working copy)
@@ -434,7 +434,7 @@
      * @throws IOException
      */
     public Map<byte [], Cell> getFull(byte [] row) throws IOException {
-      return region.getFull(row, null, HConstants.LATEST_TIMESTAMP, null);
+      return region.getFull(row, null, HConstants.LATEST_TIMESTAMP, 1, null);
     }
 
     public void flushcache() throws IOException {
@@ -555,7 +555,7 @@
   protected void assertCellEquals(final HRegion region, final byte [] row,
     final byte [] column, final long timestamp, final String value)
   throws IOException {
-    Map<byte [], Cell> result = region.getFull(row, null, timestamp, null);
+    Map<byte [], Cell> result = region.getFull(row, null, timestamp, 1, null);
     Cell cell_value = result.get(column);
     if(value == null){
       assertEquals(column.toString() + " at timestamp " + timestamp, null, cell_value);
Index: src/test/org/apache/hadoop/hbase/regionserver/TestGet2.java
===================================================================
--- src/test/org/apache/hadoop/hbase/regionserver/TestGet2.java	(revision 700743)
+++ src/test/org/apache/hadoop/hbase/regionserver/TestGet2.java	(working copy)
@@ -554,25 +554,25 @@
 
     // make sure we get all of them with standard getFull
     Map<byte [], Cell> result = region.getFull(row, null, 
-      HConstants.LATEST_TIMESTAMP, null);
+      HConstants.LATEST_TIMESTAMP, 1, null);
     assertEquals(new String(result.get(COLUMNS[0]).getValue()), "column 0");
     assertEquals(new String(result.get(COLUMNS[1]).getValue()), "column 1");
     assertEquals(new String(result.get(COLUMNS[2]).getValue()), "column 2");
           
     // try to get just one
-    result = region.getFull(row, one, HConstants.LATEST_TIMESTAMP, null);
+    result = region.getFull(row, one, HConstants.LATEST_TIMESTAMP, 1, null);
     assertEquals(new String(result.get(COLUMNS[0]).getValue()), "column 0");
     assertNull(result.get(COLUMNS[1]));                                   
     assertNull(result.get(COLUMNS[2]));                                   
                                                                           
     // try to get all of them (specified)                                 
-    result = region.getFull(row, all, HConstants.LATEST_TIMESTAMP, null);       
+    result = region.getFull(row, all, HConstants.LATEST_TIMESTAMP, 1, null);       
     assertEquals(new String(result.get(COLUMNS[0]).getValue()), "column 0");
     assertEquals(new String(result.get(COLUMNS[1]).getValue()), "column 1");
     assertEquals(new String(result.get(COLUMNS[2]).getValue()), "column 2");
     
     // try to get none with empty column set
-    result = region.getFull(row, none, HConstants.LATEST_TIMESTAMP, null);
+    result = region.getFull(row, none, HConstants.LATEST_TIMESTAMP, 1, null);
     assertNull(result.get(COLUMNS[0]));
     assertNull(result.get(COLUMNS[1]));
     assertNull(result.get(COLUMNS[2]));    
@@ -603,7 +603,7 @@
       region.flushcache();
       
       // assert that getFull gives us the older value
-      results = region.getFull(row, (Set<byte []>)null, LATEST_TIMESTAMP, null);
+      results = region.getFull(row, (Set<byte []>)null, LATEST_TIMESTAMP, 1, null);
       assertEquals("olderValue", new String(results.get(COLUMNS[0]).getValue()));
       
       // write a new value for the cell
@@ -615,7 +615,7 @@
       region.flushcache();
       
       // assert that getFull gives us the later value
-      results = region.getFull(row, (Set<byte []>)null, LATEST_TIMESTAMP, null);
+      results = region.getFull(row, (Set<byte []>)null, LATEST_TIMESTAMP, 1, null);
       assertEquals("newerValue", new String(results.get(COLUMNS[0]).getValue()));
      
       //
@@ -636,7 +636,7 @@
       region.flushcache();
       
       // assert i get both columns
-      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, null);
+      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, 1, null);
       assertEquals("Should have two columns in the results map", 2, results.size());
       assertEquals("column0 value", new String(results.get(cell1).getValue()));
       assertEquals("column1 value", new String(results.get(cell2).getValue()));
@@ -651,7 +651,7 @@
       region.flushcache(); 
       
       // assert i get the second column only
-      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, null);
+      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, 1, null);
       assertEquals("Should have one column in the results map", 1, results.size());
       assertNull("column0 value", results.get(cell1));
       assertEquals("column1 new value", new String(results.get(cell2).getValue()));
@@ -665,7 +665,7 @@
       region.batchUpdate(batchUpdate, null);
       
       // assert i get the third column only
-      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, null);
+      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, 1, null);
       assertEquals("Should have one column in the results map", 1, results.size());
       assertNull("column0 value", results.get(cell1));
       assertNull("column1 value", results.get(cell2));
@@ -686,7 +686,7 @@
   private void assertColumnsPresent(final HRegion r, final byte [] row)
   throws IOException {
     Map<byte [], Cell> result = 
-      r.getFull(row, null, HConstants.LATEST_TIMESTAMP, null);
+      r.getFull(row, null, HConstants.LATEST_TIMESTAMP, 1, null);
     int columnCount = 0;
     for (Map.Entry<byte [], Cell> e: result.entrySet()) {
       columnCount++;
Index: src/test/org/apache/hadoop/hbase/regionserver/TestHMemcache.java
===================================================================
--- src/test/org/apache/hadoop/hbase/regionserver/TestHMemcache.java	(revision 700743)
+++ src/test/org/apache/hadoop/hbase/regionserver/TestHMemcache.java	(working copy)
@@ -188,7 +188,7 @@
         new TreeMap<byte [], Cell>(Bytes.BYTES_COMPARATOR);
       TreeMap<byte [], Long> deletes =
         new TreeMap<byte [], Long>(Bytes.BYTES_COMPARATOR);
-      this.hmemcache.getFull(hsk, null, deletes, all);
+      this.hmemcache.getFull(hsk, null, 1, deletes, all);
       isExpectedRow(i, all);
     }
   }
Index: src/test/org/apache/hadoop/hbase/client/TestGetMultipleVersions.java
===================================================================
--- src/test/org/apache/hadoop/hbase/client/TestGetMultipleVersions.java	(revision 0)
+++ src/test/org/apache/hadoop/hbase/client/TestGetMultipleVersions.java	(revision 0)
@@ -0,0 +1,95 @@
+package org.apache.hadoop.hbase.client;
+
+import java.io.IOException;
+import java.util.Map.Entry;
+
+import org.apache.hadoop.hbase.HBaseClusterTestCase;
+import org.apache.hadoop.hbase.HColumnDescriptor;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.io.BatchUpdate;
+import org.apache.hadoop.hbase.io.Cell;
+import org.apache.hadoop.hbase.io.RowResult;
+import org.apache.hadoop.hbase.util.Bytes;
+
+public class TestGetMultipleVersions extends HBaseClusterTestCase implements HConstants  {
+
+  private static final byte[] TABLE = Bytes.toBytes("table");
+  private static final byte[] ROW = Bytes.toBytes("row");
+  
+  private static final byte[] COL = Bytes.toBytes("col:");
+  private static final byte[] COL_Q1 = Bytes.toBytes("col:q1");
+  private static final byte[] COL_Q2 = Bytes.toBytes("col:q2");
+  
+  private static final String[] vals = { "val1", "val2", "val3",
+                                         "val4", "val5", "val6",
+                                         "val7", "val8", "val9", "val10"};
+  
+  public void testGetRowMultipleVersions() {
+    HTable table = null;
+    long[] timestamps = {1L, 2L, 3L, 4L, 5L};
+    try {
+      HBaseAdmin admin = new HBaseAdmin(conf);
+      HTableDescriptor tableDesc =  new HTableDescriptor(TABLE);
+      tableDesc.addFamily(new HColumnDescriptor(COL));
+      admin.createTable(tableDesc);
+      
+      table = new HTable(conf, TABLE);
+      for(int i = 0; i < 5; i++) {
+        BatchUpdate bu = new BatchUpdate(ROW, timestamps[i]);
+        bu.put(COL_Q1, Bytes.toBytes(vals[i]));
+        bu.put(COL_Q2, Bytes.toBytes(vals[5 + i]));
+        table.commit(bu);
+      }
+      
+      RowResult rowResult = table.getRow(ROW, 5);
+      Cell c = rowResult.get(COL_Q1);
+      // We shouldn't get more than DEFAULT_VERSIONS
+      assertEquals(HColumnDescriptor.DEFAULT_VERSIONS, c.getNumValues());
+      int i = 4;
+      for (Entry<Long, byte[]> entry : c) {
+        assertEquals(timestamps[i], entry.getKey().longValue());
+        assertEquals(vals[i], Bytes.toString(entry.getValue()));
+        i--;
+      }
+      
+      rowResult = table.getRow(ROW, 2);
+      c = rowResult.get(COL_Q2);
+      assertEquals(2, c.getNumValues());
+      i = 4;
+      for (Entry<Long, byte[]> entry : c) {
+        assertEquals(timestamps[i], entry.getKey().longValue());
+        assertEquals(vals[5 + i], Bytes.toString(entry.getValue()));
+        i--;
+      }
+      
+      rowResult = table.getRow(ROW, timestamps[3], 2);
+      c = rowResult.get(COL_Q2);
+      // We should get one less than DEFAULT_VERSIONS as we start
+      // at the second-highest timestamp
+      assertEquals(2, c.getNumValues());
+      i = 3;
+      for (Entry<Long, byte[]> entry : c) {
+        assertEquals(timestamps[i], entry.getKey().longValue());
+        assertEquals(vals[5 + i], Bytes.toString(entry.getValue()));
+
+        i--;
+      }
+      
+      table.deleteFamily(ROW, COL, timestamps[2]);
+      rowResult = table.getRow(ROW, 5);
+      c = rowResult.get(COL_Q1);
+      assertEquals(2, c.getNumValues());
+      i = 4;
+      for (Entry<Long, byte[]> entry : c) {
+        assertEquals(timestamps[i], entry.getKey().longValue());
+        assertEquals(vals[i], Bytes.toString(entry.getValue()));
+        i--;
+      }
+    } catch (IOException e) {
+      e.printStackTrace();
+      fail("Should not have any exception " +
+        e.getClass());
+    }
+  }
+}
Index: src/java/org/apache/hadoop/hbase/regionserver/Memcache.java
===================================================================
--- src/java/org/apache/hadoop/hbase/regionserver/Memcache.java	(revision 700743)
+++ src/java/org/apache/hadoop/hbase/regionserver/Memcache.java	(working copy)
@@ -284,19 +284,20 @@
    * row and timestamp, but not a column name.
    * @param key
    * @param columns Pass null for all columns else the wanted subset.
+   * @param numVersions number of versions to retrieve
    * @param deletes Map to accumulate deletes found.
    * @param results Where to stick row results found.
    */
-  void getFull(HStoreKey key, Set<byte []> columns, Map<byte [], Long> deletes, 
-    Map<byte [], Cell> results) {
+  void getFull(HStoreKey key, Set<byte []> columns, int numVersions,
+    Map<byte [], Long> deletes, Map<byte [], Cell> results) {
     this.lock.readLock().lock();
     try {
       // The synchronizations here are because internalGet iterates
       synchronized (this.memcache) {
-        internalGetFull(this.memcache, key, columns, deletes, results);
+        internalGetFull(this.memcache, key, columns, numVersions, deletes, results);
       }
       synchronized (this.snapshot) {
-        internalGetFull(this.snapshot, key, columns, deletes, results);
+        internalGetFull(this.snapshot, key, columns, numVersions, deletes, results);
       }
     } finally {
       this.lock.readLock().unlock();
@@ -304,7 +305,7 @@
   }
 
   private void internalGetFull(SortedMap<HStoreKey, byte[]> map, HStoreKey key, 
-      Set<byte []> columns, Map<byte [], Long> deletes,
+      Set<byte []> columns, int numVersions, Map<byte [], Long> deletes,
       Map<byte [], Cell> results) {
     if (map.isEmpty() || key == null) {
       return;
@@ -315,7 +316,8 @@
     for (Map.Entry<HStoreKey, byte []> es: tailMap.entrySet()) {
       HStoreKey itKey = es.getKey();
       byte [] itCol = itKey.getColumn();
-      if (results.get(itCol) == null && key.matchesWithoutColumn(itKey)) {
+      Cell cell = results.get(itCol);
+      if ((cell == null || cell.getNumValues() < numVersions) && key.matchesWithoutColumn(itKey)) {
         if (columns == null || columns.contains(itKey.getColumn())) {
           byte [] val = tailMap.get(itKey);
           if (HLogEdit.isDeleted(val)) {
@@ -328,7 +330,11 @@
             // Skip expired cells
             if (ttl == HConstants.FOREVER ||
                   now < itKey.getTimestamp() + ttl) {
-              results.put(itCol, new Cell(val, itKey.getTimestamp()));
+              if (cell == null) {
+                results.put(itCol, new Cell(val, itKey.getTimestamp()));
+              } else {
+                cell.add(val, itKey.getTimestamp());
+              }
             } else {
               addVictim(victims, itKey);
             }
@@ -770,7 +776,7 @@
         }
         key.setRow(this.currentRow);
         key.setVersion(this.timestamp);
-        getFull(key, isWildcardScanner() ? null : this.columns, deletes,
+        getFull(key, isWildcardScanner() ? null : this.columns, 1, deletes,
             rowResults);
         for (Map.Entry<byte [], Long> e: deletes.entrySet()) {
           rowResults.put(e.getKey(),
Index: src/java/org/apache/hadoop/hbase/regionserver/HStore.java
===================================================================
--- src/java/org/apache/hadoop/hbase/regionserver/HStore.java	(revision 700743)
+++ src/java/org/apache/hadoop/hbase/regionserver/HStore.java	(working copy)
@@ -1133,8 +1133,10 @@
    * The returned object should map column names to Cells.
    */
   void getFull(HStoreKey key, final Set<byte []> columns,
-      Map<byte [], Cell> results)
+      final int numVersions, Map<byte [], Cell> results)
   throws IOException {
+    int versions = versionsToReturn(numVersions);
+
     Map<byte [], Long> deletes =
       new TreeMap<byte [], Long>(Bytes.BYTES_COMPARATOR);
 
@@ -1146,7 +1148,7 @@
     this.lock.readLock().lock();
     
     // get from the memcache first.
-    memcache.getFull(key, columns, deletes, results);
+    memcache.getFull(key, columns, versions, deletes, results);
     
     try {
       MapFile.Reader[] maparray = getReaders();
@@ -1157,7 +1159,7 @@
         
         // synchronize on the map so that no one else iterates it at the same 
         // time
-        getFullFromMapFile(map, key, columns, deletes, results);
+        getFullFromMapFile(map, key, columns, versions, deletes, results);
       }
       
     } finally {
@@ -1166,7 +1168,8 @@
   }
   
   private void getFullFromMapFile(MapFile.Reader map, HStoreKey key, 
-    Set<byte []> columns, Map<byte [], Long> deletes, Map<byte [], Cell> results) 
+    Set<byte []> columns, int numVersions, Map<byte [], Long> deletes,
+    Map<byte [], Cell> results) 
   throws IOException {
     synchronized(map) {
       long now = System.currentTimeMillis();
@@ -1180,14 +1183,17 @@
       if (readkey == null) {
         return;
       }
+      
       do {
         byte [] readcol = readkey.getColumn();
         
         // if we're looking for this column (or all of them), and there isn't 
-        // already a value for this column in the results map, and the key we 
+        // already a value for this column in the results map or there is a value
+        // but we haven't collected enough versions yet, and the key we 
         // just read matches, then we'll consider it
         if ((columns == null || columns.contains(readcol)) 
-          && !results.containsKey(readcol)
+          && (!results.containsKey(readcol) 
+              || results.get(readcol).getNumValues() < numVersions)
           && key.matchesWithoutColumn(readkey)) {
           // if the value of the cell we're looking at right now is a delete, 
           // we need to treat it differently
@@ -1206,8 +1212,13 @@
             if (!(deletes.containsKey(readcol) &&
                 deletes.get(readcol).longValue() >= readkey.getTimestamp())) {
               if (!isExpired(readkey, ttl, now)) {
-                results.put(readcol, 
-                  new Cell(readval.get(), readkey.getTimestamp()));
+                if (!results.containsKey(readcol)) {
+                  results.put(readcol,
+                              new Cell(readval.get(), readkey.getTimestamp()));
+                } else {
+                  results.get(readcol).add(readval.get(),
+                                           readkey.getTimestamp());
+                }
                 // need to reinstantiate the readval so we can reuse it, 
                 // otherwise next iteration will destroy our result
                 readval = new ImmutableBytesWritable();
Index: src/java/org/apache/hadoop/hbase/regionserver/transactional/TransactionalRegion.java
===================================================================
--- src/java/org/apache/hadoop/hbase/regionserver/transactional/TransactionalRegion.java	(revision 700743)
+++ src/java/org/apache/hadoop/hbase/regionserver/transactional/TransactionalRegion.java	(working copy)
@@ -309,12 +309,12 @@
         LOG.trace("cell: " + Bytes.toString(entry.getValue().getValue()));
       }
 
-      Map<byte[], Cell> internalResults = getFull(row, columns, ts, null);
+      Map<byte[], Cell> internalResults = getFull(row, columns, ts, 1, null);
       internalResults.putAll(localCells);
       return internalResults;
     }
 
-    return getFull(row, columns, ts, null);
+    return getFull(row, columns, ts, 1, null);
   }
 
   /**
Index: src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
===================================================================
--- src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java	(revision 700743)
+++ src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java	(working copy)
@@ -1021,7 +1021,8 @@
   }
 
   public RowResult getRow(final byte [] regionName, final byte [] row, 
-    final byte [][] columns, final long ts, final long lockId)
+    final byte [][] columns, final long ts,
+    final int numVersions, final long lockId)
   throws IOException {
     checkOpen();
     requestCount.incrementAndGet();
@@ -1034,11 +1035,8 @@
       }
       
       HRegion region = getRegion(regionName);
-      Map<byte [], Cell> map = region.getFull(row, columnSet, ts,
-          getLockFromId(lockId));
-      HbaseMapWritable<byte [], Cell> result =
-        new HbaseMapWritable<byte [], Cell>();
-      result.putAll(map);
+      HbaseMapWritable<byte [], Cell> result = region.getFull(row, columnSet, 
+          ts, numVersions, getLockFromId(lockId));
       return new RowResult(row, result);
     } catch (IOException e) {
       checkFileSystem();
Index: src/java/org/apache/hadoop/hbase/regionserver/HRegion.java
===================================================================
--- src/java/org/apache/hadoop/hbase/regionserver/HRegion.java	(revision 700743)
+++ src/java/org/apache/hadoop/hbase/regionserver/HRegion.java	(working copy)
@@ -1162,7 +1162,7 @@
 
   /**
    * Fetch all the columns for the indicated row at a specified timestamp.
-   * Returns a TreeMap that maps column names to values.
+   * Returns a HbaseMapWritable that maps column names to values.
    *
    * We should eventually use Bloom filters here, to reduce running time.  If 
    * the database has many column families and is very sparse, then we could be 
@@ -1173,12 +1173,14 @@
    * @param row
    * @param columns Array of columns you'd like to retrieve. When null, get all.
    * @param ts
+   * @param numVersions number of versions to retrieve
    * @param lockid
-   * @return Map<columnName, Cell> values
+   * @return HbaseMapWritable<columnName, Cell> values
    * @throws IOException
    */
-  public Map<byte [], Cell> getFull(final byte [] row,
-      final Set<byte []> columns, final long ts, final Integer lockid) 
+  public HbaseMapWritable<byte [], Cell> getFull(final byte [] row,
+      final Set<byte []> columns, final long ts,
+      final int numVersions, final Integer lockid) 
   throws IOException {
     // Check columns passed
     if (columns != null) {
@@ -1190,8 +1192,8 @@
     Integer lid = getLock(lockid,row);
     HashSet<HStore> storeSet = new HashSet<HStore>();
     try {
-      TreeMap<byte [], Cell> result =
-        new TreeMap<byte [], Cell>(Bytes.BYTES_COMPARATOR);
+      HbaseMapWritable<byte [], Cell> result =
+        new HbaseMapWritable<byte [], Cell>();
       // Get the concerned columns or all of them
       if (columns != null) {
         for (byte[] bs : columns) {
@@ -1211,14 +1213,14 @@
         for (byte[] bs : columns) {
           if (HStoreKey.getFamilyDelimiterIndex(bs) == (bs.length - 1)) {
             HStore store = stores.get(Bytes.mapKey(HStoreKey.getFamily(bs)));
-            store.getFull(key, null, result);
+            store.getFull(key, null, numVersions, result);
             storeSet.remove(store);
           }
         }
       }
       
       for (HStore targetStore: storeSet) {
-        targetStore.getFull(key, columns, result);
+        targetStore.getFull(key, columns, numVersions, result);
       }
       
       return result;
@@ -1268,7 +1270,7 @@
       HbaseMapWritable<byte [], Cell> cells =
         new HbaseMapWritable<byte [], Cell>();
       for (HStore s: stores.values()) {
-        s.getFull(key, null, cells);
+        s.getFull(key, null, 1, cells);
       }
       return new RowResult(key.getRow(), cells);
     } finally {
Index: src/java/org/apache/hadoop/hbase/io/Cell.java
===================================================================
--- src/java/org/apache/hadoop/hbase/io/Cell.java	(revision 700743)
+++ src/java/org/apache/hadoop/hbase/io/Cell.java	(working copy)
@@ -22,7 +22,12 @@
 import java.io.DataInput;
 import java.io.DataOutput;
 import java.io.IOException;
+import java.util.Comparator;
 import java.util.Iterator;
+import java.util.Map;
+import java.util.SortedMap;
+import java.util.TreeMap;
+import java.util.Map.Entry;
 
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.io.Writable;
@@ -33,14 +38,15 @@
  * the timestamp of a cell to a first-class value, making it easy to take 
  * note of temporal data. Cell is used all the way from HStore up to HTable.
  */
-public class Cell implements Writable, Iterable<Cell> {
-  protected byte[][] values;
-  protected long[] timestamps;
+public class Cell implements Writable, Iterable<Map.Entry<Long, byte[]>> {
+  protected final SortedMap<Long, byte[]> valueMap =
+    new TreeMap<Long, byte[]>(new Comparator<Long>() {
+      public int compare(Long l1, Long l2) {
+        return l2.compareTo(l1);
+    }});
   
   /** For Writable compatibility */
   public Cell() {
-    values = null;
-    timestamps = null;
   }
 
   /**
@@ -58,10 +64,7 @@
    * @param timestamp
    */
   public Cell(byte[] value, long timestamp) {
-    this.values = new byte[1][];
-    this.values[0] = value;
-    this.timestamps = new long[1];
-    this.timestamps[0] = timestamp;
+    valueMap.put(timestamp, value);
   }
   
   /**
@@ -69,16 +72,7 @@
    * @param ts array of timestamps
    */
   public Cell(String[] vals, long[] ts) {
-    if (vals.length != ts.length) {
-      throw new IllegalArgumentException(
-          "number of values must be the same as the number of timestamps");
-    }
-    this.values = new byte[vals.length][];
-    this.timestamps = new long[ts.length];
-    for (int i = 0; i < values.length; i++) {
-      this.values[i] = Bytes.toBytes(vals[i]);
-      this.timestamps[i] = ts[i];
-    }
+    this(Bytes.toByteArrays(vals), ts);
   }
   
   /**
@@ -90,38 +84,59 @@
       throw new IllegalArgumentException(
           "number of values must be the same as the number of timestamps");
     }
-    this.values = new byte[vals.length][];
-    this.timestamps = new long[ts.length];
-    System.arraycopy(vals, 0, this.values, 0, vals.length);
-    System.arraycopy(ts, 0, this.timestamps, 0, ts.length);
+    for (int i = 0; i < vals.length; i++) {
+      valueMap.put(ts[i], vals[i]);
+    }
   }
   
   /** @return the current cell's value */
   public byte[] getValue() {
-    return values[0];
+    return valueMap.get(valueMap.firstKey());
   }
   
   /** @return the current cell's timestamp */
   public long getTimestamp() {
-    return timestamps[0];
+    return valueMap.firstKey();
   }
   
+  /** @return the number of values this cell holds */
+  public int getNumValues() {
+    return valueMap.size();
+  }
+  
+  /** Add values and timestamps of another cell into this cell 
+   * @param c Cell
+   */
+  public void mergeCell(Cell c) {
+    valueMap.putAll(c.valueMap);
+  }
+  
+  /** Add a new timestamp and value to this cell
+   * @param val value
+   * @param ts timestamp
+   */
+  public void add(byte[] val, long ts) {
+    valueMap.put(ts, val);
+  }
+  
   @Override
   public String toString() {
-    if (this.values.length == 1) {
-      return "timestamp=" + this.timestamps[0] + ", value=" +
-        Bytes.toString(this.values[0]);
+    if (valueMap.size() == 1) {
+      return "timestamp=" + getTimestamp() + ", value=" +
+        Bytes.toString(getValue());
     }
     StringBuilder s = new StringBuilder("{ ");
-    for (int i = 0; i < this.values.length; i++) {
+    int i = 0;
+    for (Map.Entry<Long, byte[]> entry : valueMap.entrySet()) {
       if (i > 0) {
         s.append(", ");
       }
       s.append("[timestamp=");
-      s.append(timestamps[i]);
+      s.append(entry.getKey());
       s.append(", value=");
-      s.append(Bytes.toString(values[i]));
+      s.append(Bytes.toString(entry.getValue()));
       s.append("]");
+      i++;
     }
     s.append(" }");
     return s.toString();
@@ -133,46 +148,41 @@
 
   public void readFields(final DataInput in) throws IOException {
     int nvalues = in.readInt();
-    this.timestamps = new long[nvalues];
-    this.values = new byte[nvalues][];
     for (int i = 0; i < nvalues; i++) {
-      this.timestamps[i] = in.readLong();
+      long timestamp = in.readLong();
+      byte[] value = Bytes.readByteArray(in);
+      valueMap.put(timestamp, value);
     }
-    for (int i = 0; i < nvalues; i++) {
-      this.values[i] = Bytes.readByteArray(in);
-    }
   }
 
   public void write(final DataOutput out) throws IOException {
-    out.writeInt(this.values.length);
-    for (int i = 0; i < this.timestamps.length; i++) {
-      out.writeLong(this.timestamps[i]);
+    out.writeInt(valueMap.size());
+    for (Map.Entry<Long, byte[]> entry : valueMap.entrySet()) {
+      out.writeLong(entry.getKey());
+      Bytes.writeByteArray(out, entry.getValue());
     }
-    for (int i = 0; i < this.values.length; i++) {
-      Bytes.writeByteArray(out, this.values[i]);
-    }
   }
   
   //
   // Iterable
   //
 
-  public Iterator<Cell> iterator() {
+  public Iterator<Entry<Long, byte[]>> iterator() {
     return new CellIterator();
   }
-  private class CellIterator implements Iterator<Cell> {
-    private int currentValue = 0;
+  
+  private class CellIterator implements Iterator<Entry<Long, byte[]>> {
+    private Iterator<Entry<Long, byte[]>> it;
     CellIterator() {
+      it = valueMap.entrySet().iterator();
     }
     
     public boolean hasNext() {
-      return currentValue < values.length;
+      return it.hasNext();
     }
     
-    public Cell next() {
-      Cell c = new Cell(values[currentValue], timestamps[currentValue]);
-      currentValue++;
-      return c;
+    public Entry<Long, byte[]> next() {
+      return it.next();
     }
     
     public void remove() throws UnsupportedOperationException {
Index: src/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java
===================================================================
--- src/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java	(revision 700743)
+++ src/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java	(working copy)
@@ -36,9 +36,8 @@
 public interface HRegionInterface extends VersionedProtocol {
   /**
    * Protocol version.
-   * Upped to 5 when we added scanner caching
    */
-  public static final long versionID = 5L;
+  public static final long versionID = 6L;
 
   /** 
    * Get metainfo about an HRegion
@@ -86,12 +85,14 @@
    * @param row row key
    * @param columns columns to get
    * @param ts time stamp
+   * @param numVersions number of versions
    * @param lockId lock id
    * @return map of values
    * @throws IOException
    */
   public RowResult getRow(final byte [] regionName, final byte [] row, 
-    final byte[][] columns, final long ts, final long lockId)
+    final byte[][] columns, final long ts,
+    final int numVersions, final long lockId)
   throws IOException;
 
   /**
Index: src/java/org/apache/hadoop/hbase/client/HTable.java
===================================================================
--- src/java/org/apache/hadoop/hbase/client/HTable.java	(revision 700743)
+++ src/java/org/apache/hadoop/hbase/client/HTable.java	(working copy)
@@ -411,8 +411,35 @@
   public RowResult getRow(final byte [] row) throws IOException {
     return getRow(row, HConstants.LATEST_TIMESTAMP);
   }
+ 
+  /** 
+   * Get more than one version of all columns for the specified row
+   * 
+   * @param row row key
+   * @param numVersions number of versions to return
+   * @return RowResult is empty if row does not exist.
+   * @throws IOException
+   */
+  public RowResult getRow(final String row, final int numVersions)
+  throws IOException {
+    return getRow(Bytes.toBytes(row), null, 
+                  HConstants.LATEST_TIMESTAMP, numVersions, null);
+  }
 
   /** 
+   * Get more than one version of all columns for the specified row
+   * 
+   * @param row row key
+   * @param numVersions number of versions to return
+   * @return RowResult is empty if row does not exist.
+   * @throws IOException
+   */
+  public RowResult getRow(final byte[] row, final int numVersions)
+  throws IOException {
+    return getRow(row, null, HConstants.LATEST_TIMESTAMP, numVersions, null);
+  }
+
+  /** 
    * Get all the data for the specified row at a specified timestamp
    * 
    * @param row row key
@@ -437,6 +464,26 @@
   throws IOException {
     return getRow(row,null,ts);
   }
+  
+  public RowResult getRow(final String row, final long ts,
+      final int numVersions) throws IOException {
+    return getRow(Bytes.toBytes(row), null, ts, numVersions, null);
+  }
+  
+  /** 
+   * Get more than one version of all columns for the specified row
+   * at a specified timestamp
+   * 
+   * @param row row key
+   * @param ts timestamp
+   * @param numVersions number of versions to return
+   * @return RowResult is empty if row does not exist.
+   * @throws IOException
+   */
+  public RowResult getRow(final byte[] row, final long timestamp,
+      final int numVersions) throws IOException {
+    return getRow(row, null, timestamp, numVersions, null);
+  }
 
   /** 
    * Get selected columns for the specified row at the latest timestamp
@@ -463,6 +510,35 @@
   throws IOException {
     return getRow(row, columns, HConstants.LATEST_TIMESTAMP);
   }
+  
+  /** 
+   * Get more than one version of selected columns for the specified row
+   * 
+   * @param row row key
+   * @param columns Array of column names and families you want to retrieve.
+   * @param numVersions number of versions to return
+   * @return RowResult is empty if row does not exist.
+   * @throws IOException
+   */
+  public RowResult getRow(final String row, final String[] columns,
+      final int numVersions) throws IOException {
+    return getRow(Bytes.toBytes(row), Bytes.toByteArrays(columns),
+                  HConstants.LATEST_TIMESTAMP, numVersions, null);
+  }
+  
+  /** 
+   * Get more than one version of selected columns for the specified row
+   * 
+   * @param row row key
+   * @param columns Array of column names and families you want to retrieve.
+   * @param numVersions number of versions to return
+   * @return RowResult is empty if row does not exist.
+   * @throws IOException
+   */
+  public RowResult getRow(final byte[] row, final byte[][] columns,
+      final int numVersions) throws IOException {
+    return getRow(row, columns, HConstants.LATEST_TIMESTAMP, numVersions, null);
+  }
 
   /** 
    * Get selected columns for the specified row at a specified timestamp
@@ -491,8 +567,16 @@
   public RowResult getRow(final byte [] row, final byte [][] columns, 
     final long ts) 
   throws IOException {       
-    return getRow(row,columns,ts,null);
+    return getRow(row,columns,ts,1,null);
   }
+  
+  public RowResult getRow(final String row, final String[] columns,
+      final long timestamp, final int numVersions, final RowLock rowLock)
+  throws IOException {
+    return getRow(Bytes.toBytes(row), Bytes.toByteArrays(columns), timestamp,
+                  numVersions, rowLock);
+  }
+  
 
   /** 
    * Get selected columns for the specified row at a specified timestamp
@@ -506,7 +590,7 @@
    * @throws IOException
    */
   public RowResult getRow(final byte [] row, final byte [][] columns, 
-    final long ts, final RowLock rl) 
+    final long ts, final int numVersions, final RowLock rl) 
   throws IOException {       
     return connection.getRegionServerWithRetries(
         new ServerCallable<RowResult>(connection, tableName, row) {
@@ -516,7 +600,7 @@
               lockId = rl.getLockId();
             }
             return server.getRow(location.getRegionInfo().getRegionName(), row, 
-                columns, ts, lockId);
+                columns, ts, numVersions, lockId);
           }
         }
     );
