diff --git a/src/java/org/apache/hadoop/hbase/client/HTable.java b/src/java/org/apache/hadoop/hbase/client/HTable.java
index 1fe1406..5304800 100644
--- a/src/java/org/apache/hadoop/hbase/client/HTable.java
+++ b/src/java/org/apache/hadoop/hbase/client/HTable.java
@@ -390,6 +390,18 @@ public class HTable {
   public RowResult getRow(final byte [] row) throws IOException {
     return getRow(row, HConstants.LATEST_TIMESTAMP);
   }
+    
+  public RowResult getRow(final String row, final int numVersions)
+  throws IOException {
+    return getRow(Bytes.toBytes(row), null, 
+                  HConstants.LATEST_TIMESTAMP, numVersions, null);
+  }
+
+  
+  public RowResult getRow(final byte[] row, final int numVersions)
+  throws IOException {
+    return getRow(row, null, HConstants.LATEST_TIMESTAMP, numVersions, null);
+  }
 
   /** 
    * Get all the data for the specified row at a specified timestamp
@@ -416,6 +428,16 @@ public class HTable {
   throws IOException {
     return getRow(row,null,ts);
   }
+  
+  public RowResult getRow(final String row, final long ts,
+      final int numVersions) throws IOException {
+    return getRow(Bytes.toBytes(row), null, ts, numVersions, null);
+  }
+  
+  public RowResult getRow(final byte[] row, final long timestamp,
+      final int numVersions) throws IOException {
+    return getRow(row, null, timestamp, numVersions, null);
+  }
 
   /** 
    * Get selected columns for the specified row at the latest timestamp
@@ -442,6 +464,17 @@ public class HTable {
   throws IOException {
     return getRow(row, columns, HConstants.LATEST_TIMESTAMP);
   }
+  
+  public RowResult getRow(final String row, final String[] columns,
+      final int numVersions) throws IOException {
+    return getRow(Bytes.toBytes(row), Bytes.toByteArrays(columns),
+                  HConstants.LATEST_TIMESTAMP, numVersions, null);
+  }
+  
+  public RowResult getRow(final byte[] row, final byte[][] columns,
+      final int numVersions) throws IOException {
+    return getRow(row, columns, HConstants.LATEST_TIMESTAMP, numVersions, null);
+  }
 
   /** 
    * Get selected columns for the specified row at a specified timestamp
@@ -470,8 +503,16 @@ public class HTable {
   public RowResult getRow(final byte [] row, final byte [][] columns, 
     final long ts) 
   throws IOException {       
-    return getRow(row,columns,ts,null);
+    return getRow(row,columns,ts,1,null);
   }
+  
+  public RowResult getRow(final String row, final String[] columns,
+      final long timestamp, final int numVersions, final RowLock rowLock)
+  throws IOException {
+    return getRow(Bytes.toBytes(row), Bytes.toByteArrays(columns), timestamp,
+                  numVersions, rowLock);
+  }
+  
 
   /** 
    * Get selected columns for the specified row at a specified timestamp
@@ -485,7 +526,7 @@ public class HTable {
    * @throws IOException
    */
   public RowResult getRow(final byte [] row, final byte [][] columns, 
-    final long ts, final RowLock rl) 
+    final long ts, final int numVersions, final RowLock rl) 
   throws IOException {       
     return connection.getRegionServerWithRetries(
         new ServerCallable<RowResult>(connection, tableName, row) {
@@ -495,7 +536,7 @@ public class HTable {
               lockId = rl.getLockId();
             }
             return server.getRow(location.getRegionInfo().getRegionName(), row, 
-                columns, ts, lockId);
+                columns, ts, numVersions, lockId);
           }
         }
     );
diff --git a/src/java/org/apache/hadoop/hbase/io/Cell.java b/src/java/org/apache/hadoop/hbase/io/Cell.java
index 52dc7a3..0ef044e 100644
--- a/src/java/org/apache/hadoop/hbase/io/Cell.java
+++ b/src/java/org/apache/hadoop/hbase/io/Cell.java
@@ -106,6 +106,30 @@ public class Cell implements Writable, Iterable<Cell> {
     return timestamps[0];
   }
   
+  /** @return the number of values this cell holds */
+  public int getNumValues() {
+    return values.length;
+  }
+  
+  /** Add values and timestamps of another cell into this cell 
+   * @param c Cell
+   */
+  public void mergeCell(Cell c) {
+    int newSize = values.length + c.values.length;
+    byte[][] newValues = new byte[newSize][];
+    long[] newTimestamps = new long[newSize];
+    
+    System.arraycopy(values, 0, newValues, 0, values.length);
+    System.arraycopy(c.values, 0, newValues, values.length, c.values.length);
+    
+    System.arraycopy(timestamps, 0, newTimestamps, 0, timestamps.length);
+    System.arraycopy(c.timestamps, 0, newTimestamps,
+                     timestamps.length, c.timestamps.length);
+    
+    this.values = newValues;
+    this.timestamps = newTimestamps;
+  }
+  
   @Override
   public String toString() {
     if (this.values.length == 1) {
@@ -161,7 +185,7 @@ public class Cell implements Writable, Iterable<Cell> {
     return new CellIterator();
   }
   private class CellIterator implements Iterator<Cell> {
-    private int currentValue = -1;
+    private int currentValue = 0;
     CellIterator() {
     }
     
@@ -170,8 +194,9 @@ public class Cell implements Writable, Iterable<Cell> {
     }
     
     public Cell next() {
-      currentValue += 1;
-      return new Cell(values[currentValue], timestamps[currentValue]);
+      Cell c = new Cell(values[currentValue], timestamps[currentValue]);
+      currentValue++;
+      return c;
     }
     
     public void remove() throws UnsupportedOperationException {
diff --git a/src/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java b/src/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java
index 0a41e1d..615280f 100644
--- a/src/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java
+++ b/src/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java
@@ -38,7 +38,7 @@ public interface HRegionInterface extends VersionedProtocol {
    * Protocol version.
    * Upped to 4 when we removed overloaded methods from the protocol.
    */
-  public static final long versionID = 4L;
+  public static final long versionID = 5L;
 
   /** 
    * Get metainfo about an HRegion
@@ -86,12 +86,14 @@ public interface HRegionInterface extends VersionedProtocol {
    * @param row row key
    * @param columns columns to get
    * @param ts time stamp
+   * @param numVersions number of versions
    * @param lockId lock id
    * @return map of values
    * @throws IOException
    */
   public RowResult getRow(final byte [] regionName, final byte [] row, 
-    final byte[][] columns, final long ts, final long lockId)
+    final byte[][] columns, final long ts,
+    final int numVersions, final long lockId)
   throws IOException;
 
   /**
diff --git a/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java
index 83720f2..27d3c48 100644
--- a/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java
+++ b/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java
@@ -1162,7 +1162,7 @@ public class HRegion implements HConstants {
 
   /**
    * Fetch all the columns for the indicated row at a specified timestamp.
-   * Returns a TreeMap that maps column names to values.
+   * Returns a HbaseMapWritable that maps column names to values.
    *
    * We should eventually use Bloom filters here, to reduce running time.  If 
    * the database has many column families and is very sparse, then we could be 
@@ -1173,12 +1173,14 @@ public class HRegion implements HConstants {
    * @param row
    * @param columns Array of columns you'd like to retrieve. When null, get all.
    * @param ts
+   * @param numVersions number of versions to retrieve
    * @param lockid
-   * @return Map<columnName, Cell> values
+   * @return HbaseMapWritable<columnName, Cell> values
    * @throws IOException
    */
-  public Map<byte [], Cell> getFull(final byte [] row,
-      final Set<byte []> columns, final long ts, final Integer lockid) 
+  public HbaseMapWritable<byte [], Cell> getFull(final byte [] row,
+      final Set<byte []> columns, final long ts,
+      final int numVersions, final Integer lockid) 
   throws IOException {
     // Check columns passed
     if (columns != null) {
@@ -1190,8 +1192,8 @@ public class HRegion implements HConstants {
     Integer lid = getLock(lockid,row);
     HashSet<HStore> storeSet = new HashSet<HStore>();
     try {
-      TreeMap<byte [], Cell> result =
-        new TreeMap<byte [], Cell>(Bytes.BYTES_COMPARATOR);
+      HbaseMapWritable<byte [], Cell> result =
+        new HbaseMapWritable<byte [], Cell>();
       // Get the concerned columns or all of them
       if (columns != null) {
         for (byte[] bs : columns) {
@@ -1211,14 +1213,14 @@ public class HRegion implements HConstants {
         for (byte[] bs : columns) {
           if (HStoreKey.getFamilyDelimiterIndex(bs) == (bs.length - 1)) {
             HStore store = stores.get(Bytes.mapKey(HStoreKey.getFamily(bs)));
-            store.getFull(key, null, result);
+            store.getFull(key, null, numVersions, result);
             storeSet.remove(store);
           }
         }
       }
       
       for (HStore targetStore: storeSet) {
-        targetStore.getFull(key, columns, result);
+        targetStore.getFull(key, columns, numVersions, result);
       }
       
       return result;
@@ -1268,7 +1270,7 @@ public class HRegion implements HConstants {
       HbaseMapWritable<byte [], Cell> cells =
         new HbaseMapWritable<byte [], Cell>();
       for (HStore s: stores.values()) {
-        s.getFull(key, null, cells);
+        s.getFull(key, null, 1, cells);
       }
       return new RowResult(key.getRow(), cells);
     } finally {
diff --git a/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
index 8a5a72d..5a5ba29 100644
--- a/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
+++ b/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
@@ -1020,7 +1020,8 @@ public class HRegionServer implements HConstants, HRegionInterface, Runnable {
   }
 
   public RowResult getRow(final byte [] regionName, final byte [] row, 
-    final byte [][] columns, final long ts, final long lockId)
+    final byte [][] columns, final long ts,
+    final int numVersions, final long lockId)
   throws IOException {
     checkOpen();
     requestCount.incrementAndGet();
@@ -1033,11 +1034,8 @@ public class HRegionServer implements HConstants, HRegionInterface, Runnable {
       }
       
       HRegion region = getRegion(regionName);
-      Map<byte [], Cell> map = region.getFull(row, columnSet, ts,
-          getLockFromId(lockId));
-      HbaseMapWritable<byte [], Cell> result =
-        new HbaseMapWritable<byte [], Cell>();
-      result.putAll(map);
+      HbaseMapWritable<byte [], Cell> result = region.getFull(row, columnSet, 
+          ts, numVersions, getLockFromId(lockId));
       return new RowResult(row, result);
     } catch (IOException e) {
       checkFileSystem();
diff --git a/src/java/org/apache/hadoop/hbase/regionserver/HStore.java b/src/java/org/apache/hadoop/hbase/regionserver/HStore.java
index b3c28dc..4c42aef 100644
--- a/src/java/org/apache/hadoop/hbase/regionserver/HStore.java
+++ b/src/java/org/apache/hadoop/hbase/regionserver/HStore.java
@@ -1133,7 +1133,7 @@ public class HStore implements HConstants {
    * The returned object should map column names to Cells.
    */
   void getFull(HStoreKey key, final Set<byte []> columns,
-      Map<byte [], Cell> results)
+      final int numVersions, Map<byte [], Cell> results)
   throws IOException {
     Map<byte [], Long> deletes =
       new TreeMap<byte [], Long>(Bytes.BYTES_COMPARATOR);
@@ -1146,7 +1146,7 @@ public class HStore implements HConstants {
     this.lock.readLock().lock();
     
     // get from the memcache first.
-    memcache.getFull(key, columns, deletes, results);
+    memcache.getFull(key, columns, numVersions, deletes, results);
     
     try {
       MapFile.Reader[] maparray = getReaders();
@@ -1157,7 +1157,7 @@ public class HStore implements HConstants {
         
         // synchronize on the map so that no one else iterates it at the same 
         // time
-        getFullFromMapFile(map, key, columns, deletes, results);
+        getFullFromMapFile(map, key, columns, numVersions, deletes, results);
       }
       
     } finally {
@@ -1166,7 +1166,8 @@ public class HStore implements HConstants {
   }
   
   private void getFullFromMapFile(MapFile.Reader map, HStoreKey key, 
-    Set<byte []> columns, Map<byte [], Long> deletes, Map<byte [], Cell> results) 
+    Set<byte []> columns, int numVersions, Map<byte [], Long> deletes,
+    Map<byte [], Cell> results) 
   throws IOException {
     synchronized(map) {
       long now = System.currentTimeMillis();
@@ -1180,14 +1181,17 @@ public class HStore implements HConstants {
       if (readkey == null) {
         return;
       }
+      
       do {
         byte [] readcol = readkey.getColumn();
         
         // if we're looking for this column (or all of them), and there isn't 
-        // already a value for this column in the results map, and the key we 
+        // already a value for this column in the results map or there is a value
+        // but we haven't collected enough versions yet, and the key we 
         // just read matches, then we'll consider it
         if ((columns == null || columns.contains(readcol)) 
-          && !results.containsKey(readcol)
+          && (!results.containsKey(readcol) 
+              || results.get(readcol).getNumValues() < numVersions)
           && key.matchesWithoutColumn(readkey)) {
           // if the value of the cell we're looking at right now is a delete, 
           // we need to treat it differently
@@ -1206,8 +1210,12 @@ public class HStore implements HConstants {
             if (!(deletes.containsKey(readcol) &&
                 deletes.get(readcol).longValue() >= readkey.getTimestamp())) {
               if (!isExpired(readkey, ttl, now)) {
-                results.put(readcol, 
-                  new Cell(readval.get(), readkey.getTimestamp()));
+                Cell cell = new Cell(readval.get(), readkey.getTimestamp());
+                if (!results.containsKey(readcol)) {
+                  results.put(readcol, cell);
+                } else {
+                  results.get(readcol).mergeCell(cell);
+                }
                 // need to reinstantiate the readval so we can reuse it, 
                 // otherwise next iteration will destroy our result
                 readval = new ImmutableBytesWritable();
diff --git a/src/java/org/apache/hadoop/hbase/regionserver/Memcache.java b/src/java/org/apache/hadoop/hbase/regionserver/Memcache.java
index 1621be2..5d12d8e 100644
--- a/src/java/org/apache/hadoop/hbase/regionserver/Memcache.java
+++ b/src/java/org/apache/hadoop/hbase/regionserver/Memcache.java
@@ -284,19 +284,20 @@ class Memcache {
    * row and timestamp, but not a column name.
    * @param key
    * @param columns Pass null for all columns else the wanted subset.
+   * @param numVersions number of versions to retrieve
    * @param deletes Map to accumulate deletes found.
    * @param results Where to stick row results found.
    */
-  void getFull(HStoreKey key, Set<byte []> columns, Map<byte [], Long> deletes, 
-    Map<byte [], Cell> results) {
+  void getFull(HStoreKey key, Set<byte []> columns, int numVersions,
+    Map<byte [], Long> deletes, Map<byte [], Cell> results) {
     this.lock.readLock().lock();
     try {
       // The synchronizations here are because internalGet iterates
       synchronized (this.memcache) {
-        internalGetFull(this.memcache, key, columns, deletes, results);
+        internalGetFull(this.memcache, key, columns, numVersions, deletes, results);
       }
       synchronized (this.snapshot) {
-        internalGetFull(this.snapshot, key, columns, deletes, results);
+        internalGetFull(this.snapshot, key, columns, numVersions, deletes, results);
       }
     } finally {
       this.lock.readLock().unlock();
@@ -304,7 +305,7 @@ class Memcache {
   }
 
   private void internalGetFull(SortedMap<HStoreKey, byte[]> map, HStoreKey key, 
-      Set<byte []> columns, Map<byte [], Long> deletes,
+      Set<byte []> columns, int numVersions, Map<byte [], Long> deletes,
       Map<byte [], Cell> results) {
     if (map.isEmpty() || key == null) {
       return;
@@ -315,7 +316,8 @@ class Memcache {
     for (Map.Entry<HStoreKey, byte []> es: tailMap.entrySet()) {
       HStoreKey itKey = es.getKey();
       byte [] itCol = itKey.getColumn();
-      if (results.get(itCol) == null && key.matchesWithoutColumn(itKey)) {
+      Cell cell = results.get(itCol);
+      if ((cell == null || cell.getNumValues() < numVersions) && key.matchesWithoutColumn(itKey)) {
         if (columns == null || columns.contains(itKey.getColumn())) {
           byte [] val = tailMap.get(itKey);
           if (HLogEdit.isDeleted(val)) {
@@ -328,7 +330,11 @@ class Memcache {
             // Skip expired cells
             if (ttl == HConstants.FOREVER ||
                   now < itKey.getTimestamp() + ttl) {
-              results.put(itCol, new Cell(val, itKey.getTimestamp()));
+              if (cell == null) {
+                results.put(itCol, new Cell(val, itKey.getTimestamp()));
+              } else {
+                cell.mergeCell(new Cell(val, itKey.getTimestamp()));
+              }
             } else {
               addVictim(victims, itKey);
             }
@@ -770,7 +776,7 @@ class Memcache {
         }
         key.setRow(this.currentRow);
         key.setVersion(this.timestamp);
-        getFull(key, isWildcardScanner() ? null : this.columns, deletes,
+        getFull(key, isWildcardScanner() ? null : this.columns, 1, deletes,
             rowResults);
         for (Map.Entry<byte [], Long> e: deletes.entrySet()) {
           rowResults.put(e.getKey(),
diff --git a/src/java/org/apache/hadoop/hbase/regionserver/transactional/TransactionalRegion.java b/src/java/org/apache/hadoop/hbase/regionserver/transactional/TransactionalRegion.java
index 43b9287..3fa65fa 100644
--- a/src/java/org/apache/hadoop/hbase/regionserver/transactional/TransactionalRegion.java
+++ b/src/java/org/apache/hadoop/hbase/regionserver/transactional/TransactionalRegion.java
@@ -309,12 +309,12 @@ class TransactionalRegion extends HRegion {
         LOG.trace("cell: " + Bytes.toString(entry.getValue().getValue()));
       }
 
-      Map<byte[], Cell> internalResults = getFull(row, columns, ts, null);
+      Map<byte[], Cell> internalResults = getFull(row, columns, ts, 1, null);
       internalResults.putAll(localCells);
       return internalResults;
     }
 
-    return getFull(row, columns, ts, null);
+    return getFull(row, columns, ts, 1, null);
   }
 
   /**
diff --git a/src/test/org/apache/hadoop/hbase/HBaseTestCase.java b/src/test/org/apache/hadoop/hbase/HBaseTestCase.java
index 302b110..1763996 100644
--- a/src/test/org/apache/hadoop/hbase/HBaseTestCase.java
+++ b/src/test/org/apache/hadoop/hbase/HBaseTestCase.java
@@ -434,7 +434,7 @@ public abstract class HBaseTestCase extends TestCase {
      * @throws IOException
      */
     public Map<byte [], Cell> getFull(byte [] row) throws IOException {
-      return region.getFull(row, null, HConstants.LATEST_TIMESTAMP, null);
+      return region.getFull(row, null, HConstants.LATEST_TIMESTAMP, 1, null);
     }
 
     public void flushcache() throws IOException {
@@ -555,7 +555,7 @@ public abstract class HBaseTestCase extends TestCase {
   protected void assertCellEquals(final HRegion region, final byte [] row,
     final byte [] column, final long timestamp, final String value)
   throws IOException {
-    Map<byte [], Cell> result = region.getFull(row, null, timestamp, null);
+    Map<byte [], Cell> result = region.getFull(row, null, timestamp, 1, null);
     Cell cell_value = result.get(column);
     if(value == null){
       assertEquals(column.toString() + " at timestamp " + timestamp, null, cell_value);
diff --git a/src/test/org/apache/hadoop/hbase/regionserver/TestGet2.java b/src/test/org/apache/hadoop/hbase/regionserver/TestGet2.java
index b17548e..3110f87 100644
--- a/src/test/org/apache/hadoop/hbase/regionserver/TestGet2.java
+++ b/src/test/org/apache/hadoop/hbase/regionserver/TestGet2.java
@@ -554,25 +554,25 @@ public class TestGet2 extends HBaseTestCase implements HConstants {
 
     // make sure we get all of them with standard getFull
     Map<byte [], Cell> result = region.getFull(row, null, 
-      HConstants.LATEST_TIMESTAMP, null);
+      HConstants.LATEST_TIMESTAMP, 1, null);
     assertEquals(new String(result.get(COLUMNS[0]).getValue()), "column 0");
     assertEquals(new String(result.get(COLUMNS[1]).getValue()), "column 1");
     assertEquals(new String(result.get(COLUMNS[2]).getValue()), "column 2");
           
     // try to get just one
-    result = region.getFull(row, one, HConstants.LATEST_TIMESTAMP, null);
+    result = region.getFull(row, one, HConstants.LATEST_TIMESTAMP, 1, null);
     assertEquals(new String(result.get(COLUMNS[0]).getValue()), "column 0");
     assertNull(result.get(COLUMNS[1]));                                   
     assertNull(result.get(COLUMNS[2]));                                   
                                                                           
     // try to get all of them (specified)                                 
-    result = region.getFull(row, all, HConstants.LATEST_TIMESTAMP, null);       
+    result = region.getFull(row, all, HConstants.LATEST_TIMESTAMP, 1, null);       
     assertEquals(new String(result.get(COLUMNS[0]).getValue()), "column 0");
     assertEquals(new String(result.get(COLUMNS[1]).getValue()), "column 1");
     assertEquals(new String(result.get(COLUMNS[2]).getValue()), "column 2");
     
     // try to get none with empty column set
-    result = region.getFull(row, none, HConstants.LATEST_TIMESTAMP, null);
+    result = region.getFull(row, none, HConstants.LATEST_TIMESTAMP, 1, null);
     assertNull(result.get(COLUMNS[0]));
     assertNull(result.get(COLUMNS[1]));
     assertNull(result.get(COLUMNS[2]));    
@@ -603,7 +603,7 @@ public class TestGet2 extends HBaseTestCase implements HConstants {
       region.flushcache();
       
       // assert that getFull gives us the older value
-      results = region.getFull(row, (Set<byte []>)null, LATEST_TIMESTAMP, null);
+      results = region.getFull(row, (Set<byte []>)null, LATEST_TIMESTAMP, 1, null);
       assertEquals("olderValue", new String(results.get(COLUMNS[0]).getValue()));
       
       // write a new value for the cell
@@ -615,7 +615,7 @@ public class TestGet2 extends HBaseTestCase implements HConstants {
       region.flushcache();
       
       // assert that getFull gives us the later value
-      results = region.getFull(row, (Set<byte []>)null, LATEST_TIMESTAMP, null);
+      results = region.getFull(row, (Set<byte []>)null, LATEST_TIMESTAMP, 1, null);
       assertEquals("newerValue", new String(results.get(COLUMNS[0]).getValue()));
      
       //
@@ -636,7 +636,7 @@ public class TestGet2 extends HBaseTestCase implements HConstants {
       region.flushcache();
       
       // assert i get both columns
-      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, null);
+      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, 1, null);
       assertEquals("Should have two columns in the results map", 2, results.size());
       assertEquals("column0 value", new String(results.get(cell1).getValue()));
       assertEquals("column1 value", new String(results.get(cell2).getValue()));
@@ -651,7 +651,7 @@ public class TestGet2 extends HBaseTestCase implements HConstants {
       region.flushcache(); 
       
       // assert i get the second column only
-      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, null);
+      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, 1, null);
       assertEquals("Should have one column in the results map", 1, results.size());
       assertNull("column0 value", results.get(cell1));
       assertEquals("column1 new value", new String(results.get(cell2).getValue()));
@@ -665,7 +665,7 @@ public class TestGet2 extends HBaseTestCase implements HConstants {
       region.batchUpdate(batchUpdate, null);
       
       // assert i get the third column only
-      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, null);
+      results = region.getFull(row2, (Set<byte []>)null, LATEST_TIMESTAMP, 1, null);
       assertEquals("Should have one column in the results map", 1, results.size());
       assertNull("column0 value", results.get(cell1));
       assertNull("column1 value", results.get(cell2));
@@ -686,7 +686,7 @@ public class TestGet2 extends HBaseTestCase implements HConstants {
   private void assertColumnsPresent(final HRegion r, final byte [] row)
   throws IOException {
     Map<byte [], Cell> result = 
-      r.getFull(row, null, HConstants.LATEST_TIMESTAMP, null);
+      r.getFull(row, null, HConstants.LATEST_TIMESTAMP, 1, null);
     int columnCount = 0;
     for (Map.Entry<byte [], Cell> e: result.entrySet()) {
       columnCount++;
diff --git a/src/test/org/apache/hadoop/hbase/regionserver/TestHMemcache.java b/src/test/org/apache/hadoop/hbase/regionserver/TestHMemcache.java
index d5fba1a..3f25f2e 100644
--- a/src/test/org/apache/hadoop/hbase/regionserver/TestHMemcache.java
+++ b/src/test/org/apache/hadoop/hbase/regionserver/TestHMemcache.java
@@ -188,7 +188,7 @@ public class TestHMemcache extends TestCase {
         new TreeMap<byte [], Cell>(Bytes.BYTES_COMPARATOR);
       TreeMap<byte [], Long> deletes =
         new TreeMap<byte [], Long>(Bytes.BYTES_COMPARATOR);
-      this.hmemcache.getFull(hsk, null, deletes, all);
+      this.hmemcache.getFull(hsk, null, 1, deletes, all);
       isExpectedRow(i, all);
     }
   }
