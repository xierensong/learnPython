diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
index 70ed231..c10ec46 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
@@ -1362,4 +1362,46 @@ boolean isProcedureFinished(String signature, String instance, Map<String, Strin
    * @throws IOException
    */
   public int getMasterInfoPort() throws IOException;
+
+  /**
+   * Compact the mob files in all mob-enabled column families. Asynchronous operation.
+   *
+   * @param tableName table to compact
+   * @throws IOException
+   * @throws InterruptedException
+   */
+  void compactMob(final TableName tableName) throws IOException,
+    InterruptedException;
+
+  /**
+   * Compact the mob files in a mob-enabled column family. Asynchronous operation.
+   *
+   * @param tableName table to compact
+   * @param columnFamily column family within a table
+   * @throws IOException if not a mob column family or if a remote or network exception occurs
+   * @throws InterruptedException
+   */
+  void compactMobColumn(final TableName tableName, final byte[] columnFamily) throws IOException,
+    InterruptedException;
+
+  /**
+   * Major compact the mob files in all mob-enabled column family. Asynchronous operation.
+   *
+   * @param tableName table to compact
+   * @throws IOException
+   * @throws InterruptedException
+   */
+  void majorCompactMob(final TableName tableName) throws IOException,
+    InterruptedException;
+
+  /**
+   * Major compact the mob files in a mob-enabled column family. Asynchronous operation.
+   *
+   * @param tableName table to compact
+   * @param columnFamily column family within a table
+   * @throws IOException if not a mob column family or if a remote or network exception occurs
+   * @throws InterruptedException
+   */
+  void majorCompactMobColumn(final TableName tableName, final byte[] columnFamily) throws IOException,
+    InterruptedException;
 }
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
index 3acaaf9..45305b2 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
@@ -3819,4 +3819,66 @@ public Long call(int callTimeout) throws ServiceException {
       }
     });
   }
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void compactMobColumn(final TableName tableName, final byte[] columnFamily)
+    throws IOException, InterruptedException {
+    HTableDescriptor htd = getTableDescriptor(tableName);
+    HColumnDescriptor family = htd.getFamily(columnFamily);
+    if (family == null || !family.isMobEnabled()) {
+      throw new IllegalArgumentException("Column family " + columnFamily
+        + " is not a mob column family");
+    }
+    // get the mob region info, this is a dummy region.
+    HRegionInfo info = new HRegionInfo(tableName, Bytes.toBytes(".mob"), HConstants.EMPTY_END_ROW,
+      false, 0);
+    ServerName master = getClusterStatus().getMaster();
+    compact(master, info, false, columnFamily);
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void compactMob(final TableName tableName) throws IOException, InterruptedException {
+    // get the mob region info, this is a dummy region.
+    HRegionInfo info = new HRegionInfo(tableName, Bytes.toBytes(".mob"), HConstants.EMPTY_END_ROW,
+      false, 0);
+    ServerName master = getClusterStatus().getMaster();
+    compact(master, info, false, null);
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void majorCompactMobColumn(final TableName tableName, final byte[] columnFamily)
+    throws IOException, InterruptedException {
+    HTableDescriptor htd = getTableDescriptor(tableName);
+    HColumnDescriptor family = htd.getFamily(columnFamily);
+    if (family == null || !family.isMobEnabled()) {
+      throw new IllegalArgumentException("Column family " + columnFamily
+        + " is not a mob column family");
+    }
+    // get the mob region info, this is a dummy region.
+    HRegionInfo info = new HRegionInfo(tableName, Bytes.toBytes(".mob"), HConstants.EMPTY_END_ROW,
+      false, 0);
+    ServerName master = getClusterStatus().getMaster();
+    compact(master, info, true, columnFamily);
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void majorCompactMob(final TableName tableName) throws IOException, InterruptedException {
+    // get the mob region info, this is a dummy region.
+    HRegionInfo info = new HRegionInfo(tableName, Bytes.toBytes(".mob"), HConstants.EMPTY_END_ROW,
+      false, 0);
+    ServerName master = getClusterStatus().getMaster();
+    compact(master, info, true, null);
+  }
 }
diff --git a/hbase-common/src/main/resources/hbase-default.xml b/hbase-common/src/main/resources/hbase-default.xml
index 4ba6d69..b091243 100644
--- a/hbase-common/src/main/resources/hbase-default.xml
+++ b/hbase-common/src/main/resources/hbase-default.xml
@@ -1570,10 +1570,10 @@ possible configurations would overwhelm and obscure the important.
     </description>
   </property>
   <property>
-    <name>hbase.master.mob.file.compaction.chore.threads.max</name>
+    <name>hbase.mob.file.compaction.threads.max</name>
     <value>1</value>
     <description>
-      The max number of threads used in MobFileCompactionChore.
+      The max number of threads used in MobFileCompactor.
     </description>
   </property>
   <property>
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MobFileCompactionChore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MobFileCompactionChore.java
index ce2df81..e631481 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MobFileCompactionChore.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MobFileCompactionChore.java
@@ -18,33 +18,18 @@
  */
 package org.apache.hadoop.hbase.master;
 
-import java.io.IOException;
 import java.util.Map;
 import java.util.concurrent.ExecutorService;
-import java.util.concurrent.RejectedExecutionException;
-import java.util.concurrent.RejectedExecutionHandler;
-import java.util.concurrent.SynchronousQueue;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.hbase.ScheduledChore;
 import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.TableDescriptors;
-import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.exceptions.LockTimeoutException;
-import org.apache.hadoop.hbase.master.TableLockManager.TableLock;
 import org.apache.hadoop.hbase.mob.MobConstants;
 import org.apache.hadoop.hbase.mob.MobUtils;
-import org.apache.hadoop.hbase.mob.filecompactions.MobFileCompactor;
-import org.apache.hadoop.hbase.mob.filecompactions.PartitionedMobFileCompactor;
-import org.apache.hadoop.hbase.util.ReflectionUtils;
-import org.apache.hadoop.hbase.util.Threads;
 
 /**
  * The Class MobFileCompactChore for running compaction regularly to merge small mob files.
@@ -63,14 +48,12 @@ public MobFileCompactionChore(HMaster master) {
       MobConstants.DEFAULT_MOB_FILE_COMPACTION_CHORE_PERIOD));
     this.master = master;
     this.tableLockManager = master.getTableLockManager();
-    this.pool = createThreadPool();
+    this.pool = MobUtils.createMobFileCompactorThreadPool(master.getConfiguration());
   }
 
   @Override
   protected void chore() {
     try {
-      String className = master.getConfiguration().get(MobConstants.MOB_FILE_COMPACTOR_CLASS_KEY,
-        PartitionedMobFileCompactor.class.getName());
       TableDescriptors htds = master.getTableDescriptors();
       Map<String, HTableDescriptor> map = htds.getAll();
       for (HTableDescriptor htd : map.values()) {
@@ -78,48 +61,8 @@ protected void chore() {
           if (!hcd.isMobEnabled()) {
             continue;
           }
-          // instantiate the mob file compactor.
-          MobFileCompactor compactor = null;
-          try {
-            compactor = ReflectionUtils.instantiateWithCustomCtor(className, new Class[] {
-              Configuration.class, FileSystem.class, TableName.class, HColumnDescriptor.class,
-              ExecutorService.class },
-              new Object[] { master.getConfiguration(), master.getFileSystem(), htd.getTableName(),
-                hcd, pool });
-          } catch (Exception e) {
-            throw new IOException("Unable to load configured mob file compactor '" + className
-              + "'", e);
-          }
-          // compact only for mob-enabled column.
-          // obtain a write table lock before performing compaction to avoid race condition
-          // with major compaction in mob-enabled column.
-          boolean tableLocked = false;
-          TableLock lock = null;
-          try {
-            // the tableLockManager might be null in testing. In that case, it is lock-free.
-            if (tableLockManager != null) {
-              lock = tableLockManager.writeLock(MobUtils.getTableLockName(htd.getTableName()),
-                "Run MobFileCompactChore");
-              lock.acquire();
-            }
-            tableLocked = true;
-            compactor.compact();
-          } catch (LockTimeoutException e) {
-            LOG.info("Fail to acquire the lock because of timeout, maybe a major compaction or an"
-              + " ExpiredMobFileCleanerChore is running", e);
-          } catch (Exception e) {
-            LOG.error("Fail to compact the mob files for the column " + hcd.getNameAsString()
-              + " in the table " + htd.getNameAsString(), e);
-          } finally {
-            if (lock != null && tableLocked) {
-              try {
-                lock.release();
-              } catch (IOException e) {
-                LOG.error(
-                  "Fail to release the write lock for the table " + htd.getNameAsString(), e);
-              }
-            }
-          }
+          MobUtils.doMobFileCompaction(master.getConfiguration(), master.getFileSystem(),
+            htd.getTableName(), hcd, pool, tableLockManager, false);
         }
       }
     } catch (Exception e) {
@@ -132,35 +75,4 @@ protected void cleanup() {
     super.cleanup();
     pool.shutdown();
   }
-
-  /**
-   * Creates a thread pool.
-   * @return A thread pool.
-   */
-  private ExecutorService createThreadPool() {
-    Configuration conf = master.getConfiguration();
-    int maxThreads = conf.getInt(MobConstants.MOB_FILE_COMPACTION_CHORE_THREADS_MAX,
-      MobConstants.DEFAULT_MOB_FILE_COMPACTION_CHORE_THREADS_MAX);
-    if (maxThreads == 0) {
-      maxThreads = 1;
-    }
-    long keepAliveTime = conf.getLong(MobConstants.MOB_FILE_COMPACTION_CHORE_THREADS_KEEPALIVETIME,
-      MobConstants.DEFAULT_MOB_FILE_COMPACTION_CHORE_THREADS_KEEPALIVETIME);
-    final SynchronousQueue<Runnable> queue = new SynchronousQueue<Runnable>();
-    ThreadPoolExecutor pool = new ThreadPoolExecutor(1, maxThreads, keepAliveTime,
-      TimeUnit.SECONDS, queue, Threads.newDaemonThreadFactory("MobFileCompactionChore"),
-      new RejectedExecutionHandler() {
-        @Override
-        public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
-          try {
-            // waiting for a thread to pick up instead of throwing exceptions.
-            queue.put(r);
-          } catch (InterruptedException e) {
-            throw new RejectedExecutionException(e);
-          }
-        }
-    });
-    ((ThreadPoolExecutor) pool).allowCoreThreadTimeOut(true);
-    return pool;
-  }
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobConstants.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobConstants.java
index 0c9cda8..fd0697f 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobConstants.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobConstants.java
@@ -109,14 +109,14 @@
     24 * 60 * 60 * 1000 * 7; // a week
   public static final String MOB_FILE_COMPACTOR_CLASS_KEY = "hbase.mob.file.compactor.class";
   /**
-   * The max number of threads used in MobFileCompactionChore.
+   * The max number of threads used in MobFileCompactor.
    */
-  public static final String MOB_FILE_COMPACTION_CHORE_THREADS_MAX =
-    "hbase.master.mob.file.compaction.chore.threads.max";
-  public static final int DEFAULT_MOB_FILE_COMPACTION_CHORE_THREADS_MAX = 1;
-  public static final String MOB_FILE_COMPACTION_CHORE_THREADS_KEEPALIVETIME =
-    "hbase.master.mob.file.compaction.chore.threads.keepalivetime";
-  public static final long DEFAULT_MOB_FILE_COMPACTION_CHORE_THREADS_KEEPALIVETIME = 60;
+  public static final String MOB_FILE_COMPACTION_THREADS_MAX =
+    "hbase.mob.file.compaction.threads.max";
+  public static final int DEFAULT_MOB_FILE_COMPACTION_THREADS_MAX = 1;
+  public static final String MOB_FILE_COMPACTION_THREADS_KEEPALIVETIME =
+    "hbase.mob.file.compaction.threads.keepalivetime";
+  public static final long DEFAULT_MOB_FILE_COMPACTION_THREADS_KEEPALIVETIME = 60;
   private MobConstants() {
 
   }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
index 4e8ccc1..0aafa9d 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
@@ -27,6 +27,12 @@
 import java.util.Date;
 import java.util.List;
 import java.util.UUID;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.RejectedExecutionException;
+import java.util.concurrent.RejectedExecutionHandler;
+import java.util.concurrent.SynchronousQueue;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -51,11 +57,17 @@
 import org.apache.hadoop.hbase.io.hfile.HFile;
 import org.apache.hadoop.hbase.io.hfile.HFileContext;
 import org.apache.hadoop.hbase.io.hfile.HFileContextBuilder;
+import org.apache.hadoop.hbase.master.TableLockManager;
+import org.apache.hadoop.hbase.master.TableLockManager.TableLock;
+import org.apache.hadoop.hbase.mob.filecompactions.MobFileCompactor;
+import org.apache.hadoop.hbase.mob.filecompactions.PartitionedMobFileCompactor;
 import org.apache.hadoop.hbase.regionserver.BloomType;
 import org.apache.hadoop.hbase.regionserver.HStore;
 import org.apache.hadoop.hbase.regionserver.StoreFile;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.FSUtils;
+import org.apache.hadoop.hbase.util.ReflectionUtils;
+import org.apache.hadoop.hbase.util.Threads;
 
 /**
  * The mob utilities
@@ -358,6 +370,16 @@ public static boolean isMobRegionInfo(HRegionInfo regionInfo) {
   }
 
   /**
+   * Gets whether the current region name follows the pattern of a mob region name.
+   * @param tableName The current table name.
+   * @param regionName The current region name.
+   * @return True if the current region name follows the pattern of a mob region name.
+   */
+  public static boolean isMobRegionName(TableName tableName, byte[] regionName) {
+    return Bytes.equals(regionName, getMobRegionInfo(tableName).getRegionName());
+  }
+
+  /**
    * Gets the working directory of the mob compaction.
    * @param root The root directory of the mob compaction.
    * @param jobName The current job name.
@@ -645,4 +667,89 @@ public static TableName getTableLockName(TableName tn) {
     byte[] tableName = tn.getName();
     return TableName.valueOf(Bytes.add(tableName, MobConstants.MOB_TABLE_LOCK_SUFFIX));
   }
+
+  /**
+   * Performs the mob file compaction.
+   * @param conf the Configuration
+   * @param fs the file system
+   * @param tableName the table the compact
+   * @param hcd the column descriptor
+   * @param pool the thread pool
+   * @param tableLockManager the tableLock manager
+   * @param isForceAllFiles Whether add all mob files into the compaction.
+   */
+  public static void doMobFileCompaction(Configuration conf, FileSystem fs, TableName tableName,
+    HColumnDescriptor hcd, ExecutorService pool, TableLockManager tableLockManager,
+    boolean isForceAllFiles) throws IOException {
+    String className = conf.get(MobConstants.MOB_FILE_COMPACTOR_CLASS_KEY,
+      PartitionedMobFileCompactor.class.getName());
+    // instantiate the mob file compactor.
+    MobFileCompactor compactor = null;
+    try {
+      compactor = ReflectionUtils.instantiateWithCustomCtor(className, new Class[] {
+        Configuration.class, FileSystem.class, TableName.class, HColumnDescriptor.class,
+        ExecutorService.class }, new Object[] { conf, fs, tableName, hcd, pool });
+    } catch (Exception e) {
+      throw new IOException("Unable to load configured mob file compactor '" + className + "'", e);
+    }
+    // compact only for mob-enabled column.
+    // obtain a write table lock before performing compaction to avoid race condition
+    // with major compaction in mob-enabled column.
+    boolean tableLocked = false;
+    TableLock lock = null;
+    try {
+      // the tableLockManager might be null in testing. In that case, it is lock-free.
+      if (tableLockManager != null) {
+        lock = tableLockManager.writeLock(MobUtils.getTableLockName(tableName),
+          "Run MobFileCompaction");
+        lock.acquire();
+      }
+      tableLocked = true;
+      compactor.compact(isForceAllFiles);
+    } catch (Exception e) {
+      LOG.error("Fail to compact the mob files for the column " + hcd.getNameAsString()
+        + " in the table " + tableName.getNameAsString(), e);
+    } finally {
+      if (lock != null && tableLocked) {
+        try {
+          lock.release();
+        } catch (IOException e) {
+          LOG.error("Fail to release the write lock for the table " + tableName.getNameAsString(),
+            e);
+        }
+      }
+    }
+  }
+
+  /**
+   * Creates a thread pool.
+   * @param conf the Configuration
+   * @return A thread pool.
+   */
+  public static ExecutorService createMobFileCompactorThreadPool(Configuration conf) {
+    int maxThreads = conf.getInt(MobConstants.MOB_FILE_COMPACTION_THREADS_MAX,
+      MobConstants.DEFAULT_MOB_FILE_COMPACTION_THREADS_MAX);
+    if (maxThreads == 0) {
+      maxThreads = 1;
+    }
+    long keepAliveTime = conf.getLong(
+      MobConstants.MOB_FILE_COMPACTION_THREADS_KEEPALIVETIME,
+      MobConstants.DEFAULT_MOB_FILE_COMPACTION_THREADS_KEEPALIVETIME);
+    final SynchronousQueue<Runnable> queue = new SynchronousQueue<Runnable>();
+    ThreadPoolExecutor pool = new ThreadPoolExecutor(1, maxThreads, keepAliveTime,
+      TimeUnit.SECONDS, queue, Threads.newDaemonThreadFactory("MobFileCompactor"),
+      new RejectedExecutionHandler() {
+        @Override
+        public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
+          try {
+            // waiting for a thread to pick up instead of throwing exceptions.
+            queue.put(r);
+          } catch (InterruptedException e) {
+            throw new RejectedExecutionException(e);
+          }
+        }
+      });
+    ((ThreadPoolExecutor) pool).allowCoreThreadTimeOut(true);
+    return pool;
+  }
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/MobFileCompactor.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/MobFileCompactor.java
index bbc358e..fcb39c5 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/MobFileCompactor.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/MobFileCompactor.java
@@ -65,14 +65,26 @@ public MobFileCompactor(Configuration conf, FileSystem fs, TableName tableName,
    * @throws IOException
    */
   public List<Path> compact() throws IOException {
-    return compact(Arrays.asList(fs.listStatus(mobFamilyDir)));
+    return compact(false);
+  }
+
+  /**
+   * Compacts the mob files by compaction type for the current column family.
+   * @param isForceAllFiles Whether add all mob files into the compaction.
+   * @return The paths of new mob files generated in the compaction.
+   * @throws IOException
+   */
+  public List<Path> compact(boolean isForceAllFiles) throws IOException {
+    return compact(Arrays.asList(fs.listStatus(mobFamilyDir)), isForceAllFiles);
   }
 
   /**
    * Compacts the candidate mob files.
    * @param files The candidate mob files.
+   * @param isForceAllFiles Whether add all mob files into the compaction.
    * @return The paths of new mob files generated in the compaction.
    * @throws IOException
    */
-  public abstract List<Path> compact(List<FileStatus> files) throws IOException;
+  public abstract List<Path> compact(List<FileStatus> files, boolean isForceAllFiles)
+    throws IOException;
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java
index d6ad143..1712532 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java
@@ -110,12 +110,14 @@ public PartitionedMobFileCompactor(Configuration conf, FileSystem fs, TableName
   }
 
   @Override
-  public List<Path> compact(List<FileStatus> files) throws IOException {
+  public List<Path> compact(List<FileStatus> files, boolean isForceAllFiles) throws IOException {
     if (files == null || files.isEmpty()) {
+      LOG.info("No candidate mob files");
       return null;
     }
+    LOG.info("isForceAllFiles: " + isForceAllFiles);
     // find the files to compact.
-    PartitionedMobFileCompactionRequest request = select(files);
+    PartitionedMobFileCompactionRequest request = select(files, isForceAllFiles);
     // compact the files.
     return performCompaction(request);
   }
@@ -124,11 +126,12 @@ public PartitionedMobFileCompactor(Configuration conf, FileSystem fs, TableName
    * Selects the compacted mob/del files.
    * Iterates the candidates to find out all the del files and small mob files.
    * @param candidates All the candidates.
+   * @param isForceAllFiles Whether add all mob files into the compaction.
    * @return A compaction request.
    * @throws IOException
    */
-  protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates)
-    throws IOException {
+  protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates,
+    boolean isForceAllFiles) throws IOException {
     Collection<FileStatus> allDelFiles = new ArrayList<FileStatus>();
     Map<CompactionPartitionId, CompactionPartition> filesToCompact =
       new HashMap<CompactionPartitionId, CompactionPartition>();
@@ -152,8 +155,9 @@ protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates
       }
       if (StoreFileInfo.isDelFile(linkedFile.getPath())) {
         allDelFiles.add(file);
-      } else if (linkedFile.getLen() < mergeableSize) {
-        // add the small files to the merge pool
+      } else if (isForceAllFiles || linkedFile.getLen() < mergeableSize) {
+        // add all files if isForceAllFiles is true,
+        // otherwise add the small files to the merge pool
         MobFileName fileName = MobFileName.create(linkedFile.getPath().getName());
         CompactionPartitionId id = new CompactionPartitionId(fileName.getStartKey(),
           fileName.getDate());
@@ -174,6 +178,9 @@ protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates
       // all the files are selected
       request.setCompactionType(CompactionType.ALL_FILES);
     }
+    LOG.info("The compaction type is " + request.getCompactionType() + ", the request has "
+      + allDelFiles.size() + " del files, " + selectedFileCount + " selected files, and "
+      + irrelevantFileCount + " irrelevant files");
     return request;
   }
 
@@ -201,10 +208,14 @@ protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates
       StoreFile sf = new StoreFile(fs, newDelPath, conf, compactionCacheConfig, BloomType.NONE);
       newDelFiles.add(sf);
     }
+    LOG.info("After merging, there are " + newDelFiles.size() + " del files");
     // compact the mob files by partitions.
     List<Path> paths = compactMobFiles(request, newDelFiles);
+    LOG.info("After compaction, there are " + paths.size() + " mob files");
     // archive the del files if all the mob files are selected.
     if (request.type == CompactionType.ALL_FILES && !newDelPaths.isEmpty()) {
+      LOG.info("After a mob file compaction with all files selected, archiving the del files "
+        + newDelFiles);
       try {
         MobUtils.removeMobFiles(conf, fs, tableName, mobTableDir, column.getName(), newDelFiles);
       } catch (IOException e) {
@@ -225,6 +236,7 @@ protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates
     final List<StoreFile> delFiles) throws IOException {
     Collection<CompactionPartition> partitions = request.compactionPartitions;
     if (partitions == null || partitions.isEmpty()) {
+      LOG.info("No partitions of mob files");
       return Collections.emptyList();
     }
     List<Path> paths = new ArrayList<Path>();
@@ -237,6 +249,7 @@ protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates
         results.put(partition.getPartitionId(), pool.submit(new Callable<List<Path>>() {
           @Override
           public List<Path> call() throws Exception {
+            LOG.info("Compacting mob files for partition " + partition.getPartitionId());
             return compactMobFilePartition(request, partition, delFiles, table);
           }
         }));
@@ -310,6 +323,8 @@ protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates
       // move to the next batch.
       offset += batch;
     }
+    LOG.info("Compaction is finished. The number of mob files is changed from " + files.size()
+      + " to " + newFiles.size());
     return newFiles;
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
index 787828b..b0d7178 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
@@ -242,6 +242,7 @@
 
   // Compactions
   public CompactSplitThread compactSplitThread;
+  public RegionServerMobFileCompactionThread mobFileCompactThread;
 
   /**
    * Map of regions currently being served by this region server. Key is the
@@ -784,6 +785,7 @@ private void initializeThreads() throws IOException {
 
     // Compaction thread
     this.compactSplitThread = new CompactSplitThread(this);
+    this.mobFileCompactThread = new RegionServerMobFileCompactionThread(this);
 
     // Background thread to check for compactions; needed if region has not gotten updates
     // in a while. It will take care of not checking too frequently on store-by-store basis.
@@ -998,6 +1000,10 @@ public void run() {
           this.compactSplitThread.join();
           this.compactSplitThread = null;
         }
+        if (this.mobFileCompactThread != null) {
+          this.mobFileCompactThread.join();
+          this.mobFileCompactThread = null;
+        }
         closeMetaTableRegions(abortRequested);
       }
     }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java
index 3653cfb..48e69f5 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java
@@ -46,6 +46,7 @@
 import org.apache.hadoop.hbase.DoNotRetryIOException;
 import org.apache.hadoop.hbase.DroppedSnapshotException;
 import org.apache.hadoop.hbase.HBaseIOException;
+import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.HTableDescriptor;
@@ -81,6 +82,8 @@
 import org.apache.hadoop.hbase.ipc.RpcServerInterface;
 import org.apache.hadoop.hbase.ipc.ServerNotRunningYetException;
 import org.apache.hadoop.hbase.ipc.ServerRpcController;
+import org.apache.hadoop.hbase.master.TableLockManager;
+import org.apache.hadoop.hbase.mob.MobUtils;
 import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.protobuf.RequestConverter;
 import org.apache.hadoop.hbase.protobuf.ResponseConverter;
@@ -1019,6 +1022,12 @@ public CompactRegionResponse compactRegion(final RpcController controller,
     try {
       checkOpen();
       requestCount.increment();
+      byte[] regionName = request.getRegion().getValue().toByteArray();
+      TableName tableName = HRegionInfo.getTable(regionName);
+      // if the region is a mob region, do the mob file compaction.
+      if (MobUtils.isMobRegionName(tableName, regionName)) {
+        return compactMob(request, tableName);
+      }
       HRegion region = getRegion(request.getRegion());
       region.startRegionOperation(Operation.COMPACT_REGION);
       LOG.info("Compacting " + region.getRegionNameAsString());
@@ -2249,4 +2258,55 @@ public UpdateConfigurationResponse updateConfiguration(
     }
     return UpdateConfigurationResponse.getDefaultInstance();
   }
+
+  /**
+   * Compacts the mob files in the current table.
+   * @param request the request.
+   * @param tableName the current table name.
+   * @return The response of the mob file compaction.
+   * @throws IOException
+   */
+  private CompactRegionResponse compactMob(final CompactRegionRequest request,
+    TableName tableName) throws IOException {
+    boolean isForceAllFiles = false;
+    List<HColumnDescriptor> compactedColumns = new ArrayList<HColumnDescriptor>();
+    HColumnDescriptor[] hcds = regionServer.tableDescriptors.get(tableName).getColumnFamilies();
+    byte[] family = null;
+    if (request.hasFamily()) {
+      family = request.getFamily().toByteArray();
+      for (HColumnDescriptor hcd : hcds) {
+        if (Bytes.equals(family, hcd.getName())) {
+          if (!hcd.isMobEnabled()) {
+            LOG.error("Column family " + hcd.getName() + " is not a mob column family");
+            throw new DoNotRetryIOException("Column family " + hcd.getName()
+              + " is not a mob column family");
+          }
+          compactedColumns.add(hcd);
+        }
+      }
+    } else {
+      for (HColumnDescriptor hcd : hcds) {
+        if (hcd.isMobEnabled()) {
+          compactedColumns.add(hcd);
+        }
+      }
+    }
+    if (compactedColumns.isEmpty()) {
+      LOG.error("No mob column families are assigned in the mob file compaction");
+      throw new DoNotRetryIOException(
+        "No mob column families are assigned in the mob file compaction");
+    }
+    if (request.hasMajor() && request.getMajor()) {
+      isForceAllFiles = true;
+    }
+    String familyLogMsg = (family != null) ? Bytes.toString(family) : "";
+    if (LOG.isTraceEnabled()) {
+      LOG.trace("User-triggered mob file compaction requested for table: "
+        + tableName.getNameAsString() + " for column family: " + familyLogMsg);
+    }
+    regionServer.mobFileCompactThread.requestMobFileCompaction(regionServer.getConfiguration(),
+      regionServer.getFileSystem(), tableName, compactedColumns,
+      regionServer.getTableLockManager(), isForceAllFiles);
+    return CompactRegionResponse.newBuilder().build();
+  }
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerMobFileCompactionThread.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerMobFileCompactionThread.java
new file mode 100644
index 0000000..033598d
--- /dev/null
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerMobFileCompactionThread.java
@@ -0,0 +1,154 @@
+/**
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.regionserver;
+
+import java.io.IOException;
+import java.util.List;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.PriorityBlockingQueue;
+import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.classification.InterfaceAudience;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.hbase.HColumnDescriptor;
+import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.master.TableLockManager;
+import org.apache.hadoop.hbase.mob.MobUtils;
+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
+
+/**
+ * The mob file compaction thread used in {@link RSRpcServices}
+ */
+@InterfaceAudience.Private
+public class RegionServerMobFileCompactionThread {
+  static final Log LOG = LogFactory.getLog(RegionServerMobFileCompactionThread.class);
+  private final Configuration conf;
+  private final ExecutorService mobFileComapctorPool;
+  private final ExecutorService regionServerMobPool;
+
+  public RegionServerMobFileCompactionThread(HRegionServer server) {
+    this.conf = server.getConfiguration();
+    final String n = Thread.currentThread().getName();
+    this.regionServerMobPool = new ThreadPoolExecutor(1, 2, 60, TimeUnit.SECONDS,
+      new PriorityBlockingQueue<Runnable>(), new ThreadFactory() {
+        @Override
+        public Thread newThread(Runnable r) {
+          Thread t = new Thread(r);
+          t.setName(n + "-RegionServerMobFileCompaction-" + EnvironmentEdgeManager.currentTime());
+          return t;
+        }
+      });
+    ((ThreadPoolExecutor) this.regionServerMobPool).allowCoreThreadTimeOut(true);
+    this.mobFileComapctorPool = MobUtils
+      .createMobFileCompactorThreadPool(server.getConfiguration());
+  }
+
+  /**
+   * Requests mob file compaction
+   * @param conf The Configuration
+   * @param fs The file system
+   * @param tableName The table the compact
+   * @param hcds The column descriptors
+   * @param tableLockManager The tableLock manager
+   * @param isForceAllFiles Whether add all mob files into the compaction.
+   */
+  public void requestMobFileCompaction(Configuration conf, FileSystem fs, TableName tableName,
+    List<HColumnDescriptor> hcds, TableLockManager tableLockManager, boolean isForceAllFiles)
+    throws IOException {
+    regionServerMobPool.execute(new CompactionRunner(fs, tableName, hcds, tableLockManager,
+      isForceAllFiles, mobFileComapctorPool));
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("The mob file compaction is requested for the columns " + hcds + " of the table "
+        + tableName.getNameAsString());
+    }
+  }
+
+  private class CompactionRunner implements Runnable {
+    private FileSystem fs;
+    private TableName tableName;
+    private List<HColumnDescriptor> hcds;
+    private TableLockManager tableLockManager;
+    private boolean isForceAllFiles;
+    private ExecutorService pool;
+
+    public CompactionRunner(FileSystem fs, TableName tableName, List<HColumnDescriptor> hcds,
+      TableLockManager tableLockManager, boolean isForceAllFiles, ExecutorService pool) {
+      super();
+      this.fs = fs;
+      this.tableName = tableName;
+      this.hcds = hcds;
+      this.tableLockManager = tableLockManager;
+      this.isForceAllFiles = isForceAllFiles;
+      this.pool = pool;
+    }
+
+    @Override
+    public void run() {
+      try {
+        for (HColumnDescriptor hcd : hcds) {
+          MobUtils.doMobFileCompaction(conf, fs, tableName, hcd, pool, tableLockManager,
+            isForceAllFiles);
+        }
+      } catch (IOException e) {
+        LOG.error("Failed to perform the mob file compaction", e);
+      }
+    }
+  }
+
+  /**
+   * Only interrupt once it's done with a run through the work loop.
+   */
+  void interruptIfNecessary() {
+    mobFileComapctorPool.shutdown();
+    regionServerMobPool.shutdown();
+  }
+
+  /**
+   * Wait for all the threads finish.
+   */
+  void join() {
+    waitFor(mobFileComapctorPool, "Mob file Compaction Thread");
+    waitFor(regionServerMobPool, "Region Server Mob File Compaction Thread");
+  }
+
+  /**
+   * Wait for thread finish.
+   * @param t the thread to wait
+   * @param name the thread name.
+   */
+  private void waitFor(ExecutorService t, String name) {
+    boolean done = false;
+    while (!done) {
+      try {
+        done = t.awaitTermination(60, TimeUnit.SECONDS);
+        LOG.info("Waiting for " + name + " to finish...");
+        if (!done) {
+          t.shutdownNow();
+        }
+      } catch (InterruptedException ie) {
+        LOG.warn("Interrupted waiting for " + name + " to finish...");
+      }
+    }
+  }
+}
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestMobFileCompactor.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestMobFileCompactor.java
index 4bf1623..5d95f1d 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestMobFileCompactor.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestMobFileCompactor.java
@@ -57,6 +57,7 @@
 import org.apache.hadoop.hbase.regionserver.HRegion;
 import org.apache.hadoop.hbase.regionserver.StoreFileInfo;
 import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
 import org.apache.hadoop.hbase.util.Threads;
 import org.junit.After;
 import org.junit.AfterClass;
@@ -71,28 +72,29 @@
   private Configuration conf = null;
   private String tableNameAsString;
   private TableName tableName;
-  private static HTable hTable;
-  private static Admin admin;
-  private static HTableDescriptor desc;
-  private static HColumnDescriptor hcd1;
-  private static HColumnDescriptor hcd2;
-  private static FileSystem fs;
-  private final static String family1 = "family1";
-  private final static String family2 = "family2";
-  private final static String qf1 = "qualifier1";
-  private final static String qf2 = "qualifier2";
-  private static byte[] KEYS = Bytes.toBytes("012");
-  private static int regionNum = KEYS.length;
-  private static int delRowNum = 1;
-  private static int delCellNum = 6;
-  private static int cellNumPerRow = 3;
-  private static int rowNumPerFile = 2;
+  private HTable hTable;
+  private Admin admin;
+  private HTableDescriptor desc;
+  private HColumnDescriptor hcd1;
+  private HColumnDescriptor hcd2;
+  private FileSystem fs;
+  private final String family1 = "family1";
+  private final String family2 = "family2";
+  private final String qf1 = "qualifier1";
+  private final String qf2 = "qualifier2";
+  private byte[] KEYS = Bytes.toBytes("012");
+  private int regionNum = KEYS.length;
+  private int delRowNum = 1;
+  private int delCellNum = 6;
+  private int cellNumPerRow = 3;
+  private int rowNumPerFile = 2;
   private static ExecutorService pool;
 
   @BeforeClass
   public static void setUpBeforeClass() throws Exception {
     TEST_UTIL.getConfiguration().setInt("hbase.master.info.port", 0);
     TEST_UTIL.getConfiguration().setBoolean("hbase.regionserver.info.port.auto", true);
+    TEST_UTIL.getConfiguration().setLong(MobConstants.MOB_FILE_COMPACTION_MERGEABLE_THRESHOLD, 5000);
     TEST_UTIL.startMiniCluster(1);
     pool = createThreadPool(TEST_UTIL.getConfiguration());
   }
@@ -208,41 +210,6 @@ public void testCompactionWithDelFiles() throws Exception {
     assertRefFileNameEqual(family1);
   }
 
-  private void assertRefFileNameEqual(String familyName) throws IOException {
-    Scan scan = new Scan();
-    scan.addFamily(Bytes.toBytes(familyName));
-    // Do not retrieve the mob data when scanning
-    scan.setAttribute(MobConstants.MOB_SCAN_RAW, Bytes.toBytes(Boolean.TRUE));
-    ResultScanner results = hTable.getScanner(scan);
-    Path mobFamilyPath = new Path(MobUtils.getMobRegionPath(TEST_UTIL.getConfiguration(),
-        tableName), familyName);
-    List<Path> actualFilePaths = new ArrayList<>();
-    List<Path> expectFilePaths = new ArrayList<>();
-    for (Result res : results) {
-      for (Cell cell : res.listCells()) {
-        byte[] referenceValue = CellUtil.cloneValue(cell);
-        String fileName = Bytes.toString(referenceValue, Bytes.SIZEOF_INT,
-            referenceValue.length - Bytes.SIZEOF_INT);
-        Path targetPath = new Path(mobFamilyPath, fileName);
-        if(!actualFilePaths.contains(targetPath)) {
-          actualFilePaths.add(targetPath);
-        }
-      }
-    }
-    results.close();
-    if (fs.exists(mobFamilyPath)) {
-      FileStatus[] files = fs.listStatus(mobFamilyPath);
-      for (FileStatus file : files) {
-        if (!StoreFileInfo.isDelFile(file.getPath())) {
-          expectFilePaths.add(file.getPath());
-        }
-      }
-    }
-    Collections.sort(actualFilePaths);
-    Collections.sort(expectFilePaths);
-    assertEquals(expectFilePaths, actualFilePaths);
-  }
-
   @Test
   public void testCompactionWithDelFilesAndNotMergeAllFiles() throws Exception {
     resetConf();
@@ -428,6 +395,116 @@ public void testCompactionWithHFileLink() throws IOException, InterruptedExcepti
     assertEquals("After second compaction: family2 del file count", 0, countFiles(false, family2));
     assertEquals("After second compaction: family1 hfilelink count", 0, countHFileLinks(family1));
     assertEquals("After second compaction: family2 hfilelink count", 0, countHFileLinks(family2));
+    assertRefFileNameEqual(family1);
+  }
+
+  @Test
+  public void testCompactionFromAdmin() throws Exception {
+    int count = 4;
+    // generate mob files
+    loadData(count, rowNumPerFile);
+    int rowNumPerRegion = count*rowNumPerFile;
+
+    assertEquals("Before deleting: mob rows count", regionNum*rowNumPerRegion,
+        countMobRows(hTable));
+    assertEquals("Before deleting: mob cells count", regionNum*cellNumPerRow*rowNumPerRegion,
+        countMobCells(hTable));
+    assertEquals("Before deleting: family1 mob file count", regionNum*count,
+        countFiles(true, family1));
+    assertEquals("Before deleting: family2 mob file count", regionNum*count,
+        countFiles(true, family2));
+
+    createDelFile();
+
+    assertEquals("Before compaction: mob rows count", regionNum*(rowNumPerRegion-delRowNum),
+        countMobRows(hTable));
+    assertEquals("Before compaction: mob cells count",
+        regionNum*(cellNumPerRow*rowNumPerRegion-delCellNum), countMobCells(hTable));
+    assertEquals("Before compaction: family1 mob file count", regionNum*count,
+        countFiles(true, family1));
+    assertEquals("Before compaction: family2 file count", regionNum*count,
+        countFiles(true, family2));
+    assertEquals("Before compaction: family1 del file count", regionNum,
+        countFiles(false, family1));
+    assertEquals("Before compaction: family2 del file count", regionNum,
+        countFiles(false, family2));
+
+    int largeFilesCount = countLargeFiles(5000, family1);
+    // do the mob file compaction
+    admin.compactMob(tableName, hcd1.getName());
+
+    // wait until the compaction finish.
+    long finished = EnvironmentEdgeManager.currentTime() + 60000;
+    while (EnvironmentEdgeManager.currentTime() < finished) {
+      if(countFiles(true, family1) == (regionNum + largeFilesCount)) {
+        break;
+      }
+      Thread.sleep(50);
+    }
+    assertEquals("After compaction: mob rows count", regionNum*(rowNumPerRegion-delRowNum),
+        countMobRows(hTable));
+    assertEquals("After compaction: mob cells count",
+        regionNum*(cellNumPerRow*rowNumPerRegion-delCellNum), countMobCells(hTable));
+    assertEquals("After compaction: family1 mob file count", regionNum + largeFilesCount,
+        countFiles(true, family1));
+    assertEquals("After compaction: family2 mob file count", regionNum*count,
+        countFiles(true, family2));
+    assertEquals("After compaction: family1 del file count", regionNum, countFiles(false, family1));
+    assertEquals("After compaction: family2 del file count", regionNum,
+        countFiles(false, family2));
+    assertRefFileNameEqual(family1);
+  }
+
+  @Test
+  public void testMajorCompactionFromAdmin() throws Exception {
+    int count = 4;
+    // generate mob files
+    loadData(count, rowNumPerFile);
+    int rowNumPerRegion = count*rowNumPerFile;
+
+    assertEquals("Before deleting: mob rows count", regionNum*rowNumPerRegion,
+        countMobRows(hTable));
+    assertEquals("Before deleting: mob cells count", regionNum*cellNumPerRow*rowNumPerRegion,
+        countMobCells(hTable));
+    assertEquals("Before deleting: mob file count", regionNum*count, countFiles(true, family1));
+
+    createDelFile();
+
+    assertEquals("Before compaction: mob rows count", regionNum*(rowNumPerRegion-delRowNum),
+        countMobRows(hTable));
+    assertEquals("Before compaction: mob cells count",
+        regionNum*(cellNumPerRow*rowNumPerRegion-delCellNum), countMobCells(hTable));
+    assertEquals("Before compaction: family1 mob file count", regionNum*count,
+        countFiles(true, family1));
+    assertEquals("Before compaction: family2 mob file count", regionNum*count,
+        countFiles(true, family2));
+    assertEquals("Before compaction: family1 del file count", regionNum,
+        countFiles(false, family1));
+    assertEquals("Before compaction: family2 del file count", regionNum,
+        countFiles(false, family2));
+
+    // do the major mob file compaction, it will force all files to compaction
+    admin.majorCompactMob(tableName, hcd1.getName());
+
+    // wait until the compaction finish.
+    long finished = EnvironmentEdgeManager.currentTime() + 60000;
+    while (EnvironmentEdgeManager.currentTime() < finished) {
+      if(countFiles(true, family1) == regionNum) {
+        break;
+      }
+      Thread.sleep(50);
+    }
+    assertEquals("After compaction: mob rows count", regionNum*(rowNumPerRegion-delRowNum),
+        countMobRows(hTable));
+    assertEquals("After compaction: mob cells count",
+        regionNum*(cellNumPerRow*rowNumPerRegion-delCellNum), countMobCells(hTable));
+    assertEquals("After compaction: family1 mob file count", regionNum,
+        countFiles(true, family1));
+    assertEquals("After compaction: family2 mob file count", regionNum*count,
+        countFiles(true, family2));
+    assertEquals("After compaction: family1 del file count", 0, countFiles(false, family1));
+    assertEquals("After compaction: family2 del file count", regionNum,
+        countFiles(false, family2));
   }
 
   /**
@@ -610,7 +687,7 @@ private void createDelFile() throws IOException, InterruptedException {
   /**
    * Gets the split keys
    */
-  public static byte[][] getSplitKeys() {
+  private byte[][] getSplitKeys() {
     byte[][] splitKeys = new byte[KEYS.length - 1][];
     for (int i = 0; i < splitKeys.length; ++i) {
       splitKeys[i] = new byte[] { KEYS[i + 1] };
@@ -640,6 +717,41 @@ public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
     return pool;
   }
 
+  private void assertRefFileNameEqual(String familyName) throws IOException {
+    Scan scan = new Scan();
+    scan.addFamily(Bytes.toBytes(familyName));
+    // Do not retrieve the mob data when scanning
+    scan.setAttribute(MobConstants.MOB_SCAN_RAW, Bytes.toBytes(Boolean.TRUE));
+    ResultScanner results = hTable.getScanner(scan);
+    Path mobFamilyPath = new Path(MobUtils.getMobRegionPath(TEST_UTIL.getConfiguration(),
+        tableName), familyName);
+    List<Path> actualFilePaths = new ArrayList<>();
+    List<Path> expectFilePaths = new ArrayList<>();
+    for (Result res : results) {
+      for (Cell cell : res.listCells()) {
+        byte[] referenceValue = CellUtil.cloneValue(cell);
+        String fileName = Bytes.toString(referenceValue, Bytes.SIZEOF_INT,
+            referenceValue.length - Bytes.SIZEOF_INT);
+        Path targetPath = new Path(mobFamilyPath, fileName);
+        if(!actualFilePaths.contains(targetPath)) {
+          actualFilePaths.add(targetPath);
+        }
+      }
+    }
+    results.close();
+    if (fs.exists(mobFamilyPath)) {
+      FileStatus[] files = fs.listStatus(mobFamilyPath);
+      for (FileStatus file : files) {
+        if (!StoreFileInfo.isDelFile(file.getPath())) {
+          expectFilePaths.add(file.getPath());
+        }
+      }
+    }
+    Collections.sort(actualFilePaths);
+    Collections.sort(expectFilePaths);
+    assertEquals(expectFilePaths, actualFilePaths);
+  }
+
   /**
    * Resets the configuration.
    */
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestPartitionedMobFileCompactor.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestPartitionedMobFileCompactor.java
index 12c88b2..3c73d52 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestPartitionedMobFileCompactor.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestPartitionedMobFileCompactor.java
@@ -131,7 +131,7 @@ public void testCompactionSelectWithAllFiles() throws Exception {
         expectedStartKeys.add(startKey);
       }
     }
-    testSelectFiles(tableName, CompactionType.ALL_FILES, expectedStartKeys);
+    testSelectFiles(tableName, CompactionType.ALL_FILES, false, expectedStartKeys);
   }
 
   @Test
@@ -156,7 +156,30 @@ public void testCompactionSelectWithPartFiles() throws Exception {
     }
     // set the mob file compaction mergeable threshold
     conf.setLong(MobConstants.MOB_FILE_COMPACTION_MERGEABLE_THRESHOLD, mergeSize);
-    testSelectFiles(tableName, CompactionType.PART_FILES, expectedStartKeys);
+    testSelectFiles(tableName, CompactionType.PART_FILES, false, expectedStartKeys);
+  }
+
+  @Test
+  public void testCompactionSelectWithForceAllFiles() throws Exception {
+    resetConf();
+    String tableName = "testCompactionSelectWithForceAllFiles";
+    init(tableName);
+    int count = 10;
+    // create 10 mob files.
+    createStoreFiles(basePath, family, qf, count, Type.Put);
+    // create 10 del files
+    createStoreFiles(basePath, family, qf, count, Type.Delete);
+    listFiles();
+    long mergeSize = 4000;
+    List<String> expectedStartKeys = new ArrayList<>();
+    for(FileStatus file : mobFiles) {
+      String fileName = file.getPath().getName();
+      String startKey = fileName.substring(0, 32);
+      expectedStartKeys.add(startKey);
+    }
+    // set the mob file compaction mergeable threshold
+    conf.setLong(MobConstants.MOB_FILE_COMPACTION_MERGEABLE_THRESHOLD, mergeSize);
+    testSelectFiles(tableName, CompactionType.ALL_FILES, true, expectedStartKeys);
   }
 
   @Test
@@ -169,7 +192,7 @@ public void testCompactDelFilesWithDefaultBatchSize() throws Exception {
     // create 13 del files
     createStoreFiles(basePath, family, qf, 13, Type.Delete);
     listFiles();
-    testCompactDelFiles(tableName, 1, 13);
+    testCompactDelFiles(tableName, 1, 13, false);
   }
 
   @Test
@@ -185,7 +208,7 @@ public void testCompactDelFilesWithSmallBatchSize() throws Exception {
 
     // set the mob file compaction batch size
     conf.setInt(MobConstants.MOB_FILE_COMPACTION_BATCH_SIZE, 4);
-    testCompactDelFiles(tableName, 1, 13);
+    testCompactDelFiles(tableName, 1, 13, false);
   }
 
   @Test
@@ -203,7 +226,7 @@ public void testCompactDelFilesChangeMaxDelFileCount() throws Exception {
     conf.setInt(MobConstants.MOB_DELFILE_MAX_COUNT, 5);
     // set the mob file compaction batch size
     conf.setInt(MobConstants.MOB_FILE_COMPACTION_BATCH_SIZE, 2);
-    testCompactDelFiles(tableName, 4, 13);
+    testCompactDelFiles(tableName, 4, 13, false);
   }
 
   /**
@@ -213,16 +236,17 @@ public void testCompactDelFilesChangeMaxDelFileCount() throws Exception {
    * @param expected the expected start keys
    */
   private void testSelectFiles(String tableName, final CompactionType type,
-      final List<String> expected) throws IOException {
+    final boolean isForceAllFiles, final List<String> expected) throws IOException {
     PartitionedMobFileCompactor compactor = new PartitionedMobFileCompactor(conf, fs,
       TableName.valueOf(tableName), hcd, pool) {
       @Override
-      public List<Path> compact(List<FileStatus> files) throws IOException {
+      public List<Path> compact(List<FileStatus> files, boolean isForceAllFiles)
+        throws IOException {
         if (files == null || files.isEmpty()) {
           return null;
         }
-        PartitionedMobFileCompactionRequest request = select(files);
-        // assert the compaction type is ALL_FILES
+        PartitionedMobFileCompactionRequest request = select(files, isForceAllFiles);
+        // assert the compaction type
         Assert.assertEquals(type, request.type);
         // assert get the right partitions
         compareCompactedPartitions(expected, request.compactionPartitions);
@@ -231,7 +255,7 @@ private void testSelectFiles(String tableName, final CompactionType type,
         return null;
       }
     };
-    compactor.compact(allFiles);
+    compactor.compact(allFiles, isForceAllFiles);
   }
 
   /**
@@ -241,7 +265,7 @@ private void testSelectFiles(String tableName, final CompactionType type,
    * @param expectedCellCount the expected cell count
    */
   private void testCompactDelFiles(String tableName, final int expectedFileCount,
-      final int expectedCellCount) throws IOException {
+      final int expectedCellCount, boolean isForceAllFiles) throws IOException {
     PartitionedMobFileCompactor compactor = new PartitionedMobFileCompactor(conf, fs,
       TableName.valueOf(tableName), hcd, pool) {
       @Override
@@ -258,8 +282,7 @@ private void testCompactDelFiles(String tableName, final int expectedFileCount,
         return null;
       }
     };
-
-    compactor.compact(allFiles);
+    compactor.compact(allFiles, isForceAllFiles);
   }
 
   /**
diff --git a/hbase-shell/src/main/ruby/hbase/admin.rb b/hbase-shell/src/main/ruby/hbase/admin.rb
index 170d19c..b75ca4d 100644
--- a/hbase-shell/src/main/ruby/hbase/admin.rb
+++ b/hbase-shell/src/main/ruby/hbase/admin.rb
@@ -938,5 +938,27 @@ def drop_namespace(namespace_name)
       @admin.deleteNamespace(namespace_name)
     end
 
+    #----------------------------------------------------------------------------------------------
+    # Requests a mob column family compaction
+    def compact_mob(table_name, family = nil)
+      if family == nil
+        @admin.compactMob(org.apache.hadoop.hbase.TableName.valueOf(table_name))
+      else
+        # We are compacting a mob column family within a table.
+        @admin.compactMobColumn(org.apache.hadoop.hbase.TableName.valueOf(table_name), family.to_java_bytes)
+      end
+    end
+
+    #----------------------------------------------------------------------------------------------
+    # Requests a mob column family major compaction
+    def major_compact_mob(table_name, family = nil)
+      if family == nil
+        @admin.majorCompactMob(org.apache.hadoop.hbase.TableName.valueOf(table_name))
+      else
+        # We are major compacting a mob column family within a table.
+        @admin.majorCompactMob(org.apache.hadoop.hbase.TableName.valueOf(table_name), family.to_java_bytes)
+      end
+    end
+
   end
 end
diff --git a/hbase-shell/src/main/ruby/shell.rb b/hbase-shell/src/main/ruby/shell.rb
index 5db2776..8ec4da0 100644
--- a/hbase-shell/src/main/ruby/shell.rb
+++ b/hbase-shell/src/main/ruby/shell.rb
@@ -327,6 +327,8 @@ def help_footer
     catalogjanitor_enabled
     compact_rs
     trace
+    compact_mob
+    major_compact_mob
   ],
   # TODO remove older hlog_roll command
   :aliases => {
diff --git a/hbase-shell/src/main/ruby/shell/commands/compact_mob.rb b/hbase-shell/src/main/ruby/shell/commands/compact_mob.rb
new file mode 100644
index 0000000..ef911a0
--- /dev/null
+++ b/hbase-shell/src/main/ruby/shell/commands/compact_mob.rb
@@ -0,0 +1,42 @@
+#
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+module Shell
+  module Commands
+    class CompactMob < Command
+      def help
+        return <<-EOF
+          Run compaction on a mob enabled column family
+          or all mob enabled column families within a table
+          Examples:
+          Compact a column family within a table:
+          hbase> compact_mob 't1', 'c1'
+          Compact all mob enabled column families
+          hbase> compact_mob 't1'
+        EOF
+      end
+
+      def command(table_name, family = nil)
+        format_simple_command do
+          admin.compact_mob(table_name, family)
+        end
+      end
+    end
+  end
+end
diff --git a/hbase-shell/src/main/ruby/shell/commands/major_compact_mob.rb b/hbase-shell/src/main/ruby/shell/commands/major_compact_mob.rb
new file mode 100644
index 0000000..dfcd6c9
--- /dev/null
+++ b/hbase-shell/src/main/ruby/shell/commands/major_compact_mob.rb
@@ -0,0 +1,42 @@
+#
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+module Shell
+  module Commands
+    class MajorCompactMob < Command
+      def help
+        return <<-EOF
+          Run major compaction on a mob enabled column family
+          or all mob enabled column families within a table
+          Examples:
+          Compact a column family within a table:
+          hbase> major_compact_mob 't1', 'c1'
+          Compact all mob enabled column families within a table
+          hbase> major_compact_mob 't1'
+        EOF
+      end
+
+      def command(table_name, family = nil)
+        format_simple_command do
+          admin.major_compact_mob(table_name, family)
+        end
+      end
+    end
+  end
+end
