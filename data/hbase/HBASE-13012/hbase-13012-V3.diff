diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
index 0fe2ff3..22b9134 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
@@ -580,6 +580,28 @@ void majorCompactRegion(final byte[] regionName, final byte[] columnFamily)
     throws IOException, InterruptedException;
 
   /**
+   * Compact a mob table. Asynchronous operation.
+   *
+   * @param tableName table to compact
+   * @param columnFamily column family within a table
+   * @throws IOException if not a mob column family or if a remote or network exception occurs
+   * @throws InterruptedException
+   */
+  void compactMob(final TableName tableName, final byte[] columnFamily) throws IOException,
+    InterruptedException;
+
+  /**
+   * Major compact a mob table. Asynchronous operation.
+   *
+   * @param tableName table to compact
+   * @param columnFamily column family within a table
+   * @throws IOException if not a mob column family or if a remote or network exception occurs
+   * @throws InterruptedException
+   */
+  void majorCompactMob(final TableName tableName, final byte[] columnFamily) throws IOException,
+    InterruptedException;
+
+  /**
    * Move the region <code>r</code> to <code>dest</code>.
    *
    * @param encodedRegionName The encoded region name; i.e. the hash that makes up the region name
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
index b659e87..278e37e 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
@@ -24,6 +24,7 @@
 import java.net.SocketTimeoutException;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
 import java.util.HashMap;
 import java.util.LinkedList;
 import java.util.List;
@@ -33,6 +34,7 @@
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.regex.Pattern;
 
+import org.apache.commons.lang.math.RandomUtils;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
@@ -1778,6 +1780,63 @@ private void compact(final ServerName sn, final HRegionInfo hri,
   }
 
   /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void compactMob(final TableName tableName, final byte[] columnFamily) throws IOException,
+    InterruptedException {
+    HTableDescriptor htd = getTableDescriptor(tableName);
+    HColumnDescriptor family = htd.getFamily(columnFamily);
+    if (family == null || !family.isMobEnabled()) {
+      throw new IOException("Column family " + columnFamily + " is not a MOB column family");
+    }
+    // Get the mob region info, this is a dummy region.
+    HRegionInfo info = new HRegionInfo(tableName, Bytes.toBytes(".mob"), HConstants.EMPTY_END_ROW,
+      false, 0);
+    Collection<ServerName> serversList = getClusterStatus().getServers();
+    ServerName destServerName = getRandomServerName(serversList);
+    compact(destServerName, info, false, columnFamily);
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void majorCompactMob(final TableName tableName, final byte[] columnFamily)
+    throws IOException, InterruptedException {
+    HTableDescriptor htd = getTableDescriptor(tableName);
+    HColumnDescriptor family = htd.getFamily(columnFamily);
+    if (family == null || !family.isMobEnabled()) {
+      throw new IOException("Column family " + columnFamily + " is not a MOB column family");
+    }
+    // Get the mob region info, this is a dummy region.
+    HRegionInfo info = new HRegionInfo(tableName, Bytes.toBytes(".mob"), HConstants.EMPTY_END_ROW,
+      false, 0);
+    Collection<ServerName> serversList = getClusterStatus().getServers();
+    ServerName destServerName = getRandomServerName(serversList);
+    compact(destServerName, info, true, columnFamily);
+  }
+
+  /**
+   * Random to get one server name from servers list.
+   * @param seversList The list of server names
+   * @return The server name
+   */
+  private ServerName getRandomServerName(Collection<ServerName> serversList) {
+    int index = RandomUtils.nextInt(serversList.size());
+    int i = 0;
+    ServerName destServerName = null;
+    for (ServerName serverName : serversList) {
+      if (i == index) {
+        destServerName = serverName;
+        break;
+      }
+      i++;
+    }
+    return destServerName;
+  }
+
+  /**
    * Move the region <code>r</code> to <code>dest</code>.
    * @param encodedRegionName The encoded region name; i.e. the hash that makes
    * up the region name suffix: e.g. if regionname is
diff --git a/hbase-common/src/main/resources/hbase-default.xml b/hbase-common/src/main/resources/hbase-default.xml
index d1429ad..212413b 100644
--- a/hbase-common/src/main/resources/hbase-default.xml
+++ b/hbase-common/src/main/resources/hbase-default.xml
@@ -1562,10 +1562,10 @@ possible configurations would overwhelm and obscure the important.
     </description>
   </property>
   <property>
-    <name>hbase.master.mob.file.compaction.chore.threads.max</name>
+    <name>hbase.mob.file.compaction.threads.max</name>
     <value>1</value>
     <description>
-      The max number of threads used in MobFileCompactionChore.
+      The max number of threads used in MobFileCompactor.
     </description>
   </property>
 </configuration>
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MobFileCompactionChore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MobFileCompactionChore.java
index 9973619..76d52e5 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MobFileCompactionChore.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MobFileCompactionChore.java
@@ -18,32 +18,18 @@
  */
 package org.apache.hadoop.hbase.master;
 
-import java.io.IOException;
 import java.util.Map;
 import java.util.concurrent.ExecutorService;
-import java.util.concurrent.RejectedExecutionException;
-import java.util.concurrent.RejectedExecutionHandler;
-import java.util.concurrent.SynchronousQueue;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.hbase.Chore;
 import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.TableDescriptors;
-import org.apache.hadoop.hbase.TableName;
-import org.apache.hadoop.hbase.master.TableLockManager.TableLock;
 import org.apache.hadoop.hbase.mob.MobConstants;
 import org.apache.hadoop.hbase.mob.MobUtils;
-import org.apache.hadoop.hbase.mob.filecompactions.MobFileCompactor;
-import org.apache.hadoop.hbase.mob.filecompactions.PartitionedMobFileCompactor;
-import org.apache.hadoop.hbase.util.ReflectionUtils;
-import org.apache.hadoop.hbase.util.Threads;
 
 /**
  * The Class MobFileCompactChore for running compaction regularly to merge small mob files.
@@ -62,14 +48,12 @@ public MobFileCompactionChore(HMaster master) {
       MobConstants.DEFAULT_MOB_FILE_COMPACTION_CHORE_PERIOD), master);
     this.master = master;
     this.tableLockManager = master.getTableLockManager();
-    this.pool = createThreadPool();
+    this.pool = MobUtils.createMobFileCompactorThreadPool(master.getConfiguration());
   }
 
   @Override
   protected void chore() {
     try {
-      String className = master.getConfiguration().get(MobConstants.MOB_FILE_COMPACTOR_CLASS_KEY,
-        PartitionedMobFileCompactor.class.getName());
       TableDescriptors htds = master.getTableDescriptors();
       Map<String, HTableDescriptor> map = htds.getAll();
       for (HTableDescriptor htd : map.values()) {
@@ -77,45 +61,8 @@ protected void chore() {
           if (!hcd.isMobEnabled()) {
             continue;
           }
-          // instantiate the mob file compactor.
-          MobFileCompactor compactor = null;
-          try {
-            compactor = ReflectionUtils.instantiateWithCustomCtor(className, new Class[] {
-              Configuration.class, FileSystem.class, TableName.class, HColumnDescriptor.class,
-              ExecutorService.class },
-              new Object[] { master.getConfiguration(), master.getFileSystem(), htd.getTableName(),
-                hcd, pool });
-          } catch (Exception e) {
-            throw new IOException("Unable to load configured mob file compactor '" + className
-              + "'", e);
-          }
-          // compact only for mob-enabled column.
-          // obtain a write table lock before performing compaction to avoid race condition
-          // with major compaction in mob-enabled column.
-          boolean tableLocked = false;
-          TableLock lock = null;
-          try {
-            // the tableLockManager might be null in testing. In that case, it is lock-free.
-            if (tableLockManager != null) {
-              lock = tableLockManager.writeLock(MobUtils.getTableLockName(htd.getTableName()),
-                "Run MobFileCompactChore");
-              lock.acquire();
-            }
-            tableLocked = true;
-            compactor.compact();
-          } catch (Exception e) {
-            LOG.error("Fail to compact the mob files for the column " + hcd.getNameAsString()
-              + " in the table " + htd.getNameAsString(), e);
-          } finally {
-            if (lock != null && tableLocked) {
-              try {
-                lock.release();
-              } catch (IOException e) {
-                LOG.error(
-                  "Fail to release the write lock for the table " + htd.getNameAsString(), e);
-              }
-            }
-          }
+          MobUtils.doMobFileCompaction(master.getConfiguration(), master.getFileSystem(),
+            htd.getTableName(), hcd, pool, tableLockManager, false);
         }
       }
     } catch (Exception e) {
@@ -128,35 +75,4 @@ protected void cleanup() {
     super.cleanup();
     pool.shutdown();
   }
-
-  /**
-   * Creates a thread pool.
-   * @return A thread pool.
-   */
-  private ExecutorService createThreadPool() {
-    Configuration conf = master.getConfiguration();
-    int maxThreads = conf.getInt(MobConstants.MOB_FILE_COMPACTION_CHORE_THREADS_MAX,
-      MobConstants.DEFAULT_MOB_FILE_COMPACTION_CHORE_THREADS_MAX);
-    if (maxThreads == 0) {
-      maxThreads = 1;
-    }
-    long keepAliveTime = conf.getLong(MobConstants.MOB_FILE_COMPACTION_CHORE_THREADS_KEEPALIVETIME,
-      MobConstants.DEFAULT_MOB_FILE_COMPACTION_CHORE_THREADS_KEEPALIVETIME);
-    final SynchronousQueue<Runnable> queue = new SynchronousQueue<Runnable>();
-    ThreadPoolExecutor pool = new ThreadPoolExecutor(1, maxThreads, keepAliveTime,
-      TimeUnit.SECONDS, queue, Threads.newDaemonThreadFactory("MobFileCompactionChore"),
-      new RejectedExecutionHandler() {
-        @Override
-        public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
-          try {
-            // waiting for a thread to pick up instead of throwing exceptions.
-            queue.put(r);
-          } catch (InterruptedException e) {
-            throw new RejectedExecutionException(e);
-          }
-        }
-    });
-    ((ThreadPoolExecutor) pool).allowCoreThreadTimeOut(true);
-    return pool;
-  }
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobConstants.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobConstants.java
index 0c9cda8..fd0697f 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobConstants.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobConstants.java
@@ -109,14 +109,14 @@
     24 * 60 * 60 * 1000 * 7; // a week
   public static final String MOB_FILE_COMPACTOR_CLASS_KEY = "hbase.mob.file.compactor.class";
   /**
-   * The max number of threads used in MobFileCompactionChore.
+   * The max number of threads used in MobFileCompactor.
    */
-  public static final String MOB_FILE_COMPACTION_CHORE_THREADS_MAX =
-    "hbase.master.mob.file.compaction.chore.threads.max";
-  public static final int DEFAULT_MOB_FILE_COMPACTION_CHORE_THREADS_MAX = 1;
-  public static final String MOB_FILE_COMPACTION_CHORE_THREADS_KEEPALIVETIME =
-    "hbase.master.mob.file.compaction.chore.threads.keepalivetime";
-  public static final long DEFAULT_MOB_FILE_COMPACTION_CHORE_THREADS_KEEPALIVETIME = 60;
+  public static final String MOB_FILE_COMPACTION_THREADS_MAX =
+    "hbase.mob.file.compaction.threads.max";
+  public static final int DEFAULT_MOB_FILE_COMPACTION_THREADS_MAX = 1;
+  public static final String MOB_FILE_COMPACTION_THREADS_KEEPALIVETIME =
+    "hbase.mob.file.compaction.threads.keepalivetime";
+  public static final long DEFAULT_MOB_FILE_COMPACTION_THREADS_KEEPALIVETIME = 60;
   private MobConstants() {
 
   }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
index d8b1376..361909a 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
@@ -27,6 +27,12 @@
 import java.util.Date;
 import java.util.List;
 import java.util.UUID;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.RejectedExecutionException;
+import java.util.concurrent.RejectedExecutionHandler;
+import java.util.concurrent.SynchronousQueue;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -51,11 +57,17 @@
 import org.apache.hadoop.hbase.io.hfile.HFile;
 import org.apache.hadoop.hbase.io.hfile.HFileContext;
 import org.apache.hadoop.hbase.io.hfile.HFileContextBuilder;
+import org.apache.hadoop.hbase.master.TableLockManager;
+import org.apache.hadoop.hbase.master.TableLockManager.TableLock;
+import org.apache.hadoop.hbase.mob.filecompactions.MobFileCompactor;
+import org.apache.hadoop.hbase.mob.filecompactions.PartitionedMobFileCompactor;
 import org.apache.hadoop.hbase.regionserver.BloomType;
 import org.apache.hadoop.hbase.regionserver.HStore;
 import org.apache.hadoop.hbase.regionserver.StoreFile;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.FSUtils;
+import org.apache.hadoop.hbase.util.ReflectionUtils;
+import org.apache.hadoop.hbase.util.Threads;
 
 /**
  * The mob utilities
@@ -645,4 +657,89 @@ public static TableName getTableLockName(TableName tn) {
     byte[] tableName = tn.getName();
     return TableName.valueOf(Bytes.add(tableName, MobConstants.MOB_TABLE_LOCK_SUFFIX));
   }
+
+  /**
+   * Do the mob file compaction.
+   * @param conf the Configuration
+   * @param fs the file system
+   * @param tableName the table the compact
+   * @param hcd the column descriptor
+   * @param pool the thread pool
+   * @param tableLockManager the tableLock manager
+   * @param isForceAllFiles Whether add all mob files into the compaction.
+   */
+  public static void doMobFileCompaction(Configuration conf, FileSystem fs, TableName tableName,
+    HColumnDescriptor hcd, ExecutorService pool, TableLockManager tableLockManager,
+    boolean isForceAllFiles) throws IOException {
+    String className = conf.get(MobConstants.MOB_FILE_COMPACTOR_CLASS_KEY,
+      PartitionedMobFileCompactor.class.getName());
+    // instantiate the mob file compactor.
+    MobFileCompactor compactor = null;
+    try {
+      compactor = ReflectionUtils.instantiateWithCustomCtor(className, new Class[] {
+        Configuration.class, FileSystem.class, TableName.class, HColumnDescriptor.class,
+        ExecutorService.class }, new Object[] { conf, fs, tableName, hcd, pool });
+    } catch (Exception e) {
+      throw new IOException("Unable to load configured mob file compactor '" + className + "'", e);
+    }
+    // compact only for mob-enabled column.
+    // obtain a write table lock before performing compaction to avoid race condition
+    // with major compaction in mob-enabled column.
+    boolean tableLocked = false;
+    TableLock lock = null;
+    try {
+      // the tableLockManager might be null in testing. In that case, it is lock-free.
+      if (tableLockManager != null) {
+        lock = tableLockManager.writeLock(MobUtils.getTableLockName(tableName),
+          "Run MobFileCompaction");
+        lock.acquire();
+      }
+      tableLocked = true;
+      compactor.compact(isForceAllFiles);
+    } catch (Exception e) {
+      LOG.error("Fail to compact the mob files for the column " + hcd.getNameAsString()
+        + " in the table " + tableName.getNameAsString(), e);
+    } finally {
+      if (lock != null && tableLocked) {
+        try {
+          lock.release();
+        } catch (IOException e) {
+          LOG.error("Fail to release the write lock for the table " + tableName.getNameAsString(),
+            e);
+        }
+      }
+    }
+  }
+
+  /**
+   * Creates a thread pool.
+   * @param conf the Configuration
+   * @return A thread pool.
+   */
+  public static ExecutorService createMobFileCompactorThreadPool(Configuration conf) {
+    int maxThreads = conf.getInt(MobConstants.MOB_FILE_COMPACTION_THREADS_MAX,
+      MobConstants.DEFAULT_MOB_FILE_COMPACTION_THREADS_MAX);
+    if (maxThreads == 0) {
+      maxThreads = 1;
+    }
+    long keepAliveTime = conf.getLong(
+      MobConstants.MOB_FILE_COMPACTION_THREADS_KEEPALIVETIME,
+      MobConstants.DEFAULT_MOB_FILE_COMPACTION_THREADS_KEEPALIVETIME);
+    final SynchronousQueue<Runnable> queue = new SynchronousQueue<Runnable>();
+    ThreadPoolExecutor pool = new ThreadPoolExecutor(1, maxThreads, keepAliveTime,
+      TimeUnit.SECONDS, queue, Threads.newDaemonThreadFactory("MobFileCompactor"),
+      new RejectedExecutionHandler() {
+        @Override
+        public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
+          try {
+            // waiting for a thread to pick up instead of throwing exceptions.
+            queue.put(r);
+          } catch (InterruptedException e) {
+            throw new RejectedExecutionException(e);
+          }
+        }
+      });
+    ((ThreadPoolExecutor) pool).allowCoreThreadTimeOut(true);
+    return pool;
+  }
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/MobFileCompactor.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/MobFileCompactor.java
index bbc358e..fcb39c5 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/MobFileCompactor.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/MobFileCompactor.java
@@ -65,14 +65,26 @@ public MobFileCompactor(Configuration conf, FileSystem fs, TableName tableName,
    * @throws IOException
    */
   public List<Path> compact() throws IOException {
-    return compact(Arrays.asList(fs.listStatus(mobFamilyDir)));
+    return compact(false);
+  }
+
+  /**
+   * Compacts the mob files by compaction type for the current column family.
+   * @param isForceAllFiles Whether add all mob files into the compaction.
+   * @return The paths of new mob files generated in the compaction.
+   * @throws IOException
+   */
+  public List<Path> compact(boolean isForceAllFiles) throws IOException {
+    return compact(Arrays.asList(fs.listStatus(mobFamilyDir)), isForceAllFiles);
   }
 
   /**
    * Compacts the candidate mob files.
    * @param files The candidate mob files.
+   * @param isForceAllFiles Whether add all mob files into the compaction.
    * @return The paths of new mob files generated in the compaction.
    * @throws IOException
    */
-  public abstract List<Path> compact(List<FileStatus> files) throws IOException;
+  public abstract List<Path> compact(List<FileStatus> files, boolean isForceAllFiles)
+    throws IOException;
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java
index 6cd3172..bce618e 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/filecompactions/PartitionedMobFileCompactor.java
@@ -110,12 +110,12 @@ public PartitionedMobFileCompactor(Configuration conf, FileSystem fs, TableName
   }
 
   @Override
-  public List<Path> compact(List<FileStatus> files) throws IOException {
+  public List<Path> compact(List<FileStatus> files, boolean isForceAllFiles) throws IOException {
     if (files == null || files.isEmpty()) {
       return null;
     }
     // find the files to compact.
-    PartitionedMobFileCompactionRequest request = select(files);
+    PartitionedMobFileCompactionRequest request = select(files, isForceAllFiles);
     // compact the files.
     return performCompaction(request);
   }
@@ -124,11 +124,12 @@ public PartitionedMobFileCompactor(Configuration conf, FileSystem fs, TableName
    * Selects the compacted mob/del files.
    * Iterates the candidates to find out all the del files and small mob files.
    * @param candidates All the candidates.
+   * @param isForceAllFiles Whether add all mob files into the compaction.
    * @return A compaction request.
    * @throws IOException
    */
-  protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates)
-    throws IOException {
+  protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates,
+    boolean isForceAllFiles) throws IOException {
     Collection<FileStatus> allDelFiles = new ArrayList<FileStatus>();
     Map<CompactionPartitionId, CompactionPartition> filesToCompact =
       new HashMap<CompactionPartitionId, CompactionPartition>();
@@ -152,8 +153,9 @@ protected PartitionedMobFileCompactionRequest select(List<FileStatus> candidates
       }
       if (StoreFileInfo.isDelFile(linkedFile.getPath())) {
         allDelFiles.add(file);
-      } else if (linkedFile.getLen() < mergeableSize) {
-        // add the small files to the merge pool
+      } else if (isForceAllFiles || linkedFile.getLen() < mergeableSize) {
+        // add all files if isForceAllFiles is true,
+        // otherwise add the small files to the merge pool
         MobFileName fileName = MobFileName.create(linkedFile.getPath().getName());
         CompactionPartitionId id = new CompactionPartitionId(fileName.getStartKey(),
           fileName.getDate());
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
index e11aac2..5bb47a9 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
@@ -219,6 +219,7 @@
 
   // Compactions
   public CompactSplitThread compactSplitThread;
+  public RegionSeverMobFileCompactionThread mobFileCompactThread;
 
   /**
    * Map of regions currently being served by this region server. Key is the
@@ -689,6 +690,7 @@ private void initializeThreads() throws IOException {
 
     // Compaction thread
     this.compactSplitThread = new CompactSplitThread(this);
+    this.mobFileCompactThread = new RegionSeverMobFileCompactionThread(this);
 
     // Background thread to check for compactions; needed if region has not gotten updates
     // in a while. It will take care of not checking too frequently on store-by-store basis.
@@ -845,6 +847,7 @@ public void run() {
     if(this.hMemManager != null) this.hMemManager.stop();
     if (this.cacheFlusher != null) this.cacheFlusher.interruptIfNecessary();
     if (this.compactSplitThread != null) this.compactSplitThread.interruptIfNecessary();
+    if (this.mobFileCompactThread != null) this.mobFileCompactThread.interruptIfNecessary();
     if (this.compactionChecker != null)
       this.compactionChecker.interrupt();
     if (this.healthCheckChore != null) {
@@ -893,6 +896,10 @@ public void run() {
           this.compactSplitThread.join();
           this.compactSplitThread = null;
         }
+        if (this.mobFileCompactThread != null) {
+          this.mobFileCompactThread.join();
+          this.mobFileCompactThread = null;
+        }
         closeMetaTableRegions(abortRequested);
       }
     }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java
index 22e4d88..a7fc504 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java
@@ -33,12 +33,14 @@
 import java.util.Set;
 import java.util.TreeSet;
 import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ExecutorService;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.hbase.Cell;
 import org.apache.hadoop.hbase.CellScannable;
 import org.apache.hadoop.hbase.CellScanner;
@@ -46,6 +48,7 @@
 import org.apache.hadoop.hbase.DoNotRetryIOException;
 import org.apache.hadoop.hbase.DroppedSnapshotException;
 import org.apache.hadoop.hbase.HBaseIOException;
+import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.HTableDescriptor;
@@ -83,6 +86,8 @@
 import org.apache.hadoop.hbase.ipc.RpcServerInterface;
 import org.apache.hadoop.hbase.ipc.ServerNotRunningYetException;
 import org.apache.hadoop.hbase.ipc.ServerRpcController;
+import org.apache.hadoop.hbase.master.TableLockManager;
+import org.apache.hadoop.hbase.mob.MobUtils;
 import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.protobuf.RequestConverter;
 import org.apache.hadoop.hbase.protobuf.ResponseConverter;
@@ -950,6 +955,40 @@ public CompactRegionResponse compactRegion(final RpcController controller,
     try {
       checkOpen();
       requestCount.increment();
+      RegionSpecifier regionSpecifier = request.getRegion();
+      String regionEncodedName = ProtobufUtil.getRegionEncodedName(request.getRegion());
+      byte[] regionName = regionSpecifier.getValue().toByteArray();
+      TableName tableName = HRegionInfo.getTable(regionName);
+      // if get the mob region, do the mob file compaction.
+      if (regionEncodedName.equals(MobUtils.getMobRegionInfo(tableName).getEncodedName())) {
+        boolean isForceAllFiles = false;
+        Configuration conf = regionServer.getConfiguration();
+        FileSystem fs = regionServer.getFileSystem();
+        TableLockManager tableLockManager = regionServer.getTableLockManager();
+        byte[] family = request.getFamily().toByteArray();
+        for (HColumnDescriptor hcd : regionServer.tableDescriptors.get(tableName)
+          .getColumnFamilies()) {
+          if (Bytes.equals(family, hcd.getName())) {
+            if (!hcd.isMobEnabled()) {
+              throw new IOException("Column family " + hcd.getName()
+                + " is not a MOB column family");
+            } else {
+              if (request.hasMajor()) {
+                if (request.getMajor()) {
+                  isForceAllFiles = true;
+                }
+              }
+              if (LOG.isTraceEnabled()) {
+                LOG.trace("User-triggered mob file compaction requested for table: "
+                  + tableName.getNameAsString() + " for column family: " + Bytes.toString(family));
+              }
+              regionServer.mobFileCompactThread.requestMobFileCompaction(conf, fs, tableName, hcd,
+                tableLockManager, isForceAllFiles);
+            }
+          }
+        }
+        return CompactRegionResponse.newBuilder().build();
+      }
       HRegion region = getRegion(request.getRegion());
       region.startRegionOperation(Operation.COMPACT_REGION);
       LOG.info("Compacting " + region.getRegionNameAsString());
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionSeverMobFileCompactionThread.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionSeverMobFileCompactionThread.java
new file mode 100644
index 0000000..aa62737
--- /dev/null
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionSeverMobFileCompactionThread.java
@@ -0,0 +1,146 @@
+/**
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.regionserver;
+
+import java.io.IOException;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.PriorityBlockingQueue;
+import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.classification.InterfaceAudience;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.hbase.HColumnDescriptor;
+import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.master.TableLockManager;
+import org.apache.hadoop.hbase.mob.MobUtils;
+
+/**
+ * The mob file compaction thread used in {@link RSRpcServices}
+ */
+@InterfaceAudience.Private
+public class RegionSeverMobFileCompactionThread {
+  static final Log LOG = LogFactory.getLog(RegionSeverMobFileCompactionThread.class);
+  private final Configuration conf;
+  private final ExecutorService mobFileComapctorPool;
+  private final ExecutorService regionServerMobPool;
+
+  public RegionSeverMobFileCompactionThread(HRegionServer server) {
+    this.conf = server.getConfiguration();
+    final String n = Thread.currentThread().getName();
+    this.regionServerMobPool = new ThreadPoolExecutor(1, 2, 60, TimeUnit.SECONDS,
+      new PriorityBlockingQueue<Runnable>(), new ThreadFactory() {
+        @Override
+        public Thread newThread(Runnable r) {
+          Thread t = new Thread(r);
+          t.setName(n + "-RegionServerMobFileCompaction-" + System.currentTimeMillis());
+          return t;
+        }
+      });
+    ((ThreadPoolExecutor) this.regionServerMobPool).allowCoreThreadTimeOut(true);
+    this.mobFileComapctorPool = MobUtils
+      .createMobFileCompactorThreadPool(server.getConfiguration());
+  }
+
+  /**
+   * Requests mob file compaction
+   * @param conf the Configuration
+   * @param fs the file system
+   * @param tableName the table the compact
+   * @param hcd the column descriptor
+   * @param tableLockManager the tableLock manager
+   * @param isForceAllFiles Whether add all mob files into the compaction.
+   */
+  public void requestMobFileCompaction(Configuration conf, FileSystem fs, TableName tableName,
+    HColumnDescriptor hcd, TableLockManager tableLockManager, boolean isForceAllFiles)
+    throws IOException {
+    regionServerMobPool.execute(new CompactionRunner(fs, tableName, hcd, tableLockManager,
+      isForceAllFiles, mobFileComapctorPool));
+  }
+
+  private class CompactionRunner implements Runnable {
+    private FileSystem fs;
+    private TableName tableName;
+    private HColumnDescriptor hcd;
+    private TableLockManager tableLockManager;
+    private boolean isForceAllFiles;
+    private ExecutorService pool;
+
+    public CompactionRunner(FileSystem fs, TableName tableName, HColumnDescriptor hcd,
+      TableLockManager tableLockManager, boolean isForceAllFiles, ExecutorService pool) {
+      super();
+      this.fs = fs;
+      this.tableName = tableName;
+      this.hcd = hcd;
+      this.tableLockManager = tableLockManager;
+      this.isForceAllFiles = isForceAllFiles;
+      this.pool = pool;
+    }
+
+    @Override
+    public void run() {
+      try {
+        MobUtils.doMobFileCompaction(conf, fs, tableName, hcd, pool, tableLockManager,
+          isForceAllFiles);
+      } catch (IOException e) {
+        LOG.error("Fail to do the mob file compaction", e);
+      }
+    }
+  }
+
+  /**
+   * Only interrupt once it's done with a run through the work loop.
+   */
+  void interruptIfNecessary() {
+    mobFileComapctorPool.shutdown();
+    regionServerMobPool.shutdown();
+  }
+
+  /**
+   * Wait for all the threads finish.
+   */
+  void join() {
+    waitFor(mobFileComapctorPool, "Mob file Compaction Thread");
+    waitFor(regionServerMobPool, "Region Server Mob File Compaction Thread");
+  }
+
+  /**
+   * Wait for thread finish.
+   * @param t the thread to wait
+   * @param name the thread name.
+   */
+  private void waitFor(ExecutorService t, String name) {
+    boolean done = false;
+    while (!done) {
+      try {
+        done = t.awaitTermination(60, TimeUnit.SECONDS);
+        LOG.info("Waiting for " + name + " to finish...");
+        if (!done) {
+          t.shutdownNow();
+        }
+      } catch (InterruptedException ie) {
+        LOG.warn("Interrupted waiting for " + name + " to finish...");
+      }
+    }
+  }
+}
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestMobFileCompactor.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestMobFileCompactor.java
index 9a8b7d9..b1f148c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestMobFileCompactor.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestMobFileCompactor.java
@@ -71,28 +71,29 @@
   private Configuration conf = null;
   private String tableNameAsString;
   private TableName tableName;
-  private static HTable hTable;
-  private static Admin admin;
-  private static HTableDescriptor desc;
-  private static HColumnDescriptor hcd1;
-  private static HColumnDescriptor hcd2;
-  private static FileSystem fs;
-  private final static String family1 = "family1";
-  private final static String family2 = "family2";
-  private final static String qf1 = "qualifier1";
-  private final static String qf2 = "qualifier2";
-  private static byte[] KEYS = Bytes.toBytes("012");
-  private static int regionNum = KEYS.length;
-  private static int delRowNum = 1;
-  private static int delCellNum = 6;
-  private static int cellNumPerRow = 3;
-  private static int rowNumPerFile = 2;
+  private HTable hTable;
+  private Admin admin;
+  private HTableDescriptor desc;
+  private HColumnDescriptor hcd1;
+  private HColumnDescriptor hcd2;
+  private FileSystem fs;
+  private final String family1 = "family1";
+  private final String family2 = "family2";
+  private final String qf1 = "qualifier1";
+  private final String qf2 = "qualifier2";
+  private byte[] KEYS = Bytes.toBytes("012");
+  private int regionNum = KEYS.length;
+  private int delRowNum = 1;
+  private int delCellNum = 6;
+  private int cellNumPerRow = 3;
+  private int rowNumPerFile = 2;
   private static ExecutorService pool;
 
   @BeforeClass
   public static void setUpBeforeClass() throws Exception {
     TEST_UTIL.getConfiguration().setInt("hbase.master.info.port", 0);
     TEST_UTIL.getConfiguration().setBoolean("hbase.regionserver.info.port.auto", true);
+    TEST_UTIL.getConfiguration().setLong(MobConstants.MOB_FILE_COMPACTION_MERGEABLE_THRESHOLD, 5000);
     TEST_UTIL.startMiniCluster(1);
     pool = createThreadPool(TEST_UTIL.getConfiguration());
   }
@@ -208,41 +209,6 @@ public void testCompactionWithDelFiles() throws Exception {
     assertRefFileNameEqual(family1);
   }
 
-  private void assertRefFileNameEqual(String familyName) throws IOException {
-    Scan scan = new Scan();
-    scan.addFamily(Bytes.toBytes(familyName));
-    // Do not retrieve the mob data when scanning
-    scan.setAttribute(MobConstants.MOB_SCAN_RAW, Bytes.toBytes(Boolean.TRUE));
-    ResultScanner results = hTable.getScanner(scan);
-    Path mobFamilyPath = new Path(MobUtils.getMobRegionPath(TEST_UTIL.getConfiguration(),
-        tableName), familyName);
-    List<Path> actualFilePaths = new ArrayList<>();
-    List<Path> expectFilePaths = new ArrayList<>();
-    for (Result res : results) {
-      for (Cell cell : res.listCells()) {
-        byte[] referenceValue = CellUtil.cloneValue(cell);
-        String fileName = Bytes.toString(referenceValue, Bytes.SIZEOF_INT,
-            referenceValue.length - Bytes.SIZEOF_INT);
-        Path targetPath = new Path(mobFamilyPath, fileName);
-        if(!actualFilePaths.contains(targetPath)) {
-          actualFilePaths.add(targetPath);
-        }
-      }
-    }
-    results.close();
-    if (fs.exists(mobFamilyPath)) {
-      FileStatus[] files = fs.listStatus(mobFamilyPath);
-      for (FileStatus file : files) {
-        if (!StoreFileInfo.isDelFile(file.getPath())) {
-          expectFilePaths.add(file.getPath());
-        }
-      }
-    }
-    Collections.sort(actualFilePaths);
-    Collections.sort(expectFilePaths);
-    assertEquals(expectFilePaths, actualFilePaths);
-  }
-
   @Test
   public void testCompactionWithDelFilesAndNotMergeAllFiles() throws Exception {
     resetConf();
@@ -428,6 +394,116 @@ public void testCompactionWithHFileLink() throws IOException, InterruptedExcepti
     assertEquals("After second compaction: family2 del file count", 0, countFiles(false, family2));
     assertEquals("After second compaction: family1 hfilelink count", 0, countHFileLinks(family1));
     assertEquals("After second compaction: family2 hfilelink count", 0, countHFileLinks(family2));
+    assertRefFileNameEqual(family1);
+  }
+
+  @Test
+  public void testCompactionFromAdmin() throws Exception {
+    int count = 4;
+    // generate mob files
+    loadData(count, rowNumPerFile);
+    int rowNumPerRegion = count*rowNumPerFile;
+
+    assertEquals("Before deleting: mob rows count", regionNum*rowNumPerRegion,
+        countMobRows(hTable));
+    assertEquals("Before deleting: mob cells count", regionNum*cellNumPerRow*rowNumPerRegion,
+        countMobCells(hTable));
+    assertEquals("Before deleting: family1 mob file count", regionNum*count,
+        countFiles(true, family1));
+    assertEquals("Before deleting: family2 mob file count", regionNum*count,
+        countFiles(true, family2));
+
+    createDelFile();
+
+    assertEquals("Before compaction: mob rows count", regionNum*(rowNumPerRegion-delRowNum),
+        countMobRows(hTable));
+    assertEquals("Before compaction: mob cells count",
+        regionNum*(cellNumPerRow*rowNumPerRegion-delCellNum), countMobCells(hTable));
+    assertEquals("Before compaction: family1 mob file count", regionNum*count,
+        countFiles(true, family1));
+    assertEquals("Before compaction: family2 file count", regionNum*count,
+        countFiles(true, family2));
+    assertEquals("Before compaction: family1 del file count", regionNum,
+        countFiles(false, family1));
+    assertEquals("Before compaction: family2 del file count", regionNum,
+        countFiles(false, family2));
+
+    int largeFilesCount = countLargeFiles(5000, family1);
+    // do the mob file compaction
+    admin.compactMob(tableName, hcd1.getName());
+
+    // wait until the compaction finish.
+    long finished = System.currentTimeMillis() + 60000;
+    while (System.currentTimeMillis() < finished) {
+      if(countFiles(true, family1) == (regionNum + largeFilesCount)) {
+        break;
+      }
+      Thread.sleep(50);
+    }
+    assertEquals("After compaction: mob rows count", regionNum*(rowNumPerRegion-delRowNum),
+        countMobRows(hTable));
+    assertEquals("After compaction: mob cells count",
+        regionNum*(cellNumPerRow*rowNumPerRegion-delCellNum), countMobCells(hTable));
+    assertEquals("After compaction: family1 mob file count", regionNum + largeFilesCount,
+        countFiles(true, family1));
+    assertEquals("After compaction: family2 mob file count", regionNum*count,
+        countFiles(true, family2));
+    assertEquals("After compaction: family1 del file count", regionNum, countFiles(false, family1));
+    assertEquals("After compaction: family2 del file count", regionNum,
+        countFiles(false, family2));
+    assertRefFileNameEqual(family1);
+  }
+
+  @Test
+  public void testMajorCompactionFromAdmin() throws Exception {
+    int count = 4;
+    // generate mob files
+    loadData(count, rowNumPerFile);
+    int rowNumPerRegion = count*rowNumPerFile;
+
+    assertEquals("Before deleting: mob rows count", regionNum*rowNumPerRegion,
+        countMobRows(hTable));
+    assertEquals("Before deleting: mob cells count", regionNum*cellNumPerRow*rowNumPerRegion,
+        countMobCells(hTable));
+    assertEquals("Before deleting: mob file count", regionNum*count, countFiles(true, family1));
+
+    createDelFile();
+
+    assertEquals("Before compaction: mob rows count", regionNum*(rowNumPerRegion-delRowNum),
+        countMobRows(hTable));
+    assertEquals("Before compaction: mob cells count",
+        regionNum*(cellNumPerRow*rowNumPerRegion-delCellNum), countMobCells(hTable));
+    assertEquals("Before compaction: family1 mob file count", regionNum*count,
+        countFiles(true, family1));
+    assertEquals("Before compaction: family2 mob file count", regionNum*count,
+        countFiles(true, family2));
+    assertEquals("Before compaction: family1 del file count", regionNum,
+        countFiles(false, family1));
+    assertEquals("Before compaction: family2 del file count", regionNum,
+        countFiles(false, family2));
+
+    // do the major mob file compaction, it will force all files to compaction
+    admin.majorCompactMob(tableName, hcd1.getName());
+
+    // wait until the compaction finish.
+    long finished = System.currentTimeMillis() + 60000;
+    while (System.currentTimeMillis() < finished) {
+      if(countFiles(true, family1) == regionNum) {
+        break;
+      }
+      Thread.sleep(50);
+    }
+    assertEquals("After compaction: mob rows count", regionNum*(rowNumPerRegion-delRowNum),
+        countMobRows(hTable));
+    assertEquals("After compaction: mob cells count",
+        regionNum*(cellNumPerRow*rowNumPerRegion-delCellNum), countMobCells(hTable));
+    assertEquals("After compaction: family1 mob file count", regionNum,
+        countFiles(true, family1));
+    assertEquals("After compaction: family2 mob file count", regionNum*count,
+        countFiles(true, family2));
+    assertEquals("After compaction: family1 del file count", 0, countFiles(false, family1));
+    assertEquals("After compaction: family2 del file count", regionNum,
+        countFiles(false, family2));
   }
 
   /**
@@ -610,7 +686,7 @@ private void createDelFile() throws IOException, InterruptedException {
   /**
    * Gets the split keys
    */
-  public static byte[][] getSplitKeys() {
+  private byte[][] getSplitKeys() {
     byte[][] splitKeys = new byte[KEYS.length - 1][];
     for (int i = 0; i < splitKeys.length; ++i) {
       splitKeys[i] = new byte[] { KEYS[i + 1] };
@@ -640,6 +716,41 @@ public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
     return pool;
   }
 
+  private void assertRefFileNameEqual(String familyName) throws IOException {
+    Scan scan = new Scan();
+    scan.addFamily(Bytes.toBytes(familyName));
+    // Do not retrieve the mob data when scanning
+    scan.setAttribute(MobConstants.MOB_SCAN_RAW, Bytes.toBytes(Boolean.TRUE));
+    ResultScanner results = hTable.getScanner(scan);
+    Path mobFamilyPath = new Path(MobUtils.getMobRegionPath(TEST_UTIL.getConfiguration(),
+        tableName), familyName);
+    List<Path> actualFilePaths = new ArrayList<>();
+    List<Path> expectFilePaths = new ArrayList<>();
+    for (Result res : results) {
+      for (Cell cell : res.listCells()) {
+        byte[] referenceValue = CellUtil.cloneValue(cell);
+        String fileName = Bytes.toString(referenceValue, Bytes.SIZEOF_INT,
+            referenceValue.length - Bytes.SIZEOF_INT);
+        Path targetPath = new Path(mobFamilyPath, fileName);
+        if(!actualFilePaths.contains(targetPath)) {
+          actualFilePaths.add(targetPath);
+        }
+      }
+    }
+    results.close();
+    if (fs.exists(mobFamilyPath)) {
+      FileStatus[] files = fs.listStatus(mobFamilyPath);
+      for (FileStatus file : files) {
+        if (!StoreFileInfo.isDelFile(file.getPath())) {
+          expectFilePaths.add(file.getPath());
+        }
+      }
+    }
+    Collections.sort(actualFilePaths);
+    Collections.sort(expectFilePaths);
+    assertEquals(expectFilePaths, actualFilePaths);
+  }
+
   /**
    * Resets the configuration.
    */
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestPartitionedMobFileCompactor.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestPartitionedMobFileCompactor.java
index 1d64c0c..c81e9e5 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestPartitionedMobFileCompactor.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mob/filecompactions/TestPartitionedMobFileCompactor.java
@@ -131,7 +131,7 @@ public void testCompactionSelectWithAllFiles() throws Exception {
         expectedStartKeys.add(startKey);
       }
     }
-    testSelectFiles(tableName, CompactionType.ALL_FILES, expectedStartKeys);
+    testSelectFiles(tableName, CompactionType.ALL_FILES, false, expectedStartKeys);
   }
 
   @Test
@@ -156,7 +156,30 @@ public void testCompactionSelectWithPartFiles() throws Exception {
     }
     // set the mob file compaction mergeable threshold
     conf.setLong(MobConstants.MOB_FILE_COMPACTION_MERGEABLE_THRESHOLD, mergeSize);
-    testSelectFiles(tableName, CompactionType.PART_FILES, expectedStartKeys);
+    testSelectFiles(tableName, CompactionType.PART_FILES, false, expectedStartKeys);
+  }
+
+  @Test
+  public void testCompactionSelectWithForceAllFiles() throws Exception {
+    resetConf();
+    String tableName = "testCompactionSelectWithForceAllFiles";
+    init(tableName);
+    int count = 10;
+    // create 10 mob files.
+    createStoreFiles(basePath, family, qf, count, Type.Put);
+    // create 10 del files
+    createStoreFiles(basePath, family, qf, count, Type.Delete);
+    listFiles();
+    long mergeSize = 4000;
+    List<String> expectedStartKeys = new ArrayList<>();
+    for(FileStatus file : mobFiles) {
+      String fileName = file.getPath().getName();
+      String startKey = fileName.substring(0, 32);
+      expectedStartKeys.add(startKey);
+    }
+    // set the mob file compaction mergeable threshold
+    conf.setLong(MobConstants.MOB_FILE_COMPACTION_MERGEABLE_THRESHOLD, mergeSize);
+    testSelectFiles(tableName, CompactionType.ALL_FILES, true, expectedStartKeys);
   }
 
   @Test
@@ -169,7 +192,7 @@ public void testCompactDelFilesWithDefaultBatchSize() throws Exception {
     // create 13 del files
     createStoreFiles(basePath, family, qf, 13, Type.Delete);
     listFiles();
-    testCompactDelFiles(tableName, 1, 13);
+    testCompactDelFiles(tableName, 1, 13, false);
   }
 
   @Test
@@ -185,7 +208,7 @@ public void testCompactDelFilesWithSmallBatchSize() throws Exception {
 
     // set the mob file compaction batch size
     conf.setInt(MobConstants.MOB_FILE_COMPACTION_BATCH_SIZE, 4);
-    testCompactDelFiles(tableName, 1, 13);
+    testCompactDelFiles(tableName, 1, 13, false);
   }
 
   @Test
@@ -203,7 +226,7 @@ public void testCompactDelFilesChangeMaxDelFileCount() throws Exception {
     conf.setInt(MobConstants.MOB_DELFILE_MAX_COUNT, 5);
     // set the mob file compaction batch size
     conf.setInt(MobConstants.MOB_FILE_COMPACTION_BATCH_SIZE, 2);
-    testCompactDelFiles(tableName, 4, 13);
+    testCompactDelFiles(tableName, 4, 13, false);
   }
 
   /**
@@ -213,16 +236,17 @@ public void testCompactDelFilesChangeMaxDelFileCount() throws Exception {
    * @param expected the expected start keys
    */
   private void testSelectFiles(String tableName, final CompactionType type,
-      final List<String> expected) throws IOException {
+    final boolean isForceAllFiles, final List<String> expected) throws IOException {
     PartitionedMobFileCompactor compactor = new PartitionedMobFileCompactor(conf, fs,
       TableName.valueOf(tableName), hcd, pool) {
       @Override
-      public List<Path> compact(List<FileStatus> files) throws IOException {
+      public List<Path> compact(List<FileStatus> files, boolean isForceAllFiles)
+        throws IOException {
         if (files == null || files.isEmpty()) {
           return null;
         }
-        PartitionedMobFileCompactionRequest request = select(files);
-        // assert the compaction type is ALL_FILES
+        PartitionedMobFileCompactionRequest request = select(files, isForceAllFiles);
+        // assert the compaction type
         Assert.assertEquals(type, request.type);
         // assert get the right partitions
         compareCompactedPartitions(expected, request.compactionPartitions);
@@ -231,7 +255,7 @@ private void testSelectFiles(String tableName, final CompactionType type,
         return null;
       }
     };
-    compactor.compact(allFiles);
+    compactor.compact(allFiles, isForceAllFiles);
   }
 
   /**
@@ -241,7 +265,7 @@ private void testSelectFiles(String tableName, final CompactionType type,
    * @param expectedCellCount the expected cell count
    */
   private void testCompactDelFiles(String tableName, final int expectedFileCount,
-      final int expectedCellCount) throws IOException {
+      final int expectedCellCount, boolean isForceAllFiles) throws IOException {
     PartitionedMobFileCompactor compactor = new PartitionedMobFileCompactor(conf, fs,
       TableName.valueOf(tableName), hcd, pool) {
       @Override
@@ -258,8 +282,7 @@ private void testCompactDelFiles(String tableName, final int expectedFileCount,
         return null;
       }
     };
-
-    compactor.compact(allFiles);
+    compactor.compact(allFiles, isForceAllFiles);
   }
 
   /**
diff --git a/hbase-shell/src/main/ruby/hbase/admin.rb b/hbase-shell/src/main/ruby/hbase/admin.rb
index bc3cb89..4f8a612 100644
--- a/hbase-shell/src/main/ruby/hbase/admin.rb
+++ b/hbase-shell/src/main/ruby/hbase/admin.rb
@@ -76,6 +76,20 @@ def major_compact(table_or_region_name, family = nil)
     end
 
     #----------------------------------------------------------------------------------------------
+    # Requests a mob column family compaction
+    def compact_mob(table_name, family)
+        # We are compacting a mob column family within a table.
+        @admin.compactMob(org.apache.hadoop.hbase.TableName.valueOf(table_name), family.to_java_bytes)
+    end
+
+    #----------------------------------------------------------------------------------------------
+    # Requests a mob column family major compaction
+    def major_compact_mob(table_name, family)
+        # We are major compacting a mob column family within a table.
+        @admin.majorCompactMob(org.apache.hadoop.hbase.TableName.valueOf(table_name), family.to_java_bytes)
+    end
+
+    #----------------------------------------------------------------------------------------------
     # Requests a regionserver's HLog roll
     def hlog_roll(server_name)
       @admin.rollHLogWriter(server_name)
diff --git a/hbase-shell/src/main/ruby/shell.rb b/hbase-shell/src/main/ruby/shell.rb
index 5b59254..64f7839 100644
--- a/hbase-shell/src/main/ruby/shell.rb
+++ b/hbase-shell/src/main/ruby/shell.rb
@@ -322,6 +322,8 @@ def help_footer
     catalogjanitor_switch
     catalogjanitor_enabled
     trace
+    compact_mob
+    major_compact_mob
   ]
 )
 
diff --git a/hbase-shell/src/main/ruby/shell/commands/compact_mob.rb b/hbase-shell/src/main/ruby/shell/commands/compact_mob.rb
new file mode 100644
index 0000000..2286967
--- /dev/null
+++ b/hbase-shell/src/main/ruby/shell/commands/compact_mob.rb
@@ -0,0 +1,39 @@
+#
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+module Shell
+  module Commands
+    class CompactMob < Command
+      def help
+        return <<-EOF
+          Run compaction on a mob enabled column family within a table
+          Examples:
+          Compact a column family within a table:
+          hbase> compact_mob 't1', 'c1'
+        EOF
+      end
+
+      def command(table_name, family)
+        format_simple_command do
+          admin.compact_mob(table_name, family)
+        end
+      end
+    end
+  end
+end
diff --git a/hbase-shell/src/main/ruby/shell/commands/major_compact_mob.rb b/hbase-shell/src/main/ruby/shell/commands/major_compact_mob.rb
new file mode 100644
index 0000000..12f4799
--- /dev/null
+++ b/hbase-shell/src/main/ruby/shell/commands/major_compact_mob.rb
@@ -0,0 +1,39 @@
+#
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+module Shell
+  module Commands
+    class MajorCompactMob < Command
+      def help
+        return <<-EOF
+          Run major compaction on a mob enabled column family within a table
+          Examples:
+          Compact a column family within a table:
+          hbase> major_compact_mob 't1', 'c1'
+        EOF
+      end
+
+      def command(table_name, family)
+        format_simple_command do
+          admin.major_compact_mob(table_name, family)
+        end
+      end
+    end
+  end
+end
