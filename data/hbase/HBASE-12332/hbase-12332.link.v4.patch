diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java
index 3789148..71a07b8 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java
@@ -18,11 +18,13 @@
 
 package org.apache.hadoop.hbase.io;
 
+import java.util.ArrayList;
 import java.util.Collection;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.FileNotFoundException;
+import java.util.List;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -137,12 +139,12 @@ public class FileLink {
     }
 
     @Override
-    public int read(byte b[]) throws IOException {
+    public int read(byte[] b) throws IOException {
        return read(b, 0, b.length);
     }
 
     @Override
-    public int read(byte b[], int off, int len) throws IOException {
+    public int read(byte[] b, int off, int len) throws IOException {
       int n;
       try {
         n = in.read(b, off, len);
@@ -411,11 +413,18 @@ public class FileLink {
    */
   protected void setLocations(Path originPath, Path... alternativePaths) {
     assert this.locations == null : "Link locations already set";
-    this.locations = new Path[1 + alternativePaths.length];
-    this.locations[0] = originPath;
+
+    List<Path> paths = new ArrayList<Path>(alternativePaths.length +1);
+    if (originPath != null) {
+      paths.add(originPath);
+    }
+
     for (int i = 0; i < alternativePaths.length; i++) {
-      this.locations[i + 1] = alternativePaths[i];
+      if (alternativePaths[i] != null) {
+        paths.add(alternativePaths[i]);
+      }
     }
+    this.locations = paths.toArray(new Path[0]);
   }
 
   /**
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java
index 6e97a76..932d743 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java
@@ -94,37 +94,43 @@ public class HFileLink extends FileLink {
   private final Path tempPath;
 
   /**
-   * @param conf {@link Configuration} from which to extract specific archive locations
-   * @param path The path of the HFile Link.
-   * @throws IOException on unexpected error.
+   * Dead simple hfile link constructor
    */
-  public HFileLink(Configuration conf, Path path) throws IOException {
-    this(FSUtils.getRootDir(conf), HFileArchiveUtil.getArchivePath(conf), path);
+  public HFileLink(final Path originPath, final Path tempPath,
+                   final Path archivePath, final Path mobPath) {
+    this.tempPath  = tempPath;
+    this.originPath = originPath;
+    this.archivePath = archivePath;
+    this.mobPath = mobPath;
+
+    setLocations(originPath, mobPath, tempPath, archivePath);
   }
 
   /**
-   * @param rootDir Path to the root directory where hbase files are stored
-   * @param archiveDir Path to the hbase archive directory
-   * @param mobDir path to the hbase mob directory
-   * @param path The path of the HFile Link.
+   * @param conf {@link Configuration} from which to extract specific archive locations
+   * @param hFileLinkPattern The path ending with a HFileLink pattern. (table=region-hfile)
+   * @throws IOException on unexpected error.
    */
-    public HFileLink(final Path rootDir, final Path archiveDir, final Path mobDir, final Path path) {
-        Path hfilePath = getRelativeTablePath(path);
-        this.tempPath = new Path(new Path(rootDir, HConstants.HBASE_TEMP_DIRECTORY), hfilePath);
-        this.originPath = new Path(rootDir, hfilePath);
-        this.mobPath = new Path(mobDir, hfilePath);
-        this.archivePath = new Path(archiveDir, hfilePath);
-        setLocations(originPath, mobPath, tempPath, archivePath);
-    }
-
+  public static final HFileLink buildFromHFileLinkPattern(Configuration conf, Path hFileLinkPattern)
+          throws IOException {
+    return buildFromHFileLinkPattern(FSUtils.getRootDir(conf),
+            HFileArchiveUtil.getArchivePath(conf), hFileLinkPattern);
+  }
 
-    /**
+  /**
    * @param rootDir Path to the root directory where hbase files are stored
    * @param archiveDir Path to the hbase archive directory
-   * @param path The path of the HFile Link.
+   * @param hFileLinkPattern The path of the HFile Link.
    */
-  public HFileLink(final Path rootDir, final Path archiveDir, final Path path) {
-    this(rootDir, archiveDir, new Path(rootDir, MobConstants.MOB_DIR_NAME), path);
+  public final static HFileLink buildFromHFileLinkPattern(final Path rootDir,
+                                                          final Path archiveDir,
+                                                          final Path hFileLinkPattern) {
+    Path hfilePath = getHFileLinkPatternRelativePath(hFileLinkPattern);
+    Path tempPath = new Path(new Path(rootDir, HConstants.HBASE_TEMP_DIRECTORY), hfilePath);
+    Path originPath = new Path(rootDir, hfilePath);
+    Path mobPath = new Path(new Path(rootDir, MobConstants.MOB_DIR_NAME), hfilePath);
+    Path archivePath = new Path(archiveDir, hfilePath);
+    return new HFileLink(originPath, tempPath, archivePath, mobPath);
   }
 
   /**
@@ -136,7 +142,7 @@ public class HFileLink extends FileLink {
    * @return the relative Path to open the specified table/region/family/hfile link
    */
   public static Path createPath(final TableName table, final String region,
-      final String family, final String hfile) {
+                                final String family, final String hfile) {
     if (HFileLink.isHFileLink(hfile)) {
       return new Path(family, hfile);
     }
@@ -153,9 +159,10 @@ public class HFileLink extends FileLink {
    * @return Link to the file with the specified table/region/family/hfile location
    * @throws IOException on unexpected error.
    */
-  public static HFileLink create(final Configuration conf, final TableName table,
-      final String region, final String family, final String hfile) throws IOException {
-    return new HFileLink(conf, createPath(table, region, family, hfile));
+  public static HFileLink build(final Configuration conf, final TableName table,
+                                 final String region, final String family, final String hfile)
+          throws IOException {
+    return HFileLink.buildFromHFileLinkPattern(conf, createPath(table, region, family, hfile));
   }
 
   /**
@@ -205,11 +212,11 @@ public class HFileLink extends FileLink {
    * @return Relative table path
    * @throws IOException on unexpected error.
    */
-  private static Path getRelativeTablePath(final Path path) {
+  private static Path getHFileLinkPatternRelativePath(final Path path) {
     // table=region-hfile
     Matcher m = REF_OR_HFILE_LINK_PATTERN.matcher(path.getName());
     if (!m.matches()) {
-      throw new IllegalArgumentException(path.getName() + " is not a valid HFileLink name!");
+      throw new IllegalArgumentException(path.getName() + " is not a valid HFileLink pattern!");
     }
 
     // Convert the HFileLink name into a real table/region/cf/hfile path.
@@ -223,6 +230,36 @@ public class HFileLink extends FileLink {
   }
 
   /**
+   * Path that only has table/[region]/[cf]/[file]
+   * @param fqPath Fully qualified path.
+   * @return
+   */
+  public static Path getRelativeTablePath(final Path fqPath) {
+    String hfileName = fqPath.getName();
+    String familyName = fqPath.getParent().getName();
+    String regionName = fqPath.getParent().getParent().getName();
+    TableName tableName = TableName.valueOf(fqPath.getParent().getParent().getParent().getName());
+    Path tableDir = FSUtils.getTableDir(new Path("./"), tableName);
+    return new Path(tableDir, new Path(regionName, new Path(familyName,
+            hfileName)));
+  }
+
+  /**
+   * Path that only has table/[region]/[cf]/[file]
+   * @param fqPath Fully qualified path.
+   * @return
+   */
+  public static Path getRelativeTablePath(final TableName tableName, final Path fqPath) {
+    String hfileName = fqPath.getName();
+    String familyName = fqPath.getParent().getName();
+    String regionName = fqPath.getParent().getParent().getName();
+    Path tableDir = FSUtils.getTableDir(new Path("./"), tableName);
+    return new Path(tableDir, new Path(regionName, new Path(familyName,
+            hfileName)));
+  }
+
+
+  /**
    * Get the HFile name of the referenced link
    *
    * @param fileName HFileLink file name
@@ -270,11 +307,12 @@ public class HFileLink extends FileLink {
   public boolean exists(final FileSystem fs) throws IOException {
     return fs.exists(this.originPath) ||
            fs.exists(this.tempPath) ||
-           fs.exists(this.archivePath);
+           fs.exists(this.archivePath) ||
+           fs.exists(this.mobPath);
   }
 
   /**
-   * Create a new HFileLink name
+   * Create a new HFileLink name.  Used in Test only.
    *
    * @param hfileRegionInfo - Linked HFile Region Info
    * @param hfileName - Linked HFile name
@@ -283,7 +321,7 @@ public class HFileLink extends FileLink {
   public static String createHFileLinkName(final HRegionInfo hfileRegionInfo,
       final String hfileName) {
     return createHFileLinkName(hfileRegionInfo.getTable(),
-                      hfileRegionInfo.getEncodedName(), hfileName);
+            hfileRegionInfo.getEncodedName(), hfileName);
   }
 
   /**
@@ -339,7 +377,7 @@ public class HFileLink extends FileLink {
    * @return true if the file is created, otherwise the file exists.
    * @throws IOException on file or parent directory creation failure
    */
-  public static boolean create(final Configuration conf, final FileSystem fs,
+  private static boolean create(final Configuration conf, final FileSystem fs,
       final Path dstFamilyPath, final TableName linkedTable, final String linkedRegion,
       final String hfileName) throws IOException {
     String familyName = dstFamilyPath.getName();
@@ -425,7 +463,7 @@ public class HFileLink extends FileLink {
     Path tablePath = regionPath.getParent();
 
     String linkName = createHFileLinkName(FSUtils.getTableName(tablePath),
-        regionPath.getName(), hfileName);
+            regionPath.getName(), hfileName);
     Path linkTableDir = FSUtils.getTableDir(rootDir, linkTableName);
     Path regionDir = HRegion.getRegionDir(linkTableDir, linkRegionName);
     return new Path(new Path(regionDir, familyPath.getName()), linkName);
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/io/Reference.java hbase-server/src/main/java/org/apache/hadoop/hbase/io/Reference.java
index 2b736d7..87bc754 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/io/Reference.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/io/Reference.java
@@ -23,6 +23,7 @@ import java.io.DataInput;
 import java.io.DataInputStream;
 import java.io.IOException;
 import java.io.InputStream;
+import java.util.Arrays;
 
 import org.apache.hadoop.hbase.util.ByteStringer;
 import org.apache.hadoop.classification.InterfaceAudience;
@@ -96,9 +97,11 @@ public class Reference {
 
   /**
    * Used by serializations.
+   * @deprecated need by pb serialization
    */
   @Deprecated
-  // Make this private when it comes time to let go of this constructor.  Needed by pb serialization.
+  // Make this private when it comes time to let go of this constructor.
+  // Needed by pb serialization.
   public Reference() {
     this(null, Range.bottom);
   }
@@ -213,4 +216,22 @@ public class Reference {
   byte [] toByteArray() throws IOException {
     return ProtobufUtil.prependPBMagic(convert().toByteArray());
   }
+
+  @Override
+  public int hashCode() {
+    return Arrays.hashCode(splitkey) + region.hashCode();
+  }
+
+  public boolean equals(Object o) {
+    if (this == o) return true;
+    if (o == null) return false;
+    if (!(o instanceof Reference)) return false;
+
+    Reference r = (Reference) o;
+    if (splitkey != null && r.splitkey == null) return false;
+    if (splitkey == null && r.splitkey != null) return false;
+    if (splitkey != null && !Arrays.equals(splitkey, r.splitkey)) return false;
+
+    return region.equals(r.region);
+  }
 }
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/mob/CachedMobFile.java hbase-server/src/main/java/org/apache/hadoop/hbase/mob/CachedMobFile.java
index 457eb6c..ecedf32 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/mob/CachedMobFile.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/mob/CachedMobFile.java
@@ -28,6 +28,7 @@ import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.io.hfile.CacheConfig;
 import org.apache.hadoop.hbase.regionserver.BloomType;
 import org.apache.hadoop.hbase.regionserver.StoreFile;
+import org.apache.hadoop.hbase.regionserver.StoreFileInfo;
 
 /**
  * Cached mob file.
@@ -48,6 +49,12 @@ public class CachedMobFile extends MobFile implements Comparable<CachedMobFile>
     return new CachedMobFile(sf);
   }
 
+  public static CachedMobFile create(FileSystem fs, StoreFileInfo sfi, Configuration conf,
+                               CacheConfig cacheConf) throws IOException {
+    StoreFile sf = new StoreFile(fs, sfi, conf, cacheConf, BloomType.NONE);
+    return new CachedMobFile(sf);
+  }
+
   public void access(long accessCount) {
     this.accessCount = accessCount;
   }
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFile.java hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFile.java
index a120057..8058795 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFile.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFile.java
@@ -30,6 +30,7 @@ import org.apache.hadoop.hbase.Cell;
 import org.apache.hadoop.hbase.io.hfile.CacheConfig;
 import org.apache.hadoop.hbase.regionserver.BloomType;
 import org.apache.hadoop.hbase.regionserver.StoreFile;
+import org.apache.hadoop.hbase.regionserver.StoreFileInfo;
 import org.apache.hadoop.hbase.regionserver.StoreFileScanner;
 
 /**
@@ -123,6 +124,10 @@ public class MobFile {
     }
   }
 
+  public StoreFileInfo getStoreFileInfo() {
+    return sf.getFileInfo();
+  }
+
   /**
    * Creates an instance of the MobFile.
    * @param fs The file system.
@@ -137,4 +142,10 @@ public class MobFile {
     StoreFile sf = new StoreFile(fs, path, conf, cacheConf, BloomType.NONE);
     return new MobFile(sf);
   }
+
+  public static MobFile create(FileSystem fs, StoreFileInfo sfi, Configuration conf,
+                               CacheConfig cacheConf) throws IOException {
+    StoreFile sf = new StoreFile(fs, sfi, conf, cacheConf, BloomType.NONE);
+    return new MobFile(sf);
+  }
 }
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileCache.java hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileCache.java
index cd08a98..9fafae6 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileCache.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobFileCache.java
@@ -35,7 +35,7 @@ import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.regionserver.StoreFileInfo;
 import org.apache.hadoop.hbase.util.IdLock;
 
 import com.google.common.util.concurrent.ThreadFactoryBuilder;
@@ -72,7 +72,7 @@ public class MobFileCache {
   }
 
   // a ConcurrentHashMap, accesses to this map are synchronized.
-  private Map<String, CachedMobFile> map = null;
+  private Map<StoreFileInfo, CachedMobFile> map = null;
   // caches access count
   private final AtomicLong count = new AtomicLong(0);
   private long lastAccess = 0;
@@ -102,7 +102,7 @@ public class MobFileCache {
     this.mobFileMaxCacheSize = conf.getInt(MobConstants.MOB_FILE_CACHE_SIZE_KEY,
         MobConstants.DEFAULT_MOB_FILE_CACHE_SIZE);
     isCacheEnabled = (mobFileMaxCacheSize > 0);
-    map = new ConcurrentHashMap<String, CachedMobFile>(mobFileMaxCacheSize);
+    map = new ConcurrentHashMap<StoreFileInfo, CachedMobFile>(mobFileMaxCacheSize);
     if (isCacheEnabled) {
       long period = conf.getLong(MobConstants.MOB_CACHE_EVICT_PERIOD,
           MobConstants.DEFAULT_MOB_CACHE_EVICT_PERIOD); // in seconds
@@ -142,8 +142,8 @@ public class MobFileCache {
         int start = (int) (mobFileMaxCacheSize * evictRemainRatio);
         if (start >= 0) {
           for (int i = start; i < files.size(); i++) {
-            String name = files.get(i).getFileName();
-            CachedMobFile evictedFile = map.remove(name);
+            CachedMobFile mobFile = files.get(i);
+            CachedMobFile evictedFile = map.remove(mobFile.getStoreFileInfo());
             if (evictedFile != null) {
               evictedFiles.add(evictedFile);
             }
@@ -161,23 +161,24 @@ public class MobFileCache {
     }
   }
 
+
   /**
    * Evicts the cached file by the name.
-   * @param fileName The name of a cached file.
+   * @param sfi cached StoreFileInfo entry
    */
-  public void evictFile(String fileName) {
+  public void evictFile(StoreFileInfo sfi) {
     if (isCacheEnabled) {
       IdLock.Entry lockEntry = null;
       try {
         // obtains the lock to close the cached file.
-        lockEntry = keyLock.getLockEntry(fileName.hashCode());
-        CachedMobFile evictedFile = map.remove(fileName);
+        lockEntry = keyLock.getLockEntry(sfi.hashCode());
+        CachedMobFile evictedFile = map.remove(sfi);
         if (evictedFile != null) {
           evictedFile.close();
           evictedFileCount.incrementAndGet();
         }
       } catch (IOException e) {
-        LOG.error("Fail to evict the file " + fileName, e);
+        LOG.error("Fail to evict the file " + sfi, e);
       } finally {
         if (lockEntry != null) {
           keyLock.releaseLockEntry(lockEntry);
@@ -189,28 +190,27 @@ public class MobFileCache {
   /**
    * Opens a mob file.
    * @param fs The current file system.
-   * @param path The file path.
+   * @param sfi StoreFileInfo. can contain HFileLinks or references..
    * @param cacheConf The current MobCacheConfig
    * @return A opened mob file.
    * @throws IOException
    */
-  public MobFile openFile(FileSystem fs, Path path, MobCacheConfig cacheConf) throws IOException {
+  public MobFile openFile(FileSystem fs, StoreFileInfo sfi, MobCacheConfig cacheConf) throws IOException {
     if (!isCacheEnabled) {
-      return MobFile.create(fs, path, conf, cacheConf);
+      return MobFile.create(fs, sfi, conf, cacheConf);
     } else {
-      String fileName = path.getName();
-      CachedMobFile cached = map.get(fileName);
-      IdLock.Entry lockEntry = keyLock.getLockEntry(fileName.hashCode());
+      CachedMobFile cached = map.get(sfi);
+      IdLock.Entry lockEntry = keyLock.getLockEntry(sfi.hashCode());
       try {
         if (cached == null) {
-          cached = map.get(fileName);
+          cached = map.get(sfi);
           if (cached == null) {
             if (map.size() > mobFileMaxCacheSize) {
               evict();
             }
-            cached = CachedMobFile.create(fs, path, conf, cacheConf);
+            cached = CachedMobFile.create(fs, sfi, conf, cacheConf);
             cached.open();
-            map.put(fileName, cached);
+            map.put(sfi, cached);
             miss.incrementAndGet();
           }
         }
@@ -233,7 +233,7 @@ public class MobFileCache {
       if (!isCacheEnabled) {
         file.close();
       } else {
-        lockEntry = keyLock.getLockEntry(file.getFileName().hashCode());
+        lockEntry = keyLock.getLockEntry(file.getStoreFileInfo().hashCode());
         file.close();
       }
     } catch (IOException e) {
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
index d0bb3ec..009ae6d 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/mob/MobUtils.java
@@ -244,7 +244,7 @@ public class MobUtils {
         if (!HFileLink.isHFileLink(file.getPath())) {
           mobFileName = MobFileName.create(fileName);
         } else {
-          HFileLink hfileLink = new HFileLink(conf, file.getPath());
+          HFileLink hfileLink = HFileLink.buildFromHFileLinkPattern(conf, file.getPath());
           mobFileName = MobFileName.create(hfileLink.getOriginPath().getName());
         }
         Date fileDate = parseDate(mobFileName.getDate());
@@ -463,7 +463,7 @@ public class MobUtils {
    * Commits the mob file.
    * @param @param conf The current configuration.
    * @param fs The current file system.
-   * @param path The path where the mob file is saved.
+   * @param sourceFile The path where the mob file is saved.
    * @param targetPath The directory path where the source file is renamed to.
    * @param cacheConfig The current cache config.
    * @throws IOException
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HMobStore.java hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HMobStore.java
index 569ad06..f8fb82d 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HMobStore.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HMobStore.java
@@ -28,6 +28,7 @@ import java.util.UUID;
 
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.Cell;
@@ -41,6 +42,7 @@ import org.apache.hadoop.hbase.Tag;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.filter.Filter;
 import org.apache.hadoop.hbase.filter.FilterList;
+import org.apache.hadoop.hbase.io.HFileLink;
 import org.apache.hadoop.hbase.io.compress.Compression;
 import org.apache.hadoop.hbase.io.hfile.CacheConfig;
 import org.apache.hadoop.hbase.io.hfile.HFile;
@@ -55,6 +57,7 @@ import org.apache.hadoop.hbase.mob.MobUtils;
 import org.apache.hadoop.hbase.mob.MobZookeeper;
 import org.apache.hadoop.hbase.regionserver.compactions.CompactionContext;
 import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.HFileArchiveUtil;
 import org.apache.zookeeper.KeeperException;
 
@@ -265,11 +268,7 @@ public class HMobStore extends HStore {
   public Cell resolve(Cell reference, boolean cacheBlocks) throws IOException {
     Cell result = null;
     if (MobUtils.hasValidMobRefCellValue(reference)) {
-      String fileName = MobUtils.getMobFileName(reference);
-      result = readCell(mobDirLocations, fileName, reference, cacheBlocks);
-      if (result == null) {
-        result = readClonedCell(fileName, reference, cacheBlocks);
-      }
+      result = readMobValue(reference, cacheBlocks);
     }
     if (result == null) {
       LOG.warn("The KeyValue result is null, assemble a new KeyValue with the same row,family,"
@@ -285,77 +284,60 @@ public class HMobStore extends HStore {
     return result;
   }
 
-  /**
-   * Reads the cell from a mob file.
-   * The mob file might be located in different directories.
-   * 1. The working directory.
-   * 2. The archive directory.
-   * Reads the cell from the files located in both of the above directories.
-   * @param locations The possible locations where the mob files are saved.
-   * @param fileName The file to be read.
-   * @param search The cell to be searched.
-   * @param cacheMobBlocks Whether the scanner should cache blocks.
-   * @return The found cell. Null if there's no such a cell.
-   * @throws IOException
-   */
-  private Cell readCell(List<Path> locations, String fileName, Cell search, boolean cacheMobBlocks)
-      throws IOException {
+  Cell readMobValue(Cell reference, boolean cacheMobBlocks) throws IOException {
     FileSystem fs = getFileSystem();
-    for (Path location : locations) {
-      MobFile file = null;
-      Path path = new Path(location, fileName);
-      try {
-        file = mobCacheConfig.getMobFileCache().openFile(fs, path, mobCacheConfig);
-        return file.readCell(search, cacheMobBlocks);
-      } catch (IOException e) {
-        mobCacheConfig.getMobFileCache().evictFile(fileName);
-        if (e instanceof FileNotFoundException) {
-          LOG.warn("Fail to read the cell, the mob file " + path + " doesn't exist", e);
-        } else {
-          throw e;
-        }
-      } finally {
-        if (file != null) {
-          mobCacheConfig.getMobFileCache().closeFile(file);
-        }
-      }
-    }
-    LOG.error("The mob file " + fileName + " could not be found in the locations "
-        + mobDirLocations);
-    return null;
-  }
 
-  /**
-   * Reads the cell from a mob file of source table.
-   * The table might be cloned, in this case only hfile link is created in the new table,
-   * and the mob file is located in the source table directories.
-   * 1. The working directory of the source table.
-   * 2. The archive directory of the source table.
-   * Reads the cell from the files located in both of the above directories.
-   * @param fileName The file to be read.
-   * @param search The cell to be searched.
-   * @param cacheMobBlocks Whether the scanner should cache blocks.
-   * @return The found cell. Null if there's no such a cell.
-   * @throws IOException
-   */
-  private Cell readClonedCell(String fileName, Cell search, boolean cacheMobBlocks)
-      throws IOException {
-    Tag tableNameTag = MobUtils.getTableNameTag(search);
+    String mobFileName = MobUtils.getMobFileName(reference);
+    LOG.debug("mobFileName from cell is " + mobFileName);
+
+    // Mobs for current table
+    Path mobPath = new Path(mobFamilyPath, mobFileName);
+    Path rootDir =  FSUtils.getRootDir(conf);
+
+    // Locations of mob files froma snapshotted table
+    Path archivePath, origTablePath;
+
+    // Get Region dir for snapshot sources
+    Tag tableNameTag = MobUtils.getTableNameTag(reference);
     if (tableNameTag == null) {
-      return null;
+      // TODO this is an unhandled error case currently.
+      origTablePath = null;
+      archivePath = null;
+    } else {
+      Path origTableDir, relativeOrigTablePath;
+
+      TableName origTableName = TableName.valueOf(tableNameTag.getValue());
+      origTableDir = HFileArchiveUtil.getStoreArchivePath(conf, origTableName,
+              MobUtils.getMobRegionInfo(origTableName).getEncodedName(), family.getNameAsString());
+      relativeOrigTablePath = HFileLink.getRelativeTablePath(new Path(origTableDir, mobFileName));
+
+      // Get mob from original table's archive mob dir
+      archivePath = new Path(HFileArchiveUtil.getArchivePath(conf), relativeOrigTablePath);
+
+      // Get mob from original table's mob dir
+      Path mobDir = new Path(rootDir, MobConstants.MOB_DIR_NAME);
+      origTablePath = new Path(mobDir, relativeOrigTablePath);
     }
-    byte[] tableName = tableNameTag.getValue();
-    if (Bytes.equals(this.getTableName().getName(), tableName)) {
+
+    // get Mob from current tmp dir.  // TODO this is wrong.
+    Path tempPath = new Path(new Path(rootDir, HConstants.HBASE_TEMP_DIRECTORY), HFileLink.getRelativeTablePath(mobPath));
+
+    HFileLink link = new HFileLink(origTablePath, tempPath, archivePath, mobPath);
+    FileStatus status = null;
+    StoreFileInfo sfi = new StoreFileInfo(conf, fs, status, link);
+    MobFile mf = null;
+    try {
+      mf = mobCacheConfig.getMobFileCache().openFile(fs, sfi, mobCacheConfig);
+      return mf.readCell(reference, cacheMobBlocks);
+    } catch (IOException e) {
+      mobCacheConfig.getMobFileCache().evictFile(sfi);
+      LOG.error("The mob file " + link + " could not be found");
       return null;
+    } finally {
+      if (mf != null) {
+        mobCacheConfig.getMobFileCache().closeFile(mf);
+      }
     }
-    // the possible locations in the source table.
-    List<Path> locations = new ArrayList<Path>();
-    TableName tn = TableName.valueOf(tableName);
-    locations.add(MobUtils.getMobFamilyPath(conf, tn, family.getNameAsString()));
-    locations.add(HFileArchiveUtil.getStoreArchivePath(conf, tn, MobUtils.getMobRegionInfo(tn)
-        .getEncodedName(), family.getNameAsString()));
-    // read the cell from the source table.
-    return readCell(locations, fileName, search, cacheMobBlocks);
   }
 
   /**
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java
index 13ded58..e8f3930 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java
@@ -162,9 +162,6 @@ public class StoreFile {
    */
   private final BloomType cfBloomType;
 
-  // the last modification time stamp
-  private long modificationTimeStamp = 0L;
-
   /**
    * Constructor, loads a reader and it's indices, etc. May allocate a
    * substantial amount of ram depending on the underlying files (10-20MB?).
@@ -214,9 +211,17 @@ public class StoreFile {
           "cfBloomType=" + cfBloomType + " (disabled in config)");
       this.cfBloomType = BloomType.NONE;
     }
+  }
 
-    // cache the modification time stamp of this store file
-    this.modificationTimeStamp = fileInfo.getModificationTime();
+  /**
+   * Clone
+   * @param other The StoreFile to clone from
+   */
+  public StoreFile(final StoreFile other) {
+    this.fs = other.fs;
+    this.fileInfo = other.fileInfo;
+    this.cacheConf = other.cacheConf;
+    this.cfBloomType = other.cfBloomType;
   }
 
   /**
@@ -273,10 +278,15 @@ public class StoreFile {
     return this.sequenceid;
   }
 
-  public long getModificationTimeStamp() {
-    return modificationTimeStamp;
+  public long getModificationTimeStamp() throws IOException {
+    return (fileInfo == null) ? 0 : fileInfo.getModificationTime();
   }
 
+  /**
+   * Only used by the Striped Compaction Policy
+   * @param key
+   * @return value associated with the metadata key
+   */
   public byte[] getMetadataValue(byte[] key) {
     return metadataMap.get(key);
   }
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java
index 5034b1b..35c36b8 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java
@@ -43,7 +43,7 @@ import org.apache.hadoop.hbase.util.FSUtils;
  * Describe a StoreFile (hfile, reference, link)
  */
 @InterfaceAudience.Private
-public class StoreFileInfo implements Comparable<StoreFileInfo> {
+public class StoreFileInfo {
   public static final Log LOG = LogFactory.getLog(StoreFileInfo.class);
 
   /**
@@ -70,6 +70,9 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
   // Configuration
   private Configuration conf;
 
+  // FileSystem handle
+  private final FileSystem fs;
+
   // HDFS blocks distribution information
   private HDFSBlocksDistribution hdfsBlocksDistribution = null;
 
@@ -79,8 +82,7 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
   // If this storefile is a link to another, this is the link instance.
   private final HFileLink link;
 
-  // FileSystem information for the file.
-  private final FileStatus fileStatus;
+  private final Path initialPath;
 
   private RegionCoprocessorHost coprocessorHost;
 
@@ -88,41 +90,35 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
    * Create a Store File Info
    * @param conf the {@link Configuration} to use
    * @param fs The current file system to use.
-   * @param path The {@link Path} of the file
+   * @param initialPath The {@link Path} of the file
    */
-  public StoreFileInfo(final Configuration conf, final FileSystem fs, final Path path)
+  public StoreFileInfo(final Configuration conf, final FileSystem fs, final Path initialPath)
       throws IOException {
-    this(conf, fs, fs.getFileStatus(path));
-  }
+    assert fs != null;
+    assert initialPath != null;
+    assert conf != null;
 
-  /**
-   * Create a Store File Info
-   * @param conf the {@link Configuration} to use
-   * @param fs The current file system to use.
-   * @param fileStatus The {@link FileStatus} of the file
-   */
-  public StoreFileInfo(final Configuration conf, final FileSystem fs, final FileStatus fileStatus)
-      throws IOException {
+    this.fs = fs;
     this.conf = conf;
-    this.fileStatus = fileStatus;
-    Path p = fileStatus.getPath();
+    this.initialPath = initialPath;
+    Path p = initialPath;
     if (HFileLink.isHFileLink(p)) {
       // HFileLink
       this.reference = null;
-      this.link = new HFileLink(conf, p);
+      this.link = HFileLink.buildFromHFileLinkPattern(conf, p);
       if (LOG.isTraceEnabled()) LOG.trace(p + " is a link");
     } else if (isReference(p)) {
       this.reference = Reference.read(fs, p);
       Path referencePath = getReferredToFile(p);
       if (HFileLink.isHFileLink(referencePath)) {
         // HFileLink Reference
-        this.link = new HFileLink(conf, referencePath);
+        this.link = HFileLink.buildFromHFileLinkPattern(conf, referencePath);
       } else {
         // Reference
         this.link = null;
       }
       if (LOG.isTraceEnabled()) LOG.trace(p + " is a " + reference.getFileRegion() +
-        " reference to " + referencePath);
+              " reference to " + referencePath);
     } else if (isHFile(p)) {
       // HFile
       this.reference = null;
@@ -133,6 +129,17 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
   }
 
   /**
+   * Create a Store File Info
+   * @param conf the {@link Configuration} to use
+   * @param fs The current file system to use.
+   * @param fileStatus The {@link FileStatus} of the file
+   */
+  public StoreFileInfo(final Configuration conf, final FileSystem fs, final FileStatus fileStatus)
+      throws IOException {
+    this(conf, fs, fileStatus.getPath());
+  }
+
+  /**
    * Create a Store File Info from an HFileLink
    * @param conf the {@link Configuration} to use
    * @param fs The current file system to use.
@@ -141,8 +148,10 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
   public StoreFileInfo(final Configuration conf, final FileSystem fs, final FileStatus fileStatus,
       final HFileLink link)
       throws IOException {
+    this.fs = fs;
     this.conf = conf;
-    this.fileStatus = fileStatus;
+    // initialPath can be null only if we get a link.
+    this.initialPath = (fileStatus == null) ? null : fileStatus.getPath();
       // HFileLink
     this.reference = null;
     this.link = link;
@@ -159,8 +168,9 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
   public StoreFileInfo(final Configuration conf, final FileSystem fs, final FileStatus fileStatus,
       final Reference reference)
       throws IOException {
+    this.fs = fs;
     this.conf = conf;
-    this.fileStatus = fileStatus;
+    this.initialPath = fileStatus.getPath();
     this.reference = reference;
     this.link = null;
   }
@@ -223,7 +233,7 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
       status = fs.getFileStatus(referencePath);
     } else {
       in = new FSDataInputStreamWrapper(fs, this.getPath());
-      status = fileStatus;
+      status = fs.getFileStatus(initialPath);
     }
     long length = status.getLen();
     hdfsBlocksDistribution = computeHDFSBlocksDistribution(fs);
@@ -238,7 +248,7 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
         reader = new HalfStoreFileReader(fs, this.getPath(), in, length, cacheConf, reference,
           conf);
       } else {
-        reader = new StoreFile.Reader(fs, this.getPath(), in, length, cacheConf, conf);
+        reader = new StoreFile.Reader(fs, status.getPath(), in, length, cacheConf, conf);
       }
     }
     if (this.coprocessorHost != null) {
@@ -254,7 +264,7 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
   public HDFSBlocksDistribution computeHDFSBlocksDistribution(final FileSystem fs)
       throws IOException {
 
-    // guard agains the case where we get the FileStatus from link, but by the time we
+    // guard against the case where we get the FileStatus from link, but by the time we
     // call compute the file is moved again
     if (this.link != null) {
       FileNotFoundException exToThrow = null;
@@ -321,7 +331,7 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
         }
         throw exToThrow;
       } else {
-        status = this.fileStatus;
+        status = fs.getFileStatus(initialPath);
       }
     }
     return status;
@@ -329,17 +339,17 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
 
   /** @return The {@link Path} of the file */
   public Path getPath() {
-    return this.fileStatus.getPath();
+    return initialPath;
   }
 
   /** @return The {@link FileStatus} of the file */
-  public FileStatus getFileStatus() {
-    return this.fileStatus;
+  public FileStatus getFileStatus() throws IOException {
+    return getReferencedFileStatus(fs);
   }
 
   /** @return Get the modification time of the file. */
-  public long getModificationTime() {
-    return this.fileStatus.getModificationTime();
+  public long getModificationTime() throws IOException {
+    return getFileStatus().getModificationTime();
   }
 
   @Override
@@ -475,24 +485,35 @@ public class StoreFileInfo implements Comparable<StoreFileInfo> {
 
   @Override
   public boolean equals(Object that) {
-    if (that == null) {
-      return false;
-    }
+    if (this == that) return true;
+    if (that == null) return false;
 
-    if (that instanceof StoreFileInfo) {
-      return this.compareTo((StoreFileInfo)that) == 0;
-    }
+    if (!(that instanceof StoreFileInfo)) return false;
 
-    return false;
-  };
+    StoreFileInfo o = (StoreFileInfo)that;
+    if (initialPath != null && o.initialPath == null) return false;
+    if (initialPath == null && o.initialPath != null) return false;
+    if (initialPath != o.initialPath && initialPath != null
+            && !initialPath.equals(o.initialPath)) return false;
 
-  @Override
-  public int compareTo(StoreFileInfo o) {
-    return this.fileStatus.compareTo(o.fileStatus);
-  }
+    if (reference != null && o.reference == null) return false;
+    if (reference == null && o.reference != null) return false;
+    if (reference != o.reference && reference != null
+            && !reference.equals(o.reference)) return false;
+
+    if (link != null && o.link == null) return false;
+    if (link == null && o.link != null) return false;
+    if (link != o.link && link != null && !link.equals(o.link)) return false;
+
+    return true;
+  };
 
   @Override
   public int hashCode() {
-    return this.fileStatus.hashCode();
+    int hash = 17;
+    hash = hash * 31 + ((reference == null) ? 0 : reference.hashCode());
+    hash = hash * 31 + ((initialPath ==  null) ? 0 : initialPath.hashCode());
+    hash = hash * 31 + ((link == null) ? 0 : link.hashCode());
+    return  hash;
   }
 }
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java
index 0d7efe7..2e31242 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java
@@ -24,7 +24,6 @@ import java.io.DataInput;
 import java.io.DataOutput;
 import java.io.IOException;
 import java.io.InputStream;
-import java.net.URI;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
@@ -53,20 +52,16 @@ import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.io.FileLink;
 import org.apache.hadoop.hbase.io.HFileLink;
 import org.apache.hadoop.hbase.io.HLogLink;
-import org.apache.hadoop.hbase.io.hfile.HFile;
-import org.apache.hadoop.hbase.mapreduce.JobUtil;
 import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;
 import org.apache.hadoop.hbase.mob.MobUtils;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription;
 import org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos.SnapshotFileInfo;
 import org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos.SnapshotRegionManifest;
-import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
 import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.HFileArchiveUtil;
 import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.hadoop.io.NullWritable;
-import org.apache.hadoop.io.SequenceFile;
 import org.apache.hadoop.io.Writable;
 import org.apache.hadoop.mapreduce.Job;
 import org.apache.hadoop.mapreduce.JobContext;
@@ -75,7 +70,6 @@ import org.apache.hadoop.mapreduce.InputFormat;
 import org.apache.hadoop.mapreduce.InputSplit;
 import org.apache.hadoop.mapreduce.RecordReader;
 import org.apache.hadoop.mapreduce.TaskAttemptContext;
-import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
 import org.apache.hadoop.mapreduce.lib.output.NullOutputFormat;
 import org.apache.hadoop.mapreduce.security.TokenCache;
 import org.apache.hadoop.hbase.io.hadoopbackport.ThrottledInputStream;
@@ -390,14 +384,14 @@ public class ExportSnapshot extends Configured implements Tool {
      * if the file is not found.
      */
     private FSDataInputStream openSourceFile(Context context, final SnapshotFileInfo fileInfo)
-        throws IOException {
+            throws IOException {
       try {
         Configuration conf = context.getConfiguration();
         FileLink link = null;
         switch (fileInfo.getType()) {
           case HFILE:
             Path inputPath = new Path(fileInfo.getHfile());
-            link = getFileLink(inputPath, conf);
+            link = HFileLink.buildFromHFileLinkPattern(conf, inputPath);
             break;
           case WAL:
             String serverName = fileInfo.getWalServer();
@@ -423,7 +417,7 @@ public class ExportSnapshot extends Configured implements Tool {
         switch (fileInfo.getType()) {
           case HFILE:
             Path inputPath = new Path(fileInfo.getHfile());
-            link = getFileLink(inputPath, conf);
+            link = HFileLink.buildFromHFileLinkPattern(conf, inputPath);
             break;
           case WAL:
             link = new HLogLink(inputRoot, fileInfo.getWalServer(), fileInfo.getWalName());
@@ -442,16 +436,6 @@ public class ExportSnapshot extends Configured implements Tool {
       }
     }
 
-    private FileLink getFileLink(Path path, Configuration conf) throws IOException{
-      String regionName = HFileLink.getReferencedRegionName(path.getName());
-      TableName tableName = HFileLink.getReferencedTableName(path.getName());
-      if(MobUtils.getMobRegionInfo(tableName).getEncodedName().equals(regionName)) {
-        return new HFileLink(MobUtils.getQualifiedMobRootDir(conf),
-                HFileArchiveUtil.getArchivePath(conf), path);
-      }
-      return new HFileLink(inputRoot, inputArchive, path);
-    }
-
     private FileChecksum getFileChecksum(final FileSystem fs, final Path path) {
       try {
         return fs.getFileChecksum(path);
@@ -521,7 +505,7 @@ public class ExportSnapshot extends Configured implements Tool {
             if (storeFile.hasFileSize()) {
               size = storeFile.getFileSize();
             } else {
-              size = new HFileLink(conf, path).getFileStatus(fs).getLen();
+              size = HFileLink.buildFromHFileLinkPattern(conf, path).getFileStatus(fs).getLen();
             }
             files.add(new Pair<SnapshotFileInfo, Long>(fileInfo, size));
           }
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java
index 3173e15..4cdbc23 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java
@@ -754,7 +754,7 @@ public class RestoreSnapshotHelper {
     } else {
       InputStream in;
       if (linkPath != null) {
-        in = new HFileLink(conf, linkPath).open(fs);
+        in = HFileLink.buildFromHFileLinkPattern(conf, linkPath).open(fs);
       } else {
         linkPath = new Path(new Path(HRegion.getRegionDir(snapshotManifest.getSnapshotDir(),
                         regionInfo.getEncodedName()), familyDir.getName()), hfileName);
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java
index ae7afcc..f1a3c7f 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java
@@ -227,8 +227,8 @@ public final class SnapshotInfo extends Configured implements Tool {
      */
     FileInfo addStoreFile(final HRegionInfo region, final String family,
         final SnapshotRegionManifest.StoreFile storeFile) throws IOException {
-      HFileLink link = HFileLink.create(conf, snapshotTable, region.getEncodedName(),
-                                        family, storeFile.getName());
+      HFileLink link = HFileLink.build(conf, snapshotTable, region.getEncodedName(),
+              family, storeFile.getName());
       boolean isCorrupted = false;
       boolean inArchive = false;
       long size = -1;
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotReferenceUtil.java hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotReferenceUtil.java
index 2a599d3..2072aa6 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotReferenceUtil.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotReferenceUtil.java
@@ -44,7 +44,6 @@ import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescriptio
 import org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos.SnapshotRegionManifest;
 import org.apache.hadoop.hbase.regionserver.wal.HLogUtil;
 import org.apache.hadoop.hbase.regionserver.StoreFileInfo;
-import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.FSVisitor;
 import org.apache.hadoop.hbase.util.HFileArchiveUtil;
 
@@ -276,7 +275,7 @@ public final class SnapshotReferenceUtil {
       refPath = StoreFileInfo.getReferredToFile(refPath);
       String refRegion = refPath.getParent().getParent().getName();
       refPath = HFileLink.createPath(table, refRegion, family, refPath.getName());
-      if (!new HFileLink(conf, refPath).exists(fs)) {
+      if (!HFileLink.buildFromHFileLinkPattern(conf, refPath).exists(fs)) {
         throw new CorruptedSnapshotException("Missing parent hfile for: " + fileName +
           " path=" + refPath, snapshot);
       }
@@ -295,19 +294,11 @@ public final class SnapshotReferenceUtil {
       linkPath = new Path(family, fileName);
     } else {
       linkPath = new Path(family, HFileLink.createHFileLinkName(
-        table, regionInfo.getEncodedName(), fileName));
+              table, regionInfo.getEncodedName(), fileName));
     }
 
     // check if the linked file exists (in the archive, or in the table dir)
-    HFileLink link = null;
-    if (MobUtils.isMobRegionInfo(regionInfo)) {
-      // for mob region
-      link = new HFileLink(MobUtils.getQualifiedMobRootDir(conf),
-          HFileArchiveUtil.getArchivePath(conf), linkPath);
-    } else {
-      // not mob region
-      link = new HFileLink(conf, linkPath);
-    }
+    HFileLink link = HFileLink.buildFromHFileLinkPattern(conf, linkPath);
     try {
       FileStatus fstat = link.getFileStatus(fs);
       if (storeFile.hasFileSize() && storeFile.getFileSize() != fstat.getLen()) {
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/util/HFileV1Detector.java hbase-server/src/main/java/org/apache/hadoop/hbase/util/HFileV1Detector.java
index 51bd117..faced06 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/util/HFileV1Detector.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/util/HFileV1Detector.java
@@ -365,7 +365,7 @@ public class HFileV1Detector extends Configured implements Tool {
    * @throws IOException
    */
   public FileLink getFileLinkWithPreNSPath(Path storeFilePath) throws IOException {
-    HFileLink link = new HFileLink(getConf(), storeFilePath);
+    HFileLink link = HFileLink.buildFromHFileLinkPattern(getConf(), storeFilePath);
     List<Path> pathsToProcess = getPreNSPathsForHFileLink(link);
     pathsToProcess.addAll(Arrays.asList(link.getLocations()));
     return new FileLink(pathsToProcess);
@@ -383,7 +383,7 @@ public class HFileV1Detector extends Configured implements Tool {
 
   /**
    * Removes the prefix of defaultNamespace from the path.
-   * @param originPath
+   * @param originalPath
    */
   private String removeDefaultNSPath(Path originalPath) {
     String pathStr = originalPath.toString();
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/util/ServerRegionReplicaUtil.java hbase-server/src/main/java/org/apache/hadoop/hbase/util/ServerRegionReplicaUtil.java
index 199f45e..cf87219 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/util/ServerRegionReplicaUtil.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/util/ServerRegionReplicaUtil.java
@@ -110,9 +110,8 @@ public class ServerRegionReplicaUtil extends RegionReplicaUtil {
     }
 
     // else create a store file link. The link file does not exists on filesystem though.
-    HFileLink link = new HFileLink(conf,
-      HFileLink.createPath(regionInfoForFs.getTable(), regionInfoForFs.getEncodedName()
-        , familyName, status.getPath().getName()));
+    HFileLink link = HFileLink.build(conf, regionInfoForFs.getTable(),
+            regionInfoForFs.getEncodedName(), familyName, status.getPath().getName());
     return new StoreFileInfo(conf, fs, status, link);
   }
 
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobFileCache.java hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobFileCache.java
index 154327c..c5183f9 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobFileCache.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobFileCache.java
@@ -39,6 +39,7 @@ import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.regionserver.HMobStore;
 import org.apache.hadoop.hbase.regionserver.HRegion;
 import org.apache.hadoop.hbase.regionserver.StoreFile;
+import org.apache.hadoop.hbase.regionserver.StoreFileInfo;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.junit.Test;
 import org.junit.experimental.categories.Category;
@@ -53,12 +54,6 @@ public class TestMobFileCache extends TestCase {
   private MobFileCache mobFileCache;
   private Date currentDate = new Date();
   private final String TEST_CACHE_SIZE = "2";
-  private final int EXPECTED_CACHE_SIZE_ZERO = 0;
-  private final int EXPECTED_CACHE_SIZE_ONE = 1;
-  private final int EXPECTED_CACHE_SIZE_TWO = 2;
-  private final int EXPECTED_CACHE_SIZE_THREE = 3;
-  private final long EXPECTED_REFERENCE_ONE = 1;
-  private final long EXPECTED_REFERENCE_TWO = 2;
 
   private final String TABLE = "tableName";
   private final String FAMILY1 = "family1";
@@ -160,47 +155,51 @@ public class TestMobFileCache extends TestCase {
     Path file2Path = createMobStoreFile(FAMILY2);
     Path file3Path = createMobStoreFile(FAMILY3);
 
+    StoreFileInfo sfi1 = new StoreFileInfo(conf, fs, file1Path);
+    StoreFileInfo sfi2 = new StoreFileInfo(conf, fs, file2Path);
+    StoreFileInfo sfi3 = new StoreFileInfo(conf, fs, file3Path);
+
     // Before open one file by the MobFileCache
-    assertEquals(EXPECTED_CACHE_SIZE_ZERO, mobFileCache.getCacheSize());
+    assertEquals(0, mobFileCache.getCacheSize());
     // Open one file by the MobFileCache
     CachedMobFile cachedMobFile1 = (CachedMobFile) mobFileCache.openFile(
-        fs, file1Path, mobCacheConf);
-    assertEquals(EXPECTED_CACHE_SIZE_ONE, mobFileCache.getCacheSize());
+        fs, sfi1, mobCacheConf);
+    assertEquals(1, mobFileCache.getCacheSize());
     assertNotNull(cachedMobFile1);
-    assertEquals(EXPECTED_REFERENCE_TWO, cachedMobFile1.getReferenceCount());
+    assertEquals((long) 2, cachedMobFile1.getReferenceCount());
 
     // The evict is also managed by a schedule thread pool.
     // And its check period is set as 3600 seconds by default.
     // This evict should get the lock at the most time
     mobFileCache.evict();  // Cache not full, evict it
-    assertEquals(EXPECTED_CACHE_SIZE_ONE, mobFileCache.getCacheSize());
-    assertEquals(EXPECTED_REFERENCE_TWO, cachedMobFile1.getReferenceCount());
+    assertEquals(1, mobFileCache.getCacheSize());
+    assertEquals((long) 2, cachedMobFile1.getReferenceCount());
 
-    mobFileCache.evictFile(file1Path.getName());  // Evict one file
-    assertEquals(EXPECTED_CACHE_SIZE_ZERO, mobFileCache.getCacheSize());
-    assertEquals(EXPECTED_REFERENCE_ONE, cachedMobFile1.getReferenceCount());
+    mobFileCache.evictFile(sfi1);  // Evict one file
+    assertEquals(0, mobFileCache.getCacheSize());
+    assertEquals((long) 1, cachedMobFile1.getReferenceCount());
 
     cachedMobFile1.close();  // Close the cached mob file
 
     // Reopen three cached file
     cachedMobFile1 = (CachedMobFile) mobFileCache.openFile(
-        fs, file1Path, mobCacheConf);
-    assertEquals(EXPECTED_CACHE_SIZE_ONE, mobFileCache.getCacheSize());
+        fs, sfi1, mobCacheConf);
+    assertEquals(1, mobFileCache.getCacheSize());
     CachedMobFile cachedMobFile2 = (CachedMobFile) mobFileCache.openFile(
-        fs, file2Path, mobCacheConf);
-    assertEquals(EXPECTED_CACHE_SIZE_TWO, mobFileCache.getCacheSize());
+        fs, sfi2, mobCacheConf);
+    assertEquals(2, mobFileCache.getCacheSize());
     CachedMobFile cachedMobFile3 = (CachedMobFile) mobFileCache.openFile(
-        fs, file3Path, mobCacheConf);
+        fs, sfi3, mobCacheConf);
     // Before the evict
-    // Evict the cache, should clost the first file 1
-    assertEquals(EXPECTED_CACHE_SIZE_THREE, mobFileCache.getCacheSize());
-    assertEquals(EXPECTED_REFERENCE_TWO, cachedMobFile1.getReferenceCount());
-    assertEquals(EXPECTED_REFERENCE_TWO, cachedMobFile2.getReferenceCount());
-    assertEquals(EXPECTED_REFERENCE_TWO, cachedMobFile3.getReferenceCount());
+    // Evict the cache, should close the first file 1
+    assertEquals(3, mobFileCache.getCacheSize());
+    assertEquals((long) 2, cachedMobFile1.getReferenceCount());
+    assertEquals((long) 2, cachedMobFile2.getReferenceCount());
+    assertEquals((long) 2, cachedMobFile3.getReferenceCount());
     mobFileCache.evict();
-    assertEquals(EXPECTED_CACHE_SIZE_ONE, mobFileCache.getCacheSize());
-    assertEquals(EXPECTED_REFERENCE_ONE, cachedMobFile1.getReferenceCount());
-    assertEquals(EXPECTED_REFERENCE_ONE, cachedMobFile2.getReferenceCount());
-    assertEquals(EXPECTED_REFERENCE_TWO, cachedMobFile3.getReferenceCount());
+    assertEquals(1, mobFileCache.getCacheSize());
+    assertEquals((long) 1, cachedMobFile1.getReferenceCount());
+    assertEquals((long) 1, cachedMobFile2.getReferenceCount());
+    assertEquals((long) 2, cachedMobFile3.getReferenceCount());
   }
 }
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHMobStore.java hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHMobStore.java
index 30b74d4..7c19e70 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHMobStore.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHMobStore.java
@@ -173,10 +173,8 @@ public class TestHMobStore {
     int valueLength2 = key2.getValueLength();
     int valueLength3 = key3.getValueLength();
 
-    String targetPathName = MobUtils.formatDate(currentDate);
     byte[] referenceValue =
-            Bytes.toBytes(targetPathName + Path.SEPARATOR
-                + mobFilePath.getName());
+            Bytes.toBytes(mobFilePath.getName());
     byte[] newReferenceValue1 = Bytes.add(Bytes.toBytes(valueLength1), referenceValue);
     byte[] newReferenceValue2 = Bytes.add(Bytes.toBytes(valueLength2), referenceValue);
     byte[] newReferenceValue3 = Bytes.add(Bytes.toBytes(valueLength3), referenceValue);
@@ -428,8 +426,7 @@ public class TestHMobStore {
   public void testResolve() throws Exception {
     final Configuration conf = HBaseConfiguration.create();
     init(name.getMethodName(), conf, true);
-    String targetPathName = MobUtils.formatDate(currentDate);
-    Path targetPath = new Path(store.getPath(), targetPathName);
+    Path targetPath = store.getPath();
     store.commitFile(mobFilePath, targetPath);
     //resolve
     Cell resultCell1 = store.resolve(seekKey1, false);
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/SnapshotTestingUtils.java hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/SnapshotTestingUtils.java
index cbb7dd1..899a9fa 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/SnapshotTestingUtils.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/SnapshotTestingUtils.java
@@ -429,7 +429,7 @@ public class SnapshotTestingUtils {
             final SnapshotRegionManifest.StoreFile storeFile) throws IOException {
         String region = regionInfo.getEncodedName();
         String hfile = storeFile.getName();
-        HFileLink link = HFileLink.create(conf, table, region, family, hfile);
+        HFileLink link = HFileLink.build(conf, table, region, family, hfile);
         if (corruptedFiles.size() % 2 == 0) {
           fs.delete(link.getAvailablePath(fs), true);
           corruptedFiles.add(hfile);
