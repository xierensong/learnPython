From 25b8937456301aa13462c2edde106c4e2c4a62e1 Mon Sep 17 00:00:00 2001
From: Rahul Gidwani <churro@apache.org>
Date: Wed, 10 Jan 2018 16:16:24 -0800
Subject: [PATCH] HBASE-15321 - Ability to open a HRegion from hdfs snapshot.

---
 .../apache/hadoop/hbase/regionserver/HRegion.java  |  27 ++++-
 .../hbase/regionserver/HRegionFileSystem.java      |   4 +-
 .../regionserver/TestHdfsSnapshotHRegion.java      | 117 +++++++++++++++++++++
 3 files changed, 145 insertions(+), 3 deletions(-)
 create mode 100644 hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHdfsSnapshotHRegion.java

diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
index aa9fa0384c..e18c80e54b 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
@@ -20,7 +20,6 @@ package org.apache.hadoop.hbase.regionserver;
 import static org.apache.hadoop.hbase.HConstants.REPLICATION_SCOPE_LOCAL;
 import static org.apache.hadoop.hbase.regionserver.HStoreFile.MAJOR_COMPACTION_KEY;
 import static org.apache.hadoop.hbase.util.CollectionUtils.computeIfAbsent;
-
 import java.io.EOFException;
 import java.io.FileNotFoundException;
 import java.io.IOException;
@@ -89,6 +88,7 @@ import org.apache.hadoop.hbase.ExtendedCellBuilderFactory;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HConstants.OperationStatusCode;
 import org.apache.hadoop.hbase.HDFSBlocksDistribution;
+import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.KeyValueUtil;
 import org.apache.hadoop.hbase.NamespaceDescriptor;
@@ -7001,6 +7001,31 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
     return this;
   }
 
+  /**
+   * Open a Region on a read-only file-system (like hdfs snapshots)
+   * @param conf The Configuration object to use.
+   * @param fs Filesystem to use
+   * @param info Info for region to be opened.
+   * @param htd the table descriptor
+   * @return new HRegion
+   * @throws IOException e
+   */
+  public static HRegion openReadOnlyFileSystemHRegion(final Configuration conf, final FileSystem fs,
+      final Path tableDir, RegionInfo info, final TableDescriptor htd) throws IOException {
+    if (info == null) {
+      throw new NullPointerException("Passed region info is null");
+    }
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Opening region (readOnly filesystem): " + info);
+    }
+    if (info.getReplicaId() <= 0) {
+      info = new HRegionInfo((HRegionInfo) info, 1);
+    }
+    HRegion r = HRegion.newHRegion(tableDir, null, fs, conf, info, htd, null);
+    r.writestate.setReadOnly(true);
+    return r.openHRegion(null);
+  }
+
   public static void warmupHRegion(final RegionInfo info,
       final TableDescriptor htd, final WAL wal, final Configuration conf,
       final RegionServerServices rsServices,
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java
index 11833a5137..00dc0d017f 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java
@@ -27,7 +27,6 @@ import java.util.Collection;
 import java.util.List;
 import java.util.Optional;
 import java.util.UUID;
-
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FSDataInputStream;
 import org.apache.hadoop.fs.FSDataOutputStream;
@@ -51,6 +50,7 @@ import org.apache.hadoop.hbase.util.FSHDFSUtils;
 import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.hbase.util.ServerRegionReplicaUtil;
+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;
 import org.apache.yetus.audience.InterfaceAudience;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -76,7 +76,7 @@ public class HRegionFileSystem {
   public static final String REGION_SPLITS_DIR = ".splits";
 
   /** Temporary subdirectory of the region directory used for compaction output. */
-  private static final String REGION_TEMP_DIR = ".tmp";
+  @VisibleForTesting static final String REGION_TEMP_DIR = ".tmp";
 
   private final RegionInfo regionInfo;
   //regionInfo for interacting with FS (getting encodedName, etc)
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHdfsSnapshotHRegion.java hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHdfsSnapshotHRegion.java
new file mode 100644
index 0000000000..17e698f8c1
--- /dev/null
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHdfsSnapshotHRegion.java
@@ -0,0 +1,117 @@
+/**
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.regionserver;
+
+import java.io.IOException;
+import org.apache.commons.lang.StringUtils;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.client.RegionInfo;
+import org.apache.hadoop.hbase.client.Table;
+import org.apache.hadoop.hbase.testclassification.MediumTests;
+import org.apache.hadoop.hbase.testclassification.RegionServerTests;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.FSUtils;
+import org.apache.hadoop.hdfs.DFSClient;
+import org.junit.After;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+
+@Category({RegionServerTests.class, MediumTests.class})
+public class TestHdfsSnapshotHRegion {
+
+  private static final HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
+  private static final String SNAPSHOT_NAME = "foo_snapshot";
+  private Table table;
+  public static final TableName TABLE_NAME = TableName.valueOf("foo");
+  public static final byte[] FAMILY = Bytes.toBytes("f1");
+  private DFSClient client;
+  private String baseDir;
+
+
+  @Before
+  public void setUp() throws Exception {
+    Configuration c = TEST_UTIL.getConfiguration();
+    c.setBoolean("dfs.support.append", true);
+    TEST_UTIL.startMiniCluster(1);
+    table = TEST_UTIL.createMultiRegionTable(TABLE_NAME, FAMILY);
+    TEST_UTIL.loadTable(table, FAMILY);
+
+    // setup the hdfssnapshots
+    client = new DFSClient(TEST_UTIL.getDFSCluster().getURI(), TEST_UTIL.getConfiguration());
+    String fullUrIPath = TEST_UTIL.getDefaultRootDirPath().toString();
+    String uriString = TEST_UTIL.getTestFileSystem().getUri().toString();
+    baseDir = StringUtils.removeStart(fullUrIPath, uriString);
+    client.allowSnapshot(baseDir);
+  }
+
+  @After
+  public void tearDown() throws Exception {
+    client.deleteSnapshot(baseDir, SNAPSHOT_NAME);
+    TEST_UTIL.shutdownMiniCluster();
+  }
+
+  @Test
+  public void testOpeningReadOnlyRegionBasic() throws Exception {
+    String snapshotDir = client.createSnapshot(baseDir, SNAPSHOT_NAME);
+    RegionInfo firstRegion = TEST_UTIL.getConnection().getRegionLocator(
+        table.getName()).getAllRegionLocations().stream().findFirst().get().getRegion();
+    Path tableDir = FSUtils.getTableDir(new Path(snapshotDir), TABLE_NAME);
+    HRegion snapshottedRegion = openSnapshotRegion(firstRegion, tableDir);
+    Assert.assertNotNull(snapshottedRegion);
+    snapshottedRegion.close();
+  }
+
+  @Test
+  public void testSnapshottingWithTmpSplitsAndMergeDirectoriesPresent() throws Exception {
+    // lets get a region and create those directories and make sure we ignore them
+    RegionInfo firstRegion = TEST_UTIL.getConnection().getRegionLocator(
+        table.getName()).getAllRegionLocations().stream().findFirst().get().getRegion();
+    String encodedName = firstRegion.getEncodedName();
+    Path tableDir = FSUtils.getTableDir(TEST_UTIL.getDefaultRootDirPath(), TABLE_NAME);
+    Path regionDirectoryPath = new Path(tableDir, encodedName);
+    TEST_UTIL.getTestFileSystem().create(
+        new Path(regionDirectoryPath, HRegionFileSystem.REGION_TEMP_DIR));
+    TEST_UTIL.getTestFileSystem().create(
+        new Path(regionDirectoryPath, HRegionFileSystem.REGION_SPLITS_DIR));
+    TEST_UTIL.getTestFileSystem().create(
+        new Path(regionDirectoryPath, HRegionFileSystem.REGION_MERGES_DIR));
+    // now snapshot
+    String snapshotDir = client.createSnapshot(baseDir, "foo_snapshot");
+    // everything should still open just fine
+    HRegion snapshottedRegion = openSnapshotRegion(firstRegion,
+        FSUtils.getTableDir(new Path(snapshotDir), TABLE_NAME));
+    Assert.assertNotNull(snapshottedRegion); // no errors and the region should open
+    snapshottedRegion.close();
+  }
+
+  private HRegion openSnapshotRegion(RegionInfo firstRegion, Path tableDir) throws IOException {
+    return HRegion.openReadOnlyFileSystemHRegion(
+        TEST_UTIL.getConfiguration(),
+        TEST_UTIL.getTestFileSystem(),
+        tableDir,
+        firstRegion,
+        table.getDescriptor()
+    );
+  }
+}
-- 
2.15.0

