Index: src/java/org/apache/hadoop/hbase/regionserver/HLog.java
===================================================================
--- src/java/org/apache/hadoop/hbase/regionserver/HLog.java	(revision 755244)
+++ src/java/org/apache/hadoop/hbase/regionserver/HLog.java	(working copy)
@@ -24,7 +24,11 @@
 import java.io.IOException;
 import java.io.UnsupportedEncodingException;
 import java.net.URLEncoder;
+import java.util.ArrayList;
 import java.util.Collections;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
 import java.util.Map;
 import java.util.SortedMap;
 import java.util.TreeMap;
@@ -726,115 +730,184 @@
   }
   
   /*
-   * @param rootDir
-   * @param logfiles
-   * @param fs
-   * @param conf
-   * @throws IOException
+   * @param rootDir @param logfiles @param fs @param conf @throws IOException
    */
-  private static void splitLog(final Path rootDir, final FileStatus [] logfiles,
-    final FileSystem fs, final Configuration conf)
-  throws IOException {
-    Map<byte [], SequenceFile.Writer> logWriters =
-      new TreeMap<byte [], SequenceFile.Writer>(Bytes.BYTES_COMPARATOR);
+  private static void splitLog(final Path rootDir, final FileStatus[] logfiles,
+      final FileSystem fs, final Configuration conf) throws IOException {
+
+    long millis = System.currentTimeMillis();
+    final Map<byte[], SequenceFile.Writer> logWriters = 
+      new TreeMap<byte[], SequenceFile.Writer>(Bytes.BYTES_COMPARATOR);
+
+    final Map<byte[], LinkedList<HLogEntry>> logEntries = 
+      new TreeMap<byte[], LinkedList<HLogEntry>>(Bytes.BYTES_COMPARATOR);
     try {
       for (int i = 0; i < logfiles.length; i++) {
         if (LOG.isDebugEnabled()) {
-          LOG.debug("Splitting " + (i + 1) + " of " + logfiles.length + ": " +
-            logfiles[i].getPath());
+          LOG.debug("Splitting " + (i + 1) + " of " + logfiles.length + ": "
+              + logfiles[i].getPath());
         }
         // Check for possibly empty file. With appends, currently Hadoop reports
-        // a zero length even if the file has been sync'd. Revisit if 
+        // a zero length even if the file has been sync'd. Revisit if
         // HADOOP-4751 is committed.
         boolean possiblyEmpty = logfiles[i].getLen() <= 0;
         HLogKey key = new HLogKey();
         HLogEdit val = new HLogEdit();
+        SequenceFile.Reader in = null;
+
         try {
-          SequenceFile.Reader in =
-            new SequenceFile.Reader(fs, logfiles[i].getPath(), conf);
+          in = new SequenceFile.Reader(fs, logfiles[i].getPath(), conf);
           try {
             int count = 0;
-            for (; in.next(key, val); count++) {
-              byte [] tableName = key.getTablename();
-              byte [] regionName = key.getRegionName();
-              SequenceFile.Writer w = logWriters.get(regionName);
-              if (w == null) {
-                Path logfile = new Path(
-                    HRegion.getRegionDir(
-                        HTableDescriptor.getTableDir(rootDir, tableName),
-                        HRegionInfo.encodeRegionName(regionName)),
-                        HREGION_OLDLOGFILE_NAME);
-                Path oldlogfile = null;
-                SequenceFile.Reader old = null;
-                if (fs.exists(logfile)) {
-                  LOG.warn("Old log file " + logfile +
-                  " already exists. Copying existing file to new file");
-                  oldlogfile = new Path(logfile.toString() + ".old");
-                  fs.rename(logfile, oldlogfile);
-                  old = new SequenceFile.Reader(fs, oldlogfile, conf);
-                }
-                w = SequenceFile.createWriter(fs, conf, logfile, HLogKey.class,
-                    HLogEdit.class, getCompressionType(conf));
-                // Use copy of regionName; regionName object is reused inside in
-                // HStoreKey.getRegionName so its content changes as we iterate.
-                logWriters.put(regionName, w);
-                if (LOG.isDebugEnabled()) {
-                  LOG.debug("Creating new log file writer for path " + logfile +
-                      " and region " + Bytes.toString(regionName));
-                }
-
-                if (old != null) {
-                  // Copy from existing log file
-                  HLogKey oldkey = new HLogKey();
-                  HLogEdit oldval = new HLogEdit();
-                  for (; old.next(oldkey, oldval); count++) {
-                    if (LOG.isDebugEnabled() && count > 0 && count % 10000 == 0) {
-                      LOG.debug("Copied " + count + " edits");
-                    }
-                    w.append(oldkey, oldval);
-                  }
-                  old.close();
-                  fs.delete(oldlogfile, true);
-                }
+            while (in.next(key, val)) {
+              byte[] regionName = key.getRegionName();
+              LinkedList<HLogEntry> queue = logEntries.get(regionName);
+              if (queue == null) {
+                queue = new LinkedList<HLogEntry>();
+                LOG.debug("Adding queue for " + Bytes.toString(regionName));
+                logEntries.put(regionName, queue);
               }
-              w.append(key, val);
+              queue.push(new HLogEntry(val, key));
+              count++;
             }
-            if (LOG.isDebugEnabled()) {
-              LOG.debug("Applied " + count + " total edits from " +
-                  logfiles[i].getPath().toString());
-            }
+            LOG.debug("Pushed " + count + " entries");
           } catch (IOException e) {
             e = RemoteExceptionHandler.checkIOException(e);
             if (!(e instanceof EOFException)) {
-              LOG.warn("Exception processing " + logfiles[i].getPath() +
-                  " -- continuing. Possible DATA LOSS!", e);
+              LOG.warn("Exception processing " + logfiles[i].getPath()
+                  + " -- continuing. Possible DATA LOSS!", e);
             }
-          } finally {
-            try {
-              in.close();
-            } catch (IOException e) {
-              LOG.warn("Close in finally threw exception -- continuing", e);
-            }
-            // Delete the input file now so we do not replay edits.  We could
-            // have gotten here because of an exception.  If so, probably
-            // nothing we can do about it. Replaying it, it could work but we
-            // could be stuck replaying for ever. Just continue though we
-            // could have lost some edits.
-            fs.delete(logfiles[i].getPath(), true);
           }
         } catch (IOException e) {
           if (possiblyEmpty) {
             continue;
           }
           throw e;
+        } finally {
+          try {
+            if (in != null) {
+              in.close();
+            }
+          } catch (IOException e) {
+            LOG.warn("Close in finally threw exception -- continuing", e);
+          }
+          // Delete the input file now so we do not replay edits. We could
+          // have gotten here because of an exception. If so, probably
+          // nothing we can do about it. Replaying it, it could work but we
+          // could be stuck replaying for ever. Just continue though we
+          // could have lost some edits.
+          fs.delete(logfiles[i].getPath(), true);
         }
       }
+
+      List<Thread> threads = new ArrayList<Thread>();
+      for (final byte[] key : logEntries.keySet()) {
+
+        Thread thread = new Thread() {
+          public void run() {
+            LinkedList<HLogEntry> entries = logEntries.get(key);
+            LOG.debug("Thread got " + entries.size() + " to process");
+            long threadTime = System.currentTimeMillis();
+            try {
+              int count = 0;
+              for (HLogEntry logEntry : entries) {
+                SequenceFile.Writer w = logWriters.get(key);
+                if (w == null) {
+                  Path logfile = new Path(HRegion.getRegionDir(HTableDescriptor
+                      .getTableDir(rootDir, logEntry.getKey().getTablename()),
+                      HRegionInfo.encodeRegionName(key)),
+                      HREGION_OLDLOGFILE_NAME);
+                  Path oldlogfile = null;
+                  SequenceFile.Reader old = null;
+                  if (fs.exists(logfile)) {
+                    LOG.warn("Old log file " + logfile
+                        + " already exists. Copying existing file to new file");
+                    oldlogfile = new Path(logfile.toString() + ".old");
+                    fs.rename(logfile, oldlogfile);
+                    old = new SequenceFile.Reader(fs, oldlogfile, conf);
+                  }
+                  w = SequenceFile.createWriter(fs, conf, logfile,
+                      HLogKey.class, HLogEdit.class, getCompressionType(conf));
+                  // Use copy of regionName; regionName object is reused inside
+                  // in
+                  // HStoreKey.getRegionName so its content changes as we
+                  // iterate.
+                  logWriters.put(key, w);
+                  if (LOG.isDebugEnabled()) {
+                    LOG.debug("Creating new log file writer for path "
+                        + logfile + " and region " + Bytes.toString(key));
+                  }
+
+                  if (old != null) {
+                    // Copy from existing log file
+                    HLogKey oldkey = new HLogKey();
+                    HLogEdit oldval = new HLogEdit();
+                    for (; old.next(oldkey, oldval); count++) {
+                      if (LOG.isDebugEnabled() && count > 0
+                          && count % 10000 == 0) {
+                        LOG.debug("Copied " + count + " edits");
+                      }
+                      w.append(oldkey, oldval);
+                    }
+                    old.close();
+                    fs.delete(oldlogfile, true);
+                  }
+                }
+                w.append(logEntry.getKey(), logEntry.getEdit());
+                count++;
+              }
+              if (LOG.isDebugEnabled()) {
+                LOG.debug("Applied " + count + " total edits to "
+                    + Bytes.toString(key) + " in "
+                    + (System.currentTimeMillis() - threadTime) + "ms");
+              }
+            } catch (IOException e) {
+              e = RemoteExceptionHandler.checkIOException(e);
+              LOG.warn("Got while writing region " + Bytes.toString(key)
+                  + " log " + e);
+              e.printStackTrace();
+            }
+          }
+        };
+        threads.add(thread);
+        thread.start();
+      }
+      // Wait for all threads to finish
+      for (Thread thread : threads) {
+        try {
+          thread.join();
+        } catch (InterruptedException e) {
+          e.printStackTrace();
+        }
+      }
+
+      long endMillis = System.currentTimeMillis();
+      LOG.info("Took " + (endMillis - millis) + "ms");
+
     } finally {
       for (SequenceFile.Writer w : logWriters.values()) {
         w.close();
       }
     }
   }
+  
+  public static class HLogEntry {
+    private HLogEdit edit;
+    private HLogKey key;
+    public HLogEntry(HLogEdit edit, HLogKey key) {
+      super();
+      this.edit = edit;
+      this.key = key;
+    }
+    public HLogEdit getEdit() {
+      return edit;
+    }
+    public HLogKey getKey() {
+      return key;
+    }
+    
+    
+  }
 
   /**
    * Construct the HLog directory name
