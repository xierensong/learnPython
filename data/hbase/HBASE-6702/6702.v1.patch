diff --git a/hbase-common/pom.xml b/hbase-common/pom.xml
index 9df84ef..c9f9b76 100644
--- a/hbase-common/pom.xml
+++ b/hbase-common/pom.xml
@@ -34,8 +34,16 @@
     <plugins>
       <plugin>
         <artifactId>maven-surefire-plugin</artifactId>
+        <configuration>
+          <properties>
+            <property>
+              <name>listener</name>
+              <value>org.apache.hadoop.hbase.ResourceCheckerJUnitListener</value>
+            </property>
+          </properties>
+        </configuration>
         <!-- Always skip the second part executions, since we only run
-        simple unit tests in this module -->
+  simple unit tests in this module -->
         <executions>
           <execution>
             <id>secondPartTestsExecution</id>
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/LargeTests.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/LargeTests.java
new file mode 100644
index 0000000..958ffd7
--- /dev/null
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/LargeTests.java
@@ -0,0 +1,38 @@
+/*
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase;
+
+/**
+ * Tag a test as 'large', meaning that the test class has the following
+ * characteristics:
+ *  - executed in an isolated JVM. Tests can however be executed in different
+ *    JVM on the same machine simultaneously.
+ *  - will not have to be executed by the developer before submitting a bug
+ *  - ideally, last less than 2 minutes to help parallelization
+ *
+ *  It the worst case compared to small or medium, use it only for tests that
+ *    you cannot put in the other categories
+ *
+ * @see SmallTests
+ * @see MediumTests
+ * @see IntegrationTests
+ */
+public interface LargeTests {
+}
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/MediumTests.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/MediumTests.java
new file mode 100644
index 0000000..a51a2c9
--- /dev/null
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/MediumTests.java
@@ -0,0 +1,37 @@
+/*
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase;
+
+/**
+ * Tag a test as 'Medium', meaning that the test class has the following
+ * characteristics:
+ *  - executed in an isolated JVM. Tests can however be executed in different
+ *    JVM on the same machine simultaneously.
+ *  - will have to be executed by the developer before submitting a bug
+ *  - ideally, last less than 1 minutes to help parallelization
+ *
+ *  Use it for tests that cannot be tagged as 'Small'.
+ *
+ * @see SmallTests
+ * @see LargeTests
+ * @see IntegrationTests
+ */
+public interface MediumTests {
+}
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ResourceChecker.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ResourceChecker.java
new file mode 100644
index 0000000..a639f90
--- /dev/null
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ResourceChecker.java
@@ -0,0 +1,174 @@
+/*
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+
+import java.util.*;
+
+
+/**
+ * Utility class to check the resources:
+ *  - log them before and after each test method
+ *  - check them against a minimum or maximum
+ *  - check that they don't leak during the test
+ */
+public class ResourceChecker {
+  private static final Log LOG = LogFactory.getLog(ResourceChecker.class);
+  private String tagLine;
+
+  public ResourceChecker(String tagLine) {
+    this.tagLine = tagLine;
+  }
+
+
+  /**
+   * Class to implement for each type of resource.
+   */
+  abstract static class ResourceAnalyzer {
+    /**
+     * Maximum we set for the resource. Will get a warning in logs
+     * if we go other this limit.
+     */
+    public int getMax() {
+      return Integer.MAX_VALUE;
+    }
+
+    public int getMin() {
+      return Integer.MIN_VALUE;
+    }
+
+    public String getName() {
+      String className = this.getClass().getSimpleName();
+      final String extName = ResourceAnalyzer.class.getSimpleName();
+      if (className.endsWith(extName)) {
+        return className.substring(0, className.length() - extName.length());
+      } else {
+        return className;
+      }
+    }
+
+    abstract public int getVal();
+  }
+
+
+  private List<ResourceAnalyzer> ras = new ArrayList<ResourceAnalyzer>();
+  private int[] initialValues;
+  private int[] endingValues;
+
+
+  private void fillInit() {
+    initialValues = new int[ras.size()];
+    fill(initialValues);
+  }
+
+  private void fillEndings() {
+    endingValues = new int[ras.size()];
+    fill(endingValues);
+  }
+
+  private void fill(int[] vals) {
+    int i = 0;
+    for (ResourceAnalyzer ra : ras) {
+      vals[i++] = ra.getVal();
+    }
+  }
+
+  public void checkInit() {
+    check(initialValues);
+  }
+
+  private void checkEndings() {
+    check(endingValues);
+  }
+
+  private void check(int[] vals) {
+    int i = 0;
+    for (ResourceAnalyzer ra : ras) {
+      int cur = vals[i++];
+      if (cur < ra.getMin()) {
+        LOG.warn(ra.getName() + "=" + cur + " is inferior to " + ra.getMin());
+      }
+      if (cur > ra.getMax()) {
+        LOG.warn(ra.getName() + "=" + cur + " is superior to " + ra.getMax());
+      }
+    }
+  }
+
+  private void logInit() {
+    int i = 0;
+    StringBuilder sb = new StringBuilder();
+    for (ResourceAnalyzer ra : ras) {
+      int cur = initialValues[i++];
+      if (sb.length() > 0) sb.append(", ");
+      sb.append(ra.getName()).append("=").append(cur);
+    }
+    LOG.info("before: " + tagLine + " " + sb);
+  }
+
+  private void logEndings() {
+    assert initialValues.length == ras.size();
+    assert endingValues.length == ras.size();
+
+    int i = 0;
+    StringBuilder sb = new StringBuilder();
+    for (ResourceAnalyzer ra : ras) {
+      int curP = initialValues[i];
+      int curN = endingValues[i++];
+      if (sb.length() > 0) sb.append(", ");
+      sb.append(ra.getName()).append("=").append(curN).append(" was (").append(curP).append(")");
+      if (curN > curP) {
+        sb.append(" - ").append(ra.getName()).append(" LEAK? -");
+      }
+    }
+    LOG.info("after: " + tagLine + " " + sb);
+  }
+
+
+  public void start() {
+    if (ras.size() == 0) {
+      LOG.info("No resource analyzer");
+      return;
+    }
+    fillInit();
+    logInit();
+    checkInit();
+  }
+
+  public void end() {
+    if (ras.size() == 0) {
+      LOG.info("No resource analyzer");
+      return;
+    }
+    if (initialValues == null) {
+      LOG.warn("No initial values");
+      return;
+    }
+
+    fillEndings();
+    logEndings();
+    checkEndings();
+  }
+
+  public void addResourceAnalyzer(ResourceAnalyzer ra) {
+    ras.add(ra);
+  }
+}
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ResourceCheckerJUnitListener.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ResourceCheckerJUnitListener.java
new file mode 100644
index 0000000..ff0053e
--- /dev/null
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ResourceCheckerJUnitListener.java
@@ -0,0 +1,125 @@
+package org.apache.hadoop.hbase;
+
+
+import com.sun.management.UnixOperatingSystemMXBean;
+import org.junit.runner.notification.RunListener;
+
+import java.lang.management.ManagementFactory;
+import java.lang.management.OperatingSystemMXBean;
+import java.util.HashMap;
+import java.util.Map;
+
+public class ResourceCheckerJUnitListener extends RunListener {
+  private Map<String, ResourceChecker> rcs = new HashMap<String, ResourceChecker>();
+
+  static class ThreadResourceAnalyzer extends ResourceChecker.ResourceAnalyzer {
+    public int getVal() {
+      return Thread.getAllStackTraces().size();
+    }
+
+    public int getMax() {
+      return 500;
+    }
+  }
+
+  /**
+   * On unix, we know how to get the number of open file descriptor
+   */
+  abstract static class OSResourceAnalyzer extends ResourceChecker.ResourceAnalyzer {
+    protected static final OperatingSystemMXBean osStats;
+    protected static final UnixOperatingSystemMXBean unixOsStats;
+
+    static {
+      osStats =
+          ManagementFactory.getOperatingSystemMXBean();
+      if (osStats instanceof UnixOperatingSystemMXBean) {
+        unixOsStats = (UnixOperatingSystemMXBean) osStats;
+      } else {
+        unixOsStats = null;
+      }
+    }
+  }
+
+  static class OpenFileDescriptorResourceAnalyzer extends OSResourceAnalyzer {
+    @Override
+    public int getVal() {
+      if (unixOsStats == null) {
+        return 0;
+      } else {
+        return (int) unixOsStats.getOpenFileDescriptorCount();
+      }
+    }
+
+    public int getMax() {
+      return 1024;
+    }
+  }
+
+  static class MaxFileDescriptorResourceAnalyzer extends OSResourceAnalyzer {
+    @Override
+    public int getVal() {
+      if (unixOsStats == null) {
+        return 0;
+      } else {
+        return (int) unixOsStats.getMaxFileDescriptorCount();
+      }
+    }
+  }
+
+
+  public ResourceCheckerJUnitListener() {
+  }
+
+  protected void addResourceAnalyzer(ResourceChecker rc) {
+  }
+
+  /**
+   * To be called before the test methods
+   *
+   * @param testName
+   */
+  private void start(String testName) {
+    ResourceChecker rc = new ResourceChecker(testName);
+    rc.addResourceAnalyzer(new ThreadResourceAnalyzer());
+    rc.addResourceAnalyzer(new OpenFileDescriptorResourceAnalyzer());
+    rc.addResourceAnalyzer(new MaxFileDescriptorResourceAnalyzer());
+
+    addResourceAnalyzer(rc);
+
+    rcs.put(testName, rc);
+
+    rc.start();
+  }
+
+  /**
+   * To be called after the test methods
+   *
+   * @param testName
+   */
+  private void end(String testName) {
+    ResourceChecker rc = rcs.remove(testName);
+    assert rc != null;
+    rc.end();
+  }
+
+  /**
+   * Get the test name from the JUnit Description
+   *
+   * @return the string for the short test name
+   */
+  private String descriptionToShortTestName(
+      org.junit.runner.Description description) {
+    final int toRemove = "org.apache.hadoop.hbase.".length();
+    return description.getTestClass().getName().substring(toRemove) +
+        "#" + description.getMethodName();
+  }
+
+  public void testStarted(org.junit.runner.Description description) throws java.lang.Exception {
+    start(descriptionToShortTestName(description));
+  }
+
+  public void testFinished(org.junit.runner.Description description) throws java.lang.Exception {
+    end(descriptionToShortTestName(description));
+  }
+}
+
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/SmallTests.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/SmallTests.java
new file mode 100644
index 0000000..6953667
--- /dev/null
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/SmallTests.java
@@ -0,0 +1,34 @@
+/*
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase;
+
+/**
+ * Tag a test as 'small', meaning that the test class has the following
+ * characteristics:
+ *  - can be run simultaneously with other small tests in the same JVM
+ *  - ideally, last less than 15 seconds
+ *  - does not use a cluster
+ *
+ * @see MediumTests
+ * @see LargeTests
+ * @see IntegrationTests
+ */
+public interface SmallTests {
+}
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestBytes.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestBytes.java
index da4a566..612cceb 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestBytes.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestBytes.java
@@ -26,7 +26,11 @@ import java.math.BigDecimal;
 import java.util.Arrays;
 
 import junit.framework.TestCase;
+import org.junit.experimental.categories.Category;
+import org.apache.hadoop.hbase.SmallTests;
 
+
+@Category(SmallTests.class)
 public class TestBytes extends TestCase {
   public void testNullHashCode() {
     byte [] b = null;
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestLoadTestKVGenerator.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestLoadTestKVGenerator.java
index 8bfed1f..98c1049 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestLoadTestKVGenerator.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestLoadTestKVGenerator.java
@@ -25,7 +25,11 @@ import java.util.Set;
 
 import org.apache.hadoop.hbase.util.test.LoadTestKVGenerator;
 import org.junit.Test;
+import org.junit.experimental.categories.Category;
 
+import org.apache.hadoop.hbase.SmallTests;
+
+@Category(SmallTests.class)
 public class TestLoadTestKVGenerator {
 
   private static final int MIN_LEN = 10;
diff --git a/hbase-server/pom.xml b/hbase-server/pom.xml
index c30125f..2f142d4 100644
--- a/hbase-server/pom.xml
+++ b/hbase-server/pom.xml
@@ -194,6 +194,14 @@
       <!-- Testing plugins -->
       <plugin>
         <artifactId>maven-surefire-plugin</artifactId>
+        <configuration>
+          <properties>
+            <property>
+              <name>listener</name>
+              <value>org.apache.hadoop.hbase.ServerResourceCheckerJUnitListener</value>
+            </property>
+          </properties>
+        </configuration>
       </plugin>
     </plugins>
     <!-- General Resources -->
@@ -264,6 +272,13 @@
     </dependency>
     <dependency>
       <groupId>org.apache.hbase</groupId>
+      <artifactId>hbase-common</artifactId>
+      <version>${project.version}</version>
+      <type>test-jar</type>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.apache.hbase</groupId>
       <artifactId>hbase-hadoop-compat</artifactId>
     </dependency>
     <dependency>
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/LargeTests.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/LargeTests.java
deleted file mode 100644
index 958ffd7..0000000
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/LargeTests.java
+++ /dev/null
@@ -1,38 +0,0 @@
-/*
- *
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.hbase;
-
-/**
- * Tag a test as 'large', meaning that the test class has the following
- * characteristics:
- *  - executed in an isolated JVM. Tests can however be executed in different
- *    JVM on the same machine simultaneously.
- *  - will not have to be executed by the developer before submitting a bug
- *  - ideally, last less than 2 minutes to help parallelization
- *
- *  It the worst case compared to small or medium, use it only for tests that
- *    you cannot put in the other categories
- *
- * @see SmallTests
- * @see MediumTests
- * @see IntegrationTests
- */
-public interface LargeTests {
-}
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/MediumTests.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/MediumTests.java
deleted file mode 100644
index a51a2c9..0000000
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/MediumTests.java
+++ /dev/null
@@ -1,37 +0,0 @@
-/*
- *
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.hbase;
-
-/**
- * Tag a test as 'Medium', meaning that the test class has the following
- * characteristics:
- *  - executed in an isolated JVM. Tests can however be executed in different
- *    JVM on the same machine simultaneously.
- *  - will have to be executed by the developer before submitting a bug
- *  - ideally, last less than 1 minutes to help parallelization
- *
- *  Use it for tests that cannot be tagged as 'Small'.
- *
- * @see SmallTests
- * @see LargeTests
- * @see IntegrationTests
- */
-public interface MediumTests {
-}
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ResourceChecker.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ResourceChecker.java
deleted file mode 100644
index 506d744..0000000
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ResourceChecker.java
+++ /dev/null
@@ -1,194 +0,0 @@
-/*
- *
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.hbase;
-
-import com.sun.management.UnixOperatingSystemMXBean;
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
-import org.apache.hadoop.hbase.client.HConnectionTestingUtility;
-
-import java.lang.management.ManagementFactory;
-import java.lang.management.OperatingSystemMXBean;
-import java.util.*;
-
-
-/**
- * Check the resources used:
- * - threads
- * - file descriptor
- */
-public class ResourceChecker {
-  private static final Log LOG = LogFactory.getLog(ResourceChecker.class);
-
-  /**
-   * On unix, we know how to get the number of open file descriptor
-   */
-  private static class ResourceAnalyzer {
-    private static final OperatingSystemMXBean osStats;
-    private static final UnixOperatingSystemMXBean unixOsStats;
-
-    public long getThreadsCount() {
-      return Thread.getAllStackTraces().size();
-    }
-
-    public long getOpenFileDescriptorCount() {
-      if (unixOsStats == null) {
-        return 0;
-      } else {
-        return unixOsStats.getOpenFileDescriptorCount();
-      }
-    }
-
-    public long getMaxFileDescriptorCount() {
-      if (unixOsStats == null) {
-        return 0;
-      } else {
-        return unixOsStats.getMaxFileDescriptorCount();
-      }
-    }
-
-    public long getConnectionCount(){
-      return HConnectionTestingUtility.getConnectionCount();
-    }
-
-    static {
-      osStats =
-        ManagementFactory.getOperatingSystemMXBean();
-      if (osStats instanceof UnixOperatingSystemMXBean) {
-        unixOsStats = (UnixOperatingSystemMXBean) osStats;
-      } else {
-        unixOsStats = null;
-      }
-    }
-  }
-
-  private static final ResourceAnalyzer rc = new ResourceAnalyzer();
-
-  /**
-   * Maximum we set for the thread. Will get a warning in logs
-   * if we go other this limit
-   */
-  private static final long MAX_THREADS_COUNT = 500;
-
-  /**
-   * Maximum we set for the thread. Will get a warning in logs
-   * if we go other this limit
-   */
-  private static final long MAX_FILE_HANDLES_COUNT = 1024;
-
-
-  private long initialThreadsCount;
-  private long initialFileHandlesCount;
-  private long initialConnectionCount;
-
-
-  public boolean checkThreads(String tagLine) {
-    boolean isOk = true;
-
-    if (rc.getThreadsCount() > MAX_THREADS_COUNT) {
-      LOG.error(
-        tagLine + ": too many threads used. We use " +
-          rc.getThreadsCount() + " our max is " + MAX_THREADS_COUNT);
-      isOk = false;
-    }
-
-    return isOk;
-  }
-
-  public boolean check(String tagLine) {
-
-    boolean isOk = checkThreads(tagLine);
-    if (!checkFileHandles(tagLine)) isOk = false;
-
-    return isOk;
-  }
-
-  public ResourceChecker(String tagLine) {
-    init(tagLine);
-  }
-
-  public final void init(String tagLine) {
-    if (rc.getMaxFileDescriptorCount() < MAX_FILE_HANDLES_COUNT) {
-      LOG.error(
-        "Bad configuration: the operating systems file handles maximum is " +
-          rc.getMaxFileDescriptorCount() + " our is " + MAX_FILE_HANDLES_COUNT);
-    }
-
-    logInfo(tagLine);
-
-    initialThreadsCount = rc.getThreadsCount();
-    initialFileHandlesCount = rc.getOpenFileDescriptorCount();
-    initialConnectionCount= rc.getConnectionCount();
-
-    check(tagLine);
-  }
-
-  public void logInfo(String tagLine) {
-    LOG.info(
-      tagLine + ": " +
-        rc.getThreadsCount() + " threads" +
-        (initialThreadsCount > 0 ?
-          " (was " + initialThreadsCount + "), " : ", ") +
-        rc.getOpenFileDescriptorCount() + " file descriptors" +
-        (initialFileHandlesCount > 0 ?
-          " (was " + initialFileHandlesCount + "). " : " ") +
-        rc.getConnectionCount() + " connections" +
-        (initialConnectionCount > 0 ?
-          " (was " + initialConnectionCount + "), " : ", ") +
-        (initialThreadsCount > 0 && rc.getThreadsCount() > initialThreadsCount ?
-          " -thread leak?- " : "") +
-        (initialFileHandlesCount > 0 &&
-          rc.getOpenFileDescriptorCount() > initialFileHandlesCount ?
-          " -file handle leak?- " : "") +
-        (initialConnectionCount > 0 &&
-          rc.getConnectionCount() > initialConnectionCount ?
-          " -connection leak?- " : "" )
-    );
-  }
-
-
-  public boolean checkFileHandles(String tagLine) {
-    boolean isOk = true;
-
-    if (rc.getOpenFileDescriptorCount() > MAX_FILE_HANDLES_COUNT) {
-      LOG.error(
-        tagLine + ": too many file handles used. We use " +
-          rc.getOpenFileDescriptorCount() + " our max is " +
-          MAX_FILE_HANDLES_COUNT);
-      isOk = false;
-    }
-
-    return isOk;
-  }
-
-  /**
-   * Helper function: print the threads
-   */
-  public static void printThreads(){
-    Set<Thread> threads = Thread.getAllStackTraces().keySet();
-    System.out.println("name; state; isDameon; isAlive; isInterrupted");
-    for (Thread t: threads){
-      System.out.println(
-        t.getName()+";"+t.getState()+";"+t.isDaemon()+";"+t.isAlive()+
-          ";"+t.isInterrupted()
-      );
-    }
-  }
-}
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ResourceCheckerJUnitRule.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ResourceCheckerJUnitRule.java
index ff94272..ba155e1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ResourceCheckerJUnitRule.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ResourceCheckerJUnitRule.java
@@ -47,8 +47,6 @@ public class ResourceCheckerJUnitRule extends org.junit.rules.TestWatcher {
   private void end(String testName) {
     if (!endDone) {
       endDone = true;
-      cu.logInfo("after " + testName);
-      cu.check("after "+testName);
     }
   }
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ServerResourceCheckerJUnitListener.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ServerResourceCheckerJUnitListener.java
new file mode 100644
index 0000000..a514970
--- /dev/null
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ServerResourceCheckerJUnitListener.java
@@ -0,0 +1,38 @@
+/*
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase;
+
+import org.apache.hadoop.hbase.client.HConnectionTestingUtility;
+
+
+public class ServerResourceCheckerJUnitListener extends ResourceCheckerJUnitListener {
+
+
+  static class ConnectionCountResourceAnalyzer extends ResourceChecker.ResourceAnalyzer {
+    @Override
+    public int getVal() {
+      return HConnectionTestingUtility.getConnectionCount();
+    }
+  }
+
+  protected void addResourceAnalyzer(ResourceChecker rc) {
+    rc.addResourceAnalyzer(new ConnectionCountResourceAnalyzer());
+  }
+}
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/SmallTests.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/SmallTests.java
deleted file mode 100644
index 6953667..0000000
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/SmallTests.java
+++ /dev/null
@@ -1,34 +0,0 @@
-/*
- *
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.hbase;
-
-/**
- * Tag a test as 'small', meaning that the test class has the following
- * characteristics:
- *  - can be run simultaneously with other small tests in the same JVM
- *  - ideally, last less than 15 seconds
- *  - does not use a cluster
- *
- * @see MediumTests
- * @see LargeTests
- * @see IntegrationTests
- */
-public interface SmallTests {
-}
