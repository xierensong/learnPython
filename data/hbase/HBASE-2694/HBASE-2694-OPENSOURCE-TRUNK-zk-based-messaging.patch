Index: src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
===================================================================
--- src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java	(revision 952845)
+++ src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java	(working copy)
@@ -697,7 +697,8 @@
   }
 
   public void expireSession(ZooKeeperWrapper nodeZK) throws Exception{
-    ZooKeeperWrapper zkw = new ZooKeeperWrapper(conf, EmptyWatcher.instance);
+    ZooKeeperWrapper zkw = ZooKeeperWrapper.createInstance(conf, ZooKeeperWrapper.class.getName());
+    zkw.registerListener(EmptyWatcher.instance);
     String quorumServers = zkw.getQuorumServers();
     int sessionTimeout = 5 * 1000; // 5 seconds
 
Index: src/test/java/org/apache/hadoop/hbase/TestZKBasedReopenRegion.java
===================================================================
--- src/test/java/org/apache/hadoop/hbase/TestZKBasedReopenRegion.java	(revision 0)
+++ src/test/java/org/apache/hadoop/hbase/TestZKBasedReopenRegion.java	(revision 0)
@@ -0,0 +1,244 @@
+package org.apache.hadoop.hbase;
+
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.Put;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.ResultScanner;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.executor.TestZKUnassignedWatcher.EventsListener;
+import org.apache.hadoop.hbase.master.HMaster;
+import org.apache.hadoop.hbase.master.ProcessRegionClose;
+import org.apache.hadoop.hbase.master.ProcessRegionOpen;
+import org.apache.hadoop.hbase.master.RegionServerOperation;
+import org.apache.hadoop.hbase.master.RegionServerOperationListener;
+import org.apache.hadoop.hbase.regionserver.HRegion;
+import org.apache.hadoop.hbase.regionserver.HRegionServer;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Threads;
+import org.apache.hadoop.hbase.util.Writables;
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+public class TestZKBasedReopenRegion {
+  private static final Log LOG = LogFactory.getLog(TestZKBasedReopenRegion.class);
+  private static final HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
+  private static final String TABLENAME = "master_transitions";
+  private static final byte [][] FAMILIES = new byte [][] {Bytes.toBytes("a"),
+    Bytes.toBytes("b"), Bytes.toBytes("c")};
+
+  @BeforeClass public static void beforeAllTests() throws Exception {
+    Configuration c = TEST_UTIL.getConfiguration();
+    c.setBoolean("dfs.support.append", true);
+    c.setInt("hbase.regionserver.info.port", 0);
+    c.setInt("hbase.master.meta.thread.rescanfrequency", 5*1000);
+    TEST_UTIL.startMiniCluster(2);
+    TEST_UTIL.createTable(Bytes.toBytes(TABLENAME), FAMILIES);
+    HTable t = new HTable(TEST_UTIL.getConfiguration(), TABLENAME);
+    int countOfRegions = TEST_UTIL.createMultiRegions(t, getTestFamily());
+    waitUntilAllRegionsAssigned(countOfRegions);
+    addToEachStartKey(countOfRegions);
+  }
+
+  @AfterClass public static void afterAllTests() throws IOException {
+    TEST_UTIL.shutdownMiniCluster();
+  }
+
+  @Before public void setup() throws IOException {
+    if (TEST_UTIL.getHBaseCluster().getLiveRegionServerThreads().size() < 2) {
+      // Need at least two servers.
+      LOG.info("Started new server=" +
+        TEST_UTIL.getHBaseCluster().startRegionServer());
+      
+    }
+  }
+
+  @Test (timeout=300000) public void testOpenRegion()
+  throws Exception {
+    MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
+    LOG.info("Number of region servers = " + cluster.getLiveRegionServerThreads().size());
+
+    int rsIdx = 0;
+    HRegionServer regionServer = TEST_UTIL.getHBaseCluster().getRegionServer(rsIdx);
+    Collection<HRegion> regions = regionServer.getOnlineRegions();
+    HRegion region = regions.iterator().next();
+    LOG.debug("Asking RS to close region " + region.getRegionNameAsString());
+
+    AtomicBoolean closeEventProcessed = new AtomicBoolean(false);
+    AtomicBoolean reopenEventProcessed = new AtomicBoolean(false);
+    RegionServerOperationListener listener = 
+      new ReopenRegionEventListener(region.getRegionNameAsString(), 
+                                    closeEventProcessed,
+                                    reopenEventProcessed);
+    HMaster master = TEST_UTIL.getHBaseCluster().getMaster();
+    master.getRegionServerOperationQueue().registerRegionServerOperationListener(listener);
+    HMsg closeRegionMsg = new HMsg(HMsg.Type.MSG_REGION_CLOSE, 
+                                   region.getRegionInfo(),
+                                   Bytes.toBytes("Forcing close in test")
+                                  );
+    TEST_UTIL.getHBaseCluster().addMessageToSendRegionServer(rsIdx, closeRegionMsg);
+    
+    synchronized(closeEventProcessed) {
+      closeEventProcessed.wait(3*60*1000);
+    }
+    if(!closeEventProcessed.get()) {
+      throw new Exception("Timed out, close event not called on master.");
+    }
+
+    synchronized(reopenEventProcessed) {
+      reopenEventProcessed.wait(3*60*1000);
+    }
+    if(!reopenEventProcessed.get()) {
+      throw new Exception("Timed out, open event not called on master after region close.");
+    }    
+    
+    LOG.info("Done with test, RS informed master successfully.");
+  }
+  
+  public static class ReopenRegionEventListener implements RegionServerOperationListener {
+    
+    private static final Log LOG = LogFactory.getLog(EventsListener.class);
+    String regionToClose;
+    AtomicBoolean closeEventProcessed;
+    AtomicBoolean reopenEventProcessed;
+
+    public ReopenRegionEventListener(String regionToClose, 
+                                     AtomicBoolean closeEventProcessed,
+                                     AtomicBoolean reopenEventProcessed) {
+      this.regionToClose = regionToClose;
+      this.closeEventProcessed = closeEventProcessed;
+      this.reopenEventProcessed = reopenEventProcessed;
+    }
+
+    @Override
+    public boolean process(HServerInfo serverInfo, HMsg incomingMsg) {
+      return true;
+    }
+
+    @Override
+    public boolean process(RegionServerOperation op) throws IOException {
+      return true;
+    }
+
+    @Override
+    public void processed(RegionServerOperation op) {
+      LOG.debug("Master processing object: " + op.getClass().getCanonicalName());
+      if(op instanceof ProcessRegionClose) {
+        ProcessRegionClose regionCloseOp = (ProcessRegionClose)op;
+        String region = regionCloseOp.getRegionInfo().getRegionNameAsString();
+        LOG.debug("Finished closing region " + region + ", expected to close region " + regionToClose);
+        if(regionToClose.equals(region)) {
+          closeEventProcessed.set(true);
+        }
+        synchronized(closeEventProcessed) {
+          closeEventProcessed.notifyAll();
+        }
+      }
+      // Wait for open event AFTER we have closed the region
+      if(closeEventProcessed.get()) {
+        if(op instanceof ProcessRegionOpen) {
+          ProcessRegionOpen regionOpenOp = (ProcessRegionOpen)op;
+          String region = regionOpenOp.getRegionInfo().getRegionNameAsString();
+          LOG.debug("Finished closing region " + region + ", expected to close region " + regionToClose);
+          if(regionToClose.equals(region)) {
+            reopenEventProcessed.set(true);
+          }
+          synchronized(reopenEventProcessed) {
+            reopenEventProcessed.notifyAll();
+          }
+        }        
+      }
+      
+    }
+    
+  }
+  
+
+  private static void waitUntilAllRegionsAssigned(final int countOfRegions)
+  throws IOException {
+    HTable meta = new HTable(TEST_UTIL.getConfiguration(),
+      HConstants.META_TABLE_NAME);
+    while (true) {
+      int rows = 0;
+      Scan scan = new Scan();
+      scan.addColumn(HConstants.CATALOG_FAMILY, HConstants.SERVER_QUALIFIER);
+      ResultScanner s = meta.getScanner(scan);
+      for (Result r = null; (r = s.next()) != null;) {
+        byte [] b =
+          r.getValue(HConstants.CATALOG_FAMILY, HConstants.SERVER_QUALIFIER);
+        if (b == null || b.length <= 0) break;
+        rows++;
+      }
+      s.close();
+      // If I get to here and all rows have a Server, then all have been assigned.
+      if (rows == countOfRegions) break;
+      LOG.info("Found=" + rows);
+      Threads.sleep(1000); 
+    }
+  }
+
+  /*
+   * Add to each of the regions in .META. a value.  Key is the startrow of the
+   * region (except its 'aaa' for first region).  Actual value is the row name.
+   * @param expected
+   * @return
+   * @throws IOException
+   */
+  private static int addToEachStartKey(final int expected) throws IOException {
+    HTable t = new HTable(TEST_UTIL.getConfiguration(), TABLENAME);
+    HTable meta = new HTable(TEST_UTIL.getConfiguration(),
+        HConstants.META_TABLE_NAME);
+    int rows = 0;
+    Scan scan = new Scan();
+    scan.addColumn(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER);
+    ResultScanner s = meta.getScanner(scan);
+    for (Result r = null; (r = s.next()) != null;) {
+      byte [] b =
+        r.getValue(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER);
+      if (b == null || b.length <= 0) break;
+      HRegionInfo hri = Writables.getHRegionInfo(b);
+      // If start key, add 'aaa'.
+      byte [] row = getStartKey(hri);
+      Put p = new Put(row);
+      p.add(getTestFamily(), getTestQualifier(), row);
+      t.put(p);
+      rows++;
+    }
+    s.close();
+    Assert.assertEquals(expected, rows);
+    return rows;
+  }
+
+  private static byte [] getStartKey(final HRegionInfo hri) {
+    return Bytes.equals(HConstants.EMPTY_START_ROW, hri.getStartKey())?
+        Bytes.toBytes("aaa"): hri.getStartKey();
+  }
+
+  private static byte [] getTestFamily() {
+    return FAMILIES[0];
+  }
+
+  private static byte [] getTestQualifier() {
+    return getTestFamily();
+  }
+  
+  public static void main(String args[]) throws Exception {
+    TestZKBasedReopenRegion.beforeAllTests();
+    
+    TestZKBasedReopenRegion test = new TestZKBasedReopenRegion();
+    test.setup();
+    test.testOpenRegion();
+    
+    TestZKBasedReopenRegion.afterAllTests();
+  }
+}
\ No newline at end of file
Index: src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java
===================================================================
--- src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java	(revision 952845)
+++ src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java	(working copy)
@@ -96,7 +96,8 @@
       throws IOException, InterruptedException {
     new HTable(conf, HConstants.META_TABLE_NAME);
 
-    ZooKeeperWrapper zkw = new ZooKeeperWrapper(conf, EmptyWatcher.instance);
+    ZooKeeperWrapper zkw = ZooKeeperWrapper.createInstance(conf, TestZooKeeper.class.getName());
+    zkw.registerListener(EmptyWatcher.instance);
     String quorumServers = zkw.getQuorumServers();
     int sessionTimeout = 5 * 1000; // 5 seconds
     HConnection connection = HConnectionManager.getConnection(conf);
@@ -158,7 +159,7 @@
       HTable localMeta = new HTable(conf, HConstants.META_TABLE_NAME);
       Configuration otherConf = HBaseConfiguration.create(conf);
       otherConf.set(HConstants.ZOOKEEPER_QUORUM, "127.0.0.1");
-      HTable ipMeta = new HTable(conf, HConstants.META_TABLE_NAME);
+      HTable ipMeta = new HTable(otherConf, HConstants.META_TABLE_NAME);
 
       // dummy, just to open the connection
       localMeta.exists(new Get(HConstants.LAST_ROW));
@@ -184,7 +185,8 @@
    */
   @Test
   public void testZNodeDeletes() throws Exception {
-    ZooKeeperWrapper zkw = new ZooKeeperWrapper(conf, EmptyWatcher.instance);
+    ZooKeeperWrapper zkw = ZooKeeperWrapper.createInstance(conf, TestZooKeeper.class.getName());
+    zkw.registerListener(EmptyWatcher.instance);
     zkw.ensureExists("/l1/l2/l3/l4");
     try {
       zkw.deleteZNode("/l1/l2");
Index: src/test/java/org/apache/hadoop/hbase/TestZKBasedCloseRegion.java
===================================================================
--- src/test/java/org/apache/hadoop/hbase/TestZKBasedCloseRegion.java	(revision 0)
+++ src/test/java/org/apache/hadoop/hbase/TestZKBasedCloseRegion.java	(revision 0)
@@ -0,0 +1,217 @@
+package org.apache.hadoop.hbase;
+
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.Put;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.ResultScanner;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.executor.TestZKUnassignedWatcher.EventsListener;
+import org.apache.hadoop.hbase.master.HMaster;
+import org.apache.hadoop.hbase.master.ProcessRegionClose;
+import org.apache.hadoop.hbase.master.RegionServerOperation;
+import org.apache.hadoop.hbase.master.RegionServerOperationListener;
+import org.apache.hadoop.hbase.regionserver.HRegion;
+import org.apache.hadoop.hbase.regionserver.HRegionServer;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Threads;
+import org.apache.hadoop.hbase.util.Writables;
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+public class TestZKBasedCloseRegion {
+  private static final Log LOG = LogFactory.getLog(TestZKBasedCloseRegion.class);
+  private static final HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
+  private static final String TABLENAME = "master_transitions";
+  private static final byte [][] FAMILIES = new byte [][] {Bytes.toBytes("a"),
+    Bytes.toBytes("b"), Bytes.toBytes("c")};
+
+  @BeforeClass public static void beforeAllTests() throws Exception {
+    Configuration c = TEST_UTIL.getConfiguration();
+    c.setBoolean("dfs.support.append", true);
+    c.setInt("hbase.regionserver.info.port", 0);
+    c.setInt("hbase.master.meta.thread.rescanfrequency", 5*1000);
+    TEST_UTIL.startMiniCluster(2);
+    TEST_UTIL.createTable(Bytes.toBytes(TABLENAME), FAMILIES);
+    HTable t = new HTable(TEST_UTIL.getConfiguration(), TABLENAME);
+    int countOfRegions = TEST_UTIL.createMultiRegions(t, getTestFamily());
+    waitUntilAllRegionsAssigned(countOfRegions);
+    addToEachStartKey(countOfRegions);
+  }
+
+  @AfterClass public static void afterAllTests() throws IOException {
+    TEST_UTIL.shutdownMiniCluster();
+  }
+
+  @Before public void setup() throws IOException {
+    if (TEST_UTIL.getHBaseCluster().getLiveRegionServerThreads().size() < 2) {
+      // Need at least two servers.
+      LOG.info("Started new server=" +
+        TEST_UTIL.getHBaseCluster().startRegionServer());
+      
+    }
+  }
+
+  @Test (timeout=300000) public void testCloseRegion()
+  throws Exception {
+    LOG.info("Running testCloseRegion");
+    MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
+    LOG.info("Number of region servers = " + cluster.getLiveRegionServerThreads().size());
+
+    int rsIdx = 0;
+    HRegionServer regionServer = TEST_UTIL.getHBaseCluster().getRegionServer(rsIdx);
+    Collection<HRegion> regions = regionServer.getOnlineRegions();
+    HRegion region = regions.iterator().next();
+    LOG.debug("Asking RS to close region " + region.getRegionNameAsString());
+
+    AtomicBoolean closeEventProcessed = new AtomicBoolean(false);
+    RegionServerOperationListener listener = 
+      new CloseRegionEventListener(region.getRegionNameAsString(), closeEventProcessed);
+    HMaster master = TEST_UTIL.getHBaseCluster().getMaster();
+    master.getRegionServerOperationQueue().registerRegionServerOperationListener(listener);
+    HMsg closeRegionMsg = new HMsg(HMsg.Type.MSG_REGION_CLOSE, 
+                                   region.getRegionInfo(),
+                                   Bytes.toBytes("Forcing close in test")
+                                  );
+    TEST_UTIL.getHBaseCluster().addMessageToSendRegionServer(rsIdx, closeRegionMsg);
+    
+    synchronized(closeEventProcessed) {
+      // wait for 3 minutes
+      closeEventProcessed.wait(3*60*1000);
+    }
+    if(!closeEventProcessed.get()) {
+      throw new Exception("Timed out, close event not called on master.");
+    }
+    else {
+      LOG.info("Done with test, RS informed master successfully.");
+    }
+  }
+  
+  public static class CloseRegionEventListener implements RegionServerOperationListener {
+    
+    private static final Log LOG = LogFactory.getLog(EventsListener.class);
+    String regionToClose;
+    AtomicBoolean closeEventProcessed;
+
+    public CloseRegionEventListener(String regionToClose, AtomicBoolean closeEventProcessed) {
+      this.regionToClose = regionToClose;
+      this.closeEventProcessed = closeEventProcessed;
+    }
+
+    @Override
+    public boolean process(HServerInfo serverInfo, HMsg incomingMsg) {
+      return true;
+    }
+
+    @Override
+    public boolean process(RegionServerOperation op) throws IOException {
+      return true;
+    }
+
+    @Override
+    public void processed(RegionServerOperation op) {
+      LOG.debug("Master processing object: " + op.getClass().getCanonicalName());
+      if(op instanceof ProcessRegionClose) {
+        ProcessRegionClose regionCloseOp = (ProcessRegionClose)op;
+        String region = regionCloseOp.getRegionInfo().getRegionNameAsString();
+        LOG.debug("Finished closing region " + region + ", expected to close region " + regionToClose);
+        if(regionToClose.equals(region)) {
+          closeEventProcessed.set(true);
+        }
+        synchronized(closeEventProcessed) {
+          closeEventProcessed.notifyAll();
+        }
+      }
+    }
+    
+  }
+  
+
+  private static void waitUntilAllRegionsAssigned(final int countOfRegions)
+  throws IOException {
+    HTable meta = new HTable(TEST_UTIL.getConfiguration(),
+      HConstants.META_TABLE_NAME);
+    while (true) {
+      int rows = 0;
+      Scan scan = new Scan();
+      scan.addColumn(HConstants.CATALOG_FAMILY, HConstants.SERVER_QUALIFIER);
+      ResultScanner s = meta.getScanner(scan);
+      for (Result r = null; (r = s.next()) != null;) {
+        byte [] b =
+          r.getValue(HConstants.CATALOG_FAMILY, HConstants.SERVER_QUALIFIER);
+        if (b == null || b.length <= 0) break;
+        rows++;
+      }
+      s.close();
+      // If I get to here and all rows have a Server, then all have been assigned.
+      if (rows == countOfRegions) break;
+      LOG.info("Found=" + rows);
+      Threads.sleep(1000); 
+    }
+  }
+
+  /*
+   * Add to each of the regions in .META. a value.  Key is the startrow of the
+   * region (except its 'aaa' for first region).  Actual value is the row name.
+   * @param expected
+   * @return
+   * @throws IOException
+   */
+  private static int addToEachStartKey(final int expected) throws IOException {
+    HTable t = new HTable(TEST_UTIL.getConfiguration(), TABLENAME);
+    HTable meta = new HTable(TEST_UTIL.getConfiguration(),
+        HConstants.META_TABLE_NAME);
+    int rows = 0;
+    Scan scan = new Scan();
+    scan.addColumn(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER);
+    ResultScanner s = meta.getScanner(scan);
+    for (Result r = null; (r = s.next()) != null;) {
+      byte [] b =
+        r.getValue(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER);
+      if (b == null || b.length <= 0) break;
+      HRegionInfo hri = Writables.getHRegionInfo(b);
+      // If start key, add 'aaa'.
+      byte [] row = getStartKey(hri);
+      Put p = new Put(row);
+      p.add(getTestFamily(), getTestQualifier(), row);
+      t.put(p);
+      rows++;
+    }
+    s.close();
+    Assert.assertEquals(expected, rows);
+    return rows;
+  }
+
+  private static byte [] getStartKey(final HRegionInfo hri) {
+    return Bytes.equals(HConstants.EMPTY_START_ROW, hri.getStartKey())?
+        Bytes.toBytes("aaa"): hri.getStartKey();
+  }
+
+  private static byte [] getTestFamily() {
+    return FAMILIES[0];
+  }
+
+  private static byte [] getTestQualifier() {
+    return getTestFamily();
+  }
+  
+  public static void main(String args[]) throws Exception {
+    TestZKBasedCloseRegion.beforeAllTests();
+    
+    TestZKBasedCloseRegion test = new TestZKBasedCloseRegion();
+    test.setup();
+    test.testCloseRegion();
+    
+    TestZKBasedCloseRegion.afterAllTests();
+  }
+}
\ No newline at end of file
Index: src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWrapper.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWrapper.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWrapper.java	(working copy)
@@ -1,5 +1,5 @@
 /**
- * Copyright 2010 The Apache Software Foundation
+ * Copyright 2009 The Apache Software Foundation
  *
  * Licensed to the Apache Software Foundation (ASF) under one
  * or more contributor license agreements.  See the NOTICE file
@@ -19,151 +19,226 @@
  */
 package org.apache.hadoop.hbase.zookeeper;
 
+import java.io.BufferedReader;
+import java.io.ByteArrayOutputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.io.PrintWriter;
+import java.net.Socket;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Properties;
+import java.util.Set;
+import java.util.concurrent.locks.Lock;
+import java.util.concurrent.locks.ReentrantLock;
+
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HServerAddress;
 import org.apache.hadoop.hbase.HServerInfo;
+import org.apache.hadoop.hbase.executor.HBEventHandler.HBEventType;
 import org.apache.hadoop.hbase.util.Bytes;
-import org.apache.hadoop.util.StringUtils;
 import org.apache.zookeeper.CreateMode;
 import org.apache.zookeeper.KeeperException;
+import org.apache.zookeeper.WatchedEvent;
 import org.apache.zookeeper.Watcher;
+import org.apache.zookeeper.ZooKeeper;
 import org.apache.zookeeper.ZooDefs.Ids;
-import org.apache.zookeeper.ZooKeeper;
 import org.apache.zookeeper.ZooKeeper.States;
 import org.apache.zookeeper.data.Stat;
 
-import java.io.BufferedReader;
-import java.io.IOException;
-import java.io.InputStreamReader;
-import java.io.PrintWriter;
-import java.net.InetAddress;
-import java.net.Socket;
-import java.net.UnknownHostException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map.Entry;
-import java.util.Properties;
-
 /**
  * Wraps a ZooKeeper instance and adds HBase specific functionality.
  *
  * This class provides methods to:
  * - read/write/delete the root region location in ZooKeeper.
  * - set/check out of safe mode flag.
+ * 
+ * ------------------------------------------
+ * The following STATIC ZNodes are created:
+ * ------------------------------------------
+ * - parentZNode     : All the HBase directories are hosted under this parent 
+ *                     node, default = "/hbase"
+ * - rsZNode         : This is the directory where the RS's create ephemeral 
+ *                     nodes. The master watches these nodes, and their expiry 
+ *                     indicates RS death. The default location is "/hbase/rs"
+ * 
+ * ------------------------------------------
+ * The following DYNAMIC ZNodes are created:
+ * ------------------------------------------
+ * - rootRegionZNode     : Specifies the RS hosting root.
+ * - masterElectionZNode : ZNode used for election of the primary master when 
+ *                         there are secondaries. All the masters race to write 
+ *                         their addresses into this location, the one that 
+ *                         succeeds is the primary. Others block.
+ * - clusterStateZNode   : Determines if the cluster is running. Its default 
+ *                         location is "/hbase/shutdown". It always has a value 
+ *                         of "up". If present with the valus, cluster is up 
+ *                         and running. If deleted, the cluster is shutting 
+ *                         down.
+ * - rgnsInTransitZNode  : All the nodes under this node are names of regions 
+ *                         in transition. The first byte of the data for each 
+ *                         of these nodes is the event type. This is used to 
+ *                         deserialize the rest of the data.
  */
-public class ZooKeeperWrapper implements HConstants {
+public class ZooKeeperWrapper implements HConstants, Watcher {
   protected static final Log LOG = LogFactory.getLog(ZooKeeperWrapper.class);
 
+  // instances of the watcher
+  private static Map<String,ZooKeeperWrapper> instances_ = 
+    new HashMap<String,ZooKeeperWrapper>();
+  // lock for ensuring a singleton per instance type
+  private static Lock createLock_ = new ReentrantLock();
+  // name of this instance
+  private String instanceName;
+
   // TODO: Replace this with ZooKeeper constant when ZOOKEEPER-277 is resolved.
   private static final char ZNODE_PATH_SEPARATOR = '/';
 
   private String quorumServers = null;
+  private final int sessionTimeout;
+  private ZooKeeper zooKeeper;
 
-  private final ZooKeeper zooKeeper;
-
-  private final String parentZNode;
+  /*
+   * All the HBase directories are hosted under this parent
+   */
+  public final String parentZNode;
+  /*
+   * Specifies the RS hosting root
+   */
   private final String rootRegionZNode;
+  /* 
+   * This is the directory where the RS's create ephemeral nodes. The master 
+   * watches these nodes, and their expiry indicates RS death. 
+   */
   private final String rsZNode;
+  /*
+   * ZNode used for election of the primary master when there are secondaries. 
+   */
   private final String masterElectionZNode;
+  /*
+   * State of the cluster - if up and running or shutting down
+   */
   public final String clusterStateZNode;
+  /*
+   * Regions that are in transition
+   */  
+  private final String rgnsInTransitZNode;
+  /*
+   * List of ZNodes in the unassgined region that are already being watched
+   */
+  private Set<String> unassignedZNodesWatched = new HashSet<String>();
 
+  private List<Watcher> listeners_ = Collections.synchronizedList(new ArrayList<Watcher>());
+
+  // return the singleton given the name of the instance
+  public static ZooKeeperWrapper getInstance(String name) {
+    return instances_.get(name);
+  }
+  // creates only one instance
+  public static ZooKeeperWrapper createInstance(Configuration conf, String name) {
+    if (getInstance(name) != null) {
+      return getInstance(name);
+    }
+    ZooKeeperWrapper.createLock_.lock();
+    try {
+      if (getInstance(name) == null) {
+        try {
+          ZooKeeperWrapper instance = new ZooKeeperWrapper(conf, name);
+          instances_.put(name, instance);
+        }
+        catch (Exception e) {
+          LOG.error("<" + name + ">" + "Error creating a ZooKeeperWrapper " + e);
+        }
+      }
+    }
+    finally {
+      createLock_.unlock();
+    }
+    return getInstance(name);
+  }
+
   /**
-   * Create a ZooKeeperWrapper.
-   * @param conf Configuration to read settings from.
-   * @param watcher ZooKeeper watcher to register.
+   * Create a ZooKeeperWrapper. The Zookeeper wrapper listens to all messages
+   * from Zookeeper, and notifies all the listeners about all the messages. Any
+   * component can subscribe to these messages by adding itself as a listener,
+   * and remove itself from being a listener.
+   *
+   * @param conf HBaseConfiguration to read settings from.
    * @throws IOException If a connection error occurs.
    */
-  public ZooKeeperWrapper(Configuration conf, Watcher watcher)
+  private ZooKeeperWrapper(Configuration conf, String instanceName)
   throws IOException {
+    this.instanceName = instanceName;
     Properties properties = HQuorumPeer.makeZKProps(conf);
-    setQuorumServers(properties);
+    quorumServers = HQuorumPeer.getZKQuorumServersString(properties);
     if (quorumServers == null) {
-      throw new IOException("Could not read quorum servers from " +
-                            ZOOKEEPER_CONFIG_NAME);
+      throw new IOException("Could not read quorum servers from " + ZOOKEEPER_CONFIG_NAME);
     }
+    sessionTimeout = conf.getInt("zookeeper.session.timeout", 60 * 1000);
+    reconnectToZk();
+    
+    parentZNode = conf.get(ZOOKEEPER_ZNODE_PARENT, DEFAULT_ZOOKEEPER_ZNODE_PARENT);
 
-    int sessionTimeout = conf.getInt("zookeeper.session.timeout", 60 * 1000);
+    String rootServerZNodeName = conf.get("zookeeper.znode.rootserver", "root-region-server");
+    String rsZNodeName         = conf.get("zookeeper.znode.rs", "rs");
+    String masterAddressZNodeName = conf.get("zookeeper.znode.master", "master");
+    String stateZNodeName      = conf.get("zookeeper.znode.state", "shutdown");
+    String regionsInTransitZNodeName = conf.get("zookeeper.znode.regionInTransition", "UNASSIGNED");
+
+    rootRegionZNode     = getZNode(parentZNode, rootServerZNodeName);
+    rsZNode             = getZNode(parentZNode, rsZNodeName);
+    rgnsInTransitZNode  = getZNode(parentZNode, regionsInTransitZNodeName);
+    masterElectionZNode = getZNode(parentZNode, masterAddressZNodeName);
+    clusterStateZNode   = getZNode(parentZNode, stateZNodeName);
+  }
+  
+  public void reconnectToZk() throws IOException {
     try {
-      zooKeeper = new ZooKeeper(quorumServers, sessionTimeout, watcher);
+      LOG.info("Reconnecting to zookeeper");
+      if(zooKeeper != null) {
+        zooKeeper.close();
+        LOG.debug("<" + instanceName + ">" + "Closed existing zookeeper client");
+      }
+      zooKeeper = new ZooKeeper(quorumServers, sessionTimeout, this);
+      LOG.debug("<" + instanceName + ">" + "Connected to zookeeper again");
     } catch (IOException e) {
-      LOG.error("Failed to create ZooKeeper object: " + e);
+      LOG.error("<" + instanceName + ">" + "Failed to create ZooKeeper object: " + e);
       throw new IOException(e);
-    }
+    } catch (InterruptedException e) {
+      LOG.error("<" + instanceName + ">" + "Error closing ZK connection: " + e);
+      throw new IOException(e);
+    }    
+  }
 
-    parentZNode = conf.get(ZOOKEEPER_ZNODE_PARENT,
-        DEFAULT_ZOOKEEPER_ZNODE_PARENT);
+  public void registerListener(Watcher watcher) {
+    listeners_.add(watcher);
+  }
 
-    String rootServerZNodeName = conf.get("zookeeper.znode.rootserver",
-                                          "root-region-server");
-    String rsZNodeName = conf.get("zookeeper.znode.rs", "rs");
-    String masterAddressZNodeName = conf.get("zookeeper.znode.master",
-      "master");
-    String stateZNodeName = conf.get("zookeeper.znode.state",
-    "shutdown");
-
-    rootRegionZNode = getZNode(parentZNode, rootServerZNodeName);
-    rsZNode = getZNode(parentZNode, rsZNodeName);
-    masterElectionZNode = getZNode(parentZNode, masterAddressZNodeName);
-    clusterStateZNode = getZNode(parentZNode, stateZNodeName);
+  public void unregisterListener(Watcher watcher) {
+    listeners_.remove(watcher);
   }
 
-  private void setQuorumServers(Properties properties) {
-    String clientPort = null;
-    List<String> servers = new ArrayList<String>();
-
-    // The clientPort option may come after the server.X hosts, so we need to
-    // grab everything and then create the final host:port comma separated list.
-    boolean anyValid = false;
-    for (Entry<Object,Object> property : properties.entrySet()) {
-      String key = property.getKey().toString().trim();
-      String value = property.getValue().toString().trim();
-      if (key.equals("clientPort")) {
-        clientPort = value;
+  /**
+   * This is the primary ZK watcher
+   * @see org.apache.zookeeper.Watcher#process(org.apache.zookeeper.WatchedEvent)
+   */
+  @Override
+  public synchronized void process(WatchedEvent event) {
+    for(Watcher w : listeners_) {
+      try {
+        w.process(event);
+      } catch (Throwable t) {
+        LOG.error("<"+instanceName+">" + "ZK updates listener threw an exception in process()", t);
       }
-      else if (key.startsWith("server.")) {
-        String host = value.substring(0, value.indexOf(':'));
-        servers.add(host);
-        try {
-          //noinspection ResultOfMethodCallIgnored
-          InetAddress.getByName(host);
-          anyValid = true;
-        } catch (UnknownHostException e) {
-          LOG.warn(StringUtils.stringifyException(e));
-        }
-      }
     }
-
-    if (!anyValid) {
-      LOG.error("no valid quorum servers found in " + ZOOKEEPER_CONFIG_NAME);
-      return;
-    }
-
-    if (clientPort == null) {
-      LOG.error("no clientPort found in " + ZOOKEEPER_CONFIG_NAME);
-      return;
-    }
-
-    if (servers.isEmpty()) {
-      LOG.fatal("No server.X lines found in conf/zoo.cfg. HBase must have a " +
-                "ZooKeeper cluster configured for its operation.");
-      return;
-    }
-
-    StringBuilder hostPortBuilder = new StringBuilder();
-    for (int i = 0; i < servers.size(); ++i) {
-      String host = servers.get(i);
-      if (i > 0) {
-        hostPortBuilder.append(',');
-      }
-      hostPortBuilder.append(host);
-      hostPortBuilder.append(':');
-      hostPortBuilder.append(clientPort);
-    }
-
-    quorumServers = hostPortBuilder.toString();
   }
 
   /** @return String dump of everything in ZooKeeper. */
@@ -171,7 +246,7 @@
   public String dump() {
     StringBuilder sb = new StringBuilder();
     sb.append("\nHBase tree in ZooKeeper is rooted at ").append(parentZNode);
-    sb.append("\n  Cluster up? ").append(exists(clusterStateZNode));
+    sb.append("\n  Cluster up? ").append(exists(clusterStateZNode, true));
     sb.append("\n  Master address: ").append(readMasterAddress(null));
     sb.append("\n  Region server holding ROOT: ").append(readRootRegionLocation());
     sb.append("\n  Region servers:");
@@ -235,9 +310,24 @@
     return res.toArray(new String[res.size()]);
   }
 
-  private boolean exists(String znode) {
+  public boolean exists(String znode, boolean watch) {
     try {
-      return zooKeeper.exists(znode, null) != null;
+      return zooKeeper.exists(getZNode(parentZNode, znode), watch?this:null) != null;
+    } catch (KeeperException.SessionExpiredException e) {
+      // if the session has expired try to reconnect to ZK, then perform query
+      try {
+        reconnectToZk();
+        return zooKeeper.exists(getZNode(parentZNode, znode), watch?this:null) != null;
+      } catch (IOException e1) {
+        LOG.error("Error reconnecting to zookeeper", e1);
+        throw new RuntimeException("Error reconnecting to zookeeper", e1);
+      } catch (KeeperException e1) {
+        LOG.error("Error reading after reconnecting to zookeeper", e1);
+        throw new RuntimeException("Error reading after reconnecting to zookeeper", e1);
+      } catch (InterruptedException e1) {
+        LOG.error("Error reading after reconnecting to zookeeper", e1);
+        throw new RuntimeException("Error reading after reconnecting to zookeeper", e1);
+      }
     } catch (KeeperException e) {
       return false;
     } catch (InterruptedException e) {
@@ -310,13 +400,13 @@
    * Watch the state of the cluster, up or down
    * @param watcher Watcher to set on cluster state node
    */
-  public void setClusterStateWatch(Watcher watcher) {
+  public void setClusterStateWatch() {
     try {
-      zooKeeper.exists(clusterStateZNode, watcher);
+      zooKeeper.exists(clusterStateZNode, this);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to check on ZNode " + clusterStateZNode, e);
+      LOG.warn("<" + instanceName + ">" + "Failed to check on ZNode " + clusterStateZNode, e);
     } catch (KeeperException e) {
-      LOG.warn("Failed to check on ZNode " + clusterStateZNode, e);
+      LOG.warn("<" + instanceName + ">" + "Failed to check on ZNode " + clusterStateZNode, e);
     }
   }
 
@@ -334,19 +424,19 @@
         byte[] data = Bytes.toBytes("up");
         zooKeeper.create(clusterStateZNode, data,
             Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
-        LOG.debug("State node wrote in ZooKeeper");
+        LOG.debug("<" + instanceName + ">" + "State node wrote in ZooKeeper");
       } else {
         zooKeeper.delete(clusterStateZNode, -1);
-        LOG.debug("State node deleted in ZooKeeper");
+        LOG.debug("<" + instanceName + ">" + "State node deleted in ZooKeeper");
       }
       return true;
     } catch (InterruptedException e) {
-      LOG.warn("Failed to set state node in ZooKeeper", e);
+      LOG.warn("<" + instanceName + ">" + "Failed to set state node in ZooKeeper", e);
     } catch (KeeperException e) {
       if(e.code() == KeeperException.Code.NODEEXISTS) {
-        LOG.debug("State node exists.");
+        LOG.debug("<" + instanceName + ">" + "State node exists.");
       } else {
-        LOG.warn("Failed to set state node in ZooKeeper", e);
+        LOG.warn("<" + instanceName + ">" + "Failed to set state node in ZooKeeper", e);
       }
     }
 
@@ -363,13 +453,13 @@
     try {
       zooKeeper.exists(masterElectionZNode, watcher);
     } catch (KeeperException e) {
-      LOG.warn("Failed to set watcher on ZNode " + masterElectionZNode, e);
+      LOG.warn("<" + instanceName + ">" + "Failed to set watcher on ZNode " + masterElectionZNode, e);
       return false;
     } catch (InterruptedException e) {
-      LOG.warn("Failed to set watcher on ZNode " + masterElectionZNode, e);
+      LOG.warn("<" + instanceName + ">" + "Failed to set watcher on ZNode " + masterElectionZNode, e);
       return false;
     }
-    LOG.debug("Set watcher on master address ZNode " + masterElectionZNode);
+    LOG.debug("<" + instanceName + ">" + "Set watcher on master address ZNode " + masterElectionZNode);
     return true;
   }
 
@@ -377,7 +467,7 @@
     try {
       return readAddressOrThrow(znode, watcher);
     } catch (IOException e) {
-      LOG.debug("Failed to read " + e.getMessage());
+      LOG.debug("<" + instanceName + ">" + "Failed to read " + e.getMessage());
       return null;
     }
   }
@@ -393,7 +483,7 @@
     }
 
     String addressString = Bytes.toString(data);
-    LOG.debug("Read ZNode " + znode + " got " + addressString);
+    LOG.debug("<" + instanceName + ">" + "Read ZNode " + znode + " got " + addressString);
     return new HServerAddress(addressString);
   }
 
@@ -410,17 +500,17 @@
       }
       zooKeeper.create(znode, new byte[0],
                        Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
-      LOG.debug("Created ZNode " + znode);
+      LOG.debug("<" + instanceName + ">" + "Created ZNode " + znode);
       return true;
     } catch (KeeperException.NodeExistsException e) {
       return true;      // ok, move on.
     } catch (KeeperException.NoNodeException e) {
       return ensureParentExists(znode) && ensureExists(znode);
     } catch (KeeperException e) {
-      LOG.warn("Failed to create " + znode +
+      LOG.warn("<" + instanceName + ">" + "Failed to create " + znode +
         " -- check quorum servers, currently=" + this.quorumServers, e);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to create " + znode +
+      LOG.warn("<" + instanceName + ">" + "Failed to create " + znode +
         " -- check quorum servers, currently=" + this.quorumServers, e);
     }
     return false;
@@ -449,9 +539,9 @@
     } catch (KeeperException.NoNodeException e) {
       return true;    // ok, move on.
     } catch (KeeperException e) {
-      LOG.warn("Failed to delete " + rootRegionZNode + ": " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to delete " + rootRegionZNode + ": " + e);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to delete " + rootRegionZNode + ": " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to delete " + rootRegionZNode + ": " + e);
     }
 
     return false;
@@ -478,18 +568,18 @@
   public void deleteZNode(String znode, boolean recursive)
     throws KeeperException, InterruptedException {
     if (recursive) {
-      LOG.info("deleteZNode get children for " + znode);
+      LOG.info("<" + instanceName + ">" + "deleteZNode get children for " + znode);
       List<String> znodes = this.zooKeeper.getChildren(znode, false);
       if (znodes.size() > 0) {
         for (String child : znodes) {
           String childFullPath = getZNode(znode, child);
-          LOG.info("deleteZNode recursive call " + childFullPath);
+          LOG.info("<" + instanceName + ">" + "deleteZNode recursive call " + childFullPath);
           this.deleteZNode(childFullPath, true);
         }
       }
     }
     this.zooKeeper.delete(znode, -1);
-    LOG.debug("Deleted ZNode " + znode);
+    LOG.debug("<" + instanceName + ">" + "Deleted ZNode " + znode);
   }
 
   private boolean createRootRegionLocation(String address) {
@@ -497,12 +587,12 @@
     try {
       zooKeeper.create(rootRegionZNode, data, Ids.OPEN_ACL_UNSAFE,
                        CreateMode.PERSISTENT);
-      LOG.debug("Created ZNode " + rootRegionZNode + " with data " + address);
+      LOG.debug("<" + instanceName + ">" + "Created ZNode " + rootRegionZNode + " with data " + address);
       return true;
     } catch (KeeperException e) {
-      LOG.warn("Failed to create root region in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to create root region in ZooKeeper: " + e);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to create root region in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to create root region in ZooKeeper: " + e);
     }
 
     return false;
@@ -512,12 +602,12 @@
     byte[] data = Bytes.toBytes(address);
     try {
       zooKeeper.setData(rootRegionZNode, data, -1);
-      LOG.debug("SetData of ZNode " + rootRegionZNode + " with " + address);
+      LOG.debug("<" + instanceName + ">" + "SetData of ZNode " + rootRegionZNode + " with " + address);
       return true;
     } catch (KeeperException e) {
-      LOG.warn("Failed to set root region location in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to set root region location in ZooKeeper: " + e);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to set root region location in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to set root region location in ZooKeeper: " + e);
     }
 
     return false;
@@ -553,20 +643,22 @@
    * @return true if operation succeeded, false otherwise.
    */
   public boolean writeMasterAddress(final HServerAddress address) {
+    LOG.debug("<" + instanceName + ">" + "Writing master address " + address.toString() + " to znode " + masterElectionZNode);
     if (!ensureParentExists(masterElectionZNode)) {
       return false;
     }
+    LOG.debug("<" + instanceName + ">" + "Znode exists : " + masterElectionZNode);
 
     String addressStr = address.toString();
     byte[] data = Bytes.toBytes(addressStr);
     try {
       zooKeeper.create(masterElectionZNode, data, Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);
-      LOG.debug("Wrote master address " + address + " to ZooKeeper");
+      LOG.debug("<" + instanceName + ">" + "Wrote master address " + address + " to ZooKeeper");
       return true;
     } catch (InterruptedException e) {
-      LOG.warn("Failed to write master address " + address + " to ZooKeeper", e);
+      LOG.warn("<" + instanceName + ">" + "Failed to write master address " + address + " to ZooKeeper", e);
     } catch (KeeperException e) {
-      LOG.warn("Failed to write master address " + address + " to ZooKeeper", e);
+      LOG.warn("<" + instanceName + ">" + "Failed to write master address " + address + " to ZooKeeper", e);
     }
 
     return false;
@@ -581,16 +673,16 @@
   public boolean writeRSLocation(HServerInfo info) {
     ensureExists(rsZNode);
     byte[] data = Bytes.toBytes(info.getServerAddress().toString());
-    String znode = joinPath(rsZNode, Long.toString(info.getStartCode()));
+    String znode = joinPath(rsZNode, info.getServerName());
     try {
       zooKeeper.create(znode, data, Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);
-      LOG.debug("Created ZNode " + znode
+      LOG.debug("<" + instanceName + ">" + "Created ZNode " + znode
           + " with data " + info.getServerAddress().toString());
       return true;
     } catch (KeeperException e) {
-      LOG.warn("Failed to create " + znode + " znode in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to create " + znode + " znode in ZooKeeper: " + e);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to create " + znode + " znode in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to create " + znode + " znode in ZooKeeper: " + e);
     }
     return false;
   }
@@ -603,17 +695,17 @@
    */
   public boolean updateRSLocationGetWatch(HServerInfo info, Watcher watcher) {
     byte[] data = Bytes.toBytes(info.getServerAddress().toString());
-    String znode = rsZNode + ZNODE_PATH_SEPARATOR + info.getStartCode();
+    String znode = rsZNode + ZNODE_PATH_SEPARATOR + info.getServerName();
     try {
       zooKeeper.setData(znode, data, -1);
-      LOG.debug("Updated ZNode " + znode
+      LOG.debug("<" + instanceName + ">" + "Updated ZNode " + znode
           + " with data " + info.getServerAddress().toString());
       zooKeeper.getData(znode, watcher, null);
       return true;
     } catch (KeeperException e) {
-      LOG.warn("Failed to update " + znode + " znode in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to update " + znode + " znode in ZooKeeper: " + e);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to update " + znode + " znode in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to update " + znode + " znode in ZooKeeper: " + e);
     }
 
     return false;
@@ -627,6 +719,10 @@
     return scanAddressDirectory(rsZNode, null);
   }
 
+  public List<HServerAddress> scanKnownRSDirectory() {
+    return scanAddressDirectory(rsZNode, null);
+  }
+
   /**
    * Scans the regions servers directory and sets a watch on each znode
    * @param watcher a watch to use for each znode
@@ -644,13 +740,13 @@
     try {
       List<String> nodes = zooKeeper.getChildren(rsZNode, false);
       for (String node : nodes) {
-        LOG.debug("Deleting node: " + node);
+        LOG.debug("<" + instanceName + ">" + "Deleting node: " + node);
         zooKeeper.delete(joinPath(this.rsZNode, node), -1);
       }
     } catch (KeeperException e) {
-      LOG.warn("Failed to delete " + rsZNode + " znodes in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to delete " + rsZNode + " znodes in ZooKeeper: " + e);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to delete " + rsZNode + " znodes in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to delete " + rsZNode + " znodes in ZooKeeper: " + e);
     }
   }
 
@@ -659,9 +755,9 @@
     try {
       stat = zooKeeper.exists(path, false);
     } catch (KeeperException e) {
-      LOG.warn("checking existence of " + path, e);
+      LOG.warn("<" + instanceName + ">" + "checking existence of " + path, e);
     } catch (InterruptedException e) {
-      LOG.warn("checking existence of " + path, e);
+      LOG.warn("<" + instanceName + ">" + "checking existence of " + path, e);
     }
 
     return stat != null;
@@ -673,9 +769,10 @@
   public void close() {
     try {
       zooKeeper.close();
-      LOG.debug("Closed connection with ZooKeeper; " + this.rootRegionZNode);
+      instances_.remove(instanceName);
+      LOG.debug("<" + instanceName + ">" + "Closed connection with ZooKeeper; " + this.rootRegionZNode);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to close connection with ZooKeeper");
+      LOG.warn("<" + instanceName + ">" + "Failed to close connection with ZooKeeper");
     }
   }
 
@@ -684,6 +781,10 @@
         znodeName : joinPath(parentZNode, znodeName);
   }
 
+  public String getZNodePathForHBase(String znodeName) {
+    return getZNode(parentZNode, znodeName);
+  }
+
   private String joinPath(String parent, String child) {
     return parent + ZNODE_PATH_SEPARATOR + child;
   }
@@ -713,7 +814,7 @@
   public List<HServerAddress> scanAddressDirectory(String znode,
       Watcher watcher) {
     List<HServerAddress> list = new ArrayList<HServerAddress>();
-    List<String> nodes = this.listZnodes(znode, watcher);
+    List<String> nodes = this.listZnodes(znode);
     if(nodes == null) {
       return list;
     }
@@ -730,44 +831,39 @@
    * @param watcher watch to set, can be null
    * @return a list of all the znodes
    */
-  public List<String> listZnodes(String znode, Watcher watcher) {
+  public List<String> listZnodes(String znode) {
     List<String> nodes = null;
     try {
       if (checkExistenceOf(znode)) {
-        if (watcher == null) {
-          nodes = zooKeeper.getChildren(znode, false);
-        } else {
-          nodes = zooKeeper.getChildren(znode, watcher);
-          for (String node : nodes) {
-            getDataAndWatch(znode, node, watcher);
-          }
+        nodes = zooKeeper.getChildren(znode, this);
+        for (String node : nodes) {
+          getDataAndWatch(znode, node, this);
         }
-
       }
     } catch (KeeperException e) {
-      LOG.warn("Failed to read " + znode + " znode in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to read " + znode + " znode in ZooKeeper: " + e);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to read " + znode + " znode in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to read " + znode + " znode in ZooKeeper: " + e);
     }
     return nodes;
   }
 
-  public String getData(String parentZNode, String znode) {
+  public byte[] getData(String parentZNode, String znode) {
     return getDataAndWatch(parentZNode, znode, null);
   }
 
-  public String getDataAndWatch(String parentZNode,
+  public byte[] getDataAndWatch(String parentZNode,
                                 String znode, Watcher watcher) {
-    String data = null;
+    byte[] data = null;
     try {
       String path = joinPath(parentZNode, znode);
       if (checkExistenceOf(path)) {
-        data = Bytes.toString(zooKeeper.getData(path, watcher, null));
+        data = zooKeeper.getData(path, watcher, null);
       }
     } catch (KeeperException e) {
-      LOG.warn("Failed to read " + znode + " znode in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to read " + znode + " znode in ZooKeeper: " + e);
     } catch (InterruptedException e) {
-      LOG.warn("Failed to read " + znode + " znode in ZooKeeper: " + e);
+      LOG.warn("<" + instanceName + ">" + "Failed to read " + znode + " znode in ZooKeeper: " + e);
     }
     return data;
   }
@@ -800,17 +896,17 @@
       boolean failOnWrite) throws InterruptedException, KeeperException {
     String path = joinPath(parentPath, child);
     if (!ensureExists(parentPath)) {
-      LOG.error("unable to ensure parent exists: " + parentPath);
+      LOG.error("<" + instanceName + ">" + "unable to ensure parent exists: " + parentPath);
     }
     byte[] data = Bytes.toBytes(strData);
     Stat stat = this.zooKeeper.exists(path, false);
     if (failOnWrite || stat == null) {
       this.zooKeeper.create(path, data,
           Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
-      LOG.debug("Created " + path);
+      LOG.debug("<" + instanceName + ">" + "Created " + path);
     } else {
       this.zooKeeper.setData(path, data, -1);
-      LOG.debug("Updated " + path);
+      LOG.debug("<" + instanceName + ">" + "Updated " + path);
     }
   }
 
@@ -820,6 +916,14 @@
   }
 
   /**
+   * Get the znode that has all the regions in transition.
+   * @return path to znode
+   */
+  public String getRegionInTransitionZNode() {
+    return this.rgnsInTransitZNode;
+  }
+
+  /**
    * Get the path of this region server's znode
    * @return path to znode
    */
@@ -827,4 +931,206 @@
     return this.rsZNode;
   }
 
+  public void deleteZNode(String zNodeName, int version) {
+    String fullyQualifiedZNodeName = getZNode(parentZNode, zNodeName);
+    try
+    {
+      zooKeeper.delete(fullyQualifiedZNodeName, version);
+    }
+    catch (InterruptedException e)
+    {
+      LOG.warn("<" + instanceName + ">" + "Failed to delete ZNode " + fullyQualifiedZNodeName + " in ZooKeeper", e);
+    }
+    catch (KeeperException e)
+    {
+      LOG.warn("<" + instanceName + ">" + "Failed to delete ZNode " + fullyQualifiedZNodeName + " in ZooKeeper", e);
+    }
+  }
+
+  public String createZNodeIfNotExists(String zNodeName) {
+    return createZNodeIfNotExists(zNodeName, null, CreateMode.PERSISTENT, true);
+  }
+
+  public void watchZNode(String zNodeName) {
+    String fullyQualifiedZNodeName = getZNode(parentZNode, zNodeName);
+
+    try {
+      zooKeeper.exists(fullyQualifiedZNodeName, this);
+      zooKeeper.getData(fullyQualifiedZNodeName, this, null);
+      zooKeeper.getChildren(fullyQualifiedZNodeName, this);
+    } catch (InterruptedException e) {
+      LOG.warn("<" + instanceName + ">" + "Failed to create ZNode " + fullyQualifiedZNodeName + " in ZooKeeper", e);
+    } catch (KeeperException e) {
+      LOG.warn("<" + instanceName + ">" + "Failed to create ZNode " + fullyQualifiedZNodeName + " in ZooKeeper", e);
+    }
+  }
+
+  public String createZNodeIfNotExists(String zNodeName, byte[] data, CreateMode createMode, boolean watch) {
+    String fullyQualifiedZNodeName = getZNode(parentZNode, zNodeName);
+
+    if (!ensureParentExists(fullyQualifiedZNodeName)) {
+      return null;
+    }
+
+    try {
+      if(!exists(fullyQualifiedZNodeName, watch)) {
+        // create the znode
+        zooKeeper.create(fullyQualifiedZNodeName, data, Ids.OPEN_ACL_UNSAFE, createMode);
+        LOG.debug("<" + instanceName + ">" + "Created ZNode " + fullyQualifiedZNodeName + " in ZooKeeper");
+        // watch the znode for deletion, data change, creation of children
+        if(watch) {
+          watchZNode(zNodeName);
+        }
+      }
+      return fullyQualifiedZNodeName;
+    } catch (InterruptedException e) {
+      LOG.warn("<" + instanceName + ">" + "Failed to create ZNode " + fullyQualifiedZNodeName + " in ZooKeeper", e);
+    } catch (KeeperException e) {
+      LOG.warn("<" + instanceName + ">" + "Failed to create ZNode " + fullyQualifiedZNodeName + " in ZooKeeper", e);
+    }
+
+    return null;
+  }
+
+  public byte[] readZNode(String znodeName, Stat stat) throws IOException {
+    byte[] data;
+    try {
+      String fullyQualifiedZNodeName = getZNode(parentZNode, znodeName);
+      data = zooKeeper.getData(fullyQualifiedZNodeName, this, stat);
+    } catch (InterruptedException e) {
+      throw new IOException(e);
+    } catch (KeeperException e) {
+      throw new IOException(e);
+    }
+    return data;
+  }
+
+  // TODO: perhaps return the version number from this write?
+  public boolean writeZNode(String znodeName, byte[] data, int version, boolean watch) throws IOException {
+      try {
+        String fullyQualifiedZNodeName = getZNode(parentZNode, znodeName);
+        zooKeeper.setData(fullyQualifiedZNodeName, data, version);
+        if(watch) {
+          zooKeeper.getData(fullyQualifiedZNodeName, this, null);
+        }
+        return true;
+      } catch (InterruptedException e) {
+        LOG.warn("<" + instanceName + ">" + "Failed to write data to ZooKeeper", e);
+        throw new IOException(e);
+      } catch (KeeperException e) {
+        LOG.warn("<" + instanceName + ">" + "Failed to write data to ZooKeeper", e);
+        throw new IOException(e);
+      }
+    }
+  
+  public void createUnassignedRegion(String regionName, byte[] data) {
+    String znode = getZNode(getRegionInTransitionZNode(), regionName);
+    if(LOG.isDebugEnabled()) {
+      // check if this node already exists - 
+      //   - it should not exist
+      //   - if it does, it should be in the CLOSED state
+      if(exists(znode, true)) {
+        Stat stat = new Stat();
+        byte[] oldData = null;
+        try {
+          oldData = readZNode(znode, stat);
+        } catch (IOException e) {
+          LOG.error("Error reading data for " + znode);
+        }
+        if(oldData == null) {
+          LOG.debug("While creating UNASSIGNED region " + regionName + " exists with no data" );          
+        }
+        else {
+          LOG.debug("While creating UNASSIGNED region " + regionName + " exists, state = " + (HBEventType.fromByte(oldData[0])));
+        }
+      }
+      else {
+        if(data == null) {
+          LOG.debug("Creating UNASSIGNED region " + regionName + " with no data" );          
+        }
+        else {
+          LOG.debug("Creating UNASSIGNED region " + regionName + " in state = " + (HBEventType.fromByte(data[0])));
+        }
+      }
+    }
+    synchronized(unassignedZNodesWatched) {
+      unassignedZNodesWatched.add(znode);
+      createZNodeIfNotExists(znode, data, CreateMode.PERSISTENT, true);
+    }
+  }
+
+  public void deleteUnassignedRegion(String regionName) {
+    String znode = getZNode(getRegionInTransitionZNode(), regionName);
+    try {
+      LOG.debug("Deleting ZNode " + znode + " in ZooKeeper as region is open...");
+      synchronized(unassignedZNodesWatched) {
+        unassignedZNodesWatched.remove(znode);
+        deleteZNode(znode);
+      }
+    } catch (KeeperException.SessionExpiredException e) {
+      LOG.error("Zookeeper session has expired", e);
+      // if the session has expired try to reconnect to ZK, then perform query
+      try {
+        reconnectToZk();
+        deleteZNode(znode);
+      } catch (IOException e1) {
+        LOG.error("Error reconnecting to zookeeper", e1);
+        throw new RuntimeException("Error reconnecting to zookeeper", e1);
+      } catch (KeeperException.SessionExpiredException e1) {
+        LOG.error("Error reading after reconnecting to zookeeper", e1);
+        throw new RuntimeException("Error reading after reconnecting to zookeeper", e1);
+      } catch (KeeperException e1) {
+        LOG.error("Error reading after reconnecting to zookeeper", e1);
+      } catch (InterruptedException e1) {
+        LOG.error("Error reading after reconnecting to zookeeper", e1);
+      }
+    } catch (KeeperException e) {
+      LOG.error("Error deleting region " + regionName, e);
+    } catch (InterruptedException e) {
+      LOG.error("Error deleting region " + regionName, e);
+    }
+  }
+
+  public List<ZNodePathAndData> watchAndGetNewChildren(String znode) {
+    List<String> nodes = null;
+    List<ZNodePathAndData> newNodes = new ArrayList<ZNodePathAndData>();
+    try {
+      if (checkExistenceOf(znode)) {
+        nodes = zooKeeper.getChildren(znode, this);
+        for (String node : nodes) {
+          String znodePath = joinPath(znode, node);
+          synchronized(unassignedZNodesWatched) {
+            if(!unassignedZNodesWatched.contains(znodePath) && exists(znodePath, false)) {
+              byte[] data = getDataAndWatch(znode, node, this);
+              newNodes.add(new ZNodePathAndData(znodePath, data));
+              unassignedZNodesWatched.add(znodePath);
+            }
+          }
+        }
+      }
+    } catch (KeeperException e) {
+      LOG.warn("<" + instanceName + ">" + "Failed to read " + znode + " znode in ZooKeeper: " + e);
+    } catch (InterruptedException e) {
+      LOG.warn("<" + instanceName + ">" + "Failed to read " + znode + " znode in ZooKeeper: " + e);
+    }
+    return newNodes;
+  }
+  
+  public static class ZNodePathAndData {
+    private String zNodePath;
+    private byte[] data;
+    
+    public ZNodePathAndData(String zNodePath, byte[] data) {
+      this.zNodePath = zNodePath;
+      this.data = data;
+    }
+    
+    public String getzNodePath() {
+      return zNodePath;
+    }
+    public byte[] getData() {
+      return data;
+    }
+    
+  }
 }
Index: src/main/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java	(working copy)
@@ -217,7 +217,69 @@
 
     return zkProperties;
   }
+  
+  /**
+   * Return the ZK Quorum servers string given zk properties returned by 
+   * makeZKProps
+   * @param properties
+   * @return
+   */
+  public static String getZKQuorumServersString(Properties properties) {
+    String clientPort = null;
+    List<String> servers = new ArrayList<String>();
 
+    // The clientPort option may come after the server.X hosts, so we need to
+    // grab everything and then create the final host:port comma separated list.
+    boolean anyValid = false;
+    for (Entry<Object,Object> property : properties.entrySet()) {
+      String key = property.getKey().toString().trim();
+      String value = property.getValue().toString().trim();
+      if (key.equals("clientPort")) {
+        clientPort = value;
+      }
+      else if (key.startsWith("server.")) {
+        String host = value.substring(0, value.indexOf(':'));
+        servers.add(host);
+        try {
+          //noinspection ResultOfMethodCallIgnored
+          InetAddress.getByName(host);
+          anyValid = true;
+        } catch (UnknownHostException e) {
+          LOG.warn(StringUtils.stringifyException(e));
+        }
+      }
+    }
+
+    if (!anyValid) {
+      LOG.error("no valid quorum servers found in " + ZOOKEEPER_CONFIG_NAME);
+      return null;
+    }
+
+    if (clientPort == null) {
+      LOG.error("no clientPort found in " + ZOOKEEPER_CONFIG_NAME);
+      return null;
+    }
+
+    if (servers.isEmpty()) {
+      LOG.fatal("No server.X lines found in conf/zoo.cfg. HBase must have a " +
+                "ZooKeeper cluster configured for its operation.");
+      return null;
+    }
+
+    StringBuilder hostPortBuilder = new StringBuilder();
+    for (int i = 0; i < servers.size(); ++i) {
+      String host = servers.get(i);
+      if (i > 0) {
+        hostPortBuilder.append(',');
+      }
+      hostPortBuilder.append(host);
+      hostPortBuilder.append(':');
+      hostPortBuilder.append(clientPort);
+    }
+
+    return hostPortBuilder.toString();
+  }
+
   /**
    * Parse ZooKeeper's zoo.cfg, injecting HBase Configuration variables in.
    * This method is used for testing so we can pass our own InputStream.
Index: src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java	(working copy)
@@ -314,7 +314,8 @@
   }
 
   private void reinitializeZooKeeper() throws IOException {
-    zooKeeperWrapper = new ZooKeeperWrapper(conf, this);
+    zooKeeperWrapper = ZooKeeperWrapper.createInstance(conf, serverInfo.getServerName());
+    zooKeeperWrapper.registerListener(this);
     watchMasterAddress();
   }
 
@@ -1205,14 +1206,7 @@
         if (LOG.isDebugEnabled())
           LOG.debug("sending initial server load: " + hsl);
         lastMsg = System.currentTimeMillis();
-        boolean startCodeOk = false;
-        while(!startCodeOk) {
-          this.serverInfo = createServerInfoWithNewStartCode(this.serverInfo);
-          startCodeOk = zooKeeperWrapper.writeRSLocation(this.serverInfo);
-          if(!startCodeOk) {
-           LOG.debug("Start code already taken, trying another one");
-          }
-        }
+        zooKeeperWrapper.writeRSLocation(this.serverInfo);
         result = this.hbaseMaster.regionServerStartup(this.serverInfo);
         break;
       } catch (IOException e) {
@@ -1407,8 +1401,11 @@
   void openRegion(final HRegionInfo regionInfo) {
     Integer mapKey = Bytes.mapKey(regionInfo.getRegionName());
     HRegion region = this.onlineRegions.get(mapKey);
+    RSZookeeperUpdater zkUpdater = 
+      new RSZookeeperUpdater(serverInfo.getServerName(), regionInfo.getRegionNameAsString());
     if (region == null) {
       try {
+        zkUpdater.startRegionOpenEvent(null, true);
         region = instantiateRegion(regionInfo);
         // Startup a compaction early if one is needed, if region has references
         // or if a store has too many store files
@@ -1423,7 +1420,14 @@
         // TODO: add an extra field in HRegionInfo to indicate that there is
         // an error. We can't do that now because that would be an incompatible
         // change that would require a migration
-        reportClose(regionInfo, StringUtils.stringifyException(t).getBytes());
+        try {
+          HMsg hmsg = new HMsg(HMsg.Type.MSG_REPORT_CLOSE, 
+                               regionInfo, 
+                               StringUtils.stringifyException(t).getBytes());
+          zkUpdater.abortOpenRegion(hmsg);
+        } catch (IOException e1) {
+          LOG.error("Failed to abort open region " + regionInfo.getRegionNameAsString(), e1);
+        }
         return;
       }
       this.lock.writeLock().lock();
@@ -1434,7 +1438,13 @@
         this.lock.writeLock().unlock();
       }
     }
-    reportOpen(regionInfo);
+    try {
+      HMsg hmsg = new HMsg(HMsg.Type.MSG_REPORT_OPEN, regionInfo);
+      zkUpdater.finishRegionOpenEvent(hmsg);
+    } catch (IOException e) {
+      LOG.error("Failed to mark region " + regionInfo.getRegionNameAsString() + " as opened", e);
+    }
+//    reportOpen(regionInfo);
   }
 
   protected HRegion instantiateRegion(final HRegionInfo regionInfo)
@@ -1463,11 +1473,19 @@
 
   protected void closeRegion(final HRegionInfo hri, final boolean reportWhenCompleted)
   throws IOException {
+    RSZookeeperUpdater zkUpdater = null;
+    if(reportWhenCompleted) {
+      zkUpdater = new RSZookeeperUpdater(serverInfo.getServerName(), hri.getRegionNameAsString());
+      zkUpdater.startRegionCloseEvent(null, false);
+    }
     HRegion region = this.removeFromOnlineRegions(hri);
     if (region != null) {
       region.close();
       if(reportWhenCompleted) {
-        reportClose(hri);
+        if(zkUpdater != null) {
+          HMsg hmsg = new HMsg(HMsg.Type.MSG_REPORT_CLOSE, hri, null);
+          zkUpdater.finishRegionCloseEvent(hmsg);
+        }
       }
     }
   }
Index: src/main/java/org/apache/hadoop/hbase/regionserver/RSZookeeperUpdater.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/regionserver/RSZookeeperUpdater.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/regionserver/RSZookeeperUpdater.java	(revision 0)
@@ -0,0 +1,162 @@
+package org.apache.hadoop.hbase.regionserver;
+
+import java.io.ByteArrayOutputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.HMsg;
+import org.apache.hadoop.hbase.executor.HBEventData;
+import org.apache.hadoop.hbase.executor.HBEventHandler;
+import org.apache.hadoop.hbase.executor.HBEventHandler.HBEventType;
+import org.apache.hadoop.hbase.util.Writables;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper;
+import org.apache.zookeeper.CreateMode;
+import org.apache.zookeeper.data.Stat;
+
+/**
+ * This is a helper class for region servers to update various states in 
+ * Zookeeper. The various updates are abstracted out here. 
+ * 
+ * The "startRegionXXX" methods are to be called first, followed by the 
+ * "finishRegionXXX" methods. Supports updating zookeeper periodically as a 
+ * part of the "startRegionXXX". Currently handles the following state updates:
+ *   - Close region
+ *   - Open region
+ */
+// TODO: make this thread local, in which case it is re-usable per thread
+public class RSZookeeperUpdater {
+  private static final Log LOG = LogFactory.getLog(RSZookeeperUpdater.class);
+  private final String regionServerName_;
+  private String regionName_ = null;
+  private String regionZNode_ = null;
+  private ZooKeeperWrapper zkWrapper_ = null;
+  private ByteArrayOutputStream  bos_ = new ByteArrayOutputStream ();
+  private DataOutputStream dos_ = new DataOutputStream(bos_);
+  private int zkVersion_ = 0;
+  HBEventType lastUpdatedState_;
+
+  public RSZookeeperUpdater(String regionServerName, String regionName) {
+    this(regionServerName, regionName, 0);
+  }
+  
+  public RSZookeeperUpdater(String regionServerName, String regionName, int zkVersion) {
+    zkWrapper_ = ZooKeeperWrapper.getInstance(regionServerName);
+    regionServerName_ = regionServerName;
+    regionName_ = regionName;
+    // get the region ZNode we have to create
+    regionZNode_ = zkWrapper_.getZNode(zkWrapper_.getRegionInTransitionZNode(), regionName_);
+    zkVersion_ = zkVersion;
+  }
+  
+  /**
+   * This method updates the various states in ZK to inform the master that the 
+   * region server has started closing the region.
+   * @param updatePeriodically - if true, periodically updates the state in ZK
+   */
+  public void startRegionCloseEvent(HMsg hmsg, boolean updatePeriodically) throws IOException {
+    // if this ZNode already exists, something is wrong
+    if(zkWrapper_.exists(regionZNode_, true)) {
+      String msg = "ZNode " + regionZNode_ + " already exists in ZooKeeper, will NOT close region.";
+      LOG.error(msg);
+      throw new IOException(msg);
+    }
+    
+    // create the region node in the unassigned directory first
+    zkWrapper_.createZNodeIfNotExists(regionZNode_, null, CreateMode.PERSISTENT, true);
+
+    // update the data for "regionName" ZNode in unassigned to CLOSING
+    updateZKWithEventData(HBEventType.RS2ZK_REGION_CLOSING, hmsg);
+    
+    // TODO: implement the updatePeriodically logic here
+  }
+
+  /**
+   * This method updates the states in ZK to signal that the region has been 
+   * closed. This will stop the periodic updater thread if one was started.
+   * @throws IOException
+   */
+  public void finishRegionCloseEvent(HMsg hmsg) throws IOException {    
+    // TODO: stop the updatePeriodically here
+
+    // update the data for "regionName" ZNode in unassigned to CLOSED
+    updateZKWithEventData(HBEventType.RS2ZK_REGION_CLOSED, hmsg);
+  }
+  
+  /**
+   * This method updates the various states in ZK to inform the master that the 
+   * region server has started opening the region.
+   * @param updatePeriodically - if true, periodically updates the state in ZK
+   */
+  public void startRegionOpenEvent(HMsg hmsg, boolean updatePeriodically) throws IOException {
+    Stat stat = new Stat();
+    byte[] data = zkWrapper_.readZNode(regionZNode_, stat);
+    // if there is no ZNode for this region, something is wrong
+    if(data == null) {
+      String msg = "ZNode " + regionZNode_ + " does not exist in ZooKeeper, will NOT open region.";
+      LOG.error(msg);
+      throw new IOException(msg);
+    }
+    // if the ZNode is not in the closed state, something is wrong
+    HBEventType rsEvent = HBEventType.fromByte(data[0]);
+    if(rsEvent != HBEventType.RS2ZK_REGION_CLOSED && rsEvent != HBEventType.M2ZK_REGION_OFFLINE) {
+      String msg = "ZNode " + regionZNode_ + " is not in CLOSED/OFFLINE state (state = " + rsEvent + "), will NOT open region.";
+      LOG.error(msg);
+      throw new IOException(msg);
+    }
+
+    // get the version to update from ZK
+    zkVersion_ = stat.getVersion();
+
+    // update the data for "regionName" ZNode in unassigned to CLOSING
+    updateZKWithEventData(HBEventType.RS2ZK_REGION_OPENING, hmsg);
+    
+    // TODO: implement the updatePeriodically logic here
+  }
+  
+  /**
+   * This method updates the states in ZK to signal that the region has been 
+   * opened. This will stop the periodic updater thread if one was started.
+   * @throws IOException
+   */
+  public void finishRegionOpenEvent(HMsg hmsg) throws IOException {
+    // TODO: stop the updatePeriodically here
+
+    // update the data for "regionName" ZNode in unassigned to CLOSED
+    updateZKWithEventData(HBEventType.RS2ZK_REGION_OPENED, hmsg);
+  }
+  
+  public boolean isClosingRegion() {
+    return (lastUpdatedState_ == HBEventType.RS2ZK_REGION_CLOSING);
+  }
+
+  public boolean isOpeningRegion() {
+    return (lastUpdatedState_ == HBEventType.RS2ZK_REGION_OPENING);
+  }
+
+  public void abortOpenRegion(HMsg hmsg) throws IOException {
+    LOG.error("Aborting open of region " + regionName_);
+
+    // TODO: stop the updatePeriodically for start open region here
+
+    // update the data for "regionName" ZNode in unassigned to CLOSED
+    updateZKWithEventData(HBEventType.RS2ZK_REGION_CLOSED, hmsg);
+  }
+
+  private void updateZKWithEventData(HBEventType hbEventType, HMsg hmsg) throws IOException {
+    // update the data for "regionName" ZNode in unassigned to "hbEventType"
+    byte[] data = null;
+    try {
+      data = Writables.getBytes(new HBEventData(hbEventType, regionServerName_, hmsg));
+    } catch (IOException e) {
+      LOG.error("Error creating event data for " + hbEventType, e);
+    }
+    LOG.debug("Updating ZNode " + regionZNode_ + 
+              " with [" + hbEventType + "]" +
+              " expected version = " + zkVersion_);
+    lastUpdatedState_ = hbEventType;
+    zkWrapper_.writeZNode(regionZNode_, data, zkVersion_, true);
+    zkVersion_++;
+  }
+}
Index: src/main/java/org/apache/hadoop/hbase/master/ServerManager.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/ServerManager.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/master/ServerManager.java	(working copy)
@@ -562,7 +562,7 @@
    * @param region
    * @param returnMsgs
    */
-  private void processRegionOpen(HServerInfo serverInfo,
+  public void processRegionOpen(HServerInfo serverInfo,
       HRegionInfo region, ArrayList<HMsg> returnMsgs) {
     boolean duplicateAssignment = false;
     synchronized (master.getRegionManager()) {
@@ -631,7 +631,7 @@
    * @param region
    * @throws Exception
    */
-  private void processRegionClose(HRegionInfo region) {
+  public void processRegionClose(HRegionInfo region) {
     synchronized (this.master.getRegionManager()) {
       if (region.isRootRegion()) {
         // Root region
Index: src/main/java/org/apache/hadoop/hbase/master/ProcessRegionOpen.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/ProcessRegionOpen.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/master/ProcessRegionOpen.java	(working copy)
@@ -25,6 +25,7 @@
 import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.ipc.HRegionInterface;
 import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper;
 
 import java.io.IOException;
 
@@ -33,7 +34,7 @@
  * serving a region. This applies to all meta and user regions except the
  * root region which is handled specially.
  */
-class ProcessRegionOpen extends ProcessRegionStatusChange {
+public class ProcessRegionOpen extends ProcessRegionStatusChange {
   protected final HServerInfo serverInfo;
 
   /**
@@ -113,6 +114,8 @@
       } else {
         master.getRegionManager().removeRegion(regionInfo);
       }
+      ZooKeeperWrapper zkWrapper = ZooKeeperWrapper.getInstance(HMaster.class.getName());
+      zkWrapper.deleteUnassignedRegion(regionInfo.getRegionNameAsString());
       return true;
     }
   }
Index: src/main/java/org/apache/hadoop/hbase/master/ZKUnassignedWatcher.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/ZKUnassignedWatcher.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/master/ZKUnassignedWatcher.java	(revision 0)
@@ -0,0 +1,143 @@
+package org.apache.hadoop.hbase.master;
+
+import java.io.IOException;
+import java.util.List;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.executor.HBEventHandler;
+import org.apache.hadoop.hbase.executor.HBEventHandler.HBEventType;
+import org.apache.hadoop.hbase.master.handler.MasterCloseRegionHandler;
+import org.apache.hadoop.hbase.master.handler.MasterOpenRegionHandler;
+import org.apache.hadoop.hbase.master.handler.MasterRootAndMetaHandler;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.ZNodePathAndData;
+import org.apache.zookeeper.WatchedEvent;
+import org.apache.zookeeper.Watcher;
+import org.apache.zookeeper.Watcher.Event.EventType;
+import org.apache.zookeeper.data.Stat;
+
+/**
+ * Watches the UNASSIGNED znode in ZK for the master, and handles all events 
+ * relating to region transitions.
+ */
+public class ZKUnassignedWatcher implements Watcher {
+  private static final Log LOG = LogFactory.getLog(ZKUnassignedWatcher.class);
+  
+  // TODO: Start move this to HConstants
+  static final String ROOT_TABLE_NAME_STR = "-ROOT-";
+  static final String META_TABLE_NAME_STR = ".META.";
+  // TODO: End move this to HConstants
+
+  private ZooKeeperWrapper zkWrapper_ = null;
+
+  public static void start() throws IOException {
+    new ZKUnassignedWatcher();
+    LOG.debug("Started ZKUnassigned watcher");
+  }
+
+  public ZKUnassignedWatcher() throws IOException {
+    zkWrapper_ = ZooKeeperWrapper.getInstance(HMaster.class.getName());
+    // If the UNASSIGNED ZNode does not exist, create it.
+    zkWrapper_.createZNodeIfNotExists(zkWrapper_.getRegionInTransitionZNode());
+    // TODO: get the outstanding changes in UNASSIGNED
+    
+    // Set a watch on Zookeeper's UNASSIGNED node if it exists.
+    zkWrapper_.registerListener(this);
+  }
+
+  /**
+   * This is the processing loop that gets triggerred from the ZooKeeperWrapper.
+   * This zookeeper events process function dies the following:
+   *   - WATCHES the following events: NodeCreated, NodeDataChanged, NodeChildrenChanged
+   *   - IGNORES the following events: None, NodeDeleted
+   */
+  @Override
+  public synchronized void process(WatchedEvent event) {
+    EventType type = event.getType();
+    LOG.debug("ZK-EVENT-PROCESS: Got zkEvent " + type +
+              " state:" + event.getState() +
+              " path:" + event.getPath());
+
+    // Handle the ignored events
+    if(type.equals(EventType.None)       ||
+       type.equals(EventType.NodeDeleted)) {
+      return;
+    }
+
+    // check if the path is for the UNASSIGNED directory we care about
+    if(event.getPath() == null ||
+       !event.getPath().startsWith(zkWrapper_.getZNodePathForHBase(zkWrapper_.getRegionInTransitionZNode()))) {
+      return;
+    }
+
+    try
+    {
+      /*
+       * If a node is created in the UNASSIGNED directory in zookeeper, then:
+       *   1. watch its updates (this is an unassigned region).
+       *   2. read to see what its state is and handle as needed (state may have
+       *      changed before we started watching it)
+       */
+      if(type.equals(EventType.NodeCreated)) {
+        zkWrapper_.watchZNode(event.getPath());
+        handleRegionStateInZK(event.getPath());
+      }
+      /*
+       * Data on some node has changed. Read to see what the state is and handle
+       * as needed.
+       */
+      else if(type.equals(EventType.NodeDataChanged)) {
+        handleRegionStateInZK(event.getPath());
+      }
+      /*
+       * If there were some nodes created then watch those nodes
+       */
+      else if(type.equals(EventType.NodeChildrenChanged)) {
+        List<ZNodePathAndData> newZNodes = zkWrapper_.watchAndGetNewChildren(event.getPath());
+        for(ZNodePathAndData zNodePathAndData : newZNodes) {
+          LOG.debug("Handling updates for znode: " + zNodePathAndData.getzNodePath());
+          handleRegionStateInZK(zNodePathAndData.getzNodePath(), zNodePathAndData.getData());
+        }
+      }
+    }
+    catch (IOException e)
+    {
+      LOG.error("Could not process event from ZooKeeper", e);
+    }
+  }
+
+  /**
+   * Read the state of a node in ZK, and do the needful. We want to do the
+   * following:
+   *   1. If region's state is updated as CLOSED, invoke the ClosedRegionHandler.
+   *   2. If region's state is updated as OPENED, invoke the OpenRegionHandler.
+   * @param zNodePath
+   * @throws IOException
+   */
+  private void handleRegionStateInZK(String zNodePath) throws IOException {
+    byte[] data = zkWrapper_.readZNode(zNodePath, null);
+    handleRegionStateInZK(zNodePath, data);
+  }
+  
+  private void handleRegionStateInZK(String zNodePath, byte[] data) {
+    // a null value is set when a node is created, we don't need to handle this
+    if(data == null) {
+      return;
+    }
+    String rgnInTransitNode = zkWrapper_.getRegionInTransitionZNode();
+    String region = zNodePath.substring(zNodePath.indexOf(rgnInTransitNode) + rgnInTransitNode.length() + 1);
+    HBEventType rsEvent = HBEventType.fromByte(data[0]);
+
+    // if the node was CLOSED then handle it
+    if(rsEvent == HBEventType.RS2ZK_REGION_CLOSED) {
+      new MasterCloseRegionHandler(rsEvent, region, data).submit();
+    }
+    // if the region was OPENED then handle that
+    else if(rsEvent == HBEventType.RS2ZK_REGION_OPENED || 
+            rsEvent == HBEventType.RS2ZK_REGION_OPENING) {
+      new MasterOpenRegionHandler(rsEvent, region, data).submit();
+    }
+  }
+}
+
Index: src/main/java/org/apache/hadoop/hbase/master/RegionServerOperation.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/RegionServerOperation.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/master/RegionServerOperation.java	(working copy)
@@ -27,7 +27,7 @@
 import java.util.concurrent.Delayed;
 import java.util.concurrent.TimeUnit;
 
-abstract class RegionServerOperation implements Delayed, HConstants {
+public abstract class RegionServerOperation implements Delayed, HConstants {
   protected static final Log LOG =
     LogFactory.getLog(RegionServerOperation.class.getName());
 
Index: src/main/java/org/apache/hadoop/hbase/master/handler/MasterOpenRegionHandler.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/handler/MasterOpenRegionHandler.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/master/handler/MasterOpenRegionHandler.java	(revision 0)
@@ -0,0 +1,84 @@
+package org.apache.hadoop.hbase.master.handler;
+
+import java.io.IOException;
+import java.util.ArrayList;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.HMsg;
+import org.apache.hadoop.hbase.HServerInfo;
+import org.apache.hadoop.hbase.executor.HBEventData;
+import org.apache.hadoop.hbase.executor.HBEventHandler;
+import org.apache.hadoop.hbase.util.Writables;
+
+/**
+ * This is the event handler for all events relating to opening regions on the
+ * HMaster. This could be one of the following:
+ *   - notification that a region server is "OPENING" a region
+ *   - notification that a region server has "OPENED" a region
+ * The following event types map to this handler:
+ *   - RS_REGION_OPENING
+ *   - RS_REGION_OPENED
+ */
+public class MasterOpenRegionHandler extends HBEventHandler {
+  private static final Log LOG = LogFactory.getLog(MasterOpenRegionHandler.class);
+  // other args passed in a byte array form
+  protected byte[] serializedData;
+  private String regionName;
+  private HBEventData hbEventData;
+
+  public MasterOpenRegionHandler(HBEventType eventType, String regionName, byte[] serData) {
+    super(false, eventType);
+    this.regionName = regionName;
+    this.serializedData = serData;
+  }
+
+  /**
+   * Handle the various events relating to opening regions. We can get the 
+   * following events here:
+   *   - RS_REGION_OPENING : Keep track to see how long the region open takes. 
+   *                         If the RS is taking too long, then revert the 
+   *                         region back to closed state so that it can be 
+   *                         re-assigned.
+   *   - RS_REGION_OPENED  : The region is opened. Add an entry into META for  
+   *                         the RS having opened this region. Then delete this 
+   *                         entry in ZK.
+   */
+  @Override
+  public void process()
+  {
+    LOG.debug("Event = " + getHBEvent() + ", region = " + regionName);
+    if(this.getHBEvent() == HBEventType.RS2ZK_REGION_OPENING) {
+      handleRegionOpeningEvent();
+    }
+    else if(this.getHBEvent() == HBEventType.RS2ZK_REGION_OPENED) {
+      handleRegionOpenedEvent();
+    }
+  }
+  
+  private void handleRegionOpeningEvent() {
+    // TODO: not implemented. 
+    // Keep track to see how long the region open takes. If the RS is taking too 
+    // long, then revert the region back to closed state so that it can be 
+    // re-assigned.
+  }
+
+  private void handleRegionOpenedEvent() {
+    try {
+      if(hbEventData == null) {
+        hbEventData = new HBEventData();
+        Writables.getWritable(serializedData, hbEventData);
+      }
+    } catch (IOException e) {
+      LOG.error("Could not deserialize additional args for Open region", e);
+    }
+    LOG.debug("RS " + hbEventData.getRsName() + " has opened region " + regionName);
+    HServerInfo serverInfo = serverManager.getServerInfo(hbEventData.getRsName());
+    ArrayList<HMsg> returnMsgs = new ArrayList<HMsg>();
+    serverManager.processRegionOpen(serverInfo, hbEventData.getHmsg().getRegionInfo(), returnMsgs);
+    if(returnMsgs.size() > 0) {
+      LOG.error("Open region tried to send message: " + returnMsgs.get(0).getType() + 
+                " about " + returnMsgs.get(0).getRegionInfo().getRegionNameAsString());
+    }
+  }
+}
Index: src/main/java/org/apache/hadoop/hbase/master/handler/MasterSendMsgToRSHandler.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/handler/MasterSendMsgToRSHandler.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/master/handler/MasterSendMsgToRSHandler.java	(revision 0)
@@ -0,0 +1,66 @@
+package org.apache.hadoop.hbase.master.handler;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.executor.HBEventHandler;
+import org.apache.hadoop.hbase.executor.HBEventHandler.HBEventType;
+
+/**
+ * This is the event handler for all events messaging from the HMaster to the 
+ * HRegionServers. This could be one of the following:
+ *   - ask a region server to open a region
+ *   - ask a region server to close a region
+ * The following event types map to this handler:
+ *   - M_REQUEST_CLOSEREGION
+ *   - M_REQUEST_OPENREGION
+ *   
+ * 
+ * It might make sense to actually expose a better API/Server from Master->RS
+ * Since we actually talk explicitly to it rather than piggybacked on heartbeats
+ * it can look more like the ClientToMasterServer.  And then the handlers
+ * would be one level lower.
+ * 
+ * Async can be because it's executed in a thread not waiting to be piggybacked!
+ * 
+ */
+public class MasterSendMsgToRSHandler extends HBEventHandler {
+  private static final Log LOG = LogFactory.getLog(MasterSendMsgToRSHandler.class);
+  
+  // region server to which communication should be sent
+  private String regionServer;
+
+  // region this request is for
+  private String regionName;
+  
+  public MasterSendMsgToRSHandler(HBEventType eventType, String regionName, String regionServer) {
+    super(false, eventType);
+    this.regionName = regionName;
+    this.regionServer = regionServer;
+  }
+
+  /**
+   * Handle the various events relating to sending messages to regionservers. We 
+   * can get the following events here:
+   *   - M_REQUEST_CLOSEREGION : Ask "regionServer" to close "regionName". 
+   *   - M_REQUEST_OPENREGION  : Ask "regionServer" to open "regionName". 
+   */
+  @Override
+  public void process()
+  {
+    LOG.debug("Event = " + getHBEvent() + ", region = " + regionName);
+    if(this.getHBEvent() == HBEventType.M2RS_REQUEST_CLOSEREGION) {
+      handleCloseRegionRequest();
+    }
+    else if(this.getHBEvent() == HBEventType.M2RS_REQUEST_OPENREGION) {
+      handleOpenRegionRequest();
+    }
+  }
+  
+  private void handleCloseRegionRequest() {
+    LOG.debug("Sending request for RS " + regionServer + " to close region " + regionName);
+  }
+
+  private void handleOpenRegionRequest() {
+    LOG.debug("Sending request for RS " + regionServer + " to open region " + regionName);
+  }  
+}
Index: src/main/java/org/apache/hadoop/hbase/master/handler/MasterCloseRegionHandler.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/handler/MasterCloseRegionHandler.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/master/handler/MasterCloseRegionHandler.java	(revision 0)
@@ -0,0 +1,67 @@
+package org.apache.hadoop.hbase.master.handler;
+
+import java.io.IOException;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.executor.HBEventData;
+import org.apache.hadoop.hbase.executor.HBEventHandler;
+import org.apache.hadoop.hbase.util.Writables;
+
+/**
+ * This is the event handler for all events relating to closing regions on the
+ * HMaster. The following event types map to this handler:
+ *   - RS_REGION_CLOSING
+ *   - RS_REGION_CLOSED
+ */
+public class MasterCloseRegionHandler extends HBEventHandler
+{
+  private static final Log LOG = LogFactory.getLog(MasterCloseRegionHandler.class);
+  
+  private String regionName;
+  protected byte[] serializedData;
+  HBEventData hbEventData;
+  
+  public MasterCloseRegionHandler(HBEventType eventType, String regionName, byte[] serializedData) {
+    super(false, eventType);
+    this.regionName = regionName;
+    this.serializedData = serializedData;
+  }
+
+  /**
+   * Handle the various events relating to closing regions. We can get the 
+   * following events here:
+   *   - RS_REGION_CLOSING : No-op
+   *   - RS_REGION_CLOSED  : The region is closed. If we are not in a shutdown 
+   *                         state, find the RS to open this region. This could 
+   *                         be a part of a region move, or just that the RS has 
+   *                         died. Should result in a M_REQUEST_OPENREGION event 
+   *                         getting created.
+   */
+  @Override
+  public void process()
+  {
+    LOG.debug("Event = " + getHBEvent() + ", region = " + regionName);
+    // handle RS_REGION_CLOSED events
+    handleRegionClosedEvent();
+  }
+  
+  private void handleRegionClosedEvent() {
+    try {
+      if(hbEventData == null) {
+        hbEventData = new HBEventData();
+        Writables.getWritable(serializedData, hbEventData);
+      }
+    } catch (IOException e) {
+      LOG.error("Could not deserialize additional args for Close region", e);
+    }
+    // process the region close - this will cause the reopening of the 
+    // region as a part of the heartbeat of some RS
+    serverManager.processRegionClose(hbEventData.getHmsg().getRegionInfo());
+    LOG.info("Processed close of region " + hbEventData.getHmsg().getRegionInfo().getRegionNameAsString());
+  }
+  
+  public String getRegionName() {
+    return regionName;
+  }
+}
Index: src/main/java/org/apache/hadoop/hbase/master/handler/MasterRootAndMetaHandler.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/handler/MasterRootAndMetaHandler.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/master/handler/MasterRootAndMetaHandler.java	(revision 0)
@@ -0,0 +1,70 @@
+package org.apache.hadoop.hbase.master.handler;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.executor.HBEventHandler;
+
+/**
+ * This is the event handler for all events relating to ROOT and META regions on 
+ * the HMaster. The following event types map to this handler:
+ *   - RS_REGION_OPENING
+ *   - RS_REGION_OPENED
+ *   - RS_REGION_CLOSING
+ *   - RS_REGION_CLOSED
+ */
+public class MasterRootAndMetaHandler extends HBEventHandler {
+  private static final Log LOG = LogFactory.getLog(MasterRootAndMetaHandler.class);
+  // other args passed in a byte array form
+  protected byte[] serializedData;
+  private String regionName;
+  
+  public MasterRootAndMetaHandler(HBEventType eventType, String regionName, byte[] serData) {
+    super(false, eventType);
+    this.regionName = regionName;
+    this.serializedData = serData;
+  }
+
+  /**
+   * Handle the various events relating to ROOT and META regions. We can get the 
+   * following events here:
+   *   - RS_REGION_OPENING : Keep track to see how long the region open takes. 
+   *                         If the RS is taking too long, then revert the 
+   *                         region back to closed state so that it can be 
+   *                         re-assigned.
+   *   - RS_REGION_OPENED  : The region is opened. Add an entry into META for  
+   *                         the RS having opened this region. Then delete this 
+   *                         entry in ZK.
+   *   - RS_REGION_CLOSING : No-op
+   *   - RS_REGION_CLOSED  : The region is closed. If we are not in a shutdown 
+   *                         state, find the RS to open this region. This could 
+   *                         be a part of a region move, or just that the RS has 
+   *                         died. Should result in a M_REQUEST_OPENREGION event 
+   *                         getting created.
+   */
+  @Override
+  public void process()
+  {
+    LOG.debug("Event = " + getHBEvent() + ", region = " + regionName);
+    if(this.getHBEvent() == HBEventType.RS2ZK_REGION_OPENING) {
+      handleRegionOpeningEvent();
+    }
+    else if(this.getHBEvent() == HBEventType.RS2ZK_REGION_OPENED) {
+      handleRegionOpenedEvent();
+    }
+    else if(this.getHBEvent() == HBEventType.RS2ZK_REGION_CLOSED) {
+      handleRegionClosedEvent();
+    }
+  }
+  
+  private void handleRegionOpeningEvent() {
+    
+  }
+
+  private void handleRegionOpenedEvent() {
+    
+  }
+
+  private void handleRegionClosedEvent() {
+    
+  }
+}
Index: src/main/java/org/apache/hadoop/hbase/master/HMaster.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/HMaster.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/master/HMaster.java	(working copy)
@@ -48,6 +48,9 @@
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.client.ServerConnection;
 import org.apache.hadoop.hbase.client.ServerConnectionManager;
+import org.apache.hadoop.hbase.executor.EventToServiceMapping;
+import org.apache.hadoop.hbase.executor.HBEventHandler;
+import org.apache.hadoop.hbase.executor.HBaseExecutorService;
 import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
 import org.apache.hadoop.hbase.ipc.HBaseRPC;
 import org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion;
@@ -197,14 +200,31 @@
     // We'll succeed if we are only  master or if we win the race when many
     // masters.  Otherwise we park here inside in writeAddressToZooKeeper.
     // TODO: Bring up the UI to redirect to active Master.
-    this.zooKeeperWrapper = new ZooKeeperWrapper(conf, this);
+    zooKeeperWrapper = ZooKeeperWrapper.createInstance(conf, HMaster.class.getName());
+    zooKeeperWrapper.registerListener(this);
     this.zkMasterAddressWatcher =
       new ZKMasterAddressWatcher(this.zooKeeperWrapper, this.shutdownRequested);
+    zooKeeperWrapper.registerListener(zkMasterAddressWatcher);
     this.zkMasterAddressWatcher.writeAddressToZooKeeper(this.address, true);
     this.regionServerOperationQueue =
       new RegionServerOperationQueue(this.conf, this.closed);
 
     serverManager = new ServerManager(this);
+
+    
+    // Start the unassigned watcher - which will create the unassgined region 
+    // in ZK. This is needed before RegionManager() constructor tries to assign 
+    // the root region.
+    ZKUnassignedWatcher.start();
+    // init the various event handlers
+    HBEventHandler.init(serverManager);
+    // start the "close region" executor service
+    HBaseExecutorService.startExecutorService(EventToServiceMapping.M_HANDLER_CLOSEREGION);
+    // start the "open region" executor service
+    HBaseExecutorService.startExecutorService(EventToServiceMapping.M_HANDLER_OPENREGION);
+
+    
+    // start the region manager
     regionManager = new RegionManager(this);
 
     setName(MASTER);
@@ -408,7 +428,7 @@
     return this.serverManager.getAverageLoad();
   }
 
-  RegionServerOperationQueue getRegionServerOperationQueue () {
+  public RegionServerOperationQueue getRegionServerOperationQueue () {
     return this.regionServerOperationQueue;
   }
 
@@ -488,6 +508,7 @@
     this.rpcServer.stop();
     this.regionManager.stop();
     this.zooKeeperWrapper.close();
+    HBaseExecutorService.shutdown();
     LOG.info("HMaster main thread exiting");
   }
 
@@ -1097,7 +1118,9 @@
    */
   @Override
   public void process(WatchedEvent event) {
-    LOG.debug(("Event " + event.getType() +  " with path " + event.getPath()));
+    LOG.debug("Event " + event.getType() + 
+              " with state " + event.getState() +  
+              " with path " + event.getPath());
     // Master should kill itself if its session expired or if its
     // znode was deleted manually (usually for testing purposes)
     if(event.getState() == KeeperState.Expired ||
@@ -1111,7 +1134,8 @@
 
       zooKeeperWrapper.close();
       try {
-        zooKeeperWrapper = new ZooKeeperWrapper(conf, this);
+        zooKeeperWrapper = ZooKeeperWrapper.createInstance(conf, HMaster.class.getName());
+        zooKeeperWrapper.registerListener(this);
         this.zkMasterAddressWatcher.setZookeeper(zooKeeperWrapper);
         if(!this.zkMasterAddressWatcher.
             writeAddressToZooKeeper(this.address,false)) {
Index: src/main/java/org/apache/hadoop/hbase/master/ProcessRegionClose.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/ProcessRegionClose.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/master/ProcessRegionClose.java	(working copy)
@@ -32,7 +32,7 @@
  * or deleted doesn't actually require post processing, it's no longer
  * necessary.
  */
-class ProcessRegionClose extends ProcessRegionStatusChange {
+public class ProcessRegionClose extends ProcessRegionStatusChange {
   protected final boolean offlineRegion;
   protected final boolean reassignRegion;
 
Index: src/main/java/org/apache/hadoop/hbase/master/RegionManager.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/RegionManager.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/master/RegionManager.java	(working copy)
@@ -32,6 +32,9 @@
 import org.apache.hadoop.hbase.HServerInfo;
 import org.apache.hadoop.hbase.HServerLoad;
 import org.apache.hadoop.hbase.client.Put;
+import org.apache.hadoop.hbase.executor.HBEventData;
+import org.apache.hadoop.hbase.executor.HBEventHandler;
+import org.apache.hadoop.hbase.executor.HBEventHandler.HBEventType;
 import org.apache.hadoop.hbase.ipc.HRegionInterface;
 import org.apache.hadoop.hbase.regionserver.HRegion;
 import org.apache.hadoop.hbase.regionserver.wal.HLog;
@@ -39,6 +42,8 @@
 import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.hbase.util.Threads;
 import org.apache.hadoop.hbase.util.Writables;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper;
+import org.apache.hadoop.io.WritableUtils;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -94,6 +99,9 @@
    */
    final SortedMap<String, RegionState> regionsInTransition =
     Collections.synchronizedSortedMap(new TreeMap<String, RegionState>());
+   
+   // regions in transition are also recorded in ZK using the zk wrapper
+   final ZooKeeperWrapper zkWrapper;
 
   // How many regions to assign a server at a time.
   private final int maxAssignInOneGo;
@@ -124,10 +132,11 @@
   private final int zooKeeperNumRetries;
   private final int zooKeeperPause;
 
-  RegionManager(HMaster master) {
+  RegionManager(HMaster master) throws IOException {
     Configuration conf = master.getConfiguration();
 
     this.master = master;
+    this.zkWrapper = ZooKeeperWrapper.getInstance(HMaster.class.getName());
     this.maxAssignInOneGo = conf.getInt("hbase.regions.percheckin", 10);
     this.loadBalancer = new LoadBalancer(conf);
 
@@ -163,10 +172,17 @@
     unsetRootRegion();
     if (!master.getShutdownRequested().get()) {
       synchronized (regionsInTransition) {
-        RegionState s = new RegionState(HRegionInfo.ROOT_REGIONINFO,
-            RegionState.State.UNASSIGNED);
-        regionsInTransition.put(
-            HRegionInfo.ROOT_REGIONINFO.getRegionNameAsString(), s);
+        String regionName = HRegionInfo.ROOT_REGIONINFO.getRegionNameAsString();
+        byte[] data = null;
+        try {
+          data = Writables.getBytes(new HBEventData(HBEventType.M2ZK_REGION_OFFLINE, "MASTER"));
+        } catch (IOException e) {
+          LOG.error("Error creating event data for " + HBEventType.M2ZK_REGION_OFFLINE, e);
+        }
+        zkWrapper.createUnassignedRegion(regionName, data);
+        LOG.debug("Created UNASSIGNED zNode " + regionName + " in state " + HBEventType.M2ZK_REGION_OFFLINE);
+        RegionState s = new RegionState(HRegionInfo.ROOT_REGIONINFO, RegionState.State.UNASSIGNED);
+        regionsInTransition.put(regionName, s);
         LOG.info("ROOT inserted into regionsInTransition");
       }
     }
@@ -328,6 +344,14 @@
     LOG.info("Assigning region " + regionName + " to " + sinfo.getServerName());
     rs.setPendingOpen(sinfo.getServerName());
     synchronized (this.regionsInTransition) {
+      byte[] data = null;
+      try {
+        data = Writables.getBytes(new HBEventData(HBEventType.M2ZK_REGION_OFFLINE, "MASTER"));
+      } catch (IOException e) {
+        LOG.error("Error creating event data for " + HBEventType.M2ZK_REGION_OFFLINE, e);
+      }
+      zkWrapper.createUnassignedRegion(regionName, data);
+      LOG.debug("Created UNASSIGNED zNode " + regionName + " in state " + HBEventType.M2ZK_REGION_OFFLINE);
       this.regionsInTransition.put(regionName, rs);
     }
 
@@ -966,6 +990,14 @@
     synchronized(this.regionsInTransition) {
       s = regionsInTransition.get(info.getRegionNameAsString());
       if (s == null) {
+        byte[] data = null;
+        try {
+          data = Writables.getBytes(new HBEventData(HBEventType.M2ZK_REGION_OFFLINE, "MASTER"));
+        } catch (IOException e) {
+          LOG.error("Error creating event data for " + HBEventType.M2ZK_REGION_OFFLINE, e);
+        }
+        zkWrapper.createUnassignedRegion(info.getRegionNameAsString(), data);
+        LOG.debug("Created UNASSIGNED zNode " + info.getRegionNameAsString() + " in state " + HBEventType.M2ZK_REGION_OFFLINE);
         s = new RegionState(info, RegionState.State.UNASSIGNED);
         regionsInTransition.put(info.getRegionNameAsString(), s);
       }
@@ -1210,7 +1242,8 @@
    */
   public void setRootRegionLocation(HServerAddress address) {
     writeRootRegionLocationToZooKeeper(address);
-
+    // the root region has been assigned, remove it from transition in ZK
+    zkWrapper.deleteUnassignedRegion(HRegionInfo.ROOT_REGIONINFO.getRegionNameAsString());
     synchronized (rootRegionLocation) {
       rootRegionLocation.set(new HServerAddress(address));
       rootRegionLocation.notifyAll();
Index: src/main/java/org/apache/hadoop/hbase/master/ZKMasterAddressWatcher.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/ZKMasterAddressWatcher.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/master/ZKMasterAddressWatcher.java	(working copy)
@@ -74,7 +74,7 @@
     } else if(type.equals(EventType.NodeCreated) &&
         event.getPath().equals(this.zookeeper.clusterStateZNode)) {
       LOG.debug("Resetting watch on cluster state node.");
-      this.zookeeper.setClusterStateWatch(this);
+      this.zookeeper.setClusterStateWatch();
     }
   }
 
@@ -87,7 +87,7 @@
       try {
         LOG.debug("Waiting for master address ZNode to be deleted " +
           "(Also watching cluster state node)");
-        this.zookeeper.setClusterStateWatch(this);
+        this.zookeeper.setClusterStateWatch();
         wait();
       } catch (InterruptedException e) {
       }
@@ -110,7 +110,7 @@
       }
       if(this.zookeeper.writeMasterAddress(address)) {
         this.zookeeper.setClusterState(true);
-        this.zookeeper.setClusterStateWatch(this);
+        this.zookeeper.setClusterStateWatch();
         // Watch our own node
         this.zookeeper.readMasterAddress(this);
         return true;
Index: src/main/java/org/apache/hadoop/hbase/master/ProcessRegionStatusChange.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/master/ProcessRegionStatusChange.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/master/ProcessRegionStatusChange.java	(working copy)
@@ -78,4 +78,8 @@
     }
     return this.metaRegion;
   }
+  
+  public HRegionInfo getRegionInfo() {
+    return regionInfo;
+  }
 }
\ No newline at end of file
Index: src/main/java/org/apache/hadoop/hbase/executor/EventToServiceMapping.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/executor/EventToServiceMapping.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/executor/EventToServiceMapping.java	(revision 0)
@@ -0,0 +1,78 @@
+package org.apache.hadoop.hbase.executor;
+
+import org.apache.hadoop.hbase.executor.HBEventHandler.HBEventType;
+
+/**
+ * This class has a mappings from the various events to service names.
+ */
+public class EventToServiceMapping {
+  /**
+   * The following is a list of names for the various HBaseEventHandlers in the 
+   * Master.
+   */
+  public static final String M_HANDLER_CLOSEREGION = "M-CloseRegion";
+  public static final String M_HANDLER_OPENREGION  = "M-OpenRegion";
+  public static final String M_HANDLER_ROOT_META   = "M-RootMeta";
+  public static final String M_HANDLER_MESSAGE_RS  = "M-MessageRS";
+  public static final String M_HANDLER_RS_EXPIRY   = "M-RSExpiry";
+
+  /**
+   * The following is a list of names for the various HBaseEventHandlers in the 
+   * RegionServer.
+   */
+  public static final String RS_HANDLER_CLOSEREGION = "RS-CloseRegion";
+  public static final String RS_HANDLER_OPENREGION  = "RS-OpenRegion";
+  public static final String RS_HANDLER_ROOT_META   = "RS-RootMeta";
+
+  /**
+   * Called by the HMaster. Returns a name given an event type. Each event 
+   * should map to some event handler if it is to be handled. If you want a new 
+   * HBEventType, extend this class to pass the correct event type to the super 
+   * constructor, and add a mapping to this function.
+   * @return name of the event service
+   */
+  public static String getMasterHandlerNameForHBEvent(HBEventType eventType) {
+    String handlerName = "";
+    if(eventType == HBEventType.RS2ZK_REGION_CLOSING ||
+       eventType == HBEventType.RS2ZK_REGION_CLOSED) {
+      handlerName = M_HANDLER_CLOSEREGION;
+    }
+    else if(eventType == HBEventType.RS2ZK_REGION_OPENING ||
+            eventType == HBEventType.RS2ZK_REGION_OPENED) {
+      handlerName = M_HANDLER_OPENREGION;
+    }
+    else if(eventType == HBEventType.M2RS_REQUEST_CLOSEREGION || 
+            eventType == HBEventType.M2RS_REQUEST_OPENREGION  || 
+            eventType == HBEventType.M2RS_REQUEST_METAROOT_OP) {
+      handlerName = M_HANDLER_MESSAGE_RS;
+    }
+    else if(eventType == HBEventType.ZK2M_REGIONSERVER_EXPIRY) {
+      handlerName = M_HANDLER_RS_EXPIRY;
+    }
+    else if(eventType == HBEventType.RS2ZK_REGION_ROOT_META) {
+      handlerName = M_HANDLER_ROOT_META;
+    }
+    return handlerName;
+  }
+
+  /**
+   * Called by the RegionServer. Returns a name given an event type. Each event 
+   * should map to some event handler if it is to be handled. If you want a new 
+   * HBEventType, extend this class to pass the correct event type to the super 
+   * constructor, and add a mapping to this function.
+   * @return name of the event service
+   */
+  public static String getRSHandlerNameForHBEvent(HBEventType eventType) {
+    String handlerName = "";
+    if(eventType == HBEventType.M2RS_REQUEST_CLOSEREGION) {
+      handlerName = RS_HANDLER_CLOSEREGION;
+    }
+    else if(eventType == HBEventType.M2RS_REQUEST_OPENREGION) {
+      handlerName = RS_HANDLER_OPENREGION;
+    }
+    else if(eventType == HBEventType.M2RS_REQUEST_METAROOT_OP) {
+      handlerName = RS_HANDLER_ROOT_META;
+    }
+    return handlerName;
+  }
+}
Index: src/main/java/org/apache/hadoop/hbase/executor/HBaseExecutorService.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/executor/HBaseExecutorService.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/executor/HBaseExecutorService.java	(revision 0)
@@ -0,0 +1,101 @@
+package org.apache.hadoop.hbase.executor;
+
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+
+/**
+ * This is a generic HBase executor service. This component abstract a
+ * threadpool, a queue to which jobs can be submitted and a Runnable that
+ * handles the object that is added to the queue.
+ *
+ * In order to create a new HBExecutorService, you need to do:
+ *   HBExecutorService.startExecutorService("myService");
+ *
+ * In order to use the service created above, you need to override the
+ * HBEventHandler class and create an event type that submits to this service.
+ *
+ */
+public class HBaseExecutorService
+{
+  private static final Log LOG = LogFactory.getLog(HBaseExecutorService.class);
+  // default number of threads in the pool
+  private int corePoolSize_ = 1;
+  // max number of threads - maximum concurrency
+  private int maximumPoolSize_ = 5;
+  // how long to retain excess threads
+  private long keepAliveTimeInMillis_ = 1000;
+  // the thread pool executor that services the requests
+  ThreadPoolExecutor threadPoolExecutor_;
+  // work queue to use - unbounded queue
+  BlockingQueue<Runnable> workQueue_ = new LinkedBlockingQueue<Runnable>();
+  // name for this executor service
+  String name_;
+  // hold the all the executors created in a map addressable by their names
+  static Map<String, HBaseExecutorService> executorServicesMap_ =
+    Collections.synchronizedMap(new HashMap<String, HBaseExecutorService>());
+
+
+  /**
+   * Start an executor service with a given name. If there was a service already
+   * started with the same name, this throws a RuntimeException.
+   * @param name Name of the service to start.
+   */
+  public static void startExecutorService(String name) {
+    if(executorServicesMap_.get(name) != null) {
+      throw new RuntimeException("An executor service with the name " + name + " is already running!");
+    }
+    HBaseExecutorService hbes = new HBaseExecutorService(name);
+    executorServicesMap_.put(name, hbes);
+    LOG.debug("Starting executor service: " + name);
+  }
+
+  /**
+   * This method is an accessor for all the HBExecutorServices running so far
+   * addressable by name. If there is no such service, then it returns null.
+   */
+  public static HBaseExecutorService getExecutorService(String name) {
+    HBaseExecutorService executor = executorServicesMap_.get(name);
+    if(executor == null) {
+      LOG.debug("Executor service [" + name + "] not found.");
+    }
+    return executor;
+  }
+  
+  public static void shutdown() {
+    for(Entry<String, HBaseExecutorService> entry : executorServicesMap_.entrySet()) {
+      entry.getValue().threadPoolExecutor_.shutdown();
+    }
+    executorServicesMap_.clear();
+  }
+
+  protected HBaseExecutorService(String name) {
+    name_ = name;
+    // create the thread pool executor
+    threadPoolExecutor_ = new ThreadPoolExecutor(
+                                corePoolSize_,
+                                maximumPoolSize_,
+                                keepAliveTimeInMillis_,
+                                TimeUnit.MILLISECONDS,
+                                workQueue_
+                                );
+    // name the threads for this threadpool
+    threadPoolExecutor_.setThreadFactory(new NamedThreadFactory(name_));
+  }
+
+  /**
+   * Submit the event to the queue for handling.
+   * @param event
+   */
+  public void submit(Runnable event) {
+    threadPoolExecutor_.execute(event);
+  }
+}
Index: src/main/java/org/apache/hadoop/hbase/executor/TestZKUnassignedWatcher.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/executor/TestZKUnassignedWatcher.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/executor/TestZKUnassignedWatcher.java	(revision 0)
@@ -0,0 +1,277 @@
+package org.apache.hadoop.hbase.executor;
+
+
+import java.io.ByteArrayOutputStream;
+import java.io.DataOutputStream;
+import java.io.File;
+import java.io.IOException;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.MiniZooKeeperCluster;
+import org.apache.hadoop.hbase.executor.HBEventHandler.HBEventType;
+import org.apache.hadoop.hbase.master.HMaster;
+import org.apache.hadoop.hbase.master.ZKUnassignedWatcher;
+import org.apache.hadoop.hbase.master.handler.MasterSendMsgToRSHandler;
+import org.apache.hadoop.hbase.regionserver.HRegionServer;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper;
+import org.apache.log4j.Level;
+import org.apache.log4j.Logger;
+import org.apache.zookeeper.CreateMode;
+import org.apache.zookeeper.data.Stat;
+
+public class TestZKUnassignedWatcher {
+  private static final Log LOG = LogFactory.getLog(TestZKUnassignedWatcher.class);
+  
+  public static String regionName = "R1";
+
+  public static void main(String[] args) throws Exception {
+    // make the root logger display only errors
+    Logger.getRootLogger().setLevel(Level.ERROR);
+    // enable debugging for our package
+    Logger.getLogger("com.facebook.hbase.master").setLevel(Level.DEBUG);
+
+    // create an HBase config with zookeeper info
+    String zkServer = "localhost";
+    int zkPort = 21810;
+    String hbBaseDir = "/tmp/kranganathan-ZK";
+    
+    MiniZooKeeperCluster miniZkCluster = new MiniZooKeeperCluster();
+    miniZkCluster.setClientPort(zkPort);
+    miniZkCluster.startup(new File(hbBaseDir));
+    LOG.info("Brought up mini ZK cluster on " + zkServer + ":" + zkPort);
+    Thread.sleep(1000);
+    
+    Configuration c = new Configuration();
+    c.set("hbase.zookeeper.quorum", zkServer);
+    c.set("hbase.zookeeper.property.clientPort", "" + zkPort);
+
+    // start the services in HMaster
+    startServices_MASTER(c);    
+    // start the services in the RS
+    startServices_RS(c);
+    
+    System.out.println("\n\n-------- testSimulatedRegionServer ---------\n");
+    cleanUpZK(regionName);
+    testSimulatedRegionServer();
+    
+    Thread.sleep(1000);
+    
+    System.out.println("\n\n-------- testMasterRegionServerEvents ---------\n");
+    cleanUpZK(regionName);
+    testMasterRegionServerEvents();
+  }
+  
+  public static void testSimulatedRegionServer() throws Exception {
+    // close region R1 on RS1
+  simulateCloseRegion_RS(regionName, "rs1.hostname");
+  // let some time pass - time to close region
+  Thread.sleep(1000);
+  // open region R1 on RS2
+  simulateOpenRegion_RS(regionName, "rs2.hostname");    
+  }
+  
+  
+  public static boolean masterRegionServerEventsDone = false;
+  public static void testMasterRegionServerEvents() throws InterruptedException {
+    // clean up old state
+    cleanUpZK(regionName);
+
+    // register an events listener to handle communication with the RS
+    EventsListener listener = new EventsListener();
+    HBEventHandler.registerListener(listener);
+    // fire off a close region event
+    new MasterSendMsgToRSHandler(HBEventType.M2RS_REQUEST_CLOSEREGION, regionName, "someRegionServer").submit();
+    
+    while(!masterRegionServerEventsDone) {
+      Thread.sleep(1000);
+    }
+  }
+  
+  public static class EventsListener implements HBEventHandler.IEventHandlerListener {
+    private static final Log LOG = LogFactory.getLog(EventsListener.class);
+
+    @Override
+    public void afterProcess(HBEventHandler event) {
+      LOG.debug((event.isRegionServer()?"REGIONSERVER":"MASTER") + " executed Event = " + event.getHBEvent()); //+ ", region = " + event.getRegionName());
+      // handle RS events
+      if(event.isRegionServer()) {
+        // if we have opened a region, the test is done
+        if(event.getHBEvent() == HBEventType.M2RS_REQUEST_OPENREGION) {
+          masterRegionServerEventsDone = true;
+        }
+      }
+      // handle Master events on the RS side
+      else {
+        try {
+          // pass on the request to close a region
+          if(event.getHBEvent() == HBEventType.M2RS_REQUEST_CLOSEREGION) {
+            simulateCloseRegion_RS(regionName, "rs1.hostname");
+  //          new RSCloseRegionHandler(event.getHBEvent(), regionName).submit();
+          }
+          // pass on the request to open a region
+          else if(event.getHBEvent() == HBEventType.M2RS_REQUEST_OPENREGION) {
+            simulateOpenRegion_RS(regionName, "rs2.hostname");
+  //          new RSOpenRegionHandler(event.getHBEvent(), regionName).submit();
+          }
+        } catch (Exception e) {
+          e.printStackTrace();
+        }
+      }
+    }
+
+    @Override
+    public void beforeProcess(HBEventHandler event) {
+      
+    }
+    
+  }
+  
+  public static void startServices_MASTER(Configuration conf) throws IOException {
+    // start the "close region" executor service
+    HBaseExecutorService.startExecutorService(EventToServiceMapping.M_HANDLER_CLOSEREGION);
+    // start the "open region" executor service
+    HBaseExecutorService.startExecutorService(EventToServiceMapping.M_HANDLER_OPENREGION);
+    // start the executor service to handle ROOT and META messages
+    HBaseExecutorService.startExecutorService(EventToServiceMapping.M_HANDLER_ROOT_META);
+    // start the executor service to send requests to region servers
+    HBaseExecutorService.startExecutorService(EventToServiceMapping.M_HANDLER_MESSAGE_RS);
+    // start the executor service to handle expired region servers
+    HBaseExecutorService.startExecutorService(EventToServiceMapping.M_HANDLER_RS_EXPIRY);
+    // ZooKeeper wrapper that watches all ZK events and exposes helpers
+    ZooKeeperWrapper.createInstance(conf, HMaster.class.getName());
+    // create the unassigned regions watcher
+    ZKUnassignedWatcher.start();
+  }
+  
+  public static void startServices_RS(Configuration conf) {
+    // start the "close region" executor service
+    HBaseExecutorService.startExecutorService(EventToServiceMapping.RS_HANDLER_CLOSEREGION);
+    // start the "open region" executor service
+    HBaseExecutorService.startExecutorService(EventToServiceMapping.RS_HANDLER_OPENREGION);
+    // start the executor service to handle ROOT and META messages
+    HBaseExecutorService.startExecutorService(EventToServiceMapping.RS_HANDLER_ROOT_META);    
+    // ZooKeeper wrapper that watches all ZK events and exposes helpers
+    ZooKeeperWrapper.createInstance(conf, HRegionServer.class.getName());
+  }
+
+  public static void cleanUpZK(String regionName) {
+    ZooKeeperWrapper zkWrapper = ZooKeeperWrapper.getInstance(HMaster.class.getName());
+    String r1InUnassignedRegions = zkWrapper.getZNode(zkWrapper.getRegionInTransitionZNode(), regionName);
+
+    // Clean up old state: if the region node already exists in unassigned, 
+    // then delete it
+    if(zkWrapper.exists(r1InUnassignedRegions, true)) {
+      LOG.debug("Deleting ZNode " + r1InUnassignedRegions + " in ZooKeeper...");
+      zkWrapper.deleteZNode(r1InUnassignedRegions, -1);
+    }
+  }
+
+  /**
+   * Simulate the closing region part of the transaction from a region server. The
+   * following transaction is mimicked on behalf of the RS.
+   *
+   * M  -> RS : close R1
+   * RS -> ZK : create (/UNASSIGNED/R1[CLOSING,TS1 VERSION = 1]
+   * M  -> ZK : watch /UNASSIGNED/R1
+   * ZK -> M  : Updated /UNASSIGNED/R1 with [CLOSED,TS2 VERSION = 2]
+   */
+  static int simulateCloseRegion_RS(String regionName, String hostname) throws Exception {
+    int version = -1;
+    ZooKeeperWrapper zkWrapper = ZooKeeperWrapper.getInstance(HRegionServer.class.getName());
+    String r1InUnassignedRegions = zkWrapper.getZNode(zkWrapper.getRegionInTransitionZNode(), regionName);
+
+    // Clean up old state: if the region node already exists in unassigned, 
+    // then delete it
+    if(zkWrapper.exists(r1InUnassignedRegions, true)) {
+      LOG.debug("Deleting ZNode " + r1InUnassignedRegions + " in ZooKeeper...");
+      zkWrapper.deleteZNode(r1InUnassignedRegions, -1);
+    }
+
+    // create the region node in the unassigned directory
+    LOG.debug("Creating ZNode " + r1InUnassignedRegions);
+    Thread.sleep(20);
+    zkWrapper.createZNodeIfNotExists(r1InUnassignedRegions, null, CreateMode.PERSISTENT, true);
+
+    ByteArrayOutputStream  bos = new ByteArrayOutputStream ();
+    DataOutputStream dos = new DataOutputStream(bos);
+
+    // update the data for "regionName" znode in unassgined to CLOSING
+    bos.reset();
+    dos.writeByte(HBEventType.RS2ZK_REGION_CLOSING.getByteValue());
+    dos.writeUTF(hostname);
+    dos.writeLong(System.currentTimeMillis());
+    dos.flush();
+    version++;
+    LOG.debug("Updating ZNode " + r1InUnassignedRegions + " with [" + HBEventType.RS2ZK_REGION_CLOSING + "] version=" + version);
+    zkWrapper.writeZNode(r1InUnassignedRegions, bos.toByteArray(), version, true);
+
+    // let some time pass - time to close region
+    Thread.sleep(1000);
+
+    // update the state of the region to CLOSED
+    bos.reset();
+    dos.writeByte(HBEventType.RS2ZK_REGION_CLOSED.getByteValue());
+    dos.writeUTF(hostname);
+    dos.writeLong(System.currentTimeMillis());
+    dos.flush();
+    version++;
+    LOG.debug("Updating ZNode " + r1InUnassignedRegions + " with [" + HBEventType.RS2ZK_REGION_CLOSED + "] version=" + version);
+    zkWrapper.writeZNode(r1InUnassignedRegions, bos.toByteArray(), version, true);
+
+    return version;
+  }
+
+  /**
+   * Simulate the opening region part of the transaction from a region server. The
+   * following transaction is mimicked on behalf of the RS.
+   *
+   * M  -> RS : open R1
+   * RS -> ZK : update/create (/UNASSIGNED/R1[OPENING,TS1 VERSION = n]
+   *       RS : open R1
+   * RS -> ZK : update /UNASSIGNED/R1 with [OPENED,TS2 VERSION = n+1]
+   */
+  static int simulateOpenRegion_RS(String regionName, String hostname) throws Exception {
+    ZooKeeperWrapper zkWrapper = ZooKeeperWrapper.getInstance(HRegionServer.class.getName());
+    String r1InUnassignedRegions = zkWrapper.getZNode(zkWrapper.getRegionInTransitionZNode(), regionName);
+
+    // Make sure the region is in the closed state. Also get the version number.
+    Stat stat = new Stat();
+    byte[] data = zkWrapper.readZNode(r1InUnassignedRegions, stat);
+    HBEventType rsEvent = HBEventType.fromByte(data[0]);
+    if(rsEvent != HBEventType.RS2ZK_REGION_CLOSED) {
+      throw new Exception("Wrong state - cannot open region in state " + rsEvent);
+    }
+    int version = stat.getVersion();
+    
+    ByteArrayOutputStream  bos = new ByteArrayOutputStream ();
+    DataOutputStream dos = new DataOutputStream(bos);
+
+    // update the data for "regionName" znode in unassigned to OPENING
+    bos.reset();
+    dos.writeByte(HBEventType.RS2ZK_REGION_OPENING.getByteValue());
+    dos.writeUTF(hostname);
+    dos.writeLong(System.currentTimeMillis());
+    dos.flush();
+    LOG.debug("Updating ZNode " + r1InUnassignedRegions + " with [" + HBEventType.RS2ZK_REGION_OPENING + "] version=" + version);
+    zkWrapper.writeZNode(r1InUnassignedRegions, bos.toByteArray(), version, true);
+
+    Thread.sleep(1000);
+    // let some time pass - time to open region
+    LOG.debug("Process open region " + regionName);
+
+    // update the state of the region to OPENED
+    bos.reset();
+    dos.writeByte(HBEventType.RS2ZK_REGION_OPENED.getByteValue());
+    dos.writeUTF(hostname);
+    dos.writeLong(System.currentTimeMillis());
+    dos.flush();
+    version++;
+    LOG.debug("Updating ZNode " + r1InUnassignedRegions + " with [" + HBEventType.RS2ZK_REGION_OPENED + "] version=" + version);
+    zkWrapper.writeZNode(r1InUnassignedRegions, bos.toByteArray(), version, true);
+
+    return version;
+  }
+
+}
Index: src/main/java/org/apache/hadoop/hbase/executor/NamedThreadFactory.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/executor/NamedThreadFactory.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/executor/NamedThreadFactory.java	(revision 0)
@@ -0,0 +1,23 @@
+package org.apache.hadoop.hbase.executor;
+
+import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * Returns a named thread with a specified prefix.
+ *
+ */
+public class NamedThreadFactory implements ThreadFactory
+{
+  private String threadPrefix_;
+  private AtomicInteger threadId_ = new AtomicInteger(0);
+
+  public NamedThreadFactory(String threadPrefix) {
+    threadPrefix_ = threadPrefix;
+  }
+
+  @Override
+  public Thread newThread(Runnable r) {
+    return new Thread(r, threadPrefix_ + "-" + threadId_.incrementAndGet());
+  }
+}
Index: src/main/java/org/apache/hadoop/hbase/executor/HBEventData.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/executor/HBEventData.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/executor/HBEventData.java	(revision 0)
@@ -0,0 +1,73 @@
+package org.apache.hadoop.hbase.executor;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+
+import org.apache.hadoop.hbase.HMsg;
+import org.apache.hadoop.hbase.executor.HBEventHandler.HBEventType;
+import org.apache.hadoop.io.Writable;
+
+public class HBEventData implements Writable {
+  private HBEventType hbEvent;
+  private String rsName;
+  private long timeStamp;
+  private HMsg hmsg;
+  
+  public HBEventData() {
+  }
+
+  public HBEventData(HBEventType hbEvent, String rsName) {
+    this(hbEvent, rsName, null);
+  }
+
+  public HBEventData(HBEventType hbEvent, String rsName, HMsg hmsg) {
+    this.hbEvent = hbEvent;
+    this.rsName = rsName;
+    this.timeStamp = System.currentTimeMillis();
+    this.hmsg = hmsg;
+  }
+  
+  public HBEventType getHbEvent() {
+    return hbEvent;
+  }
+
+  public String getRsName() {
+    return rsName;
+  }
+
+  public long getTimeStamp() {
+    return timeStamp;
+  }
+
+  public HMsg getHmsg() {
+    return hmsg;
+  }
+
+  @Override
+  public void readFields(DataInput in) throws IOException {
+    // the event type byte
+    hbEvent = HBEventType.fromByte(in.readByte());
+    // the hostname of the RS sending the data
+    rsName = in.readUTF();
+    // the timestamp
+    timeStamp = in.readLong();
+    if(in.readBoolean()) {
+      // deserialized the HMsg from ZK
+      hmsg = new HMsg();
+      hmsg.readFields(in);
+    }
+  }
+
+  @Override
+  public void write(DataOutput out) throws IOException {
+    out.writeByte(hbEvent.getByteValue());
+    out.writeUTF(rsName);
+    out.writeLong(System.currentTimeMillis());
+    out.writeBoolean((hmsg != null));
+    if(hmsg != null) {
+      hmsg.write(out);
+    }
+  }
+
+}
Index: src/main/java/org/apache/hadoop/hbase/executor/HBEventHandler.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/executor/HBEventHandler.java	(revision 0)
+++ src/main/java/org/apache/hadoop/hbase/executor/HBEventHandler.java	(revision 0)
@@ -0,0 +1,236 @@
+package org.apache.hadoop.hbase.executor;
+
+import java.io.ByteArrayOutputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.HMsg;
+import org.apache.hadoop.hbase.master.ServerManager;
+import org.apache.hadoop.hbase.master.handler.MasterCloseRegionHandler;
+
+
+public abstract class HBEventHandler implements Runnable
+{
+  private static final Log LOG = LogFactory.getLog(HBEventHandler.class);
+  // type of event this object represents
+  protected HBEventType eventType = HBEventType.NONE;
+  // is this a region server or master?
+  protected boolean isRegionServer;
+  // listeners that are called before and after an event is processed
+  protected static List<IEventHandlerListener> eventHandlerListeners_ = 
+    Collections.synchronizedList(new ArrayList<IEventHandlerListener>());  
+  // static instances needed by the handlers
+  protected static ServerManager serverManager;
+  
+  /**
+   * Note that this has to be called first BEFORE the subclass constructors.
+   * @param serverManager
+   */
+  public static void init(ServerManager serverManager) {
+    HBEventHandler.serverManager = serverManager;
+  }
+  
+  /**
+   * This interface provides hooks to listen to various events received by the 
+   * queue. A class implementing this can listen to the updates by calling 
+   * registerListener and stop receiving updates by calling unregisterListener
+   */
+  public interface IEventHandlerListener {
+    /**
+     * Called before any event is processed
+     */
+    public void beforeProcess(HBEventHandler event);
+    /**
+     * Called after any event is processed
+     */
+    public void afterProcess(HBEventHandler event);
+  }
+
+  /**
+   * These are a list of HBase events that can be handled by the various
+   * HBaseExecutorService's. All the events are serialized as byte values.
+   */
+  public enum HBEventType {
+    NONE (-1),
+    // Messages originating from RS (NOTE: there is NO direct communication from 
+    // RS to Master). These are a result of RS updates into ZK.
+    RS2ZK_REGION_CLOSING      (1),   // RS is in process of closing a region
+    RS2ZK_REGION_CLOSED       (2),   // RS has finished closing a region
+    RS2ZK_REGION_OPENING      (3),   // RS is in process of opening a region
+    RS2ZK_REGION_OPENED       (4),   // RS has finished opening a region
+    RS2ZK_REGION_ROOT_META    (5),   // Handle root and meta region related messages
+    
+    // Messages originating from Master to RS. Directly sent to RS, not through 
+    // ZK. These messages are be IDEMPOTENT and CAN BE LOST. These are handled 
+    // on the RS side as well as the Master.
+    M2RS_REQUEST_CLOSEREGION  (32),  // Master asks an RS to close a region
+    M2RS_REQUEST_OPENREGION   (33),  // Master asks an RS to open a region
+    M2RS_REQUEST_METAROOT_OP  (34),  // Master asks RS to do something to ROOT/META
+    
+    // Updates from master to ZK. This is done by the master and there is 
+    // nothing to process by either Master or RS
+    M2ZK_REGION_OFFLINE       (50),  // Master adds this region as offline in ZK
+    
+    // Messages originating from ZK, watched by Master
+    ZK2M_REGIONSERVER_EXPIRY  (64),  // ZK message to master on RS expiry
+
+    // Messages originating from Client to the Master (Direct)
+    C2M_CREATE_TABLE          (90),  // Client creating a new table
+    C2M_DELETE_TABLE          (91),  // Client deleting a table
+    C2M_MODIFY_TABLE          (92),  // Client modifying a table
+    C2M_ADD_FAMILY            (95),  // Client adding a family to a table
+    C2M_DELETE_FAMILY         (96),  // Client deleting a family from a table
+    C2M_MODIFY_FAMILY         (97),  // Client modifying a family of a table
+    C2M_ENABLE_TABLE          (100), // Client enabling a table
+    C2M_DISABLE_TABLE         (101), // Client disabling a table
+    
+    // Messages origination from Master and for Master
+    M_ASSIGN_REGIONS          (112),  // Master wants immediate assignment of regions
+    M_UNASSIGN_REGIONS        (113);  // Master wants immediate unassignment of regions
+    
+    private final byte value;
+
+    HBEventType(int intValue) {
+      this.value = (byte)intValue;
+    }
+
+    public byte getByteValue() {
+      return value;
+    }
+
+    public static HBEventType fromByte(byte value) {
+      switch(value) {
+        case  -1: return HBEventType.NONE;
+        case  1 : return HBEventType.RS2ZK_REGION_CLOSING;
+        case  2 : return HBEventType.RS2ZK_REGION_CLOSED;
+        case  3 : return HBEventType.RS2ZK_REGION_OPENING;
+        case  4 : return HBEventType.RS2ZK_REGION_OPENED;
+        case  5 : return HBEventType.RS2ZK_REGION_ROOT_META;
+        case  32: return HBEventType.M2RS_REQUEST_CLOSEREGION;
+        case  33: return HBEventType.M2RS_REQUEST_OPENREGION;
+        case  34: return HBEventType.M2RS_REQUEST_METAROOT_OP;
+        case  50: return HBEventType.M2ZK_REGION_OFFLINE;
+        case  64: return HBEventType.ZK2M_REGIONSERVER_EXPIRY;
+        case  96: return HBEventType.C2M_CREATE_TABLE;
+
+        default:
+          throw new RuntimeException("Invalid byte value for conversion to RSEventType");
+      }
+    }
+  }
+  
+  public static byte[] serialize(HBEventType hbEvent, String rsName, HMsg hmsg) {
+    ByteArrayOutputStream  bos = new ByteArrayOutputStream ();
+    DataOutputStream dos = new DataOutputStream(bos);
+
+    try {
+      dos.writeByte(hbEvent.getByteValue());
+      dos.writeUTF(rsName);
+      dos.writeLong(System.currentTimeMillis());
+      if(hmsg != null) {
+        hmsg.write(dos);
+      }
+    dos.flush();
+    } catch (IOException e) {
+      LOG.error("Cound not serialize HBEventType " + hbEvent, e);
+    }
+
+    byte[] data = bos.toByteArray();
+    return data;
+  }
+
+  /**
+   * Default base class constructor.
+   * @param handlerName
+   * @param eventType
+   * @param regionName
+   */
+  public HBEventHandler(boolean isRegionServer, HBEventType eventType) {
+    this.isRegionServer = isRegionServer;
+    this.eventType = eventType;
+  }
+  
+  /**
+   * This is a wrapper around process, used to update listeners before and after 
+   * events are processed. 
+   */
+  public void run() {
+    // fire all beforeProcess listeners
+    for(int i = 0; i < eventHandlerListeners_.size(); ++i) {
+      eventHandlerListeners_.get(i).beforeProcess(this);
+    }
+    
+    // call the main process function
+    process();
+
+    // fire all afterProcess listeners
+    for(int i = 0; i < eventHandlerListeners_.size(); ++i) {
+      LOG.debug("Firing " + eventHandlerListeners_.get(i).getClass().getName() + 
+                ".afterProcess event listener for event " + eventType);
+      eventHandlerListeners_.get(i).afterProcess(this);
+    }
+  }
+  
+  /**
+   * This method is the main processing loop to be implemented by the various 
+   * subclasses.
+   */
+  public abstract void process();
+  
+  /**
+   * Subscribe to updates before and after processing events
+   */
+  public static void registerListener(IEventHandlerListener listener) {
+    eventHandlerListeners_.add(listener);
+  }
+  
+  /**
+   * Stop receiving updates before and after processing events
+   */
+  public static void unregisterListener(IEventHandlerListener listener) {
+    eventHandlerListeners_.remove(listener);
+  }
+  
+  public boolean isRegionServer() {
+    return isRegionServer;
+  }
+
+  /**
+   * Return the name for this event type.
+   * @return
+   */
+  public String getEventHandlerName() {
+    return isRegionServer?
+           EventToServiceMapping.getRSHandlerNameForHBEvent(eventType):
+           EventToServiceMapping.getMasterHandlerNameForHBEvent(eventType);
+  }
+  
+  /**
+   * Return the event type
+   * @return
+   */
+  public HBEventType getHBEvent() {
+    return eventType;
+  }
+
+  /**
+   * Submits this event object to the correct executor service. This is causes
+   * this object to get executed by the correct ExecutorService.
+   */
+  public void submit() {
+    HBaseExecutorService.getExecutorService(getEventHandlerName()).submit(this);
+  }
+  
+  /**
+   * Executes this event object in the caller's thread. This is a synchronous 
+   * way of executing the event.
+   */
+  public void execute() {
+    this.run();
+  }
+}
Index: src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java
===================================================================
--- src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java	(revision 952845)
+++ src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java	(working copy)
@@ -222,13 +222,16 @@
     }
 
     /**
-     * Get this watcher's ZKW, instanciate it if necessary.
+     * Get this watcher's ZKW, instantiate it if necessary.
      * @return ZKW
      * @throws java.io.IOException if a remote or network exception occurs
      */
     public synchronized ZooKeeperWrapper getZooKeeperWrapper() throws IOException {
       if(zooKeeperWrapper == null) {
-        zooKeeperWrapper = new ZooKeeperWrapper(conf, this);
+        String zkWrapperName = HConnectionManager.class.getName() + "-" + 
+                               ZooKeeperWrapper.getZookeeperClusterKey(conf);
+        zooKeeperWrapper = ZooKeeperWrapper.createInstance(conf, zkWrapperName);
+        zooKeeperWrapper.registerListener(this);
       }
       return zooKeeperWrapper;
     }
