Index: bin/hbase
===================================================================
--- bin/hbase	(revision 1470935)
+++ bin/hbase	(working copy)
@@ -85,6 +85,7 @@
   echo "  rest             run an HBase REST server" 
   echo "  thrift           run the HBase Thrift server" 
   echo "  thrift2          run the HBase Thrift2 server"
+  echo "  clean            run the HBase clean up script"
   echo ""
   echo "PACKAGE MANAGEMENT"
   echo "  classpath        dump hbase CLASSPATH"
@@ -306,6 +307,9 @@
   if [ "$1" != "stop" ] ; then
     HBASE_OPTS="$HBASE_OPTS $HBASE_ZOOKEEPER_OPTS"
   fi
+elif [ "$COMMAND" = "clean" ] ; then
+  "$bin"/hbase-cleanup.sh $@
+  exit $?
 
 elif [ "$COMMAND" = "classpath" ] ; then
   echo $CLASSPATH
Index: bin/hbase-cleanup.sh
===================================================================
--- bin/hbase-cleanup.sh	(revision 0)
+++ bin/hbase-cleanup.sh	(working copy)
@@ -0,0 +1,142 @@
+#!/usr/bin/env bash
+#
+#/**
+# * Licensed to the Apache Software Foundation (ASF) under one
+# * or more contributor license agreements.  See the NOTICE file
+# * distributed with this work for additional information
+# * regarding copyright ownership.  The ASF licenses this file
+# * to you under the Apache License, Version 2.0 (the
+# * "License"); you may not use this file except in compliance
+# * with the License.  You may obtain a copy of the License at
+# *
+# *     http://www.apache.org/licenses/LICENSE-2.0
+# *
+# * Unless required by applicable law or agreed to in writing, software
+# * distributed under the License is distributed on an "AS IS" BASIS,
+# * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# * See the License for the specific language governing permissions and
+# * limitations under the License.
+# */
+#
+# cleans hbase related data from zookeeper and hdfs if no hbase process is alive.
+#
+# Environment Variables
+#
+#   HBASE_REGIONSERVERS    File naming remote hosts.
+#     Default is ${HADOOP_CONF_DIR}/regionservers
+#   HADOOP_CONF_DIR  Alternate conf dir. Default is ${HADOOP_HOME}/conf.
+#   HBASE_CONF_DIR  Alternate hbase conf dir. Default is ${HBASE_HOME}/conf.
+#   HADOOP_SLAVE_SLEEP Seconds to sleep between spawning remote commands.
+#   HADOOP_SLAVE_TIMEOUT Seconds to wait for timing out a remote command.
+#   HADOOP_SSH_OPTS Options passed to ssh when running remote commands.
+#
+
+usage="Usage: hbase-cleanup.sh [--formatZK] [--formatFS]"
+
+bin=`dirname "$0"`
+bin=`cd "$bin">/dev/null; pwd`
+
+# This will set HBASE_HOME, etc.
+. "$bin"/hbase-config.sh
+
+if [ "$1" = "--formatZK" ];then
+  formatzk=$1
+  shift
+fi
+if [ "$1" = "--formatFS" ];then
+  formatfs=$1
+  shift
+fi
+
+if [ "$formatzk$formatfs" = "" ];then
+  exit 1
+fi
+
+distMode=`$bin/hbase org.apache.hadoop.hbase.util.HBaseConfTool hbase.cluster.distributed | head -n 1`
+
+if [ "$distMode" == 'false' ];then
+  echo "Skipping hbase data clearing in standalone mode." 2>&1
+  exit 1;
+fi
+
+zparent=`$bin/hbase org.apache.hadoop.hbase.util.HBaseConfTool zookeeper.znode.parent`
+if [ "$zparent" == "null" ]; then zparent="/hbase"; fi
+
+hrootdir=`$bin/hbase org.apache.hadoop.hbase.util.HBaseConfTool hbase.rootdir`
+if [ "$hrootdir" == "null" ]; then hrootdir="file:///tmp/hbase-${USER}/hbase"; fi
+
+check_for_znodes() {
+  command=$1;
+  case $command in
+    regionservers)
+      zchild=`$bin/hbase org.apache.hadoop.hbase.util.HBaseConfTool zookeeper.znode.rs`
+      if [ "$zchild" == "null" ]; then zchild="rs"; fi
+      ;;
+    backupmasters)
+      zchild=`$bin/hbase org.apache.hadoop.hbase.util.HBaseConfTool zookeeper.znode.backup.masters`
+      if [ "$zchild" == "null" ]; then zchild="backup-masters"; fi
+      ;;
+  esac
+  znodes=`"$bin"/hbase zkcli ls $zparent/$zchild 2>&1 | tail -1 | sed "s/\[//" | sed "s/\]//"`
+  if [ "$znodes" != "" ]; then
+    echo -n "ZNode(s) [${znodes}] of $command are not expired. Exiting without cleaning hbase data."
+    echo #force a newline	
+    exit 1;
+  else
+    echo -n "All ZNode(s) of $command are expired."
+  fi
+  echo #force a newline
+}
+
+execute_zk_command() {
+  command=$1;
+  "$bin"/hbase zkcli $command 2>&1
+}
+
+execute_hdfs_command() {
+  command=$1;
+  "$bin"/hbase org.apache.hadoop.fs.FsShell $command 2>&1
+}
+
+clean_up() {
+  while [ $# -gt 0 ]
+  do
+    if [ "$1" == "--formatZK" ]; then
+      execute_zk_command "rmr ${zparent}";
+    elif [ "$1" == "--formatFS" ]; then
+      execute_hdfs_command "-rmr ${hrootdir}"
+    fi
+    shift
+  done
+}
+
+check_znode_exists() {
+  command=$1
+  "$bin"/hbase zkcli stat $command 2>&1 | grep "Node does not exist\|Connection refused"
+}
+
+check_znode_exists $zparent
+if [ $? -ne 0 ]; then
+  # make sure the online region server(s) znode(s) have been deleted before continuing
+  check_for_znodes regionservers
+  # make sure the backup master(s) znode(s) has been deleted before continuing
+  check_for_znodes backupmasters
+  # make sure the master znode has been deleted before continuing
+  zmaster=`$bin/hbase org.apache.hadoop.hbase.util.HBaseConfTool zookeeper.znode.master`
+  if [ "$zmaster" == "null" ]; then zmaster="master"; fi
+    zmaster=$zparent/$zmaster
+    check_znode_exists $zmaster
+  if [ $? -ne 0 ]; then
+    echo -n "Master ZNode is not expired. Exiting without cleaning hbase data."
+    echo #force a new line
+    exit 1
+  else
+    echo "Active Master ZNode also expired."
+  fi
+  echo #force a newline
+else
+  echo "HBase parent znode ${zparent} does not exist."
+fi
+
+# cleans zookeeper and hdfs data.
+clean_up $formatzk $formatfs
Index: bin/hbase-daemon.sh
===================================================================
--- bin/hbase-daemon.sh	(revision 1470935)
+++ bin/hbase-daemon.sh	(working copy)
@@ -36,7 +36,7 @@
 
 usage="Usage: hbase-daemon.sh [--config <conf-dir>]\
  (start|stop|restart|autorestart) <hbase-command> \
- <args...>"
+ [--formatZK] [--formatFS] <args...>"
 
 # if no args specified, show usage
 if [ $# -le 1 ]; then
@@ -57,6 +57,19 @@
 command=$1
 shift
 
+if [ "$startStop" = "start" ];then
+  for i in 1 2
+  do
+    if [ "$1" = "--formatZK" ];then
+      formatzk=$1
+      shift
+    elif [ "$1" = "--formatFS" ];then
+      formatfs=$1
+      shift
+    fi
+  done
+fi
+
 hbase_rotate_log ()
 {
     log=$1;
@@ -98,6 +111,10 @@
     fi
 }
 
+clean_hbase_data() {
+  "$bin"/hbase clean $formatzk $formatfs
+}
+
 wait_until_done ()
 {
     p=$1
@@ -172,6 +189,7 @@
 
 (start)
     check_before_start
+    clean_hbase_data
     nohup $thiscmd --config "${HBASE_CONF_DIR}" internal_start $command $args < /dev/null > /dev/null 2>&1  &
   ;;
 
Index: bin/start-hbase.sh
===================================================================
--- bin/start-hbase.sh	(revision 1470935)
+++ bin/start-hbase.sh	(working copy)
@@ -24,7 +24,7 @@
 
 # Start hadoop hbase daemons.
 # Run this on master node.
-usage="Usage: start-hbase.sh"
+usage="Usage: start-hbase.sh [autorestart] [--formatZK] [--formatFS]"
 
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin">/dev/null; pwd`
@@ -37,12 +37,19 @@
 then
   exit $errCode
 fi
+for i in 1 2 3
+do
+  if [ "$1" = "autorestart" ];then
+    commandToRun="autorestart"
+  elif [ "$1" = "--formatZK" ];then
+    formatzk=$1
+  elif [ "$1" = "--formatFS" ];then
+    formatfs=$1
+  fi
+  shift
+done
 
-
-if [ "$1" = "autorestart" ]
-then
-  commandToRun="autorestart"
-else 
+if [ "$commandToRun" = "" ];then
   commandToRun="start"
 fi
 
@@ -52,10 +59,10 @@
 
 if [ "$distMode" == 'false' ] 
 then
-  "$bin"/hbase-daemon.sh $commandToRun master
+  "$bin"/hbase-daemon.sh $commandToRun master $formatzk $formatfs
 else
   "$bin"/hbase-daemons.sh --config "${HBASE_CONF_DIR}" $commandToRun zookeeper
-  "$bin"/hbase-daemon.sh --config "${HBASE_CONF_DIR}" $commandToRun master 
+  "$bin"/hbase-daemon.sh --config "${HBASE_CONF_DIR}" $commandToRun master  $formatzk $formatfs
   "$bin"/hbase-daemons.sh --config "${HBASE_CONF_DIR}" \
     --hosts "${HBASE_REGIONSERVERS}" $commandToRun regionserver
   "$bin"/hbase-daemons.sh --config "${HBASE_CONF_DIR}" \
