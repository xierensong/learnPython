diff --git dev-support/test-patch.sh dev-support/test-patch.sh
index 3ba7bb9..661b327 100755
--- dev-support/test-patch.sh
+++ dev-support/test-patch.sh
@@ -389,9 +389,9 @@ checkJavadocWarnings () {
   echo "======================================================================"
   echo ""
   echo ""
-  echo "$MVN clean compile javadoc:javadoc -DskipTests -D${PROJECT_NAME}PatchProcess > $PATCH_DIR/patchJavadocWarnings.txt 2>&1"
+  echo "$MVN clean package javadoc:javadoc -DskipTests -D${PROJECT_NAME}PatchProcess > $PATCH_DIR/patchJavadocWarnings.txt 2>&1"
   export MAVEN_OPTS="${MAVEN_OPTS}"
-  $MVN clean compile javadoc:javadoc -DskipTests -D${PROJECT_NAME}PatchProcess > $PATCH_DIR/patchJavadocWarnings.txt 2>&1
+  $MVN clean package javadoc:javadoc -DskipTests -D${PROJECT_NAME}PatchProcess > $PATCH_DIR/patchJavadocWarnings.txt 2>&1
   javadocWarnings=`$GREP '\[WARNING\]' $PATCH_DIR/patchJavadocWarnings.txt | $AWK '/Javadoc Warnings/,EOF' | $GREP warning | $AWK 'BEGIN {total = 0} {total += 1} END {print total}'`
   echo ""
   echo ""
@@ -422,9 +422,9 @@ checkJavacWarnings () {
   echo "======================================================================"
   echo ""
   echo ""
-  echo "$MVN clean compile -DskipTests -D${PROJECT_NAME}PatchProcess > $PATCH_DIR/patchJavacWarnings.txt 2>&1"
+  echo "$MVN clean package -DskipTests -D${PROJECT_NAME}PatchProcess > $PATCH_DIR/patchJavacWarnings.txt 2>&1"
   export MAVEN_OPTS="${MAVEN_OPTS}"
-  $MVN clean compile -DskipTests -D${PROJECT_NAME}PatchProcess  > $PATCH_DIR/patchJavacWarnings.txt 2>&1
+  $MVN clean package -DskipTests -D${PROJECT_NAME}PatchProcess  > $PATCH_DIR/patchJavacWarnings.txt 2>&1
   if [[ $? != 0 ]] ; then
     JIRA_COMMENT="$JIRA_COMMENT
 
@@ -508,9 +508,9 @@ checkStyle () {
   echo "THIS IS NOT IMPLEMENTED YET"
   echo ""
   echo ""
-  echo "$MVN compile checkstyle:checkstyle -D${PROJECT_NAME}PatchProcess"
+  echo "$MVN compile checkstyle:checkstyle -D${PROJECT_NAME}PatchProcess -DskipTests"
   export MAVEN_OPTS="${MAVEN_OPTS}"
-  $MVN compile checkstyle:checkstyle -D${PROJECT_NAME}PatchProcess
+  $MVN package checkstyle:checkstyle -D${PROJECT_NAME}PatchProcess -DskipTests
 
   JIRA_COMMENT_FOOTER="Checkstyle results: $BUILD_URL/artifact/trunk/build/test/checkstyle-errors.html
 $JIRA_COMMENT_FOOTER"
@@ -541,9 +541,9 @@ checkFindbugsWarnings () {
   echo "======================================================================"
   echo ""
   echo ""
-  echo "$MVN clean compile findbugs:findbugs -D${PROJECT_NAME}PatchProcess" 
+  echo "$MVN clean package findbugs:findbugs -D${PROJECT_NAME}PatchProcess" 
   export MAVEN_OPTS="${MAVEN_OPTS}"
-  $MVN clean compile findbugs:findbugs -D${PROJECT_NAME}PatchProcess < /dev/null
+  $MVN clean package findbugs:findbugs -D${PROJECT_NAME}PatchProcess -DskipTests < /dev/null
 
   if [ $? != 0 ] ; then
     JIRA_COMMENT="$JIRA_COMMENT
diff --git hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/CompatibilityFactory.java hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/CompatibilityFactory.java
new file mode 100644
index 0000000..43a1bb3
--- /dev/null
+++ hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/CompatibilityFactory.java
@@ -0,0 +1,70 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+
+import java.util.Iterator;
+import java.util.ServiceLoader;
+
+/**
+ * Class that will create many instances of classes provided by the hbase-hadoop{1|2}-compat jars.
+ */
+public class CompatibilityFactory {
+
+  private static final Log LOG = LogFactory.getLog(CompatibilitySingletonFactory.class);
+  public static final String EXCEPTION_START = "Could not create  ";
+  public static final String EXCEPTION_END = " Is the hadoop compatibility jar on the classpath?";
+
+  public static synchronized <T> T getInstance(Class<T> klass) {
+    T instance = null;
+    try {
+      ServiceLoader<T> loader = ServiceLoader.load(klass);
+      Iterator<T> it = loader.iterator();
+      instance = it.next();
+      if (it.hasNext()) {
+        StringBuilder msg = new StringBuilder();
+        msg.append("ServiceLoader provided more than one implementation for class: ")
+           .append(klass)
+           .append(", using implementation: ").append(instance.getClass())
+           .append(", other implementations: {");
+        while (it.hasNext()) {
+          msg.append(it.next()).append(" ");
+        }
+        msg.append("}");
+        LOG.warn(msg);
+      }
+    } catch (Exception e) {
+      throw new RuntimeException(createExceptionString(klass), e);
+    } catch (Error e) {
+      throw new RuntimeException(createExceptionString(klass), e);
+    }
+
+    // If there was nothing returned and no exception then throw an exception.
+    if (instance == null) {
+      throw new RuntimeException(createExceptionString(klass));
+    }
+    return instance;
+  }
+
+  protected static String createExceptionString(Class klass) {
+    return EXCEPTION_START + klass.toString() + EXCEPTION_END;
+  }
+}
diff --git hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/CompatibilitySingletonFactory.java hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/CompatibilitySingletonFactory.java
index 7fbf518..4528678 100644
--- hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/CompatibilitySingletonFactory.java
+++ hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/CompatibilitySingletonFactory.java
@@ -20,7 +20,6 @@ package org.apache.hadoop.hbase;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.hadoop.hbase.master.metrics.MasterMetricsSource;
 
 import java.util.HashMap;
 import java.util.Iterator;
@@ -28,12 +27,11 @@ import java.util.Map;
 import java.util.ServiceLoader;
 
 /**
- *  Factory for classes supplied by hadoop compatibility modules.
+ *  Factory for classes supplied by hadoop compatibility modules.  Only one of each class will be
+ *  created.
  */
-public class CompatibilitySingletonFactory {
+public class CompatibilitySingletonFactory extends CompatibilityFactory {
   private static final Log LOG = LogFactory.getLog(CompatibilitySingletonFactory.class);
-  public static final String EXCEPTION_START = "Could not create  ";
-  public static final String EXCEPTION_END = " Is the hadoop compatibility jar on the classpath?";
 
   private static final Map<Class, Object> instances = new HashMap<Class, Object>();
 
@@ -75,9 +73,4 @@ public class CompatibilitySingletonFactory {
     }
     return instance;
   }
-
-  private static String createExceptionString(Class klass) {
-     return EXCEPTION_START + klass.toString() + EXCEPTION_END;
-  }
-
 }
diff --git hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSource.java hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSource.java
index 23130ea..7b9c9e3 100644
--- hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSource.java
+++ hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSource.java
@@ -24,6 +24,11 @@ package org.apache.hadoop.hbase.metrics;
 public interface BaseMetricsSource {
 
   /**
+   * Clear out the metrics and re-prepare the source.
+   */
+  public void init();
+
+  /**
    * Set a gauge to a specific value.
    *
    * @param gaugeName the name of the gauge
diff --git hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetricsSource.java hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetricsSource.java
new file mode 100644
index 0000000..9d7f691
--- /dev/null
+++ hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetricsSource.java
@@ -0,0 +1,91 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.rest.metrics;
+
+import org.apache.hadoop.hbase.metrics.BaseMetricsSource;
+
+/**
+ * Interface of the Metrics Source that will export data to Hadoop's Metrics2 system.
+ */
+public interface RESTMetricsSource extends BaseMetricsSource {
+
+  public static String METRICS_NAME = "Rest";
+
+  public static String CONTEXT = "rest";
+
+  public static String JMX_CONTEXT = "Rest";
+
+  public static String METRICS_DESCRIPTION = "Metrics about the HBase REST server";
+
+  static String REQUEST_KEY = "requests";
+
+  static String SUCCESSFUL_GET_KEY = "successfulGet";
+
+  static String SUCCESSFUL_PUT_KEY = "successfulPut";
+
+  static String SUCCESSFUL_DELETE_KEY = "successfulDelete";
+
+  static String FAILED_GET_KEY = "failedGet";
+
+  static String FAILED_PUT_KEY = "failedPut";
+
+  static String FAILED_DELETE_KEY = "failedDelete";
+
+  /**
+   * Increment the number of requests
+   * @param inc Ammount to increment by
+   */
+  void incrementRequests(int inc);
+
+  /**
+   * Increment the number of successful Get requests.
+   * @param inc Number of successful get requests.
+   */
+  void incrementSucessfulGetRequests(int inc);
+
+  /**
+   * Increment the number of successful Put requests.
+   * @param inc Number of successful put requests.
+   */
+  void incrementSucessfulPutRequests(int inc);
+
+  /**
+   * Increment the number of successful Delete requests.
+   * @param inc
+   */
+  void incrementSucessfulDeleteRequests(int inc);
+
+  /**
+   * Increment the number of failed Put Requests.
+   * @param inc Number of failed Put requests.
+   */
+  void incrementFailedPutRequests(int inc);
+
+  /**
+   * Increment the number of failed Get requests.
+   * @param inc The number of failed Get Requests.
+   */
+  void incrementFailedGetRequests(int inc);
+
+  /**
+   * Increment the number of failed Delete requests.
+   * @param inc The number of failed delete requests.
+   */
+  void incrementFailedDeleteRequests(int inc);
+}
diff --git hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSource.java hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSource.java
new file mode 100644
index 0000000..04b4773
--- /dev/null
+++ hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSource.java
@@ -0,0 +1,78 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.thrift.metrics;
+
+import org.apache.hadoop.hbase.metrics.BaseMetricsSource;
+
+/**
+ * Inteface of a class that will export metrics about Thrift to hadoop's metrics2.
+ */
+public interface ThriftServerMetricsSource extends BaseMetricsSource {
+
+  public static final String BATCH_GET_KEY = "BatchGet";
+  public static final String BATCH_MUTATE_KEY = "BatchMutate";
+  public static final String TIME_IN_QUEUE_KEY = "timeInQueue";
+  public static final String THRIFT_CALL_KEY = "thriftCall";
+  public static final String SLOW_THRIFT_CALL_KEY = "slowThriftCall";
+  public static final String CALL_QUEUE_LEN_KEY = "callQueueLen";
+
+  /**
+   * Add how long an operation was in the queue.
+   * @param time
+   */
+  public void incTimeInQueue(long time);
+
+  /**
+   * Set the call queue length.
+   * @param len Time
+   */
+  public void setCallQueueLen(int len);
+
+  /**
+   * Add how many keys were in a batch get.
+   * @param diff Num Keys
+   */
+  public void incNumRowKeysInBatchGet(int diff);
+
+  /**
+   * Add how many keys were in a batch mutate.
+   * @param diff Num Keys
+   */
+  public void incNumRowKeysInBatchMutate(int diff);
+
+  /**
+   * Add how long a method took
+   * @param name Method name
+   * @param time Time
+   */
+  public void incMethodTime(String name, long time);
+
+  /**
+   * Add how long a call took
+   * @param time Time
+   */
+  public void incCall(long time);
+
+  /**
+   * Increment how long a slow call took.
+   * @param time Time
+   */
+  public void incSlowCall(long time);
+
+}
diff --git hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceFactory.java hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceFactory.java
new file mode 100644
index 0000000..f83d660
--- /dev/null
+++ hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceFactory.java
@@ -0,0 +1,37 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.thrift.metrics;
+
+/**
+ *
+ */
+public interface ThriftServerMetricsSourceFactory {
+
+  public static final String METRICS_NAME = "Thrift";
+  public static final String METRICS_DESCRIPTION = "Thrift Server Metrics";
+  public static final String THRIFT_ONE_METRICS_CONTEXT = "thrift-one";
+  public static final String THRIFT_ONE_JMX_CONTEXT = "Thrift,sub=ThriftOne";
+  public static final String THRIFT_TWO_METRICS_CONTEXT = "thrift-two";
+  public static final String THRIFT_TWO_JMX_CONTEXT = "Thrift,sub=ThriftTwo";
+
+  public ThriftServerMetricsSource createThriftOneSource();
+
+  public ThriftServerMetricsSource createThriftTwoSource();
+
+}
diff --git hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/test/MetricsAssertHelper.java hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/test/MetricsAssertHelper.java
new file mode 100644
index 0000000..6cec909
--- /dev/null
+++ hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/test/MetricsAssertHelper.java
@@ -0,0 +1,48 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.test;
+
+import org.apache.hadoop.hbase.metrics.BaseMetricsSource;
+
+/**
+ *
+ */
+public interface MetricsAssertHelper {
+
+  public void assertTag(String name, String expected, BaseMetricsSource source);
+
+  public void assertGauge(String name, long expected, BaseMetricsSource source);
+
+  public void assertGaugeGt(String name, long expected, BaseMetricsSource source);
+
+  public void assertGaugeLt(String name, long expected, BaseMetricsSource source);
+
+  public void assertGauge(String name, double expected, BaseMetricsSource source);
+
+  public void assertGaugeGt(String name, double expected, BaseMetricsSource source);
+
+  public void assertGaugeLt(String name, double expected, BaseMetricsSource source);
+
+  public void assertCounter(String name, long expected, BaseMetricsSource source);
+
+  public void assertCounterGt(String name, long expected, BaseMetricsSource source);
+
+  public void assertCounterLt(String name, long expected, BaseMetricsSource source);
+
+}
diff --git hbase-hadoop1-compat/pom.xml hbase-hadoop1-compat/pom.xml
index 9a54c5c..a48eba8 100644
--- hbase-hadoop1-compat/pom.xml
+++ hbase-hadoop1-compat/pom.xml
@@ -93,5 +93,12 @@ limitations under the License.
       <optional>true</optional>
       <scope>test</scope>
     </dependency>
+    <dependency>
+      <groupId>org.apache.hbase</groupId>
+      <artifactId>hbase-hadoop-compat</artifactId>
+      <version>${project.version}</version>
+      <type>test-jar</type>
+      <scope>test</scope>
+    </dependency>
   </dependencies>
 </project>
diff --git hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceFactoryImpl.java hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceFactoryImpl.java
index ffb80d9..4a17046 100644
--- hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceFactoryImpl.java
+++ hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceFactoryImpl.java
@@ -22,9 +22,16 @@ package org.apache.hadoop.hbase.master.metrics;
  *  Factory to create MasterMetricsSource when given a  MasterMetricsWrapper
  */
 public class MasterMetricsSourceFactoryImpl implements MasterMetricsSourceFactory {
+  private static enum FactoryStorage {
+    INSTANCE;
+    MasterMetricsSource source;
+  }
 
   @Override
-  public MasterMetricsSource create(MasterMetricsWrapper beanWrapper) {
-    return new MasterMetricsSourceImpl(beanWrapper);
+  public synchronized MasterMetricsSource create(MasterMetricsWrapper beanWrapper) {
+    if (FactoryStorage.INSTANCE.source == null ) {
+      FactoryStorage.INSTANCE.source = new MasterMetricsSourceImpl(beanWrapper);
+    }
+    return FactoryStorage.INSTANCE.source;
   }
 }
diff --git hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceImpl.java hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceImpl.java
index 329727b..205db88 100644
--- hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceImpl.java
+++ hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceImpl.java
@@ -26,18 +26,16 @@ import org.apache.hadoop.metrics2.MetricsRecordBuilder;
 import org.apache.hadoop.metrics2.lib.MetricMutableCounterLong;
 import org.apache.hadoop.metrics2.lib.MetricMutableGaugeLong;
 
-/**
- * Hadoop1 implementation of MasterMetricsSource.
- */
+/** Hadoop1 implementation of MasterMetricsSource. */
 public class MasterMetricsSourceImpl
-        extends BaseMetricsSourceImpl implements MasterMetricsSource {
+    extends BaseMetricsSourceImpl implements MasterMetricsSource {
 
   private static final Log LOG = LogFactory.getLog(MasterMetricsSourceImpl.class.getName());
 
-  final MetricMutableCounterLong clusterRequestsCounter;
-  final MetricMutableGaugeLong ritGauge;
-  final MetricMutableGaugeLong ritCountOverThresholdGauge;
-  final MetricMutableGaugeLong ritOldestAgeGauge;
+  MetricMutableCounterLong clusterRequestsCounter;
+  MetricMutableGaugeLong ritGauge;
+  MetricMutableGaugeLong ritCountOverThresholdGauge;
+  MetricMutableGaugeLong ritOldestAgeGauge;
 
   private final MasterMetricsWrapper masterWrapper;
 
@@ -51,8 +49,12 @@ public class MasterMetricsSourceImpl
                                  String metricsJmxContext,
                                  MasterMetricsWrapper masterWrapper) {
     super(metricsName, metricsDescription, metricsContext, metricsJmxContext);
-
     this.masterWrapper = masterWrapper;
+  }
+
+  @Override
+  public void init() {
+    this.metricsRegistry.clearMetrics();
     clusterRequestsCounter = getLongCounter("cluster_requests", 0);
     ritGauge = getLongGauge("ritCount", 0);
     ritCountOverThresholdGauge = getLongGauge("ritCountOverThreshold", 0);
@@ -110,4 +112,5 @@ public class MasterMetricsSourceImpl
 
     metricsRegistry.snapshot(metricsRecordBuilder, true);
   }
+
 }
diff --git hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSourceImpl.java hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSourceImpl.java
index efb8d4c..c0477e5 100644
--- hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSourceImpl.java
+++ hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSourceImpl.java
@@ -75,6 +75,11 @@ public class BaseMetricsSourceImpl implements BaseMetricsSource, MetricsSource {
 
     //Register this instance.
     DefaultMetricsSystem.INSTANCE.registerSource(metricsJmxContext, metricsDescription, this);
+    init();
+  }
+
+  public void init() {
+    this.metricsRegistry.clearMetrics();
   }
 
   /**
@@ -173,4 +178,12 @@ public class BaseMetricsSourceImpl implements BaseMetricsSource, MetricsSource {
   public void getMetrics(MetricsBuilder metricsBuilder, boolean all) {
     metricsRegistry.snapshot(metricsBuilder.addRecord(metricsRegistry.name()), all);
   }
+
+  /**
+   * Used to get at the DynamicMetricsRegistry.
+   * @return
+   */
+  protected DynamicMetricsRegistry getMetricsRegistry() {
+    return metricsRegistry;
+  }
 }
diff --git hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetricsSourceImpl.java hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetricsSourceImpl.java
new file mode 100644
index 0000000..1c665ba
--- /dev/null
+++ hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetricsSourceImpl.java
@@ -0,0 +1,98 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.rest.metrics;
+
+import org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl;
+import org.apache.hadoop.metrics2.lib.MetricMutableCounterLong;
+
+/**
+ * Hadoop One implementation of a metrics2 source that will export metrics from the Rest server to
+ * the hadoop metrics2 subsystem.
+ */
+public class RESTMetricsSourceImpl extends BaseMetricsSourceImpl implements RESTMetricsSource {
+
+  private MetricMutableCounterLong request;
+  private MetricMutableCounterLong sucGet;
+  private MetricMutableCounterLong sucPut;
+  private MetricMutableCounterLong sucDel;
+  private MetricMutableCounterLong fGet;
+  private MetricMutableCounterLong fPut;
+  private MetricMutableCounterLong fDel;
+
+  public RESTMetricsSourceImpl() {
+    this(METRICS_NAME, METRICS_DESCRIPTION, CONTEXT, JMX_CONTEXT);
+  }
+
+  public RESTMetricsSourceImpl(String metricsName,
+                               String metricsDescription,
+                               String metricsContext,
+                               String metricsJmxContext) {
+    super(metricsName, metricsDescription, metricsContext, metricsJmxContext);
+    init();
+  }
+
+  @Override
+  public void init() {
+    super.init();
+    request = getLongCounter(REQUEST_KEY, 0l);
+
+    sucGet = getLongCounter(SUCCESSFUL_GET_KEY, 0l);
+    sucPut = getLongCounter(SUCCESSFUL_PUT_KEY, 0l);
+    sucDel = getLongCounter(SUCCESSFUL_DELETE_KEY, 0l);
+
+    fGet = getLongCounter(FAILED_GET_KEY, 0l);
+    fPut = getLongCounter(FAILED_PUT_KEY, 0l);
+    fDel = getLongCounter(FAILED_DELETE_KEY, 0l);
+  }
+
+  @Override
+  public void incrementRequests(int inc) {
+    request.incr(inc);
+  }
+
+  @Override
+  public void incrementSucessfulGetRequests(int inc) {
+    sucGet.incr(inc);
+  }
+
+  @Override
+  public void incrementSucessfulPutRequests(int inc) {
+    sucPut.incr(inc);
+  }
+
+  @Override
+  public void incrementSucessfulDeleteRequests(int inc) {
+    sucDel.incr(inc);
+  }
+
+  @Override
+  public void incrementFailedGetRequests(int inc) {
+    fGet.incr(inc);
+  }
+
+  @Override
+  public void incrementFailedPutRequests(int inc) {
+    fPut.incr(inc);
+  }
+
+  @Override
+  public void incrementFailedDeleteRequests(int inc) {
+    fDel.incr(inc);
+  }
+}
diff --git hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceFactoryImpl.java hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceFactoryImpl.java
new file mode 100644
index 0000000..83d010e
--- /dev/null
+++ hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceFactoryImpl.java
@@ -0,0 +1,52 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.thrift.metrics;
+
+/**
+ *  Class used to create metrics sources for Thrift and Thrift2 servers.
+ */
+public class ThriftServerMetricsSourceFactoryImpl implements ThriftServerMetricsSourceFactory {
+
+
+  /**
+   * A singleton used to make sure that only one thrift metrics source per server type is ever
+   * created.
+   */
+  private static enum FactoryStorage {
+    INSTANCE;
+    ThriftServerMetricsSourceImpl thriftOne = new ThriftServerMetricsSourceImpl(METRICS_NAME,
+        METRICS_DESCRIPTION,
+        THRIFT_ONE_METRICS_CONTEXT,
+        THRIFT_ONE_JMX_CONTEXT);
+    ThriftServerMetricsSourceImpl thriftTwo = new ThriftServerMetricsSourceImpl(METRICS_NAME,
+        METRICS_DESCRIPTION,
+        THRIFT_TWO_METRICS_CONTEXT,
+        THRIFT_TWO_JMX_CONTEXT);
+  }
+
+  @Override
+  public ThriftServerMetricsSource createThriftOneSource() {
+    return FactoryStorage.INSTANCE.thriftOne;
+  }
+
+  @Override
+  public ThriftServerMetricsSource createThriftTwoSource() {
+    return FactoryStorage.INSTANCE.thriftTwo;
+  }
+}
diff --git hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceImpl.java hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceImpl.java
new file mode 100644
index 0000000..67f49b3
--- /dev/null
+++ hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceImpl.java
@@ -0,0 +1,97 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.thrift.metrics;
+
+import org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl;
+import org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSource;
+import org.apache.hadoop.metrics2.lib.MetricMutableGaugeLong;
+import org.apache.hadoop.metrics2.lib.MetricMutableStat;
+
+/**
+ * Hadoop 1 version of ThriftServerMetricsSource{@link ThriftServerMetricsSource}
+ */
+public class ThriftServerMetricsSourceImpl extends BaseMetricsSourceImpl implements
+    ThriftServerMetricsSource {
+
+
+  private MetricMutableStat batchGetStat;
+  private MetricMutableStat batchMutateStat;
+  private MetricMutableStat queueTimeStat;
+
+  private MetricMutableStat thriftCallStat;
+  private MetricMutableStat thriftSlowCallStat;
+
+  private MetricMutableGaugeLong callQueueLenGauge;
+
+  public ThriftServerMetricsSourceImpl(String metricsName,
+                                       String metricsDescription,
+                                       String metricsContext,
+                                       String metricsJmxContext) {
+    super(metricsName, metricsDescription, metricsContext, metricsJmxContext);
+  }
+
+  @Override
+  public void init() {
+    super.init();
+    batchGetStat = getMetricsRegistry().newStat(BATCH_GET_KEY, "", "Keys", "Ops");
+    batchMutateStat = getMetricsRegistry().newStat(BATCH_MUTATE_KEY, "", "Keys", "Ops");
+    queueTimeStat = getMetricsRegistry().newStat(TIME_IN_QUEUE_KEY);
+    thriftCallStat = getMetricsRegistry().newStat(THRIFT_CALL_KEY);
+    thriftSlowCallStat = getMetricsRegistry().newStat(SLOW_THRIFT_CALL_KEY);
+    callQueueLenGauge = getLongGauge(CALL_QUEUE_LEN_KEY, 0);
+
+  }
+
+  @Override
+  public void incTimeInQueue(long time) {
+    queueTimeStat.add(time);
+  }
+
+  @Override
+  public void setCallQueueLen(int len) {
+    callQueueLenGauge.set(len);
+  }
+
+  @Override
+  public void incNumRowKeysInBatchGet(int diff) {
+    batchGetStat.add(diff);
+  }
+
+  @Override
+  public void incNumRowKeysInBatchMutate(int diff) {
+    batchMutateStat.add(diff);
+  }
+
+  @Override
+  public void incMethodTime(String name, long time) {
+    MetricMutableStat s = getMetricsRegistry().newStat(name);
+    s.add(time);
+  }
+
+  @Override
+  public void incCall(long time) {
+    thriftCallStat.add(time);
+  }
+
+  @Override
+  public void incSlowCall(long time) {
+    thriftSlowCallStat.add(time);
+  }
+
+}
diff --git hbase-hadoop1-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java hbase-hadoop1-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java
index b980454..88cfdfa 100644
--- hbase-hadoop1-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java
+++ hbase-hadoop1-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java
@@ -352,4 +352,8 @@ public class DynamicMetricsRegistry {
 
     return (T) metric;
   }
+
+  public void clearMetrics() {
+    metricsMap.clear();
+  }
 }
diff --git hbase-hadoop1-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.rest.metrics.RESTMetricsSource hbase-hadoop1-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.rest.metrics.RESTMetricsSource
new file mode 100644
index 0000000..9e7a28d
--- /dev/null
+++ hbase-hadoop1-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.rest.metrics.RESTMetricsSource
@@ -0,0 +1 @@
+org.apache.hadoop.hbase.rest.metrics.RESTMetricsSourceImpl
\ No newline at end of file
diff --git hbase-hadoop1-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSourceFactory hbase-hadoop1-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSourceFactory
new file mode 100644
index 0000000..62d1c6a
--- /dev/null
+++ hbase-hadoop1-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSourceFactory
@@ -0,0 +1 @@
+org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSourceFactoryImpl
\ No newline at end of file
diff --git hbase-hadoop1-compat/src/test/java/org/apache/hadoop/hbase/test/MetricsAssertHelperImpl.java hbase-hadoop1-compat/src/test/java/org/apache/hadoop/hbase/test/MetricsAssertHelperImpl.java
new file mode 100644
index 0000000..0511ceb
--- /dev/null
+++ hbase-hadoop1-compat/src/test/java/org/apache/hadoop/hbase/test/MetricsAssertHelperImpl.java
@@ -0,0 +1,214 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.test;
+
+import org.apache.hadoop.hbase.metrics.BaseMetricsSource;
+import org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl;
+import org.apache.hadoop.metrics2.Metric;
+import org.apache.hadoop.metrics2.MetricsBuilder;
+import org.apache.hadoop.metrics2.MetricsRecordBuilder;
+import org.apache.hadoop.metrics2.MetricsTag;
+
+import java.util.HashMap;
+import java.util.Map;
+
+import static org.junit.Assert.*;
+
+/**
+ *
+ */
+public class MetricsAssertHelperImpl implements MetricsAssertHelper {
+
+  private Map<String, String> tags = new HashMap<String, String>();
+  private Map<String, Number> gauges = new HashMap<String, Number>();
+  private Map<String, Long> counters = new HashMap<String, Long>();
+
+  public class MockMetricsBuilder implements MetricsBuilder {
+
+    @Override
+    public MetricsRecordBuilder addRecord(String s) {
+      return new MockRecordBuilder();
+    }
+  }
+
+  public class MockRecordBuilder extends MetricsRecordBuilder {
+
+    @Override
+    public MetricsRecordBuilder tag(String s, String s1, String s2) {
+      tags.put(canonicalizeMetricName(s), s2);
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder add(MetricsTag metricsTag) {
+      tags.put(canonicalizeMetricName(metricsTag.name()), metricsTag.value());
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder setContext(String s) {
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addCounter(String s, String s1, int i) {
+      counters.put(canonicalizeMetricName(s), Long.valueOf(i));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addCounter(String s, String s1, long l) {
+      counters.put(canonicalizeMetricName(s), Long.valueOf(l));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addGauge(String s, String s1, int i) {
+      gauges.put(canonicalizeMetricName(s), Long.valueOf(i));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addGauge(String s, String s1, long l) {
+      gauges.put(canonicalizeMetricName(s), Long.valueOf(l));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addGauge(String s, String s1, float v) {
+      gauges.put(canonicalizeMetricName(s), Double.valueOf(v));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addGauge(String s, String s1, double v) {
+      gauges.put(canonicalizeMetricName(s), Double.valueOf(v));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder add(Metric metric) {
+      gauges.put(canonicalizeMetricName(metric.name()), metric.value());
+      return this;
+    }
+  }
+
+  @Override
+  public void assertTag(String name, String expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertEquals("Tags should be equal", expected, tags.get(cName));
+  }
+
+  @Override
+  public void assertGauge(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertEquals("Metrics Should be equal", Long.valueOf(expected), gauges.get(cName));
+  }
+
+  @Override
+  public void assertGaugeGt(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(gauges.get(cName));
+    long found = gauges.get(cName).longValue();
+    assertTrue(name + " (" + found + ") should be greater than " + expected, found > expected);
+  }
+
+  @Override
+  public void assertGaugeLt(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(gauges.get(cName));
+    long found = gauges.get(cName).longValue();
+    assertTrue(name + "(" + found + ") should be less than " + expected, found < expected);
+  }
+
+  @Override
+  public void assertGauge(String name, double expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertEquals("Metrics Should be equal", Double.valueOf(expected), gauges.get(cName));
+  }
+
+  @Override
+  public void assertGaugeGt(String name, double expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(gauges.get(cName));
+    double found = gauges.get(cName).doubleValue();
+    assertTrue(name + "(" + found + ") should be greater than " + expected, found > expected);
+  }
+
+  @Override
+  public void assertGaugeLt(String name, double expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(gauges.get(cName));
+    double found = gauges.get(cName).doubleValue();
+    assertTrue(name + "(" + found + ") should be less than " + expected, found < expected);
+  }
+
+  @Override
+  public void assertCounter(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertEquals("Metrics Counters should be equal", Long.valueOf(expected), counters.get(cName));
+  }
+
+  @Override
+  public void assertCounterGt(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(counters.get(cName));
+    long found = counters.get(cName).longValue();
+    assertTrue(name + " (" + found + ") should be greater than " + expected, found > expected);
+  }
+
+  @Override
+  public void assertCounterLt(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(counters.get(cName));
+    long found = counters.get(cName).longValue();
+    assertTrue(name + "(" + found + ") should be less than " + expected, found < expected);
+  }
+
+  private void reset() {
+    tags.clear();
+    gauges.clear();
+    counters.clear();
+  }
+
+  private void getMetrics(BaseMetricsSource source) {
+    reset();
+    if (!(source instanceof BaseMetricsSourceImpl)) {
+      assertTrue(false);
+    }
+    BaseMetricsSourceImpl impl = (BaseMetricsSourceImpl) source;
+
+    impl.getMetrics(new MockMetricsBuilder(), true);
+
+  }
+
+  private String canonicalizeMetricName(String in) {
+    return in.toLowerCase().replaceAll("[^A-Za-z0-9 ]", "");
+  }
+}
diff --git hbase-hadoop1-compat/src/test/resources/META-INF/services/org.apache.hadoop.hbase.test.MetricsAssertHelper hbase-hadoop1-compat/src/test/resources/META-INF/services/org.apache.hadoop.hbase.test.MetricsAssertHelper
new file mode 100644
index 0000000..c31ec09
--- /dev/null
+++ hbase-hadoop1-compat/src/test/resources/META-INF/services/org.apache.hadoop.hbase.test.MetricsAssertHelper
@@ -0,0 +1 @@
+org.apache.hadoop.hbase.test.MetricsAssertHelperImpl
diff --git hbase-hadoop2-compat/pom.xml hbase-hadoop2-compat/pom.xml
index a3c307a..5a6e519 100644
--- hbase-hadoop2-compat/pom.xml
+++ hbase-hadoop2-compat/pom.xml
@@ -113,6 +113,13 @@ limitations under the License.
       <artifactId>hbase-hadoop-compat</artifactId>
     </dependency>
     <dependency>
+      <groupId>org.apache.hbase</groupId>
+      <artifactId>hbase-hadoop-compat</artifactId>
+      <version>${project.version}</version>
+      <type>test-jar</type>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-client</artifactId>
       <version>${hadoop-two.version}</version>
@@ -122,6 +129,11 @@ limitations under the License.
       <artifactId>hadoop-annotations</artifactId>
       <version>${hadoop-two.version}</version>
     </dependency>
+    <dependency>
+      <groupId>org.apache.hadoop</groupId>
+      <artifactId>hadoop-common</artifactId>
+      <version>${hadoop-two.version}</version>
+    </dependency>
     <!-- This was marked as test dep in earlier pom, but was scoped compile. Where
       do we actually need it? -->
     <dependency>
diff --git hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceFactoryImpl.java hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceFactoryImpl.java
index ffb80d9..4a17046 100644
--- hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceFactoryImpl.java
+++ hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceFactoryImpl.java
@@ -22,9 +22,16 @@ package org.apache.hadoop.hbase.master.metrics;
  *  Factory to create MasterMetricsSource when given a  MasterMetricsWrapper
  */
 public class MasterMetricsSourceFactoryImpl implements MasterMetricsSourceFactory {
+  private static enum FactoryStorage {
+    INSTANCE;
+    MasterMetricsSource source;
+  }
 
   @Override
-  public MasterMetricsSource create(MasterMetricsWrapper beanWrapper) {
-    return new MasterMetricsSourceImpl(beanWrapper);
+  public synchronized MasterMetricsSource create(MasterMetricsWrapper beanWrapper) {
+    if (FactoryStorage.INSTANCE.source == null ) {
+      FactoryStorage.INSTANCE.source = new MasterMetricsSourceImpl(beanWrapper);
+    }
+    return FactoryStorage.INSTANCE.source;
   }
 }
diff --git hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceImpl.java hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceImpl.java
index 7050417..677becd 100644
--- hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceImpl.java
+++ hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/metrics/MasterMetricsSourceImpl.java
@@ -50,7 +50,11 @@ public class MasterMetricsSourceImpl
                                  MasterMetricsWrapper masterWrapper) {
     super(metricsName, metricsDescription, metricsContext, metricsJmxContext);
     this.masterWrapper = masterWrapper;
+  }
 
+ @Override
+ public void init() {
+     super.init();
     clusterRequestsCounter = getLongCounter("cluster_requests", 0);
     ritGauge = getLongGauge("ritCount", 0);
     ritCountOverThresholdGauge = getLongGauge("ritCountOverThreshold", 0);
diff --git hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSourceImpl.java hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSourceImpl.java
index 7155c4e..181e6fe 100644
--- hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSourceImpl.java
+++ hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseMetricsSourceImpl.java
@@ -58,12 +58,18 @@ public class BaseMetricsSourceImpl implements BaseMetricsSource, MetricsSource {
     if (!defaultMetricsSystemInited) {
       //Not too worried about mutlithread here as all it does is spam the logs.
       defaultMetricsSystemInited = true;
+
       DefaultMetricsSystem.initialize(HBASE_METRICS_SYSTEM_NAME);
       jvmMetricsSource = JvmMetrics.create(metricsName, "", DefaultMetricsSystem.instance());
     }
 
     DefaultMetricsSystem.instance().register(metricsJmxContext, metricsDescription, this);
+    init();
+
+  }
 
+  public void init() {
+    this.metricsRegistry.clearMetrics();
   }
 
   /**
@@ -151,8 +157,14 @@ public class BaseMetricsSourceImpl implements BaseMetricsSource, MetricsSource {
     return metricsRegistry.getLongCounter(counterName, potentialStartingValue);
   }
 
+  protected DynamicMetricsRegistry getMetricsRegistry() {
+    return metricsRegistry;
+  }
+
   @Override
   public void getMetrics(MetricsCollector metricsCollector, boolean all) {
     metricsRegistry.snapshot(metricsCollector.addRecord(metricsRegistry.info()), all);
   }
+
+
 }
diff --git hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/replication/regionserver/metrics/ReplicationMetricsSourceImpl.java hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/replication/regionserver/metrics/ReplicationMetricsSourceImpl.java
index 436b30e..3f2a40d 100644
--- hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/replication/regionserver/metrics/ReplicationMetricsSourceImpl.java
+++ hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/replication/regionserver/metrics/ReplicationMetricsSourceImpl.java
@@ -19,7 +19,6 @@
 package org.apache.hadoop.hbase.replication.regionserver.metrics;
 
 import org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl;
-import org.apache.hadoop.metrics2.MetricsSource;
 
 /**
  * Hadoop2 implementation of ReplicationMetricsSource. This provides access to metrics gauges and
diff --git hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetricsSourceImpl.java hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetricsSourceImpl.java
new file mode 100644
index 0000000..b1a7d42
--- /dev/null
+++ hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetricsSourceImpl.java
@@ -0,0 +1,97 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.rest.metrics;
+
+import org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl;
+import org.apache.hadoop.metrics2.lib.MutableCounterLong;
+
+/**
+ * Hadoop Two implementation of a metrics2 source that will export metrics from the Rest server to
+ * the hadoop metrics2 subsystem.
+ */
+public class RESTMetricsSourceImpl extends BaseMetricsSourceImpl implements RESTMetricsSource {
+
+  private MutableCounterLong request;
+  private MutableCounterLong sucGet;
+  private MutableCounterLong sucPut;
+  private MutableCounterLong sucDel;
+  private MutableCounterLong fGet;
+  private MutableCounterLong fPut;
+  private MutableCounterLong fDel;
+
+  public RESTMetricsSourceImpl() {
+    this(METRICS_NAME, METRICS_DESCRIPTION, CONTEXT, JMX_CONTEXT);
+  }
+
+  public RESTMetricsSourceImpl(String metricsName,
+                               String metricsDescription,
+                               String metricsContext,
+                               String metricsJmxContext) {
+    super(metricsName, metricsDescription, metricsContext, metricsJmxContext);
+
+  }
+  @Override
+  public void init() {
+    super.init();
+    request = getLongCounter(REQUEST_KEY, 0l);
+
+    sucGet = getLongCounter(SUCCESSFUL_GET_KEY, 0l);
+    sucPut = getLongCounter(SUCCESSFUL_PUT_KEY, 0l);
+    sucDel = getLongCounter(SUCCESSFUL_DELETE_KEY, 0l);
+
+    fGet = getLongCounter(FAILED_GET_KEY, 0l);
+    fPut = getLongCounter(FAILED_PUT_KEY, 0l);
+    fDel = getLongCounter(FAILED_DELETE_KEY, 0l);
+  }
+
+  @Override
+  public void incrementRequests(int inc) {
+    request.incr(inc);
+  }
+
+  @Override
+  public void incrementSucessfulGetRequests(int inc) {
+    sucGet.incr(inc);
+  }
+
+  @Override
+  public void incrementSucessfulPutRequests(int inc) {
+    sucPut.incr(inc);
+  }
+
+  @Override
+  public void incrementSucessfulDeleteRequests(int inc) {
+    sucDel.incr(inc);
+  }
+
+  @Override
+  public void incrementFailedGetRequests(int inc) {
+    fGet.incr(inc);
+  }
+
+  @Override
+  public void incrementFailedPutRequests(int inc) {
+    fPut.incr(inc);
+  }
+
+  @Override
+  public void incrementFailedDeleteRequests(int inc) {
+   fDel.incr(inc);
+  }
+}
diff --git hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceFactoryImpl.java hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceFactoryImpl.java
new file mode 100644
index 0000000..718e4b0
--- /dev/null
+++ hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceFactoryImpl.java
@@ -0,0 +1,51 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.thrift.metrics;
+
+/**
+ *  Class used to create metrics sources for Thrift and Thrift2 servers.
+ */
+public class ThriftServerMetricsSourceFactoryImpl implements ThriftServerMetricsSourceFactory {
+
+  /**
+   * A singleton used to make sure that only one thrift metrics source per server type is ever
+   * created.
+   */
+  private static enum FactoryStorage {
+    INSTANCE;
+    ThriftServerMetricsSourceImpl thriftOne = new ThriftServerMetricsSourceImpl(METRICS_NAME,
+        METRICS_DESCRIPTION,
+        THRIFT_ONE_METRICS_CONTEXT,
+        THRIFT_ONE_JMX_CONTEXT);
+    ThriftServerMetricsSourceImpl thriftTwo = new ThriftServerMetricsSourceImpl(METRICS_NAME,
+        METRICS_DESCRIPTION,
+        THRIFT_TWO_METRICS_CONTEXT,
+        THRIFT_TWO_JMX_CONTEXT);
+  }
+
+  @Override
+  public ThriftServerMetricsSource createThriftOneSource() {
+    return FactoryStorage.INSTANCE.thriftOne;
+  }
+
+  @Override
+  public ThriftServerMetricsSource createThriftTwoSource() {
+    return FactoryStorage.INSTANCE.thriftTwo;
+  }
+}
diff --git hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceImpl.java hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceImpl.java
new file mode 100644
index 0000000..82f3b98
--- /dev/null
+++ hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/thrift/metrics/ThriftServerMetricsSourceImpl.java
@@ -0,0 +1,98 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.thrift.metrics;
+
+import org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl;
+import org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSource;
+import org.apache.hadoop.metrics2.lib.MutableGaugeLong;
+import org.apache.hadoop.metrics2.lib.MutableStat;
+
+/**
+ * Hadoop 2 version of ThriftServerMetricsSource{@link ThriftServerMetricsSource}
+ */
+public class ThriftServerMetricsSourceImpl extends BaseMetricsSourceImpl implements
+    ThriftServerMetricsSource {
+
+  private MutableStat batchGetStat;
+  private MutableStat batchMutateStat;
+  private MutableStat queueTimeStat;
+
+  private MutableStat thriftCallStat;
+  private MutableStat thriftSlowCallStat;
+
+  private MutableGaugeLong callQueueLenGauge;
+
+  public ThriftServerMetricsSourceImpl(String metricsName,
+                                       String metricsDescription,
+                                       String metricsContext,
+                                       String metricsJmxContext) {
+    super(metricsName, metricsDescription, metricsContext, metricsJmxContext);
+  }
+
+  @Override
+  public void init() {
+    super.init();
+    batchGetStat = getMetricsRegistry().newStat(BATCH_GET_KEY, "", "Keys", "Ops");
+    batchMutateStat = getMetricsRegistry().newStat(BATCH_MUTATE_KEY, "", "Keys", "Ops");
+    queueTimeStat = getMetricsRegistry().newRate(TIME_IN_QUEUE_KEY) ;
+
+    thriftCallStat = getMetricsRegistry().newRate(THRIFT_CALL_KEY);
+    thriftSlowCallStat = getMetricsRegistry().newRate(SLOW_THRIFT_CALL_KEY);
+
+    callQueueLenGauge = getLongGauge(CALL_QUEUE_LEN_KEY, 0) ;
+
+  }
+
+  @Override
+  public void incTimeInQueue(long time) {
+    queueTimeStat.add(time);
+  }
+
+  @Override
+  public void setCallQueueLen(int len) {
+    callQueueLenGauge.set(len);
+  }
+
+  @Override
+  public void incNumRowKeysInBatchGet(int diff) {
+    batchGetStat.add(diff);
+  }
+
+  @Override
+  public void incNumRowKeysInBatchMutate(int diff) {
+    batchMutateStat.add(diff);
+  }
+
+  @Override
+  public void incMethodTime(String name, long time) {
+    MutableStat s = getMetricsRegistry().newRate(name);
+    s.add(time);
+  }
+
+  @Override
+  public void incCall(long time) {
+    thriftCallStat.add(time);
+  }
+
+  @Override
+  public void incSlowCall(long time) {
+    thriftSlowCallStat.add(time);
+  }
+
+}
diff --git hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java
index c55ef2d..4c63baa 100644
--- hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java
+++ hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java
@@ -465,4 +465,8 @@ public class DynamicMetricsRegistry {
 
     return (T) metric;
   }
+
+  public void clearMetrics() {
+    metricsMap.clear();
+  }
 }
diff --git hbase-hadoop2-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.rest.metrics.RESTMetricsSource hbase-hadoop2-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.rest.metrics.RESTMetricsSource
new file mode 100644
index 0000000..9e7a28d
--- /dev/null
+++ hbase-hadoop2-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.rest.metrics.RESTMetricsSource
@@ -0,0 +1 @@
+org.apache.hadoop.hbase.rest.metrics.RESTMetricsSourceImpl
\ No newline at end of file
diff --git hbase-hadoop2-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSourceFactory hbase-hadoop2-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSourceFactory
new file mode 100644
index 0000000..62d1c6a
--- /dev/null
+++ hbase-hadoop2-compat/src/main/resources/META-INF/services/org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSourceFactory
@@ -0,0 +1 @@
+org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSourceFactoryImpl
\ No newline at end of file
diff --git hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/test/MetricsAssertHelperImpl.java hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/test/MetricsAssertHelperImpl.java
new file mode 100644
index 0000000..07fb7d9
--- /dev/null
+++ hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/test/MetricsAssertHelperImpl.java
@@ -0,0 +1,233 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.test;
+
+import org.apache.hadoop.hbase.metrics.BaseMetricsSource;
+import org.apache.hadoop.hbase.metrics.BaseMetricsSourceImpl;
+import org.apache.hadoop.metrics2.AbstractMetric;
+import org.apache.hadoop.metrics2.MetricsCollector;
+import org.apache.hadoop.metrics2.MetricsInfo;
+import org.apache.hadoop.metrics2.MetricsRecordBuilder;
+import org.apache.hadoop.metrics2.MetricsTag;
+
+import java.util.HashMap;
+import java.util.Map;
+
+import static org.junit.Assert.*;
+
+/**
+ *
+ */
+public class MetricsAssertHelperImpl implements MetricsAssertHelper {
+
+  private Map<String, String> tags = new HashMap<String, String>();
+  private Map<String, Number> gauges = new HashMap<String, Number>();
+  private Map<String, Long> counters = new HashMap<String, Long>();
+
+  public class MockMetricsBuilder implements MetricsCollector {
+
+    @Override
+    public MetricsRecordBuilder addRecord(String s) {
+      return new MockRecordBuilder(this);
+    }
+
+    @Override
+    public MetricsRecordBuilder addRecord(MetricsInfo metricsInfo) {
+      return new MockRecordBuilder(this);
+    }
+  }
+
+  public class MockRecordBuilder extends MetricsRecordBuilder {
+
+    private final MetricsCollector mockMetricsBuilder;
+
+    public MockRecordBuilder(MetricsCollector mockMetricsBuilder) {
+
+      this.mockMetricsBuilder = mockMetricsBuilder;
+    }
+
+    @Override
+    public MetricsRecordBuilder tag(MetricsInfo metricsInfo, String s) {
+
+      tags.put(metricsInfo.name(), s);
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder add(MetricsTag metricsTag) {
+      tags.put(canonicalizeMetricName(metricsTag.name()), metricsTag.value());
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder add(AbstractMetric abstractMetric) {
+      gauges.put(canonicalizeMetricName(abstractMetric.name()), abstractMetric.value());
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder setContext(String s) {
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addCounter(MetricsInfo metricsInfo, int i) {
+      counters.put(canonicalizeMetricName(metricsInfo.name()), Long.valueOf(i));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addCounter(MetricsInfo metricsInfo, long l) {
+      counters.put(canonicalizeMetricName(metricsInfo.name()), Long.valueOf(l));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addGauge(MetricsInfo metricsInfo, int i) {
+      gauges.put(canonicalizeMetricName(metricsInfo.name()), Long.valueOf(i));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addGauge(MetricsInfo metricsInfo, long l) {
+      gauges.put(canonicalizeMetricName(metricsInfo.name()), Long.valueOf(l));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addGauge(MetricsInfo metricsInfo, float v) {
+      gauges.put(canonicalizeMetricName(metricsInfo.name()), Double.valueOf(v));
+      return this;
+    }
+
+    @Override
+    public MetricsRecordBuilder addGauge(MetricsInfo metricsInfo, double v) {
+      gauges.put(canonicalizeMetricName(metricsInfo.name()), Double.valueOf(v));
+      return this;
+    }
+
+    @Override
+    public MetricsCollector parent() {
+      return mockMetricsBuilder;
+    }
+  }
+
+  @Override
+  public void assertTag(String name, String expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertEquals("Tags should be equal", expected, tags.get(cName));
+  }
+
+  @Override
+  public void assertGauge(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertEquals("Metrics Should be equal", Long.valueOf(expected), gauges.get(cName));
+  }
+
+  @Override
+  public void assertGaugeGt(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(gauges.get(cName));
+    long found = gauges.get(cName).longValue();
+    assertTrue(name + " (" + found + ") should be greater than " + expected, found > expected);
+  }
+
+  @Override
+  public void assertGaugeLt(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(gauges.get(cName));
+    long found = gauges.get(cName).longValue();
+    assertTrue(name + "(" + found + ") should be less than " + expected, found < expected);
+  }
+
+  @Override
+  public void assertGauge(String name, double expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertEquals("Metrics Should be equal", Double.valueOf(expected), gauges.get(cName));
+  }
+
+  @Override
+  public void assertGaugeGt(String name, double expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(gauges.get(cName));
+    double found = gauges.get(cName).doubleValue();
+    assertTrue(name + "(" + found + ") should be greater than " + expected, found > expected);
+  }
+
+  @Override
+  public void assertGaugeLt(String name, double expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(gauges.get(cName));
+    double found = gauges.get(cName).doubleValue();
+    assertTrue(name + "(" + found + ") should be less than " + expected, found < expected);
+  }
+
+  @Override
+  public void assertCounter(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertEquals("Metrics Counters should be equal", Long.valueOf(expected), counters.get(cName));
+  }
+
+  @Override
+  public void assertCounterGt(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(counters.get(cName));
+    long found = gauges.get(cName).longValue();
+    assertTrue(name + " (" + found + ") should be greater than " + expected, found > expected);
+  }
+
+  @Override
+  public void assertCounterLt(String name, long expected, BaseMetricsSource source) {
+    getMetrics(source);
+    String cName = canonicalizeMetricName(name);
+    assertNotNull(counters.get(cName));
+    long found = gauges.get(cName).longValue();
+    assertTrue(name + "(" + found + ") should be less than " + expected, found < expected);
+  }
+
+  private void reset() {
+    tags.clear();
+    gauges.clear();
+    counters.clear();
+  }
+
+  private void getMetrics(BaseMetricsSource source) {
+    reset();
+    if (!(source instanceof BaseMetricsSourceImpl)) {
+      assertTrue(false);
+    }
+    BaseMetricsSourceImpl impl = (BaseMetricsSourceImpl) source;
+
+    impl.getMetrics(new MockMetricsBuilder(), true);
+
+  }
+
+  private String canonicalizeMetricName(String in) {
+    return in.toLowerCase().replaceAll("[^A-Za-z0-9 ]", "");
+  }
+}
diff --git hbase-hadoop2-compat/src/test/resources/META-INF/services/org.apache.hadoop.hbase.test.MetricsAssertHelper hbase-hadoop2-compat/src/test/resources/META-INF/services/org.apache.hadoop.hbase.test.MetricsAssertHelper
new file mode 100644
index 0000000..c31ec09
--- /dev/null
+++ hbase-hadoop2-compat/src/test/resources/META-INF/services/org.apache.hadoop.hbase.test.MetricsAssertHelper
@@ -0,0 +1 @@
+org.apache.hadoop.hbase.test.MetricsAssertHelperImpl
diff --git hbase-server/pom.xml hbase-server/pom.xml
index d83cb25..c30125f 100644
--- hbase-server/pom.xml
+++ hbase-server/pom.xml
@@ -268,9 +268,23 @@
     </dependency>
     <dependency>
       <groupId>org.apache.hbase</groupId>
+      <artifactId>hbase-hadoop-compat</artifactId>
+      <version>${project.version}</version>
+      <type>test-jar</type>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.apache.hbase</groupId>
       <artifactId>${compat.module}</artifactId>
       <version>${project.version}</version>
     </dependency>
+    <dependency>
+      <groupId>org.apache.hbase</groupId>
+      <artifactId>${compat.module}</artifactId>
+      <version>${project.version}</version>
+      <type>test-jar</type>
+      <scope>test</scope>
+    </dependency>
     <!-- General dependencies -->
     <dependency>
       <groupId>io.netty</groupId>
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetrics.java hbase-server/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetrics.java
index fd4ac4e..660dca8 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetrics.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTMetrics.java
@@ -21,6 +21,7 @@
 package org.apache.hadoop.hbase.rest.metrics;
 
 import org.apache.hadoop.classification.InterfaceAudience;
+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;
 import org.apache.hadoop.hbase.metrics.MetricsRate;
 
 import org.apache.hadoop.metrics.MetricsContext;
@@ -31,162 +32,65 @@ import org.apache.hadoop.metrics.jvm.JvmMetrics;
 import org.apache.hadoop.metrics.util.MetricsRegistry;
 
 @InterfaceAudience.Private
-public class RESTMetrics implements Updater {
-  private final MetricsRecord metricsRecord;
-  private final MetricsRegistry registry = new MetricsRegistry();
-  private final RESTStatistics restStatistics;
+public class RESTMetrics {
 
-  private MetricsRate requests = new MetricsRate("requests", registry);
-  private MetricsRate sucessfulGetCount =
-      new MetricsRate("sucessful.get.count", registry);
-  private MetricsRate sucessfulPutCount =
-      new MetricsRate("sucessful.put.count", registry);
-  private MetricsRate sucessfulDeleteCount =
-      new MetricsRate("sucessful.delete.count", registry);
-  
-  private MetricsRate failedGetCount =
-      new MetricsRate("failed.get.count", registry);
-  private MetricsRate failedPutCount =
-      new MetricsRate("failed.put.count", registry);
-  private MetricsRate failedDeleteCount =
-      new MetricsRate("failed.delete.count", registry);
-
-  public RESTMetrics() {
-    MetricsContext context = MetricsUtil.getContext("rest");
-    metricsRecord = MetricsUtil.createRecord(context, "rest");
-    String name = Thread.currentThread().getName();
-    metricsRecord.setTag("REST", name);
-    context.registerUpdater(this);
-    JvmMetrics.init("rest", name);
-    // expose the MBean for metrics
-    restStatistics = new RESTStatistics(registry);
-
-  }
-
-  public void shutdown() {
-    if (restStatistics != null) {
-      restStatistics.shutdown();
-    }
+  public RESTMetricsSource getSource() {
+    return source;
   }
 
-  /**
-   * Since this object is a registered updater, this method will be called
-   * periodically, e.g. every 5 seconds.
-   * @param unused 
-   */
-  public void doUpdates(MetricsContext unused) {
-    synchronized (this) {
-      requests.pushMetric(metricsRecord);
-      sucessfulGetCount.pushMetric(metricsRecord);
-      sucessfulPutCount.pushMetric(metricsRecord);
-      sucessfulDeleteCount.pushMetric(metricsRecord);
-      failedGetCount.pushMetric(metricsRecord);
-      failedPutCount.pushMetric(metricsRecord);
-      failedDeleteCount.pushMetric(metricsRecord);
-    }
-    this.metricsRecord.update();
-  }
-  
-  public void resetAllMinMax() {
-    // Nothing to do
-  }
+  private RESTMetricsSource source;
 
-  /**
-   * @return Count of requests.
-   */
-  public float getRequests() {
-    return requests.getPreviousIntervalValue();
+  public RESTMetrics() {
+     source = CompatibilitySingletonFactory.getInstance(RESTMetricsSource.class);
   }
   
   /**
    * @param inc How much to add to requests.
    */
   public void incrementRequests(final int inc) {
-    requests.inc(inc);
-  }
-  
-  /**
-   * @return Count of sucessfulGetCount.
-   */
-  public float getSucessfulGetCount() {
-    return sucessfulGetCount.getPreviousIntervalValue();
+    source.incrementRequests(inc);
   }
   
   /**
    * @param inc How much to add to sucessfulGetCount.
    */
   public void incrementSucessfulGetRequests(final int inc) {
-    sucessfulGetCount.inc(inc);
-  }
-  
-  /**
-   * @return Count of sucessfulGetCount.
-   */
-  public float getSucessfulPutCount() {
-    return sucessfulPutCount.getPreviousIntervalValue();
+    source.incrementSucessfulGetRequests(inc);
   }
   
   /**
    * @param inc How much to add to sucessfulPutCount.
    */
   public void incrementSucessfulPutRequests(final int inc) {
-    sucessfulPutCount.inc(inc);
-  }
-  
-  /**
-   * @return Count of failedPutCount.
-   */
-  public float getFailedPutCount() {
-    return failedPutCount.getPreviousIntervalValue();
+    source.incrementSucessfulPutRequests(inc);
   }
-  
+
   /**
    * @param inc How much to add to failedPutCount.
    */
   public void incrementFailedPutRequests(final int inc) {
-    failedPutCount.inc(inc);
-  }
-  
-  /**
-   * @return Count of failedGetCount.
-   */
-  public float getFailedGetCount() {
-    return failedGetCount.getPreviousIntervalValue();
+    source.incrementFailedPutRequests(inc);
   }
   
   /**
    * @param inc How much to add to failedGetCount.
    */
   public void incrementFailedGetRequests(final int inc) {
-    failedGetCount.inc(inc);
+    source.incrementFailedGetRequests(inc);
   }
-  
-  /**
-   * @return Count of sucessfulGetCount.
-   */
-  public float getSucessfulDeleteCount() {
-    return sucessfulDeleteCount.getPreviousIntervalValue();
-  }
-  
+
   /**
    * @param inc How much to add to sucessfulDeleteCount.
    */
   public void incrementSucessfulDeleteRequests(final int inc) {
-    sucessfulDeleteCount.inc(inc);
-  }
-
-  /**
-   * @return Count of failedDeleteCount.
-   */
-  public float getFailedDeleteCount() {
-    return failedDeleteCount.getPreviousIntervalValue();
+    source.incrementSucessfulDeleteRequests(inc);
   }
   
   /**
    * @param inc How much to add to failedDeleteCount.
    */
   public void incrementFailedDeleteRequests(final int inc) {
-    failedDeleteCount.inc(inc);
+    source.incrementFailedDeleteRequests(inc);
   }
   
 }
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTStatistics.java hbase-server/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTStatistics.java
deleted file mode 100644
index 03035a2..0000000
--- hbase-server/src/main/java/org/apache/hadoop/hbase/rest/metrics/RESTStatistics.java
+++ /dev/null
@@ -1,46 +0,0 @@
-/*
- * Copyright 2010 The Apache Software Foundation
- *
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.hbase.rest.metrics;
-
-import javax.management.ObjectName;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.hbase.metrics.MetricsMBeanBase;
-
-import org.apache.hadoop.metrics.util.MBeanUtil;
-import org.apache.hadoop.metrics.util.MetricsRegistry;
-
-@InterfaceAudience.Private
-public class RESTStatistics  extends MetricsMBeanBase {
-  private final ObjectName mbeanName;
-
-  public RESTStatistics(MetricsRegistry registry) {
-    super(registry, "restStatistics");
-    mbeanName = MBeanUtil.registerMBean("rest", "restStatistics", this);
-  }
-
-  public void shutdown() {
-    if (mbeanName != null) {
-      MBeanUtil.unregisterMBean(mbeanName);
-    }
-  }
-
-}
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftMetrics.java hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftMetrics.java
index 62b0f5a..1568b7e 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftMetrics.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftMetrics.java
@@ -19,128 +19,74 @@
 
 package org.apache.hadoop.hbase.thrift;
 
-import java.lang.reflect.Method;
-
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.hbase.thrift.generated.Hbase;
-import org.apache.hadoop.metrics.MetricsContext;
-import org.apache.hadoop.metrics.MetricsRecord;
-import org.apache.hadoop.metrics.MetricsUtil;
-import org.apache.hadoop.metrics.Updater;
-import org.apache.hadoop.metrics.util.MetricsBase;
-import org.apache.hadoop.metrics.util.MetricsIntValue;
-import org.apache.hadoop.metrics.util.MetricsRegistry;
-import org.apache.hadoop.metrics.util.MetricsTimeVaryingInt;
-import org.apache.hadoop.metrics.util.MetricsTimeVaryingLong;
-import org.apache.hadoop.metrics.util.MetricsTimeVaryingRate;
+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;
+import org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSource;
+import org.apache.hadoop.hbase.thrift.metrics.ThriftServerMetricsSourceFactory;
 
 /**
  * This class is for maintaining the various statistics of thrift server
  * and publishing them through the metrics interfaces.
  */
 @InterfaceAudience.Private
-public class ThriftMetrics implements Updater {
-  public final static Log LOG = LogFactory.getLog(ThriftMetrics.class);
-  public final static String CONTEXT_NAME = "thriftserver";
+public class ThriftMetrics  {
+
+
+  public enum ThriftServerType {
+    ONE,
+    TWO
+  }
+
+  public ThriftServerMetricsSource getSource() {
+    return source;
+  }
 
-  private final MetricsContext context;
-  private final MetricsRecord metricsRecord;
-  private final MetricsRegistry registry = new MetricsRegistry();
+  public void setSource(ThriftServerMetricsSource source) {
+    this.source = source;
+  }
+
+  private ThriftServerMetricsSource source;
   private final long slowResponseTime;
   public static final String SLOW_RESPONSE_NANO_SEC =
     "hbase.thrift.slow.response.nano.second";
   public static final long DEFAULT_SLOW_RESPONSE_NANO_SEC = 10 * 1000 * 1000;
 
-  private final MetricsIntValue callQueueLen =
-      new MetricsIntValue("callQueueLen", registry);
-  private final MetricsTimeVaryingRate numRowKeysInBatchGet =
-      new MetricsTimeVaryingRate("numRowKeysInBatchGet", registry);
-  private final MetricsTimeVaryingRate numRowKeysInBatchMutate =
-      new MetricsTimeVaryingRate("numRowKeysInBatchMutate", registry);
-  private final MetricsTimeVaryingRate timeInQueue =
-      new MetricsTimeVaryingRate("timeInQueue", registry);
-  private MetricsTimeVaryingRate thriftCall =
-      new MetricsTimeVaryingRate("thriftCall", registry);
-  private MetricsTimeVaryingRate slowThriftCall =
-      new MetricsTimeVaryingRate("slowThriftCall", registry);
-
-  public ThriftMetrics(int port, Configuration conf, Class<?> iface) {
-    slowResponseTime = conf.getLong(
-        SLOW_RESPONSE_NANO_SEC, DEFAULT_SLOW_RESPONSE_NANO_SEC);
-    context = MetricsUtil.getContext(CONTEXT_NAME);
-    metricsRecord = MetricsUtil.createRecord(context, CONTEXT_NAME);
 
-    metricsRecord.setTag("port", port + "");
+  public ThriftMetrics(Configuration conf, ThriftServerType t) {
+    slowResponseTime = conf.getLong( SLOW_RESPONSE_NANO_SEC, DEFAULT_SLOW_RESPONSE_NANO_SEC);
 
-    LOG.info("Initializing RPC Metrics with port=" + port);
-
-    context.registerUpdater(this);
+    if (t == ThriftServerType.ONE) {
+      source = CompatibilitySingletonFactory.getInstance(ThriftServerMetricsSourceFactory.class).createThriftOneSource();
+    } else if (t == ThriftServerType.TWO) {
+      source = CompatibilitySingletonFactory.getInstance(ThriftServerMetricsSourceFactory.class).createThriftTwoSource();
+    }
 
-    createMetricsForMethods(iface);
   }
 
   public void incTimeInQueue(long time) {
-    timeInQueue.inc(time);
+    source.incTimeInQueue(time);
   }
 
   public void setCallQueueLen(int len) {
-    callQueueLen.set(len);
+    source.setCallQueueLen(len);
   }
 
   public void incNumRowKeysInBatchGet(int diff) {
-    numRowKeysInBatchGet.inc(diff);
+    source.incNumRowKeysInBatchGet(diff);
   }
 
   public void incNumRowKeysInBatchMutate(int diff) {
-    numRowKeysInBatchMutate.inc(diff);
+    source.incNumRowKeysInBatchMutate(diff);
   }
 
   public void incMethodTime(String name, long time) {
-    MetricsTimeVaryingRate methodTimeMetric = getMethodTimeMetrics(name);
-    if (methodTimeMetric == null) {
-      LOG.warn(
-          "Got incMethodTime() request for method that doesnt exist: " + name);
-      return; // ignore methods that dont exist.
-    }
-
-    // inc method specific processTime
-    methodTimeMetric.inc(time);
-
+    source.incMethodTime(name, time);
     // inc general processTime
-    thriftCall.inc(time);
+    source.incCall(time);
     if (time > slowResponseTime) {
-      slowThriftCall.inc(time);
-    }
-  }
-
-  private void createMetricsForMethods(Class<?> iface) {
-    LOG.debug("Creating metrics for interface " + iface.toString());
-    for (Method m : iface.getDeclaredMethods()) {
-      if (getMethodTimeMetrics(m.getName()) == null)
-        LOG.debug("Creating metrics for method:" + m.getName());
-        createMethodTimeMetrics(m.getName());
+      source.incSlowCall(time);
     }
   }
 
-  private MetricsTimeVaryingRate getMethodTimeMetrics(String key) {
-    return (MetricsTimeVaryingRate) registry.get(key);
-  }
-
-  private MetricsTimeVaryingRate createMethodTimeMetrics(String key) {
-    return new MetricsTimeVaryingRate(key, this.registry);
-  }
-
-  /**
-   * Push the metrics to the monitoring subsystem on doUpdate() call.
-   */
-  public void doUpdates(final MetricsContext context) {
-    // getMetricsList() and pushMetric() are thread safe methods
-    for (MetricsBase m : registry.getMetricsList()) {
-      m.pushMetric(metricsRecord);
-    }
-    metricsRecord.update();
-  }
 }
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java
index 7760b5c..3441c14 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java
@@ -235,7 +235,7 @@ public class ThriftServerRunner implements Runnable {
   public ThriftServerRunner(Configuration conf, HBaseHandler handler) {
     this.conf = HBaseConfiguration.create(conf);
     this.listenPort = conf.getInt(PORT_CONF_KEY, DEFAULT_LISTEN_PORT);
-    this.metrics = new ThriftMetrics(listenPort, conf, Hbase.Iface.class);
+    this.metrics = new ThriftMetrics(conf, ThriftMetrics.ThriftServerType.ONE);
     handler.initMetrics(metrics);
     this.handler = HbaseHandlerMetricsProxy.newInstance(handler, metrics, conf);
   }
diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java hbase-server/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java
index d617e29..62d1908 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java
@@ -224,8 +224,7 @@ public class ThriftServer {
       boolean hsha = cmd.hasOption("hsha");
 
       Configuration conf = HBaseConfiguration.create();
-      ThriftMetrics metrics = new ThriftMetrics(
-          listenPort, conf, THBaseService.Iface.class);
+      ThriftMetrics metrics = new ThriftMetrics(conf, ThriftMetrics.ThriftServerType.TWO);
 
       // Construct correct ProtocolFactory
       TProtocolFactory protocolFactory = getTProtocolFactory(cmd.hasOption("compact"));
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/rest/TestRowResource.java hbase-server/src/test/java/org/apache/hadoop/hbase/rest/TestRowResource.java
index 1b67046..c073c7b 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/rest/TestRowResource.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/rest/TestRowResource.java
@@ -40,6 +40,7 @@ import org.apache.hadoop.hbase.rest.client.Response;
 import org.apache.hadoop.hbase.rest.model.CellModel;
 import org.apache.hadoop.hbase.rest.model.CellSetModel;
 import org.apache.hadoop.hbase.rest.model.RowModel;
+import org.apache.hadoop.hbase.test.MetricsAssertHelper;
 import org.apache.hadoop.hbase.util.Bytes;
 
 import static org.junit.Assert.*;
@@ -68,6 +69,8 @@ public class TestRowResource {
   private static final HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
   private static final HBaseRESTTestingUtility REST_TEST_UTIL = 
     new HBaseRESTTestingUtility();
+  private static final MetricsAssertHelper METRICS_ASSERT =
+      CompatibilityFactory.getInstance(MetricsAssertHelper.class);
   private static Client client;
   private static JAXBContext context;
   private static Marshaller marshaller;
@@ -527,6 +530,35 @@ public class TestRowResource {
   }
 
   @Test
+  public void testMetrics() throws IOException, JAXBException {
+    final String path = "/" + TABLE + "/" + ROW_4 + "/" + COLUMN_1;
+    Response response = client.put(path, Constants.MIMETYPE_BINARY,
+        Bytes.toBytes(VALUE_4));
+    assertEquals(response.getCode(), 200);
+    Thread.yield();
+    response = client.get(path, Constants.MIMETYPE_JSON);
+    assertEquals(response.getCode(), 200);
+    response = deleteRow(TABLE, ROW_4);
+    assertEquals(response.getCode(), 200);
+
+    METRICS_ASSERT.assertCounterGt("requests",
+                                    2l,
+                                    RESTServlet.getInstance(conf).getMetrics().getSource());
+
+    METRICS_ASSERT.assertCounterGt("successfulGet",
+                                   0l,
+                                   RESTServlet.getInstance(conf).getMetrics().getSource());
+
+    METRICS_ASSERT.assertCounterGt("successfulPut",
+                                    0l,
+                                    RESTServlet.getInstance(conf).getMetrics().getSource());
+
+    METRICS_ASSERT.assertCounterGt("successfulDelete",
+                                    0l,
+                                    RESTServlet.getInstance(conf).getMetrics().getSource());
+  }
+
+  @Test
   public void testURLEncodedKey() throws IOException, JAXBException {
     String urlKey = "http://example.com/foo";
     StringBuilder path = new StringBuilder();
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/thrift/TestCallQueue.java hbase-server/src/test/java/org/apache/hadoop/hbase/thrift/TestCallQueue.java
index 671991e..8621222 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/thrift/TestCallQueue.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/thrift/TestCallQueue.java
@@ -28,15 +28,11 @@ import java.util.concurrent.LinkedBlockingQueue;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.CompatibilitySingletonFactory;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
 import org.apache.hadoop.hbase.SmallTests;
+import org.apache.hadoop.hbase.test.MetricsAssertHelper;
 import org.apache.hadoop.hbase.thrift.CallQueue.Call;
-import org.apache.hadoop.hbase.thrift.generated.Hbase;
-import org.apache.hadoop.metrics.ContextFactory;
-import org.apache.hadoop.metrics.MetricsContext;
-import org.apache.hadoop.metrics.MetricsUtil;
-import org.apache.hadoop.metrics.spi.NoEmitMetricsContext;
-import org.apache.hadoop.metrics.spi.OutputRecord;
 import org.junit.experimental.categories.Category;
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
@@ -54,6 +50,9 @@ public class TestCallQueue {
   public static final Log LOG = LogFactory.getLog(TestCallQueue.class);
   private static final HBaseTestingUtility UTIL = new HBaseTestingUtility();
 
+  private static final MetricsAssertHelper metricsHelper =
+      CompatibilitySingletonFactory.getInstance(MetricsAssertHelper.class);
+
   private int elementsAdded;
   private int elementsRemoved;
 
@@ -74,6 +73,7 @@ public class TestCallQueue {
     this.elementsRemoved = elementsRemoved;
     LOG.debug("elementsAdded:" + elementsAdded +
               " elementsRemoved:" + elementsRemoved);
+
   }
 
   @Test(timeout=3000)
@@ -105,28 +105,16 @@ public class TestCallQueue {
   }
 
   private static ThriftMetrics createMetrics() throws Exception {
-    setupMetricsContext();
     Configuration conf = UTIL.getConfiguration();
-    return new ThriftMetrics(
-        ThriftServerRunner.DEFAULT_LISTEN_PORT, conf, Hbase.Iface.class);
+    ThriftMetrics m = new ThriftMetrics(conf, ThriftMetrics.ThriftServerType.ONE);
+    m.getSource().init();
+    return m;
   }
 
-  private static void setupMetricsContext() throws Exception {
-    ContextFactory factory = ContextFactory.getFactory();
-    factory.setAttribute(ThriftMetrics.CONTEXT_NAME + ".class",
-        NoEmitMetricsContext.class.getName());
-    MetricsUtil.getContext(ThriftMetrics.CONTEXT_NAME)
-               .createRecord(ThriftMetrics.CONTEXT_NAME).remove();
-  }
 
   private static void verifyMetrics(ThriftMetrics metrics, String name, int expectValue)
       throws Exception { 
-    MetricsContext context = MetricsUtil.getContext( 
-        ThriftMetrics.CONTEXT_NAME); 
-    metrics.doUpdates(context); 
-    OutputRecord record = context.getAllRecords().get( 
-        ThriftMetrics.CONTEXT_NAME).iterator().next(); 
-    assertEquals(expectValue, record.getMetric(name).intValue()); 
+      metricsHelper.assertCounter(name, expectValue, metrics.getSource());
   }
 
   private static Runnable createDummyRunnable() {
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/thrift/TestThriftServer.java hbase-server/src/test/java/org/apache/hadoop/hbase/thrift/TestThriftServer.java
index 85f22d4..1159409 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/thrift/TestThriftServer.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/thrift/TestThriftServer.java
@@ -32,11 +32,13 @@ import java.util.Map;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.CompatibilityFactory;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.MediumTests;
 import org.apache.hadoop.hbase.filter.ParseFilter;
+import org.apache.hadoop.hbase.test.MetricsAssertHelper;
 import org.apache.hadoop.hbase.thrift.ThriftServerRunner.HBaseHandler;
 import org.apache.hadoop.hbase.thrift.generated.BatchMutation;
 import org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor;
@@ -67,6 +69,8 @@ import org.junit.experimental.categories.Category;
 public class TestThriftServer {
   private static final HBaseTestingUtility UTIL = new HBaseTestingUtility();
   private static final Log LOG = LogFactory.getLog(TestThriftServer.class);
+  private static final MetricsAssertHelper metricsHelper = CompatibilityFactory
+      .getInstance(MetricsAssertHelper.class);
   protected static final int MAXVERSIONS = 3;
 
   private static ByteBuffer asByteBuffer(String i) {
@@ -165,14 +169,14 @@ public class TestThriftServer {
     Hbase.Iface handler = getHandlerForMetricsTest(metrics, conf);
     createTestTables(handler);
     dropTestTables(handler);
-    verifyMetrics(metrics, "createTable_num_ops", 2);
-    verifyMetrics(metrics, "deleteTable_num_ops", 2);
-    verifyMetrics(metrics, "disableTable_num_ops", 2);
+    metricsHelper.assertCounter("createTable_num_ops", 2, metrics.getSource());
+    metricsHelper.assertCounter("deleteTable_num_ops", 2, metrics.getSource());
+    metricsHelper.assertCounter("disableTable_num_ops", 2, metrics.getSource());
     handler.getTableNames(); // This will have an artificial delay.
 
-    // 3 to 6 seconds (to account for potential slowness), measured in nanoseconds.
-    verifyMetricRange(metrics, "getTableNames_avg_time", 3L * 1000 * 1000 * 1000,
-        6L * 1000 * 1000 * 1000);
+    // 3 to 6 seconds (to account for potential slowness), measured in nanoseconds
+   metricsHelper.assertGaugeGt("getTableNames_avg_time", 3L * 1000 * 1000 * 1000, metrics.getSource());
+   metricsHelper.assertGaugeLt("getTableNames_avg_time",6L * 1000 * 1000 * 1000, metrics.getSource());
   }
 
   private static Hbase.Iface getHandlerForMetricsTest(ThriftMetrics metrics, Configuration conf)
@@ -182,17 +186,9 @@ public class TestThriftServer {
   }
 
   private static ThriftMetrics getMetrics(Configuration conf) throws Exception {
-    setupMetricsContext();
-    return new ThriftMetrics(ThriftServerRunner.DEFAULT_LISTEN_PORT, conf, Hbase.Iface.class);
+    return new ThriftMetrics( conf, ThriftMetrics.ThriftServerType.ONE);
   }
 
-  private static void setupMetricsContext() throws IOException {
-    ContextFactory factory = ContextFactory.getFactory();
-    factory.setAttribute(ThriftMetrics.CONTEXT_NAME + ".class",
-        NoEmitMetricsContext.class.getName());
-    MetricsUtil.getContext(ThriftMetrics.CONTEXT_NAME)
-               .createRecord(ThriftMetrics.CONTEXT_NAME).remove();
-  }
 
   public static void createTestTables(Hbase.Iface handler) throws Exception {
     // Create/enable/disable/delete tables, ensure methods act correctly
@@ -225,31 +221,6 @@ public class TestThriftServer {
     assertEquals(handler.getTableNames().size(), 0);
   }
 
-  private static void verifyMetrics(ThriftMetrics metrics, String name, long expectValue)
-      throws Exception {
-    long metricVal = getMetricValue(metrics, name);
-    assertEquals(expectValue, metricVal);
-  }
-
-  private static void verifyMetricRange(ThriftMetrics metrics, String name,
-      long minValue, long maxValue)
-      throws Exception {
-    long metricVal = getMetricValue(metrics, name);
-    if (metricVal < minValue || metricVal > maxValue) {
-      throw new AssertionError("Value of metric " + name + " is outside of the expected " +
-          "range [" +  minValue + ", " + maxValue + "]: " + metricVal);
-    }
-  }
-
-  private static long getMetricValue(ThriftMetrics metrics, String name) {
-    MetricsContext context = MetricsUtil.getContext(
-        ThriftMetrics.CONTEXT_NAME);
-    metrics.doUpdates(context);
-    OutputRecord record = context.getAllRecords().get(
-        ThriftMetrics.CONTEXT_NAME).iterator().next();
-    return record.getMetric(name).longValue();
-  }
-
   public void doTestIncrements() throws Exception {
     ThriftServerRunner.HBaseHandler handler =
         new ThriftServerRunner.HBaseHandler(UTIL.getConfiguration());
diff --git hbase-server/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandler.java hbase-server/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandler.java
index b848ac7..3d4f976 100644
--- hbase-server/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandler.java
+++ hbase-server/src/test/java/org/apache/hadoop/hbase/thrift2/TestThriftHBaseServiceHandler.java
@@ -19,28 +19,16 @@
  */
 package org.apache.hadoop.hbase.thrift2;
 
-import static org.junit.Assert.assertArrayEquals;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNull;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
-
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.List;
-
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.CompatibilityFactory;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
 import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.MediumTests;
 import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.test.MetricsAssertHelper;
 import org.apache.hadoop.hbase.thrift.ThriftMetrics;
 import org.apache.hadoop.hbase.thrift2.generated.TColumn;
 import org.apache.hadoop.hbase.thrift2.generated.TColumnIncrement;
@@ -56,11 +44,6 @@ import org.apache.hadoop.hbase.thrift2.generated.TPut;
 import org.apache.hadoop.hbase.thrift2.generated.TResult;
 import org.apache.hadoop.hbase.thrift2.generated.TScan;
 import org.apache.hadoop.hbase.util.Bytes;
-import org.apache.hadoop.metrics.ContextFactory;
-import org.apache.hadoop.metrics.MetricsContext;
-import org.apache.hadoop.metrics.MetricsUtil;
-import org.apache.hadoop.metrics.spi.NoEmitMetricsContext;
-import org.apache.hadoop.metrics.spi.OutputRecord;
 import org.apache.thrift.TException;
 import org.junit.AfterClass;
 import org.junit.Before;
@@ -68,6 +51,14 @@ import org.junit.BeforeClass;
 import org.junit.Test;
 import org.junit.experimental.categories.Category;
 
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.List;
+
+import static org.junit.Assert.*;
+
 /**
  * Unit testing for ThriftServer.HBaseHandler, a part of the org.apache.hadoop.hbase.thrift2 package.
  */
@@ -91,6 +82,11 @@ public class TestThriftHBaseServiceHandler {
           .setMaxVersions(2)
   };
 
+
+  private static final MetricsAssertHelper metricsHelper =
+      CompatibilityFactory.getInstance(MetricsAssertHelper.class);
+
+
   public void assertTColumnValuesEqual(List<TColumnValue> columnValuesA, List<TColumnValue> columnValuesB) {
     assertEquals(columnValuesA.size(), columnValuesB.size());
     Comparator<TColumnValue> comparator = new Comparator<TColumnValue>() {
@@ -558,50 +554,14 @@ public class TestThriftHBaseServiceHandler {
     handler.put(table, put);
 
     assertTrue(handler.exists(table, get));
-    logMetrics(metrics);
-    verifyMetrics(metrics, "put_num_ops", 1);
-    verifyMetrics(metrics, "exists_num_ops", 2);
-  }
- 
-  private static ThriftMetrics getMetrics(Configuration conf) throws Exception {
-    setupMetricsContext();
-    return new ThriftMetrics(Integer.parseInt(ThriftServer.DEFAULT_LISTEN_PORT),
-        conf, THBaseService.Iface.class);
-  }
- 
-  private static void setupMetricsContext() throws IOException {
-    ContextFactory factory = ContextFactory.getFactory();
-    factory.setAttribute(ThriftMetrics.CONTEXT_NAME + ".class",
-        NoEmitMetricsContext.class.getName());
-    MetricsUtil.getContext(ThriftMetrics.CONTEXT_NAME)
-               .createRecord(ThriftMetrics.CONTEXT_NAME).remove();
-  }
- 
-  private static void logMetrics(ThriftMetrics metrics) throws Exception {
-    if (LOG.isDebugEnabled()) {
-      return;
-    }
-    MetricsContext context = MetricsUtil.getContext( 
-        ThriftMetrics.CONTEXT_NAME); 
-    metrics.doUpdates(context); 
-    for (String key : context.getAllRecords().keySet()) {
-      for (OutputRecord record : context.getAllRecords().get(key)) {
-        for (String name : record.getMetricNames()) {
-          LOG.debug("metrics:" + name + " value:" +
-              record.getMetric(name).intValue());
-        }
-      }
-    }
+    metricsHelper.assertCounter("put_num_ops", 1, metrics.getSource());
+    metricsHelper.assertCounter( "exists_num_ops", 2, metrics.getSource());
   }
 
-  private static void verifyMetrics(ThriftMetrics metrics, String name, int expectValue)
-      throws Exception { 
-    MetricsContext context = MetricsUtil.getContext( 
-        ThriftMetrics.CONTEXT_NAME); 
-    metrics.doUpdates(context); 
-    OutputRecord record = context.getAllRecords().get( 
-        ThriftMetrics.CONTEXT_NAME).iterator().next(); 
-    assertEquals(expectValue, record.getMetric(name).intValue()); 
+  private static ThriftMetrics getMetrics(Configuration conf) throws Exception {
+    ThriftMetrics m = new ThriftMetrics(conf, ThriftMetrics.ThriftServerType.TWO);
+    m.getSource().init(); //Clear all the metrics
+    return m;
   }
 
   @org.junit.Rule
diff --git src/docbkx/developer.xml src/docbkx/developer.xml
index 355c90d..6d923e7 100644
--- src/docbkx/developer.xml
+++ src/docbkx/developer.xml
@@ -128,13 +128,13 @@ Access restriction: The method getLong(Object, long) from the type Unsafe is not
        <title>Building HBase</title>
       <section xml:id="build.basic">
        <title>Basic Compile</title>
-       <para>Thanks to maven, building HBase is easy. You can read about the various maven commands in <xref linkend="maven.build.commands"/>, but the simplest command to compile HBase from its java source code is:
+       <para>Thanks to maven, building HBase is pretty easy. You can read about the various maven commands in <xref linkend="maven.build.commands"/>, but the simplest command to compile HBase from its java source code is:
        <programlisting>
-mvn compile
+mvn package -DskipTests
        </programlisting>
        Or, to clean up before compiling:
        <programlisting>
-mvn clean compile
+mvn clean package -DskipTests
        </programlisting>
        With Eclipse set up as explained above in <xref linkend="eclipse"/>, you can also simply use the build command in Eclipse. To create the full installable HBase package takes a little bit more work, so read on. 
        </para>
